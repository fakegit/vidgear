{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 \u2009 VidGear is a High-Performance Framework that provides an one-stop Video-Processing solution for building real-time media applications in python VidGear provides an easy-to-use, highly extensible, Multi-Threaded + Asyncio wrapper around many state-of-the-art specialized libraries like OpenCV , FFmpeg , ZeroMQ , picamera , starlette , pafy and python-mss at its backend, and enable us to flexibly exploit their internal parameters and methods, while silently delivering robust error-handling and unparalleled real-time performance. VidGear primarily focuses on simplicity, and thereby lets programmers and software developers to easily integrate and perform Complex Video Processing Tasks in just few lines of python code. \u2009 Getting Started \u00b6 If this is your first time using VidGear, head straight to the Installation \u27b6 to install VidGear. Once you have VidGear installed, checkout its well-documented Gears \u27b6 Also, if you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 Or, if you're just getting started with OpenCV with Python, then see here \u27b6 \u2009 Gears \u00b6 VidGear is built on multiple Gears \u27b6 (APIs), which are exclusively designed to handle/control different device-specific video streams, network streams, and powerful media encoders. These Gears can be classified as follows: VideoCapture Gears CamGear : Multi-threaded API targeting various IP-USB-Cameras/Network-Streams/YouTube-Video-URLs. PiGear : Multi-threaded API targeting various Raspberry Pi Camera Modules. ScreenGear : Multi-threaded ultra-fast Screencasting. VideoGear : Common API with internal Video Stabilizer \u27b6 wrapper. VideoWriter Gears WriteGear : Handles Flexible Lossless Video Encoding and Compression. Streaming Gears StreamGear : Handles Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. Network Gears NetGear : Handles high-performance video-frames & data transfer between interconnecting systems over the network. Asynchronous I/O Network Gears: WebGear : ASGI Video Server that can send live video-frames to any web browser on the network. NetGear_Async : Immensely Memory-efficient Asyncio video-frames network messaging framework. \u2009 Contributions \u00b6 Contributions are welcome, and greatly appreciated! Please see our Contribution Guidelines \u27b6 for more details. \u2009 Community Channel \u00b6 If you've come up with some new idea, or looking for the fastest way troubleshoot your problems, then join our Gitter community channel \u27b6 \u2009 Become a Stargazer \u00b6 You can be a Stargazer by starring us on Github, it helps us a lot and you're making it easier for others to find & trust this library. Thanks! \u2009 Support Us \u00b6 VidGear is free, but rely on your support Sending a donation using link below is extremely helpful in keeping VidGear development alive: kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); \u2009 Citation \u00b6 Here is a Bibtex entry you can use to cite this project in a publication: @misc { vidgear , author = {Abhishek Thakur} , title = {vidgear} , howpublished = {\\url{https://github.com/abhiTronix/vidgear}} , year = {2019-2020} }","title":"Overview"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#getting-started","text":"If this is your first time using VidGear, head straight to the Installation \u27b6 to install VidGear. Once you have VidGear installed, checkout its well-documented Gears \u27b6 Also, if you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 Or, if you're just getting started with OpenCV with Python, then see here \u27b6","title":"Getting Started"},{"location":"#gears","text":"VidGear is built on multiple Gears \u27b6 (APIs), which are exclusively designed to handle/control different device-specific video streams, network streams, and powerful media encoders. These Gears can be classified as follows: VideoCapture Gears CamGear : Multi-threaded API targeting various IP-USB-Cameras/Network-Streams/YouTube-Video-URLs. PiGear : Multi-threaded API targeting various Raspberry Pi Camera Modules. ScreenGear : Multi-threaded ultra-fast Screencasting. VideoGear : Common API with internal Video Stabilizer \u27b6 wrapper. VideoWriter Gears WriteGear : Handles Flexible Lossless Video Encoding and Compression. Streaming Gears StreamGear : Handles Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. Network Gears NetGear : Handles high-performance video-frames & data transfer between interconnecting systems over the network. Asynchronous I/O Network Gears: WebGear : ASGI Video Server that can send live video-frames to any web browser on the network. NetGear_Async : Immensely Memory-efficient Asyncio video-frames network messaging framework.","title":"Gears"},{"location":"#contributions","text":"Contributions are welcome, and greatly appreciated! Please see our Contribution Guidelines \u27b6 for more details.","title":"Contributions"},{"location":"#community-channel","text":"If you've come up with some new idea, or looking for the fastest way troubleshoot your problems, then join our Gitter community channel \u27b6","title":"Community Channel"},{"location":"#become-a-stargazer","text":"You can be a Stargazer by starring us on Github, it helps us a lot and you're making it easier for others to find & trust this library. Thanks!","title":"Become a Stargazer"},{"location":"#support-us","text":"VidGear is free, but rely on your support Sending a donation using link below is extremely helpful in keeping VidGear development alive: kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw();","title":"Support Us"},{"location":"#citation","text":"Here is a Bibtex entry you can use to cite this project in a publication: @misc { vidgear , author = {Abhishek Thakur} , title = {vidgear} , howpublished = {\\url{https://github.com/abhiTronix/vidgear}} , year = {2019-2020} }","title":"Citation"},{"location":"changelog/","text":"Release Notes \u00b6 v0.1.9 (2020-08-31) \u00b6 New Features \u00b6 StreamGear API: New API that automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. Implemented multi-platform , standalone, highly extensible and flexible wrapper around FFmpeg for generating chunked-encoded media segments of the media, and easily accessing almost all of its parameters. API automatically transcodes videos/audio files & real-time frames into a sequence of multiple smaller chunks/segments and also creates a Manifest file. Added initial support for MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) . Constructed default behavior in StreamGear, for auto-creating a Primary Stream of same resolution and framerate as source. Added TQDM progress bar in non-debugged output for visual representation of internal processes. Implemented several internal methods for preprocessing FFmpeg and internal parameters for producing streams. Several standalone internal checks to ensure robust performance. New terminate() function to terminate StremGear Safely. New StreamGear Dual Modes of Operation: Implemented Single-Source and Real-time Frames like independent Transcoding Modes. Linked -video_source attribute for activating these modes Single-Source Mode , transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller segments for streaming Real-time Frames Mode , directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller segments for streaming Added separate functions, stream() for Real-time Frame Mode and transcode_source() for Single-Source Mode for easy transcoding. Included auto-colorspace detection and RGB Mode like features (extracted from WriteGear) , into StreamGear. New StreamGear Parameters: Developed several new parameters such as: output : handles assets directory formats : handles adaptive HTTP streaming format. custom_ffmpeg : handles custom FFmpeg location. stream_params : handles internal and FFmpeg parameter seamlessly. logging : turns logging on or off. New stream_params parameter allows us to exploit almost all FFmpeg parameters and flexibly change its internal settings, and seamlessly generating high-quality streams with its attributes: -streams (list of dictionaries) for building additional streams with -resolution , -video_bitrate & -framerate like sub-attributes. -audio for specifying external audio. -video_source for specifying Single-Source Mode source. -input_framerate for handling input framerate in Real-time Frames Mode. -bpp attribute for handling bits-per-pixels used to auto-calculate video-bitrate. -gop to manually specify GOP length. -ffmpeg_download_path to handle custom FFmpeg download path on windows. -clear_prev_assets to remove any previous copies of SteamGear Assets. New StreamGear docs, MPEG-DASH demo, and recommended DASH players list: Added new StreamGear docs, usage examples, parameters, references, new FAQs. Added Several StreamGear usage examples w.r.t Mode of Operation. Implemented Clappr based on Shaka-Player , as Demo Player. Added Adaptive-dimensional behavior for Demo-player, purely in css. Hosted StreamGear generated DASH chunks on GitHub and served with raw.githack.com . Introduced variable quality level-selector plugin for Clapper Player. Provide various required javascripts and implemented additional functionality for player in extra.js . Recommended tested Online, Command-line and GUI Adaptive Stream players. Implemented separate FFmpeg installation doc for StreamGear API. Reduced rebufferingGoal for faster response. New StreamGear CI tests: Added IO and API initialization CI tests for its Modes. Added various mode Streaming check CI tests. NetGear_Async API: Added new send_terminate_signal internal method. Added WindowsSelectorEventLoopPolicy() for windows 3.8+ envs. Moved Client auto-termination to separate method. Implemented graceful termination with signal API on UNIX machines. Added new timeout attribute for controlling Timeout in Connections. Added missing termination optimizer ( linger=0 ) flag. Several ZMQ Optimizer Flags added to boost performance. WriteGear API: Added support for adding duplicate FFmpeg parameters to output_params : Added new -clones attribute in output_params parameter for handing this behavior.. Support to pass FFmpeg parameters as list, while maintaining the exact order it was specified. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Added new CI tests debugging this behavior. Updated docs accordingly. Added support for Networks URLs in Compression Mode: output_filename parameter supports Networks URLs in compression modes only Added automated handling of non path/file Networks URLs as input. Implemented new is_valid_url helper method to easily validate assigned URLs value. Validates whether the given URL value has scheme/protocol supported by assigned/installed ffmpeg or not. WriteGear will throw ValueError if -output_filename is not supported. Added related CI tests and docs. Added disable_force_termination attribute in WriteGear to disable force-termination. NetGear API: Added option to completely disable Native Frame-Compression: Checks if any Incorrect/Invalid value is assigned on compression_format attribute. Completely disables Native Frame-Compression. Updated docs accordingly. CamGear API: Added new and robust regex for identifying YouTube URLs. Moved youtube_url_validator to Helper. New helper.py methods: Added validate_video function to validate video_source. Added extract_time Extract time from give string value. Added get_video_bitrate to caliculate video birate from resolution, framerate, bits-per-pixels values. Added delete_safe to safely delete files of given extension. Added validate_audio to validate audio source. Added new Helper CI tests. Added new check_valid_mpd function to test MPD files validity. Added mpegdash library to CI requirements. Deployed New Docs Upgrades: Added new assets like images, gifs, custom scripts, javascripts fonts etc. for achieving better visual graphics in docs. Added clappr.min.js , dash-shaka-playback.js , clappr-level-selector.min.js third-party javascripts locally. Extended Overview docs Hyperlinks to include all major sub-pages (such as Usage Examples, Reference, FAQs etc.) . Replaced GIF with interactive MPEG-DASH Video Example in Stabilizer Docs. Added new pymdownx.keys to replace [Ctrl+C]/[\u2318+C] formats. Added new custom.css stylescripts variables for fluid animations in docs. Overridden announce bar and added donation button. Lossless WEBP compressed all PNG assets for faster loading. Enabled lazy-loading for GIFS and Images for performance. Reimplemented Admonitions contexts and added new ones. Added StreamGear and its different modes Docs Assets. Added patch for images & unicodes for PiP flavored markdown in setup.py . Added Request Info and Welcome GitHub Apps to automate PR and issue workflow Added new config.yml for customizations. Added various suitable configurations. Added new -clones attribute to handle FFmpeg parameter clones in StreamGear and WriteGear API. Added new Video-only and Audio-Only sources in bash script. Added new paths in bash script for storing StreamGear & WriteGear assets temporarily. Updates/Improvements \u00b6 Added patch for NotImplementedError in NetGear_Async API on Windows 3.8+ envs. Check for valid output file extension according to format selected in StreamGear. Completed migration to travis.com . Created new temp_write temp directory for WriteGear Assets in bash script. Deleted old Redundant assets and added new ones. Employed isort library to sort and group imports in Vidgear APIs. Enabled exception for list, tuple, int, float in WriteGear API's output_params dict. Enabled missing support for frame-compression in its primary Receive Mode. Enforced pixel formats for streams. Improved check for valid system path detection in WriteGear API. Overrided pytest-asyncio fixture in NetGear_Async API. Quoted Gear Headline for understanding each gear easily. Re-Positioned Gear's banner images in overview for better readability. Reduced redundant try-except blocks in NetGear Async. Reformatted and Simplified Docs context. Reimplemented return_testvideo_path CI function with variable streams. Reimplemented skip_loop in NetGear_Async to fix asyncio.CancelledError . Reimplemented buggy audio handler in StreamGear. Reimplemented images with <figure> and <figurecaption> like tags. Removed Python < 3.8 condition from all CI tests. Removed or Grouped redundant code for increasing codecov. Removed redundant code and simplified algorithmic complexities in Gears. Replaced ;nbsp with ;thinsp and ;emsp . Replaced IOError with more reliable RuntimeError in StreamGear Pipelines. Replaced del with pop in dicts. Replaced all Netgear CI tests with more reliable try-except-final blocks. Replaced simple lists with pymdownx.tasklist . Replaced subprocess call() with run() for better error handling in execute_ffmpeg_cmd function. Resized over-sized docs images. Simplified delete_safe Helper function. Simplified default audio-bitrate logic in StreamGear Updated CI tests and cleared redundant code from NetGear_Async API. Updated CI with new tests and Bumped Codecov. Updated Issue and PR templates. Updated Licenses for new files and shrink images dimensions. Updated Missing Helpful tips and increased logging. Updated PR guidelines for more clarity. Updated WebGear examples addresses from 0.0.0.0 to localhost . Updated WriteGear and StreamGear CI tests for not supporting temp directory. Updated README.md and changelog.md with new changes. Updated check_output and added force_retrieve_stderr support to **kwargs to extract stderr output even on FFmpeg error. Updated dicts2args to support internal repeated coreX FFmpeg parameters for StreamGear. Updated mkdocs.yml , changelog.md and README.md with latest changes. Updated validate_audio Helper function will now retrieve audio-bitrate for validation. Updated buggy mpegdash dependency with custom dev fork for Windows machines. Updated core parameters for audio handling. Updated logging for debugging selected eventloops in NetGear_Async API. Updated termination linger to zero at Server's end. Breaking Updates/Changes \u00b6 Changed Webgear API default address to localhost for cross-compatibility between different platforms. In Netgear_Async API, source value can now be NoneType for a custom frame-generator at Server-end only. Temp_(such as /tmp in linux)_ is now not a valid directory for WriteGear & StreamGear API outputs. Moved vidgear docs assets (i.e images, gifs, javascripts and stylescripts) to override directory. Bug-fixes \u00b6 Added workaround for system path not handle correctly. Fixed Bug: URL Audio format not being handled properly. Fixed Critical Bug in NetGear_Async throwing ValueError with None-type Source. Fixed Critical StreamGear Bug: FFmpeg pipeline terminating prematurely in Single-Source Mode. Fixed Critical external audio handler bug: moved audio-input to input_parameters. Fixed Frozen-threads bug in CI tests. Fixed Mkdocs only accepting Relative paths. Fixed OSError in WriteGear's compression mode. Fixed StreamGear CI bugs for Windows and CI envs. Fixed Typos and Indentation bugs in NetGear API. Fixed ZMQ throwing error on termination if all max-tries exhausted. Fixed NameError bug in NetGear API. Fixed NameError bugs in StreamGear CI. Fixed NameError in CI functions and tests. Fixed TimeoutError bug in NetGear_Async CI tests. Fixed get_valid_ffmpeg_path throwing TypeError with non-string values. Fixed broken links in docs. Fixed critical duplicate logging bug. Fixed default gop value not handle correctly. Fixed handling of incorrect paths detection. Fixed incorrect definitions in NetGear_Async. Fixed left-over attribute bug in WriteGear. Fixed logic and indentation bugs in CI tests. Fixed logic for handling output parameters in WriteGear API. Fixed missing definitions and logic bug in StreamGear. Fixed missing import and incorrect CI definitions. Fixed missing source dimensions from extract_resolutions output in StreamGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed round off error in FPS. Fixed several CI bugs and updated extract_resolutions method. Fixed several bugs from CI Bidirectional Mode tests. Fixed several typos in docs usage examples. Fixed various AttributeError with wrong attribute names and definition in CI Helper functions. Fixed wrong and missing definitions in docs. Fixed wrong logic for extracting OpenCV frames. Fixed wrong type bug in StreamGear API. Fixed wrong type error bug in WriteGear API. Fixed wrong variable assignments bug in WriteGear API. Fixes to CLI tests and missing docs imports. Many minor typos and wrong definitions. Pull Requests \u00b6 PR #129 PR #130 PR #155 v0.1.8 (2020-06-12) \u00b6 New Features \u00b6 Multiple Clients support in NetGear API: Implemented support for handling any number of Clients simultaneously with a single Server in this mode. Added new multiclient_mode attribute for enabling this mode easily. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Implemented ability to receive data from all Client(s) along with frames with zmq.REQ/zmq.REP pattern only. Updated related CI tests Support for robust Lazy Pirate pattern(auto-reconnection) in NetGear API for both server and client ends: Implemented a algorithm where NetGear rather than doing a blocking receive, will now: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Implemented its default support for REQ/REP and PAIR messaging patterns internally. Added new max_retries and request_timeout (in seconds) for handling polling. Added DONTWAIT flag for interruption-free data receiving. Both Server and Client can now reconnect even after a premature termination. Performance Updates for NetGear API: Added default Frame Compression support for Bidirectional frame transmission in Bidirectional mode. Added support for Reducer() function in Helper.py to aid reducing frame-size on-the-go for more performance. Added small delay in recv() function at client's end to reduce system load. Reworked and Optimized NetGear termination, and also removed/changed redundant definitions and flags. Docs Migration to Mkdocs: Implemented a beautiful, static documentation site based on MkDocs which will then be hosted on GitHub Pages. Crafted base mkdocs with third-party elegant & simplistic mkdocs-material theme. Implemented new mkdocs.yml for Mkdocs with relevant data. Added new docs folder to handle markdown pages and its assets. Added new Markdown pages( .md ) to docs folder, which are carefully crafted documents - based on previous Wiki's docs, and some completely new additions. Added navigation under tabs for easily accessing each document. New Assets: Added new assets like gifs, images, custom scripts, favicons, site.webmanifest etc. for bringing standard and quality to docs visual design. Designed brand new logo and banner for VidGear Documents. Deployed all assets under separate Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License . Added Required Plugins and Extensions: Added support for all pymarkdown-extensions . Added support for some important admonition , attr_list , codehilite , def_list , footnotes , meta , and toc like Mkdocs extensions. Enabled search , minify and git-revision-date-localized plugins support. Added various VidGear's social links to yaml. Added support for en (English) language. Auto-Build API Reference with mkdocstrings: Added support for mkdocstrings plugin for auto-building each VidGear's API references. Added python handler for parsing python source-code to mkdocstrings . Auto-Deploy Docs with Github Actions: Implemented Automated Docs Deployment on gh-pages through GitHub Actions workflow. Added new workflow yaml with minimal configuration for automated docs deployment. Added all required python dependencies and environment for this workflow. Added master branch on Ubuntu machine to build matrix. Updates/Improvements \u00b6 Added in-built support for bidirectional frames( NDarray ) transfer in Bidirectional mode. Added support for User-Defined compression params in Bidirectional frames transfer. Added workaround for address already in use bug at client's end. Unified Bidirectional and Multi-Clients mode for client's return data transmission. Replaced ValueError with more suitable RuntimeError . Updated logging for better readability. Added CI test for Multi-Clients mode. Reformatted and grouped imports in VidGear. Added Reducer Helper function CI test. Added Reliability tests for both Server and Client end. Disabled reliable reconnection for Multi-Clients mode. Replaced os.devnull with suprocess's inbuilt function. Updated README.md, Issue and PR templates with new information and updates. Moved changelog.md to /docs and updated contribution guidelines. Improved source-code docs for compatibility with mkdocstrings . Added additional dependency mkdocs-exclude , for excluding files from Mkdocs builds. Updated license and compressed images/diagrams. Added new CI tests and Bumped Codecov. Changed YouTube video URL for CI tests to Creative Commons(CC) video. Removed redundant code. Breaking Updates/Changes \u00b6 VidGear Docs moved to GitHub Pages, Now Available at https://abhitronix.github.io/vidgear . Removed filter attribute from options parameter in NetGear API. Removed force_terminate parameter support from NetGear API. Disabled additional data of datatype numpy.ndarray for Server end in Bidirectional Mode. Bug-fixes \u00b6 Fixed 'NoneType' object is not subscriptable bug. Fixed bugs related to delayed termination in NetGear API. Reduced default request_timeout value to 4 and also lowered cut-off limit for the same. Removed redundant ZMQ context termination and similar variables. Added missing VidGear installation in workflow. Excluded conflicting assets README.md from Mkdocs builds. Fixed pattern value check bypassed if wrong value is assigned. Fixed incorrect handling of additional data transferred in synchronous mode at both Server and Client end. Replaced Netgear CI test with more reliable try-except-final blocks. Updated termination linger to zero at Server's end. Fixed NameError bug in NetGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed ZMQ throwing error on termination if all max-tries exhausted. Enabled missing support for frame compression in its primary receive mode. Fixed several bugs from CI Bidirectional Mode tests. Removed or Grouped redundant code for increasing codecov. Fixed Mkdocs only accepting Relative paths. Fixed broken links in docs. Fixed round off error in FPS. Many small typos and bugs fixes. Pull Requests \u00b6 PR #129 PR #130 v0.1.7 (2020-04-29) \u00b6 New Features \u00b6 WebGear API: Added a robust Live Video Server API that can transfer live video frames to any web browser on the network in real-time. Implemented a flexible asyncio wrapper around starlette ASGI Application Server. Added seamless access to various starlette's Response classes, Routing tables, Static Files, Template engine(with Jinja2), etc. Added a special internal access to VideoGear API and all its parameters. Implemented a new Auto-Generation Work-flow to generate/download & thereby validate WebGear API data files from its GitHub server automatically. Added on-the-go dictionary parameter in WebGear to tweak performance, Route Tables and other internal properties easily. Added new simple & elegant default Bootstrap Cover Template for WebGear Server. Added __main__.py to directly run WebGear Server through the terminal. Added new gif and related docs for WebGear API. Added and Updated various CI tests for this API. NetGear_Async API: Designed NetGear_Async asynchronous network API built upon ZeroMQ's asyncio API. Implemented support for state-of-the-art asyncio event loop uvloop at its backend. Achieved Unmatchable high-speed and lag-free video streaming over the network with minimal resource constraint. Added exclusive internal wrapper around VideoGear API for this API. Implemented complete server-client handling and options to use variable protocols/patterns for this API. Implemented support for all four ZeroMQ messaging patterns: i.e zmq.PAIR , zmq.REQ/zmq.REP , zmq.PUB/zmq.SUB , and zmq.PUSH/zmq.PULL . Implemented initial support for tcp and ipc protocols. Added new Coverage CI tests for NetGear_Async Network Gear. Added new Benchmark tests for benchmarking NetGear_Async against NetGear. Asynchronous Enhancements: Added asyncio package to for handling asynchronous APIs. Moved WebGear API(webgear.py) to asyncio and created separate asyncio helper.py for it. Various Performance tweaks for Asyncio APIs with concurrency within a single thread. Moved __main__.py to asyncio for easier access to WebGear API through the terminal. Updated setup.py with new dependencies and separated asyncio dependencies. General Enhancements: Added new highly-precise Threaded FPS class for accurate benchmarking with time.perf_counter python module. Added a new Gitter community channel. Added a new Reducer function to reduce the frame size on-the-go. Add Flake8 tests to Travis CI to find undefined names. (PR by @cclauss ) Added a new unified logging handler helper function for vidgear. Updates/Improvements \u00b6 Re-implemented and simplified logic for NetGear Async server-end. Added new dependencies for upcoming asyncio updates to setup.py . Added retry function and replaced wget with curl for Linux test envs. Bumped OpenCV to latest 4.2.0-dev for Linux test envs. Updated YAML files to reflect new changes to different CI envs. Separated each API logger with a common helper method to avoid multiple copies. Limited Importing OpenCV API version check's scope to helper.py only. Implemented case for incorrect color_space value in ScreenGear API. Removed old conflicting logging formatter with a common method and expanded logging. Improved and added shutdown function for safely stopping frame producer threads in WebGear API. Re-implemented and simplified all CI tests with maximum code-coverage in mind. Replaced old mkdir function with new mkdir_safe helper function for creating directories safely. Updated ReadMe.md with updated diagrams, gifs and information. Improve, structured and Simplified the Contribution Guidelines. Bundled CI requirements in a single command.(Suggested by @cclauss ) Replaced line endings CRLF with LF endings. Added dos2unix for Travis OSX envs. Bumped Codecov to maximum. Breaking Updates/Changes \u00b6 Dropped support for Python 3.5 and below legacies. (See issue #99 ) Dropped and replaced Python 3.5 matrices with new Python 3.8 matrices in all CI environments. Implemented PEP-8 Styled Black formatting throughout the source-code. Limited protocols support to tcp and ipc only, in NetGear API. Bug-fixes \u00b6 Fixed Major NetGear_Async bug where __address and __port are not set in async mode.(PR by @otter-in-a-suit ) Fixed Major PiGear Color-space Conversion logic bug. Workaround for CAP_IMAGES error in YouTube Mode. Replaced incorrect terminate() with join() in PiGear. Removed uvloop for windows as still NOT yet supported . Refactored Asynchronous Package name async to asyncio , since it is used as Keyword in python>=3.7 (raises SyntaxError) . Fixed unfinished close of event loops bug in WebGear API. Fixed NameError in helper.py. Added fix for OpenCV installer failure on Linux test envs. Fixed undefined NameError in helper.py context. ( @cclauss ) Fixed incorrect logic while pulling frames from ScreenGear API. Fixed missing functions in __main__.py . Fixed Typos and definitions in docs. Added missing camera_num parameter to VideoGear. Added OpenSSL's [SSL: CERTIFICATE_VERIFY_FAILED] bug workaround for macOS envs. Removed download_url meta from setup.py. Removed PiGear from CI completely due to hardware emulation limitation. Removed VideoCapture benchmark tests for macOS envs. Removed trivial __main__.py from codecov. Removed several redundant try-catch loops. Renamed youtube_url_validation as youtube_url_validator . Several minor wrong/duplicate variable definitions and various bugs fixed. Fixed, Improved & removed many Redundant CI tests for various APIs. Pull Requests \u00b6 PR #88 PR #91 PR #93 PR #95 PR #98 PR #101 PR #114 PR #118 PR #124 v0.1.6 (2020-01-01) \u00b6 New Features \u00b6 NetGear API: Added powerful ZMQ Authentication & Data Encryption features for NetGear API: Added exclusive secure_mode param for enabling it. Added support for two most powerful Stonehouse & Ironhouse ZMQ security mechanisms. Added smart auth-certificates/key generation and validation features. Implemented Robust Multi-Servers support for NetGear API: Enables Multiple Servers messaging support with a single client. Added exclusive multiserver_mode param for enabling it. Added support for REQ/REP & PUB/SUB patterns for this mode. Added ability to send additional data of any datatype along with the frame in realtime in this mode. Introducing exclusive Bidirectional Mode for bidirectional data transmission: Added new return_data parameter to recv() function. Added new bidirectional_mode attribute for enabling this mode. Added support for PAIR & REQ/REP patterns for this mode Added support for sending data of any python datatype. Added support for message parameter for non-exclusive primary modes for this mode. Implemented compression support with on-the-fly flexible frame encoding for the Server-end: Added initial support for JPEG , PNG & BMP encoding formats . Added exclusive options attribute compression_format & compression_param to tweak this feature. Client-end will now decode frame automatically based on the encoding as well as support decoding flags. Added force_terminate attribute flag for handling force socket termination at the Server-end if there's latency in the network. Implemented new Publish/Subscribe( zmq.PUB/zmq.SUB ) pattern for seamless Live Streaming in NetGear API. PiGear API: Added new threaded internal timing function for PiGear to handle any hardware failures/frozen threads. PiGear will not exit safely with SystemError if Picamera ribbon cable is pulled out to save resources. Added support for new user-defined HWFAILURE_TIMEOUT options attribute to alter timeout. VideoGear API: Added framerate global variable and removed redundant function. Added CROP_N_ZOOM attribute in Videogear API for supporting Crop and Zoom stabilizer feature. WriteGear API: Added new execute_ffmpeg_cmd function to pass a custom command to its FFmpeg pipeline. Stabilizer class: Added new Crop and Zoom feature. Added crop_n_zoom param for enabling this feature. Updated docs. CI & Tests updates: Replaced python 3.5 matrices with latest python 3.8 matrices in Linux environment. Added full support for Codecov in all CI environments. Updated OpenCV to v4.2.0-pre(master branch). Added various Netgear API tests. Added initial Screengear API test. More test RTSP feeds added with better error handling in CamGear network test. Added tests for ZMQ authentication certificate generation. Added badge and Minor doc updates. Added VidGear's official native support for MacOS environments. Updates/Improvements \u00b6 Replace print logging commands with python's logging module completely. Implemented encapsulation for class functions and variables on all gears. Updated support for screen casting from multiple/all monitors in ScreenGear API. Updated ScreenGear API to use Threaded Queue Mode by default, thereby removed redundant THREADED_QUEUE_MODE param. Updated bash script path to download test dataset in $TMPDIR rather than $HOME directory for downloading testdata. Implemented better error handling of colorspace in various videocapture APIs. Updated bash scripts, Moved FFmpeg static binaries to github.com . Updated bash scripts, Added additional flag to support un-secure apt sources. CamGear API will now throw RuntimeError if source provided is invalid. Updated threaded Queue mode in CamGear API for more robust performance. Added new camera_num to support multiple Picameras. Moved thread exceptions to the main thread and then re-raised. Added alternate github mirror for FFmpeg static binaries auto-installation on windows oses. Added colorlog python module for presentable colored logging. Replaced traceback with sys.exc_info . Overall APIs Code and Docs optimizations. Updated Code Readability and Wiki Docs. Updated ReadMe & Changelog with the latest changes. Updated Travis CI Tests with support for macOS environment. Reformatted & implemented necessary MacOS related changes and dependencies in travis.yml . Breaking Updates/Changes \u00b6 Warning Python 2.7 legacy support dropped completely. Source-code Relicensed to Apache 2.0 License. Python 3+ are only supported legacies for installing v0.1.6 and above. Python 2.7 and 3.4 legacies support dropped from CI tests. Bug-fixes \u00b6 Reimplemented Pub/Sub pattern for smoother performance on various networks. Fixed Assertion error in CamGear API during colorspace manipulation. Fixed random freezing in Secure Mode and several related performance updates Fixed multiserver_mode not working properly over some networks. Fixed assigned Port address ignored bug (commit 073bca1). Fixed several wrong definition bugs from NetGear API(commit 8f7153c). Fixed unreliable dataset video URL(rehosted file on github.com ). Disabled overwrite_cert for client-end in NetGear API. Disabled Universal Python wheel builds in setup.cfg file. Removed duplicate code to import MSS( @BoboTiG ) from ScreenGear API. Eliminated unused redundant code blocks from library. Fixed Code indentation in setup.py and updated new release information. Fixed code definitions & Typos. Fixed several bugs related to secure_mode & multiserver_mode Modes. Fixed various macOS environment bugs. Pull Requests \u00b6 PR #39 PR #42 PR #44 PR #52 PR #55 PR #62 PR #67 PR #72 PR #77 PR #78 PR #82 PR #84 v0.1.5 (2019-07-24) \u00b6 New Features \u00b6 Added new ScreenGear API, supports Live ScreenCasting. Added new NetGear API, aids real-time frame transfer through messaging(ZmQ) over network. Added new new Stabilizer Class, for minimum latency Video Stabilization with OpenCV. Added Option to use API's standalone. Added Option to use VideoGear API as internal wrapper around Stabilizer Class. Added new parameter stabilize to API, to enable or disable Video Stabilization. Added support for **option dict attributes to update VidGear's video stabilizer parameters directly. Added brand new logo and functional block diagram ( .svg ) in readme.md Added new pictures and GIFs for improving readme.md readability Added new contributing.md and changelog.md for reference. Added collections.deque import in Threaded Queue Mode for performance consideration Added new install_opencv.sh bash scripts for Travis cli, to handle OpenCV installation. Added new Project Issue & PR Templates Added new Sponsor Button( FUNDING.yml ) Updates/Improvements \u00b6 Updated New dependencies: mss , pyzmq and rejected redundant ones. Revamped and refreshed look for readme.md and added new badges. Updated Releases Documentation completely. Updated CI tests for new changes Updated Code Documentation. Updated bash scripts and removed redundant information Updated Youtube video URL in tests Completely Reformatted and Updated Wiki Docs with new changes. Breaking Updates/Changes \u00b6 Implemented experimental Threaded Queue Mode( a.k.a Blocking Mode ) for fast, synchronized, error-free multi-threading. Renamed bash script pre-install.sh to prepare_dataset.sh - downloads opensourced test datasets and static FFmpeg binaries for debugging. Changed script folder location to bash/script . Python 3.4 removed from Travis CI tests. Bug-fixes \u00b6 Temporarily fixed Travis CI bug: Replaced opencv-contrib-python with OpenCV built from scratch as dependency. Fixed CI Timeout Bug: Disable Threaded Queue Mode for CI Tests Fixes** sys.stderr.close() throws ValueError bug: Replaced sys.close() with DEVNULL.close() Fixed Youtube Live Stream bug that return NonType frames in CamGear API. Fixed NoneType frames bug in PiGear class on initialization. Fixed Wrong function definitions Removed /xe2 unicode bug from Stabilizer class. Fixed **output_params KeyError bug in WriteGear API Fixed subprocess not closing properly on exit in WriteGear API. Fixed bugs in ScreenGear: Non-negative monitor values Fixed missing import, typos, wrong variable definitions Removed redundant hack from setup.py Fixed Minor YouTube playback Test CI Bug Fixed new Twitter Intent Fixed bug in bash script that not working properly due to changes at server end. Pull Requests \u00b6 PR #17 PR #21 PR #22 PR #27 PR #31 PR #32 PR #33 PR #34 v0.1.4 (2019-05-11) \u00b6 New Features \u00b6 Added new WriteGear API: for enabling lossless video encoding and compression(built around FFmpeg and OpenCV Video Writer) Added YouTube Mode for direct Video Pipelining from YouTube in CamGear API Added new y_tube to access YouTube Mode in CamGear API. Added flexible Output file Compression control capabilities in compression-mode(WriteGear). Added -output_dimensions special parameter to WriteGear API. Added new helper.py to handle special helper functions. Added feature to auto-download and configure FFmpeg Static binaries(if not found) on Windows platforms. Added -input_framerate special parameter to WriteGear class to change/control output constant framerate in compression mode(WriteGear). Added new Direct Video colorspace Conversion capabilities in CamGear and PiGear API. Added new framerate class variable for CamGear API, to retrieve input framerate. Added new parameter backend - changes the backend of CamGear's API Added automatic required prerequisites installation ability, when installation from source. Added Travis CI Complete Integration for Linux-based Testing for VidGear. Added and configured travis.yml Added Appveyor CI Complete Integration for Windows-based Testing in VidGear. Added and configured new appveyor.yml Added new bash script pre-install.sh to download opensourced test datasets and static FFmpeg binaries for debugging. Added several new Tests(including Benchmarking Tests) for each API for testing with pytest . Added license to code docs. Added Say Thank you! badge to readme. Updates/Improvements \u00b6 Removed redundant dependencies Updated youtube-dl as a dependency, as required by pafy 's backend. Updated common VideoGear API with new parameter. Update robust algorithm to auto-detect FFmpeg executables and test them, if failed, auto fallback to OpenCV's VideoWriter API. Improved system previously installed OpenCV detection in setup.py. Updated setup.py with hack to remove bullets from pypi description. Updated Code Documentation Reformatted & Modernized readme.md with new badges. Reformatted and Updated Wiki Docs. Breaking Updates/Changes \u00b6 Bugs Patched: Removed unnecessary -height and -width parameter from CamGear API. Replaced dependency opencv-python with opencv-contrib-python completely Bug-fixes \u00b6 Windows Cross-Platform fix: replaced dependency os with platform in setup.py. Fixed Bug: Arises due to spaces in input **options / **output_param dictionary keys. Fixed several wrong/missing variable & function definitions. Fixed code uneven indentation. Fixed several typos in docs. Pull Requests \u00b6 PR #7 PR #8 PR #10 PR #12 v0.1.3 (2019-04-07) \u00b6 Bug-fixes \u00b6 Patched Major PiGear Bug: Incorrect import of PiRGBArray function in PiGear Class Several Fixes** for backend picamera API handling during frame capture(PiGear) Fixed missing frame variable initialization. Fixed minor typos Pull Requests \u00b6 PR #6 PR #5 v0.1.2 (2019-03-27) \u00b6 New Features \u00b6 Added easy Source manipulation feature in CamGear API, to control features like resolution, brightness, framerate etc. Added new **option parameter to CamGear API, provides the flexibility to manipulate input stream directly. Added new parameters for Camgear API for time delay and logging. Added new Logo to readme.md Added new Wiki Documentation. Updates/Improvements \u00b6 Reformatted readme.md. Updated Wiki Docs with new changes. Bug-fixes \u00b6 Improved Error Handling in CamGear & PiGear API. Fixed minor typos in docs. Pull Requests \u00b6 PR #4 v0.1.1 (2019-03-24) \u00b6 New Features \u00b6 Release ViGear binaries on the Python Package Index (PyPI) Added new and configured setup.py & setup.cfg Bug-fixes \u00b6 Fixed PEP bugs: added and configured properly __init__.py in each folder Fixed PEP bugs: improved code Indentation Fixed wrong imports: replaced distutils.core with setuptools Fixed readme.md v0.1.0 (2019-03-17) \u00b6 New Features \u00b6 Initial Release Converted my imutils PR into Python Project. Renamed conventions and reformatted complete source-code from scratch. Added support for both python 2.7 and 3 legacies Added new multi-threaded CamGear, PiGear, and VideoGear APIs Added multi-platform compatibility Added robust & flexible control over the source in PiGear API.","title":"Release Notes"},{"location":"changelog/#release-notes","text":"","title":"Release Notes"},{"location":"changelog/#v019-2020-08-31","text":"","title":"v0.1.9 (2020-08-31)"},{"location":"changelog/#new-features","text":"StreamGear API: New API that automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. Implemented multi-platform , standalone, highly extensible and flexible wrapper around FFmpeg for generating chunked-encoded media segments of the media, and easily accessing almost all of its parameters. API automatically transcodes videos/audio files & real-time frames into a sequence of multiple smaller chunks/segments and also creates a Manifest file. Added initial support for MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) . Constructed default behavior in StreamGear, for auto-creating a Primary Stream of same resolution and framerate as source. Added TQDM progress bar in non-debugged output for visual representation of internal processes. Implemented several internal methods for preprocessing FFmpeg and internal parameters for producing streams. Several standalone internal checks to ensure robust performance. New terminate() function to terminate StremGear Safely. New StreamGear Dual Modes of Operation: Implemented Single-Source and Real-time Frames like independent Transcoding Modes. Linked -video_source attribute for activating these modes Single-Source Mode , transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller segments for streaming Real-time Frames Mode , directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller segments for streaming Added separate functions, stream() for Real-time Frame Mode and transcode_source() for Single-Source Mode for easy transcoding. Included auto-colorspace detection and RGB Mode like features (extracted from WriteGear) , into StreamGear. New StreamGear Parameters: Developed several new parameters such as: output : handles assets directory formats : handles adaptive HTTP streaming format. custom_ffmpeg : handles custom FFmpeg location. stream_params : handles internal and FFmpeg parameter seamlessly. logging : turns logging on or off. New stream_params parameter allows us to exploit almost all FFmpeg parameters and flexibly change its internal settings, and seamlessly generating high-quality streams with its attributes: -streams (list of dictionaries) for building additional streams with -resolution , -video_bitrate & -framerate like sub-attributes. -audio for specifying external audio. -video_source for specifying Single-Source Mode source. -input_framerate for handling input framerate in Real-time Frames Mode. -bpp attribute for handling bits-per-pixels used to auto-calculate video-bitrate. -gop to manually specify GOP length. -ffmpeg_download_path to handle custom FFmpeg download path on windows. -clear_prev_assets to remove any previous copies of SteamGear Assets. New StreamGear docs, MPEG-DASH demo, and recommended DASH players list: Added new StreamGear docs, usage examples, parameters, references, new FAQs. Added Several StreamGear usage examples w.r.t Mode of Operation. Implemented Clappr based on Shaka-Player , as Demo Player. Added Adaptive-dimensional behavior for Demo-player, purely in css. Hosted StreamGear generated DASH chunks on GitHub and served with raw.githack.com . Introduced variable quality level-selector plugin for Clapper Player. Provide various required javascripts and implemented additional functionality for player in extra.js . Recommended tested Online, Command-line and GUI Adaptive Stream players. Implemented separate FFmpeg installation doc for StreamGear API. Reduced rebufferingGoal for faster response. New StreamGear CI tests: Added IO and API initialization CI tests for its Modes. Added various mode Streaming check CI tests. NetGear_Async API: Added new send_terminate_signal internal method. Added WindowsSelectorEventLoopPolicy() for windows 3.8+ envs. Moved Client auto-termination to separate method. Implemented graceful termination with signal API on UNIX machines. Added new timeout attribute for controlling Timeout in Connections. Added missing termination optimizer ( linger=0 ) flag. Several ZMQ Optimizer Flags added to boost performance. WriteGear API: Added support for adding duplicate FFmpeg parameters to output_params : Added new -clones attribute in output_params parameter for handing this behavior.. Support to pass FFmpeg parameters as list, while maintaining the exact order it was specified. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Added new CI tests debugging this behavior. Updated docs accordingly. Added support for Networks URLs in Compression Mode: output_filename parameter supports Networks URLs in compression modes only Added automated handling of non path/file Networks URLs as input. Implemented new is_valid_url helper method to easily validate assigned URLs value. Validates whether the given URL value has scheme/protocol supported by assigned/installed ffmpeg or not. WriteGear will throw ValueError if -output_filename is not supported. Added related CI tests and docs. Added disable_force_termination attribute in WriteGear to disable force-termination. NetGear API: Added option to completely disable Native Frame-Compression: Checks if any Incorrect/Invalid value is assigned on compression_format attribute. Completely disables Native Frame-Compression. Updated docs accordingly. CamGear API: Added new and robust regex for identifying YouTube URLs. Moved youtube_url_validator to Helper. New helper.py methods: Added validate_video function to validate video_source. Added extract_time Extract time from give string value. Added get_video_bitrate to caliculate video birate from resolution, framerate, bits-per-pixels values. Added delete_safe to safely delete files of given extension. Added validate_audio to validate audio source. Added new Helper CI tests. Added new check_valid_mpd function to test MPD files validity. Added mpegdash library to CI requirements. Deployed New Docs Upgrades: Added new assets like images, gifs, custom scripts, javascripts fonts etc. for achieving better visual graphics in docs. Added clappr.min.js , dash-shaka-playback.js , clappr-level-selector.min.js third-party javascripts locally. Extended Overview docs Hyperlinks to include all major sub-pages (such as Usage Examples, Reference, FAQs etc.) . Replaced GIF with interactive MPEG-DASH Video Example in Stabilizer Docs. Added new pymdownx.keys to replace [Ctrl+C]/[\u2318+C] formats. Added new custom.css stylescripts variables for fluid animations in docs. Overridden announce bar and added donation button. Lossless WEBP compressed all PNG assets for faster loading. Enabled lazy-loading for GIFS and Images for performance. Reimplemented Admonitions contexts and added new ones. Added StreamGear and its different modes Docs Assets. Added patch for images & unicodes for PiP flavored markdown in setup.py . Added Request Info and Welcome GitHub Apps to automate PR and issue workflow Added new config.yml for customizations. Added various suitable configurations. Added new -clones attribute to handle FFmpeg parameter clones in StreamGear and WriteGear API. Added new Video-only and Audio-Only sources in bash script. Added new paths in bash script for storing StreamGear & WriteGear assets temporarily.","title":"New Features"},{"location":"changelog/#updatesimprovements","text":"Added patch for NotImplementedError in NetGear_Async API on Windows 3.8+ envs. Check for valid output file extension according to format selected in StreamGear. Completed migration to travis.com . Created new temp_write temp directory for WriteGear Assets in bash script. Deleted old Redundant assets and added new ones. Employed isort library to sort and group imports in Vidgear APIs. Enabled exception for list, tuple, int, float in WriteGear API's output_params dict. Enabled missing support for frame-compression in its primary Receive Mode. Enforced pixel formats for streams. Improved check for valid system path detection in WriteGear API. Overrided pytest-asyncio fixture in NetGear_Async API. Quoted Gear Headline for understanding each gear easily. Re-Positioned Gear's banner images in overview for better readability. Reduced redundant try-except blocks in NetGear Async. Reformatted and Simplified Docs context. Reimplemented return_testvideo_path CI function with variable streams. Reimplemented skip_loop in NetGear_Async to fix asyncio.CancelledError . Reimplemented buggy audio handler in StreamGear. Reimplemented images with <figure> and <figurecaption> like tags. Removed Python < 3.8 condition from all CI tests. Removed or Grouped redundant code for increasing codecov. Removed redundant code and simplified algorithmic complexities in Gears. Replaced ;nbsp with ;thinsp and ;emsp . Replaced IOError with more reliable RuntimeError in StreamGear Pipelines. Replaced del with pop in dicts. Replaced all Netgear CI tests with more reliable try-except-final blocks. Replaced simple lists with pymdownx.tasklist . Replaced subprocess call() with run() for better error handling in execute_ffmpeg_cmd function. Resized over-sized docs images. Simplified delete_safe Helper function. Simplified default audio-bitrate logic in StreamGear Updated CI tests and cleared redundant code from NetGear_Async API. Updated CI with new tests and Bumped Codecov. Updated Issue and PR templates. Updated Licenses for new files and shrink images dimensions. Updated Missing Helpful tips and increased logging. Updated PR guidelines for more clarity. Updated WebGear examples addresses from 0.0.0.0 to localhost . Updated WriteGear and StreamGear CI tests for not supporting temp directory. Updated README.md and changelog.md with new changes. Updated check_output and added force_retrieve_stderr support to **kwargs to extract stderr output even on FFmpeg error. Updated dicts2args to support internal repeated coreX FFmpeg parameters for StreamGear. Updated mkdocs.yml , changelog.md and README.md with latest changes. Updated validate_audio Helper function will now retrieve audio-bitrate for validation. Updated buggy mpegdash dependency with custom dev fork for Windows machines. Updated core parameters for audio handling. Updated logging for debugging selected eventloops in NetGear_Async API. Updated termination linger to zero at Server's end.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges","text":"Changed Webgear API default address to localhost for cross-compatibility between different platforms. In Netgear_Async API, source value can now be NoneType for a custom frame-generator at Server-end only. Temp_(such as /tmp in linux)_ is now not a valid directory for WriteGear & StreamGear API outputs. Moved vidgear docs assets (i.e images, gifs, javascripts and stylescripts) to override directory.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes","text":"Added workaround for system path not handle correctly. Fixed Bug: URL Audio format not being handled properly. Fixed Critical Bug in NetGear_Async throwing ValueError with None-type Source. Fixed Critical StreamGear Bug: FFmpeg pipeline terminating prematurely in Single-Source Mode. Fixed Critical external audio handler bug: moved audio-input to input_parameters. Fixed Frozen-threads bug in CI tests. Fixed Mkdocs only accepting Relative paths. Fixed OSError in WriteGear's compression mode. Fixed StreamGear CI bugs for Windows and CI envs. Fixed Typos and Indentation bugs in NetGear API. Fixed ZMQ throwing error on termination if all max-tries exhausted. Fixed NameError bug in NetGear API. Fixed NameError bugs in StreamGear CI. Fixed NameError in CI functions and tests. Fixed TimeoutError bug in NetGear_Async CI tests. Fixed get_valid_ffmpeg_path throwing TypeError with non-string values. Fixed broken links in docs. Fixed critical duplicate logging bug. Fixed default gop value not handle correctly. Fixed handling of incorrect paths detection. Fixed incorrect definitions in NetGear_Async. Fixed left-over attribute bug in WriteGear. Fixed logic and indentation bugs in CI tests. Fixed logic for handling output parameters in WriteGear API. Fixed missing definitions and logic bug in StreamGear. Fixed missing import and incorrect CI definitions. Fixed missing source dimensions from extract_resolutions output in StreamGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed round off error in FPS. Fixed several CI bugs and updated extract_resolutions method. Fixed several bugs from CI Bidirectional Mode tests. Fixed several typos in docs usage examples. Fixed various AttributeError with wrong attribute names and definition in CI Helper functions. Fixed wrong and missing definitions in docs. Fixed wrong logic for extracting OpenCV frames. Fixed wrong type bug in StreamGear API. Fixed wrong type error bug in WriteGear API. Fixed wrong variable assignments bug in WriteGear API. Fixes to CLI tests and missing docs imports. Many minor typos and wrong definitions.","title":"Bug-fixes"},{"location":"changelog/#pull-requests","text":"PR #129 PR #130 PR #155","title":"Pull Requests"},{"location":"changelog/#v018-2020-06-12","text":"","title":"v0.1.8 (2020-06-12)"},{"location":"changelog/#new-features_1","text":"Multiple Clients support in NetGear API: Implemented support for handling any number of Clients simultaneously with a single Server in this mode. Added new multiclient_mode attribute for enabling this mode easily. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Implemented ability to receive data from all Client(s) along with frames with zmq.REQ/zmq.REP pattern only. Updated related CI tests Support for robust Lazy Pirate pattern(auto-reconnection) in NetGear API for both server and client ends: Implemented a algorithm where NetGear rather than doing a blocking receive, will now: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Implemented its default support for REQ/REP and PAIR messaging patterns internally. Added new max_retries and request_timeout (in seconds) for handling polling. Added DONTWAIT flag for interruption-free data receiving. Both Server and Client can now reconnect even after a premature termination. Performance Updates for NetGear API: Added default Frame Compression support for Bidirectional frame transmission in Bidirectional mode. Added support for Reducer() function in Helper.py to aid reducing frame-size on-the-go for more performance. Added small delay in recv() function at client's end to reduce system load. Reworked and Optimized NetGear termination, and also removed/changed redundant definitions and flags. Docs Migration to Mkdocs: Implemented a beautiful, static documentation site based on MkDocs which will then be hosted on GitHub Pages. Crafted base mkdocs with third-party elegant & simplistic mkdocs-material theme. Implemented new mkdocs.yml for Mkdocs with relevant data. Added new docs folder to handle markdown pages and its assets. Added new Markdown pages( .md ) to docs folder, which are carefully crafted documents - based on previous Wiki's docs, and some completely new additions. Added navigation under tabs for easily accessing each document. New Assets: Added new assets like gifs, images, custom scripts, favicons, site.webmanifest etc. for bringing standard and quality to docs visual design. Designed brand new logo and banner for VidGear Documents. Deployed all assets under separate Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License . Added Required Plugins and Extensions: Added support for all pymarkdown-extensions . Added support for some important admonition , attr_list , codehilite , def_list , footnotes , meta , and toc like Mkdocs extensions. Enabled search , minify and git-revision-date-localized plugins support. Added various VidGear's social links to yaml. Added support for en (English) language. Auto-Build API Reference with mkdocstrings: Added support for mkdocstrings plugin for auto-building each VidGear's API references. Added python handler for parsing python source-code to mkdocstrings . Auto-Deploy Docs with Github Actions: Implemented Automated Docs Deployment on gh-pages through GitHub Actions workflow. Added new workflow yaml with minimal configuration for automated docs deployment. Added all required python dependencies and environment for this workflow. Added master branch on Ubuntu machine to build matrix.","title":"New Features"},{"location":"changelog/#updatesimprovements_1","text":"Added in-built support for bidirectional frames( NDarray ) transfer in Bidirectional mode. Added support for User-Defined compression params in Bidirectional frames transfer. Added workaround for address already in use bug at client's end. Unified Bidirectional and Multi-Clients mode for client's return data transmission. Replaced ValueError with more suitable RuntimeError . Updated logging for better readability. Added CI test for Multi-Clients mode. Reformatted and grouped imports in VidGear. Added Reducer Helper function CI test. Added Reliability tests for both Server and Client end. Disabled reliable reconnection for Multi-Clients mode. Replaced os.devnull with suprocess's inbuilt function. Updated README.md, Issue and PR templates with new information and updates. Moved changelog.md to /docs and updated contribution guidelines. Improved source-code docs for compatibility with mkdocstrings . Added additional dependency mkdocs-exclude , for excluding files from Mkdocs builds. Updated license and compressed images/diagrams. Added new CI tests and Bumped Codecov. Changed YouTube video URL for CI tests to Creative Commons(CC) video. Removed redundant code.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_1","text":"VidGear Docs moved to GitHub Pages, Now Available at https://abhitronix.github.io/vidgear . Removed filter attribute from options parameter in NetGear API. Removed force_terminate parameter support from NetGear API. Disabled additional data of datatype numpy.ndarray for Server end in Bidirectional Mode.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_1","text":"Fixed 'NoneType' object is not subscriptable bug. Fixed bugs related to delayed termination in NetGear API. Reduced default request_timeout value to 4 and also lowered cut-off limit for the same. Removed redundant ZMQ context termination and similar variables. Added missing VidGear installation in workflow. Excluded conflicting assets README.md from Mkdocs builds. Fixed pattern value check bypassed if wrong value is assigned. Fixed incorrect handling of additional data transferred in synchronous mode at both Server and Client end. Replaced Netgear CI test with more reliable try-except-final blocks. Updated termination linger to zero at Server's end. Fixed NameError bug in NetGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed ZMQ throwing error on termination if all max-tries exhausted. Enabled missing support for frame compression in its primary receive mode. Fixed several bugs from CI Bidirectional Mode tests. Removed or Grouped redundant code for increasing codecov. Fixed Mkdocs only accepting Relative paths. Fixed broken links in docs. Fixed round off error in FPS. Many small typos and bugs fixes.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_1","text":"PR #129 PR #130","title":"Pull Requests"},{"location":"changelog/#v017-2020-04-29","text":"","title":"v0.1.7 (2020-04-29)"},{"location":"changelog/#new-features_2","text":"WebGear API: Added a robust Live Video Server API that can transfer live video frames to any web browser on the network in real-time. Implemented a flexible asyncio wrapper around starlette ASGI Application Server. Added seamless access to various starlette's Response classes, Routing tables, Static Files, Template engine(with Jinja2), etc. Added a special internal access to VideoGear API and all its parameters. Implemented a new Auto-Generation Work-flow to generate/download & thereby validate WebGear API data files from its GitHub server automatically. Added on-the-go dictionary parameter in WebGear to tweak performance, Route Tables and other internal properties easily. Added new simple & elegant default Bootstrap Cover Template for WebGear Server. Added __main__.py to directly run WebGear Server through the terminal. Added new gif and related docs for WebGear API. Added and Updated various CI tests for this API. NetGear_Async API: Designed NetGear_Async asynchronous network API built upon ZeroMQ's asyncio API. Implemented support for state-of-the-art asyncio event loop uvloop at its backend. Achieved Unmatchable high-speed and lag-free video streaming over the network with minimal resource constraint. Added exclusive internal wrapper around VideoGear API for this API. Implemented complete server-client handling and options to use variable protocols/patterns for this API. Implemented support for all four ZeroMQ messaging patterns: i.e zmq.PAIR , zmq.REQ/zmq.REP , zmq.PUB/zmq.SUB , and zmq.PUSH/zmq.PULL . Implemented initial support for tcp and ipc protocols. Added new Coverage CI tests for NetGear_Async Network Gear. Added new Benchmark tests for benchmarking NetGear_Async against NetGear. Asynchronous Enhancements: Added asyncio package to for handling asynchronous APIs. Moved WebGear API(webgear.py) to asyncio and created separate asyncio helper.py for it. Various Performance tweaks for Asyncio APIs with concurrency within a single thread. Moved __main__.py to asyncio for easier access to WebGear API through the terminal. Updated setup.py with new dependencies and separated asyncio dependencies. General Enhancements: Added new highly-precise Threaded FPS class for accurate benchmarking with time.perf_counter python module. Added a new Gitter community channel. Added a new Reducer function to reduce the frame size on-the-go. Add Flake8 tests to Travis CI to find undefined names. (PR by @cclauss ) Added a new unified logging handler helper function for vidgear.","title":"New Features"},{"location":"changelog/#updatesimprovements_2","text":"Re-implemented and simplified logic for NetGear Async server-end. Added new dependencies for upcoming asyncio updates to setup.py . Added retry function and replaced wget with curl for Linux test envs. Bumped OpenCV to latest 4.2.0-dev for Linux test envs. Updated YAML files to reflect new changes to different CI envs. Separated each API logger with a common helper method to avoid multiple copies. Limited Importing OpenCV API version check's scope to helper.py only. Implemented case for incorrect color_space value in ScreenGear API. Removed old conflicting logging formatter with a common method and expanded logging. Improved and added shutdown function for safely stopping frame producer threads in WebGear API. Re-implemented and simplified all CI tests with maximum code-coverage in mind. Replaced old mkdir function with new mkdir_safe helper function for creating directories safely. Updated ReadMe.md with updated diagrams, gifs and information. Improve, structured and Simplified the Contribution Guidelines. Bundled CI requirements in a single command.(Suggested by @cclauss ) Replaced line endings CRLF with LF endings. Added dos2unix for Travis OSX envs. Bumped Codecov to maximum.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_2","text":"Dropped support for Python 3.5 and below legacies. (See issue #99 ) Dropped and replaced Python 3.5 matrices with new Python 3.8 matrices in all CI environments. Implemented PEP-8 Styled Black formatting throughout the source-code. Limited protocols support to tcp and ipc only, in NetGear API.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_2","text":"Fixed Major NetGear_Async bug where __address and __port are not set in async mode.(PR by @otter-in-a-suit ) Fixed Major PiGear Color-space Conversion logic bug. Workaround for CAP_IMAGES error in YouTube Mode. Replaced incorrect terminate() with join() in PiGear. Removed uvloop for windows as still NOT yet supported . Refactored Asynchronous Package name async to asyncio , since it is used as Keyword in python>=3.7 (raises SyntaxError) . Fixed unfinished close of event loops bug in WebGear API. Fixed NameError in helper.py. Added fix for OpenCV installer failure on Linux test envs. Fixed undefined NameError in helper.py context. ( @cclauss ) Fixed incorrect logic while pulling frames from ScreenGear API. Fixed missing functions in __main__.py . Fixed Typos and definitions in docs. Added missing camera_num parameter to VideoGear. Added OpenSSL's [SSL: CERTIFICATE_VERIFY_FAILED] bug workaround for macOS envs. Removed download_url meta from setup.py. Removed PiGear from CI completely due to hardware emulation limitation. Removed VideoCapture benchmark tests for macOS envs. Removed trivial __main__.py from codecov. Removed several redundant try-catch loops. Renamed youtube_url_validation as youtube_url_validator . Several minor wrong/duplicate variable definitions and various bugs fixed. Fixed, Improved & removed many Redundant CI tests for various APIs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_2","text":"PR #88 PR #91 PR #93 PR #95 PR #98 PR #101 PR #114 PR #118 PR #124","title":"Pull Requests"},{"location":"changelog/#v016-2020-01-01","text":"","title":"v0.1.6 (2020-01-01)"},{"location":"changelog/#new-features_3","text":"NetGear API: Added powerful ZMQ Authentication & Data Encryption features for NetGear API: Added exclusive secure_mode param for enabling it. Added support for two most powerful Stonehouse & Ironhouse ZMQ security mechanisms. Added smart auth-certificates/key generation and validation features. Implemented Robust Multi-Servers support for NetGear API: Enables Multiple Servers messaging support with a single client. Added exclusive multiserver_mode param for enabling it. Added support for REQ/REP & PUB/SUB patterns for this mode. Added ability to send additional data of any datatype along with the frame in realtime in this mode. Introducing exclusive Bidirectional Mode for bidirectional data transmission: Added new return_data parameter to recv() function. Added new bidirectional_mode attribute for enabling this mode. Added support for PAIR & REQ/REP patterns for this mode Added support for sending data of any python datatype. Added support for message parameter for non-exclusive primary modes for this mode. Implemented compression support with on-the-fly flexible frame encoding for the Server-end: Added initial support for JPEG , PNG & BMP encoding formats . Added exclusive options attribute compression_format & compression_param to tweak this feature. Client-end will now decode frame automatically based on the encoding as well as support decoding flags. Added force_terminate attribute flag for handling force socket termination at the Server-end if there's latency in the network. Implemented new Publish/Subscribe( zmq.PUB/zmq.SUB ) pattern for seamless Live Streaming in NetGear API. PiGear API: Added new threaded internal timing function for PiGear to handle any hardware failures/frozen threads. PiGear will not exit safely with SystemError if Picamera ribbon cable is pulled out to save resources. Added support for new user-defined HWFAILURE_TIMEOUT options attribute to alter timeout. VideoGear API: Added framerate global variable and removed redundant function. Added CROP_N_ZOOM attribute in Videogear API for supporting Crop and Zoom stabilizer feature. WriteGear API: Added new execute_ffmpeg_cmd function to pass a custom command to its FFmpeg pipeline. Stabilizer class: Added new Crop and Zoom feature. Added crop_n_zoom param for enabling this feature. Updated docs. CI & Tests updates: Replaced python 3.5 matrices with latest python 3.8 matrices in Linux environment. Added full support for Codecov in all CI environments. Updated OpenCV to v4.2.0-pre(master branch). Added various Netgear API tests. Added initial Screengear API test. More test RTSP feeds added with better error handling in CamGear network test. Added tests for ZMQ authentication certificate generation. Added badge and Minor doc updates. Added VidGear's official native support for MacOS environments.","title":"New Features"},{"location":"changelog/#updatesimprovements_3","text":"Replace print logging commands with python's logging module completely. Implemented encapsulation for class functions and variables on all gears. Updated support for screen casting from multiple/all monitors in ScreenGear API. Updated ScreenGear API to use Threaded Queue Mode by default, thereby removed redundant THREADED_QUEUE_MODE param. Updated bash script path to download test dataset in $TMPDIR rather than $HOME directory for downloading testdata. Implemented better error handling of colorspace in various videocapture APIs. Updated bash scripts, Moved FFmpeg static binaries to github.com . Updated bash scripts, Added additional flag to support un-secure apt sources. CamGear API will now throw RuntimeError if source provided is invalid. Updated threaded Queue mode in CamGear API for more robust performance. Added new camera_num to support multiple Picameras. Moved thread exceptions to the main thread and then re-raised. Added alternate github mirror for FFmpeg static binaries auto-installation on windows oses. Added colorlog python module for presentable colored logging. Replaced traceback with sys.exc_info . Overall APIs Code and Docs optimizations. Updated Code Readability and Wiki Docs. Updated ReadMe & Changelog with the latest changes. Updated Travis CI Tests with support for macOS environment. Reformatted & implemented necessary MacOS related changes and dependencies in travis.yml .","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_3","text":"Warning Python 2.7 legacy support dropped completely. Source-code Relicensed to Apache 2.0 License. Python 3+ are only supported legacies for installing v0.1.6 and above. Python 2.7 and 3.4 legacies support dropped from CI tests.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_3","text":"Reimplemented Pub/Sub pattern for smoother performance on various networks. Fixed Assertion error in CamGear API during colorspace manipulation. Fixed random freezing in Secure Mode and several related performance updates Fixed multiserver_mode not working properly over some networks. Fixed assigned Port address ignored bug (commit 073bca1). Fixed several wrong definition bugs from NetGear API(commit 8f7153c). Fixed unreliable dataset video URL(rehosted file on github.com ). Disabled overwrite_cert for client-end in NetGear API. Disabled Universal Python wheel builds in setup.cfg file. Removed duplicate code to import MSS( @BoboTiG ) from ScreenGear API. Eliminated unused redundant code blocks from library. Fixed Code indentation in setup.py and updated new release information. Fixed code definitions & Typos. Fixed several bugs related to secure_mode & multiserver_mode Modes. Fixed various macOS environment bugs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_3","text":"PR #39 PR #42 PR #44 PR #52 PR #55 PR #62 PR #67 PR #72 PR #77 PR #78 PR #82 PR #84","title":"Pull Requests"},{"location":"changelog/#v015-2019-07-24","text":"","title":"v0.1.5 (2019-07-24)"},{"location":"changelog/#new-features_4","text":"Added new ScreenGear API, supports Live ScreenCasting. Added new NetGear API, aids real-time frame transfer through messaging(ZmQ) over network. Added new new Stabilizer Class, for minimum latency Video Stabilization with OpenCV. Added Option to use API's standalone. Added Option to use VideoGear API as internal wrapper around Stabilizer Class. Added new parameter stabilize to API, to enable or disable Video Stabilization. Added support for **option dict attributes to update VidGear's video stabilizer parameters directly. Added brand new logo and functional block diagram ( .svg ) in readme.md Added new pictures and GIFs for improving readme.md readability Added new contributing.md and changelog.md for reference. Added collections.deque import in Threaded Queue Mode for performance consideration Added new install_opencv.sh bash scripts for Travis cli, to handle OpenCV installation. Added new Project Issue & PR Templates Added new Sponsor Button( FUNDING.yml )","title":"New Features"},{"location":"changelog/#updatesimprovements_4","text":"Updated New dependencies: mss , pyzmq and rejected redundant ones. Revamped and refreshed look for readme.md and added new badges. Updated Releases Documentation completely. Updated CI tests for new changes Updated Code Documentation. Updated bash scripts and removed redundant information Updated Youtube video URL in tests Completely Reformatted and Updated Wiki Docs with new changes.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_4","text":"Implemented experimental Threaded Queue Mode( a.k.a Blocking Mode ) for fast, synchronized, error-free multi-threading. Renamed bash script pre-install.sh to prepare_dataset.sh - downloads opensourced test datasets and static FFmpeg binaries for debugging. Changed script folder location to bash/script . Python 3.4 removed from Travis CI tests.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_4","text":"Temporarily fixed Travis CI bug: Replaced opencv-contrib-python with OpenCV built from scratch as dependency. Fixed CI Timeout Bug: Disable Threaded Queue Mode for CI Tests Fixes** sys.stderr.close() throws ValueError bug: Replaced sys.close() with DEVNULL.close() Fixed Youtube Live Stream bug that return NonType frames in CamGear API. Fixed NoneType frames bug in PiGear class on initialization. Fixed Wrong function definitions Removed /xe2 unicode bug from Stabilizer class. Fixed **output_params KeyError bug in WriteGear API Fixed subprocess not closing properly on exit in WriteGear API. Fixed bugs in ScreenGear: Non-negative monitor values Fixed missing import, typos, wrong variable definitions Removed redundant hack from setup.py Fixed Minor YouTube playback Test CI Bug Fixed new Twitter Intent Fixed bug in bash script that not working properly due to changes at server end.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_4","text":"PR #17 PR #21 PR #22 PR #27 PR #31 PR #32 PR #33 PR #34","title":"Pull Requests"},{"location":"changelog/#v014-2019-05-11","text":"","title":"v0.1.4 (2019-05-11)"},{"location":"changelog/#new-features_5","text":"Added new WriteGear API: for enabling lossless video encoding and compression(built around FFmpeg and OpenCV Video Writer) Added YouTube Mode for direct Video Pipelining from YouTube in CamGear API Added new y_tube to access YouTube Mode in CamGear API. Added flexible Output file Compression control capabilities in compression-mode(WriteGear). Added -output_dimensions special parameter to WriteGear API. Added new helper.py to handle special helper functions. Added feature to auto-download and configure FFmpeg Static binaries(if not found) on Windows platforms. Added -input_framerate special parameter to WriteGear class to change/control output constant framerate in compression mode(WriteGear). Added new Direct Video colorspace Conversion capabilities in CamGear and PiGear API. Added new framerate class variable for CamGear API, to retrieve input framerate. Added new parameter backend - changes the backend of CamGear's API Added automatic required prerequisites installation ability, when installation from source. Added Travis CI Complete Integration for Linux-based Testing for VidGear. Added and configured travis.yml Added Appveyor CI Complete Integration for Windows-based Testing in VidGear. Added and configured new appveyor.yml Added new bash script pre-install.sh to download opensourced test datasets and static FFmpeg binaries for debugging. Added several new Tests(including Benchmarking Tests) for each API for testing with pytest . Added license to code docs. Added Say Thank you! badge to readme.","title":"New Features"},{"location":"changelog/#updatesimprovements_5","text":"Removed redundant dependencies Updated youtube-dl as a dependency, as required by pafy 's backend. Updated common VideoGear API with new parameter. Update robust algorithm to auto-detect FFmpeg executables and test them, if failed, auto fallback to OpenCV's VideoWriter API. Improved system previously installed OpenCV detection in setup.py. Updated setup.py with hack to remove bullets from pypi description. Updated Code Documentation Reformatted & Modernized readme.md with new badges. Reformatted and Updated Wiki Docs.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_5","text":"Bugs Patched: Removed unnecessary -height and -width parameter from CamGear API. Replaced dependency opencv-python with opencv-contrib-python completely","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_5","text":"Windows Cross-Platform fix: replaced dependency os with platform in setup.py. Fixed Bug: Arises due to spaces in input **options / **output_param dictionary keys. Fixed several wrong/missing variable & function definitions. Fixed code uneven indentation. Fixed several typos in docs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_5","text":"PR #7 PR #8 PR #10 PR #12","title":"Pull Requests"},{"location":"changelog/#v013-2019-04-07","text":"","title":"v0.1.3 (2019-04-07)"},{"location":"changelog/#bug-fixes_6","text":"Patched Major PiGear Bug: Incorrect import of PiRGBArray function in PiGear Class Several Fixes** for backend picamera API handling during frame capture(PiGear) Fixed missing frame variable initialization. Fixed minor typos","title":"Bug-fixes"},{"location":"changelog/#pull-requests_6","text":"PR #6 PR #5","title":"Pull Requests"},{"location":"changelog/#v012-2019-03-27","text":"","title":"v0.1.2 (2019-03-27)"},{"location":"changelog/#new-features_6","text":"Added easy Source manipulation feature in CamGear API, to control features like resolution, brightness, framerate etc. Added new **option parameter to CamGear API, provides the flexibility to manipulate input stream directly. Added new parameters for Camgear API for time delay and logging. Added new Logo to readme.md Added new Wiki Documentation.","title":"New Features"},{"location":"changelog/#updatesimprovements_6","text":"Reformatted readme.md. Updated Wiki Docs with new changes.","title":"Updates/Improvements"},{"location":"changelog/#bug-fixes_7","text":"Improved Error Handling in CamGear & PiGear API. Fixed minor typos in docs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_7","text":"PR #4","title":"Pull Requests"},{"location":"changelog/#v011-2019-03-24","text":"","title":"v0.1.1 (2019-03-24)"},{"location":"changelog/#new-features_7","text":"Release ViGear binaries on the Python Package Index (PyPI) Added new and configured setup.py & setup.cfg","title":"New Features"},{"location":"changelog/#bug-fixes_8","text":"Fixed PEP bugs: added and configured properly __init__.py in each folder Fixed PEP bugs: improved code Indentation Fixed wrong imports: replaced distutils.core with setuptools Fixed readme.md","title":"Bug-fixes"},{"location":"changelog/#v010-2019-03-17","text":"","title":"v0.1.0 (2019-03-17)"},{"location":"changelog/#new-features_8","text":"Initial Release Converted my imutils PR into Python Project. Renamed conventions and reformatted complete source-code from scratch. Added support for both python 2.7 and 3 legacies Added new multi-threaded CamGear, PiGear, and VideoGear APIs Added multi-platform compatibility Added robust & flexible control over the source in PiGear API.","title":"New Features"},{"location":"contribution/","text":"Contribution Overview \u00b6 Contributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features! Contribution Opportunities If you're looking for something to work on, check for the PR WELCOMED labeled issues on our GitHub Repository. \u2009 Submission Contexts \u00b6 Got a question or problem? \u00b6 For quick questions, please refrain from opening an issue, instead read our FAQ & Troubleshooting section or you can reach us on Gitter community channel. Found a typo? \u00b6 There's no need to contribute for some typos. Just reach us on Gitter community channel, We will correct them in (less than) no time. Found a bug? \u00b6 If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines . Missing a feature/improvement? \u00b6 Subscribe to our repository You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in VidGear. Learn more about it here \u27b6 You can request a new feature by submitting an issue to our GitHub Repository. If you would like to implement a new feature/improvement, please submit an issue with a proposal template for your work first, to be sure that it is benefit for everyone in the community, and then submit a Pull Request . Based on the type of request, you can consider following: Major Feature Requests: If you require a major feature for VidGear, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! Minor Feature Requests: Small features and bugs resolved on priority and can be directly submitted as a Pull Request. You just have to submit an issue to our GitHub Repository. \u2009 Submission Guidelines \u00b6 Submitting an Issue Guidelines Submitting Pull Request(PR) Guidelines","title":"Contribution Overview"},{"location":"contribution/#contribution-overview","text":"Contributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features! Contribution Opportunities If you're looking for something to work on, check for the PR WELCOMED labeled issues on our GitHub Repository.","title":"Contribution Overview"},{"location":"contribution/#submission-contexts","text":"","title":"Submission Contexts"},{"location":"contribution/#got-a-question-or-problem","text":"For quick questions, please refrain from opening an issue, instead read our FAQ & Troubleshooting section or you can reach us on Gitter community channel.","title":"Got a question or problem?"},{"location":"contribution/#found-a-typo","text":"There's no need to contribute for some typos. Just reach us on Gitter community channel, We will correct them in (less than) no time.","title":"Found a typo?"},{"location":"contribution/#found-a-bug","text":"If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines .","title":"Found a bug?"},{"location":"contribution/#missing-a-featureimprovement","text":"Subscribe to our repository You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in VidGear. Learn more about it here \u27b6 You can request a new feature by submitting an issue to our GitHub Repository. If you would like to implement a new feature/improvement, please submit an issue with a proposal template for your work first, to be sure that it is benefit for everyone in the community, and then submit a Pull Request . Based on the type of request, you can consider following: Major Feature Requests: If you require a major feature for VidGear, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! Minor Feature Requests: Small features and bugs resolved on priority and can be directly submitted as a Pull Request. You just have to submit an issue to our GitHub Repository.","title":"Missing a feature/improvement?"},{"location":"contribution/#submission-guidelines","text":"Submitting an Issue Guidelines Submitting Pull Request(PR) Guidelines","title":"Submission Guidelines"},{"location":"gears/","text":"Introduction \u00b6 Gears generalized workflow diagram Gears, What are these? \u00b6 VidGear is built on standalone classes - also known as Gears , each with some unique functionality. These Gears provides a powerful, easy-to-use, highly extensible, Multi-Threaded + Asyncio layer above many state-of-the-art specialized libraries to exploit their internal properties flexibly, while providing robust error-free and unparalleled real-time performance. Gears Classification \u00b6 These Gears can be classified as follows: A. VideoCapture Gears \u00b6 Basic Function: Retrieves numpy.ndarray frames from various sources. CamGear : Multi-threaded API targeting various IP-USB-Cameras/Network-Streams/YouTube-Video-URLs. PiGear : Multi-threaded API targeting various Raspberry Pi Camera Modules. ScreenGear : Multi-threaded ultra-fast Screencasting. VideoGear : Common API with internal Video Stabilizer wrapper. B. VideoWriter Gears \u00b6 Basic Function: Writes numpy.ndarray frames to a video file. WriteGear : Handles Flexible Lossless Video Encoding and Compression. C. Streaming Gears \u00b6 Basic Function: Transcodes videos/audio files & numpy.ndarray frames for HTTP streaming. StreamGear : Handles Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. D. Network Gears \u00b6 Basic Function: Sends/Receives numpy.ndarray frames over the network. NetGear : Handles high-performance video-frames & data transfer between interconnecting systems over the network. Asynchronous I/O Network Gears: WebGear : ASGI Video Server that can send live video-frames to any web browser on the network. NetGear_Async : Immensely Memory-efficient Asyncio video-frames network messaging framework.","title":"Introduction"},{"location":"gears/#introduction","text":"Gears generalized workflow diagram","title":"Introduction"},{"location":"gears/#gears-what-are-these","text":"VidGear is built on standalone classes - also known as Gears , each with some unique functionality. These Gears provides a powerful, easy-to-use, highly extensible, Multi-Threaded + Asyncio layer above many state-of-the-art specialized libraries to exploit their internal properties flexibly, while providing robust error-free and unparalleled real-time performance.","title":"Gears, What are these?"},{"location":"gears/#gears-classification","text":"These Gears can be classified as follows:","title":"Gears Classification"},{"location":"gears/#a-videocapture-gears","text":"Basic Function: Retrieves numpy.ndarray frames from various sources. CamGear : Multi-threaded API targeting various IP-USB-Cameras/Network-Streams/YouTube-Video-URLs. PiGear : Multi-threaded API targeting various Raspberry Pi Camera Modules. ScreenGear : Multi-threaded ultra-fast Screencasting. VideoGear : Common API with internal Video Stabilizer wrapper.","title":"A. VideoCapture Gears"},{"location":"gears/#b-videowriter-gears","text":"Basic Function: Writes numpy.ndarray frames to a video file. WriteGear : Handles Flexible Lossless Video Encoding and Compression.","title":"B. VideoWriter Gears"},{"location":"gears/#c-streaming-gears","text":"Basic Function: Transcodes videos/audio files & numpy.ndarray frames for HTTP streaming. StreamGear : Handles Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats.","title":"C. Streaming Gears"},{"location":"gears/#d-network-gears","text":"Basic Function: Sends/Receives numpy.ndarray frames over the network. NetGear : Handles high-performance video-frames & data transfer between interconnecting systems over the network. Asynchronous I/O Network Gears: WebGear : ASGI Video Server that can send live video-frames to any web browser on the network. NetGear_Async : Immensely Memory-efficient Asyncio video-frames network messaging framework.","title":"D. Network Gears"},{"location":"help/","text":"Helping VidGear \u00b6 Liked VidGear? Would you like to help VidGear, other users, and the author? There are very simple ways to help us: Star VidGear on GitHub \u00b6 You can star VidGear on GitHub: Star It helps us a lot by making it easier for others to find & trust this library. Thanks! Help others with issues on GitHub \u00b6 You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: Issue Watch the GitHub repository \u00b6 You can \"watch\" VidGear Activities on GitHub: Watch When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request. You can try helping solving those issues, or give valuable feedback/review on new Pull Requests. Tweet about VidGear \u00b6 Tweet about VidGear and Spread the word: Tweet #vidgear Let others know how are you using VidGear and why you like it! Help Author \u00b6 You can financially support the author (me) through ko-fi: kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Thanks! Connect with Author \u00b6 You can connect with me, the author( Abhishek Thakur | @abhiTronix ): Follow me on GitHub: Follow me on Twitter. Follow @abhi_una12 Follow me on Linkedin:","title":"Helping VidGear"},{"location":"help/#helping-vidgear","text":"Liked VidGear? Would you like to help VidGear, other users, and the author? There are very simple ways to help us:","title":"Helping VidGear"},{"location":"help/#star-vidgear-on-github","text":"You can star VidGear on GitHub: Star It helps us a lot by making it easier for others to find & trust this library. Thanks!","title":"Star VidGear on GitHub"},{"location":"help/#help-others-with-issues-on-github","text":"You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: Issue","title":"Help others with issues on GitHub"},{"location":"help/#watch-the-github-repository","text":"You can \"watch\" VidGear Activities on GitHub: Watch When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request. You can try helping solving those issues, or give valuable feedback/review on new Pull Requests.","title":"Watch the GitHub repository"},{"location":"help/#tweet-about-vidgear","text":"Tweet about VidGear and Spread the word: Tweet #vidgear Let others know how are you using VidGear and why you like it!","title":"Tweet about VidGear"},{"location":"help/#help-author","text":"You can financially support the author (me) through ko-fi: kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Thanks!","title":"Help Author"},{"location":"help/#connect-with-author","text":"You can connect with me, the author( Abhishek Thakur | @abhiTronix ): Follow me on GitHub: Follow me on Twitter. Follow @abhi_una12 Follow me on Linkedin:","title":"Connect with Author"},{"location":"installation/","text":"Installation Overview \u00b6 Supported Systems \u00b6 VidGear is well-tested and supported on the following systems, with python 3.6+ and pip installed: Any Linux distro released in 2016 or later Windows 7 or later macOS 10.12.6 (Sierra) or later \u2009 Supported Python legacies \u00b6 Python 3.6+ are only supported legacies for installing Vidgear v0.1.7 and above. \u2009 Installation methods \u00b6 Install using pip (recommended) Install from source","title":"Installation Overview"},{"location":"installation/#installation-overview","text":"","title":"Installation Overview"},{"location":"installation/#supported-systems","text":"VidGear is well-tested and supported on the following systems, with python 3.6+ and pip installed: Any Linux distro released in 2016 or later Windows 7 or later macOS 10.12.6 (Sierra) or later","title":"Supported Systems"},{"location":"installation/#supported-python-legacies","text":"Python 3.6+ are only supported legacies for installing Vidgear v0.1.7 and above.","title":"Supported Python legacies"},{"location":"installation/#installation-methods","text":"Install using pip (recommended) Install from source","title":"Installation methods"},{"location":"license/","text":"License \u00b6 This library is released under the Apache 2.0 License . Copyright Notice \u00b6 Copyright (c) 2019-2020 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"license/#license","text":"This library is released under the Apache 2.0 License .","title":"License"},{"location":"license/#copyright-notice","text":"Copyright (c) 2019-2020 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Copyright Notice"},{"location":"switch_from_cv/","text":"Switching from OpenCV \u00b6 Switching OpenCV with VidGear APIs is usually a fairly painless process, and will just require changing a few lines in your python script. This document is intended to software developers who want to migrate their python code from OpenCV to VidGear APIs. Prior knowledge of Python and OpenCV won't be covered in this guide. Proficiency with OpenCV is a must in order understand this document. If you're just getting started with OpenCV with Python, then see here \u27b6 Switching VideoCapture APIs \u00b6 VidGear introduces many new state-of-the-art features, multi-device support, and multi-threaded performance upgrade for its VideoCapture Gears as compared to standard OpenCV's VideoCapture Class, while maintaining the same standard OpenCV-Python (Python API for OpenCV) coding syntax. Let's compare a bare-minimum python code for extracting frames out of webcam/USB camera (connected at index 0), between OpenCV's VideoCapture Class and VidGear's CamGear VideoCapture API side-by-side: CamGear share the same syntax as other VideoCapture Gears , thereby you can easily switch to any of those Gear in a similar manner. OpenCV VideoCapture Class # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () VidGear's CamGear API # import required libraries from vidgear.gears import CamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () and both syntax almost looks the same, easy, isn't it? Now, checkout other VideoCapture Gears \u27b6 \u2009 Differences \u00b6 Let's breakdown a few noteworthy difference in syntaxes: Task OpenCV VideoCapture Class VidGear's CamGear API Initiating stream = cv2 . VideoCapture ( 0 ) stream = CamGear ( source = 0 ) . start () Reading frames ( grabbed , frame ) = stream . read () frame = stream . read () Checking empty frame if not grabbed : if frame is None : Terminating stream . release () stream . stop () Switching VideoWriter API \u00b6 VidGear with its WriteGear API, provide a complete, flexible & robust wrapper around FFmpeg - a leading multimedia framework, processes real-time video frames into a lossless compressed format with any suitable specification and many more, as compared to standard OpenCV's VideoWriter Class , while maintaining the same standard OpenCV-Python coding syntax. Let's extend previous bare-minimum python code to save extracted frames to disk as a valid file, with OpenCV's VideoWriter Class and VidGear's WriteGear API (with FFmpeg backend) , compared side-to-side: WriteGear API also provides backend for OpenCV's VideoWriter Class. More information here \u27b6 OpenCV VideoWriter Class # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define the codec and create VideoWriter object with suitable output filename for e.g. `Output.avi` fourcc = cv2 . VideoWriter_fourcc ( * 'XVID' ) writer = cv2 . VideoWriter ( 'output.avi' , fourcc , 20.0 , ( 640 , 480 )) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . release () VidGear's WriteGear API # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # Define WriteGear Object with suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Noticed WriteGear's coding syntax looks similar but less complex? Now, checkout more examples of WriteGear API (with FFmpeg backend) here \u27b6 \u2009 Differences \u00b6 Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoWriter Class VidGear's WriteGear API Initiating writer = cv2 . VideoWriter ( 'output.avi' , cv2 . VideoWriter_fourcc ( * 'XVID' ), 20.0 , ( 640 , 480 )) writer = WriteGear ( output_filename = 'Output.mp4' ) Writing frames writer . write ( frame ) writer . write ( frame ) Terminating writer . release () writer . close ()","title":"Switching from OpenCV"},{"location":"switch_from_cv/#switching-from-opencv","text":"Switching OpenCV with VidGear APIs is usually a fairly painless process, and will just require changing a few lines in your python script. This document is intended to software developers who want to migrate their python code from OpenCV to VidGear APIs. Prior knowledge of Python and OpenCV won't be covered in this guide. Proficiency with OpenCV is a must in order understand this document. If you're just getting started with OpenCV with Python, then see here \u27b6","title":"Switching from OpenCV"},{"location":"switch_from_cv/#switching-videocapture-apis","text":"VidGear introduces many new state-of-the-art features, multi-device support, and multi-threaded performance upgrade for its VideoCapture Gears as compared to standard OpenCV's VideoCapture Class, while maintaining the same standard OpenCV-Python (Python API for OpenCV) coding syntax. Let's compare a bare-minimum python code for extracting frames out of webcam/USB camera (connected at index 0), between OpenCV's VideoCapture Class and VidGear's CamGear VideoCapture API side-by-side: CamGear share the same syntax as other VideoCapture Gears , thereby you can easily switch to any of those Gear in a similar manner. OpenCV VideoCapture Class # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () VidGear's CamGear API # import required libraries from vidgear.gears import CamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () and both syntax almost looks the same, easy, isn't it? Now, checkout other VideoCapture Gears \u27b6","title":"Switching VideoCapture APIs"},{"location":"switch_from_cv/#differences","text":"Let's breakdown a few noteworthy difference in syntaxes: Task OpenCV VideoCapture Class VidGear's CamGear API Initiating stream = cv2 . VideoCapture ( 0 ) stream = CamGear ( source = 0 ) . start () Reading frames ( grabbed , frame ) = stream . read () frame = stream . read () Checking empty frame if not grabbed : if frame is None : Terminating stream . release () stream . stop ()","title":"Differences"},{"location":"switch_from_cv/#switching-videowriter-api","text":"VidGear with its WriteGear API, provide a complete, flexible & robust wrapper around FFmpeg - a leading multimedia framework, processes real-time video frames into a lossless compressed format with any suitable specification and many more, as compared to standard OpenCV's VideoWriter Class , while maintaining the same standard OpenCV-Python coding syntax. Let's extend previous bare-minimum python code to save extracted frames to disk as a valid file, with OpenCV's VideoWriter Class and VidGear's WriteGear API (with FFmpeg backend) , compared side-to-side: WriteGear API also provides backend for OpenCV's VideoWriter Class. More information here \u27b6 OpenCV VideoWriter Class # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define the codec and create VideoWriter object with suitable output filename for e.g. `Output.avi` fourcc = cv2 . VideoWriter_fourcc ( * 'XVID' ) writer = cv2 . VideoWriter ( 'output.avi' , fourcc , 20.0 , ( 640 , 480 )) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . release () VidGear's WriteGear API # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # Define WriteGear Object with suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Noticed WriteGear's coding syntax looks similar but less complex? Now, checkout more examples of WriteGear API (with FFmpeg backend) here \u27b6","title":"Switching VideoWriter API"},{"location":"switch_from_cv/#differences_1","text":"Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoWriter Class VidGear's WriteGear API Initiating writer = cv2 . VideoWriter ( 'output.avi' , cv2 . VideoWriter_fourcc ( * 'XVID' ), 20.0 , ( 640 , 480 )) writer = WriteGear ( output_filename = 'Output.mp4' ) Writing frames writer . write ( frame ) writer . write ( frame ) Terminating writer . release () writer . close ()","title":"Differences"},{"location":"bonus/TQM/","text":"Threaded Queue Mode \u00b6 Overview \u00b6 Threaded-Queue-Mode generalized timing diagram Threaded Queue Mode is designed exclusively for VidGear's Videocapture and Network Gears (namely CamGear, ScreenGear, VideoGear, and NetGear(Client's end)) , for achieving high-performance, synchronized, and error-free frame handling with its Multi-Threaded APIs. Threaded-Queue-Mode is enabled by default for any input video stream - including Network Streams, except for any Camera Device. What does Threaded-Queue-Mode exactly do? \u00b6 Threaded-Queue-Mode helps VidGear do the Video Processing tasks in a well-organized, and most competent way possible. Multi-Threading \u00b6 Depending on the video quality, source, and physical hardware of our machine, much of the I/O bound memory is consumed by blocking OpenCV VideoCapture API's read() method, for reading/decoding next frame from source. In simple words, the main thread of our script is completely blocked, until the frame is read from source and thereby returned. VidGear's APIs in layman's words employs Multi-Threading to separate various tasks( such as frame-decoding ) to multiple independent threads. These multi-threads helps VidGear execute different Video Processing I/O-bound operations at the same time, by overlapping the waiting times. In this way, VidGear keeps on processing frames faster in background( daemon ) without having to wait for blocking I/O operations, and doesn't get effected by how sluggish our main python thread is. Monitored Fix-Sized Deques \u00b6 Multi-threading is easy, but it may have some undesired effects like frame-skipping, deadlocks, and race conditions, etc. that frequently result in random, intermittent bugs that can be quite difficult to find. Therefore to prevent these problem, in VidGear, we introduced this Thread-Queue-Mode, that utilizes monitored, thread-safe, memory efficient, and fixed-sized deques (with approximately the same O(1) performance in either direction) , that always maintains a fixed-length of frame buffer in the memory, and blocks the thread if the queue is full, or otherwise pops out the frames synchronously and efficiently without any obstructions. In this way, monitored Deques stops multiple threads from accessing the same source simultaneously, and thus preventing Global Interpreter Lock (aka GIL) too. Features \u00b6 Enables Blocking, Sequential and Threaded LIFO Frame Handling. Sequentially adds and releases frames to/from deque and handles the overflow of this queue. Utilizes thread-safe, memory efficient deques that appends and pops frames with same O(1) performance from either side. Requires less RAM at due to buffered frames in the deque . Manually disabling Threaded Queue Mode: \u00b6 To manually disable Threaded Queue Mode, VidGear provides following attribute for options dictionary parameter in respective API: Important Warning This THREADED_QUEUE_MODE attribute does NOT work with Live feed, such as Camera Devices/Modules. This THREADED_QUEUE_MODE attribute is NOT supported by ScreenGear & NetGear APIs, as Threaded Queue Mode is essential for their core operations. Disabling Threaded Queue Mode may result in UNDESIRED BEHAVIORS AND BUGS such as Non-Blocking frame handling, Frame-skipping, etc. More insight can be found here \u27b6 . THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode, to manually disable it: options = { 'THREADED_QUEUE_MODE' : False } #to disable Threaded Queue Mode. and you can pass it to options dictionary parameter of the respective API.","title":"Threaded Queue Mode"},{"location":"bonus/TQM/#threaded-queue-mode","text":"","title":"Threaded Queue Mode"},{"location":"bonus/TQM/#overview","text":"Threaded-Queue-Mode generalized timing diagram Threaded Queue Mode is designed exclusively for VidGear's Videocapture and Network Gears (namely CamGear, ScreenGear, VideoGear, and NetGear(Client's end)) , for achieving high-performance, synchronized, and error-free frame handling with its Multi-Threaded APIs. Threaded-Queue-Mode is enabled by default for any input video stream - including Network Streams, except for any Camera Device.","title":"Overview"},{"location":"bonus/TQM/#what-does-threaded-queue-mode-exactly-do","text":"Threaded-Queue-Mode helps VidGear do the Video Processing tasks in a well-organized, and most competent way possible.","title":"What does Threaded-Queue-Mode exactly do?"},{"location":"bonus/TQM/#multi-threading","text":"Depending on the video quality, source, and physical hardware of our machine, much of the I/O bound memory is consumed by blocking OpenCV VideoCapture API's read() method, for reading/decoding next frame from source. In simple words, the main thread of our script is completely blocked, until the frame is read from source and thereby returned. VidGear's APIs in layman's words employs Multi-Threading to separate various tasks( such as frame-decoding ) to multiple independent threads. These multi-threads helps VidGear execute different Video Processing I/O-bound operations at the same time, by overlapping the waiting times. In this way, VidGear keeps on processing frames faster in background( daemon ) without having to wait for blocking I/O operations, and doesn't get effected by how sluggish our main python thread is.","title":"Multi-Threading"},{"location":"bonus/TQM/#monitored-fix-sized-deques","text":"Multi-threading is easy, but it may have some undesired effects like frame-skipping, deadlocks, and race conditions, etc. that frequently result in random, intermittent bugs that can be quite difficult to find. Therefore to prevent these problem, in VidGear, we introduced this Thread-Queue-Mode, that utilizes monitored, thread-safe, memory efficient, and fixed-sized deques (with approximately the same O(1) performance in either direction) , that always maintains a fixed-length of frame buffer in the memory, and blocks the thread if the queue is full, or otherwise pops out the frames synchronously and efficiently without any obstructions. In this way, monitored Deques stops multiple threads from accessing the same source simultaneously, and thus preventing Global Interpreter Lock (aka GIL) too.","title":"Monitored Fix-Sized Deques"},{"location":"bonus/TQM/#features","text":"Enables Blocking, Sequential and Threaded LIFO Frame Handling. Sequentially adds and releases frames to/from deque and handles the overflow of this queue. Utilizes thread-safe, memory efficient deques that appends and pops frames with same O(1) performance from either side. Requires less RAM at due to buffered frames in the deque .","title":"Features"},{"location":"bonus/TQM/#manually-disabling-threaded-queue-mode","text":"To manually disable Threaded Queue Mode, VidGear provides following attribute for options dictionary parameter in respective API: Important Warning This THREADED_QUEUE_MODE attribute does NOT work with Live feed, such as Camera Devices/Modules. This THREADED_QUEUE_MODE attribute is NOT supported by ScreenGear & NetGear APIs, as Threaded Queue Mode is essential for their core operations. Disabling Threaded Queue Mode may result in UNDESIRED BEHAVIORS AND BUGS such as Non-Blocking frame handling, Frame-skipping, etc. More insight can be found here \u27b6 . THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode, to manually disable it: options = { 'THREADED_QUEUE_MODE' : False } #to disable Threaded Queue Mode. and you can pass it to options dictionary parameter of the respective API.","title":"Manually disabling Threaded Queue Mode:"},{"location":"bonus/colorspace_manipulation/","text":"Colorspace Manipulation for VideoCapture Gears \u00b6 Source ColorSpace manipulation \u00b6 All VidGear's VideoCapture Gears, namely CamGear, PiGear, ScreenGear, and VideoGear - internally supports Source ColorSpace manipulation. There are two ways to alter source colorspace: Using colorspace parameter \u00b6 Primarily, the safest way is by colorspace (string) parameter of the respective VideoCapture API, that can be used to easily alter the colorspace of the input source, during initialization. But on the downside, colorspace parameter value CANNOT be changed/altered at runtime. All possible values for this parameter are discussed below \u27b6 Using color_space global variable \u00b6 Alternatively, a more direct approach is by using color_space (integer) global variable the respective VideoCapture API, can be used for directly changing the source colorspace at runtime. It can be used in conjunction with colorspace parameter easily. Supported Colorspace Conversions Any conversion from default Source colorspace (i.e. BGR in case of OpenCV) , to any other colorspace and vice-versa (use None to revert) , is supported. Important Information Using color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . Any incorrect or None-type value, will immediately revert the colorspace to default (i.e. BGR ) . Using color_space global variable with Threaded Queue Mode may have minor lag, User discretion is advised. Tip It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Supported colorspace parameter values \u00b6 All supported string values for colorspace parameter are as follows: You can check all OpenCV Colorspace Conversion Codes here \u27b6 . Supported Conversion Values Description COLOR_BGR2BGRA BGR to BGRA COLOR_BGR2RGBA BGR to RGBA COLOR_BGR2RGB BGR to RGB backward conversions to RGB/BGR COLOR_BGR2GRAY BGR to GRAY COLOR_BGR2BGR565 BGR to BGR565 COLOR_BGR2BGR555 BGR to BGR555 COLOR_BGR2XYZ BGR to CIE XYZ COLOR_BGR2YCrCb BGR to luma-chroma (aka YCC) COLOR_BGR2HSV BGR to HSV (hue saturation value) COLOR_BGR2Lab BGR to CIE Lab COLOR_BGR2Luv BGR to CIE Luv COLOR_BGR2HLS BGR to HLS (hue lightness saturation) COLOR_BGR2HSV_FULL BGR to HSV_FULL COLOR_BGR2HLS_FULL BGR to HLS_FULL COLOR_BGR2YUV BGR to YUV COLOR_BGR2YUV_I420 BGR to YUV 4:2:0 family COLOR_BGR2YUV_IYUV BGR to IYUV COLOR_BGR2YUV_YV12 BGR to YUV_YV12 None Back to default colorspace (i.e. BGR) Usage examples \u00b6 Using CamGear with Direct Colorspace Manipulation \u00b6 The complete usage example can be found here \u27b6 Using PiGear with Direct Colorspace Manipulation \u00b6 The complete usage example can be found here \u27b6 Using VideoGear with Colorspace Manipulation \u00b6 The complete usage example can be found here \u27b6 Using ScreenGear with Direct Colorspace Manipulation \u00b6 The complete usage example can be found here \u27b6","title":"Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#colorspace-manipulation-for-videocapture-gears","text":"","title":"Colorspace Manipulation for VideoCapture Gears"},{"location":"bonus/colorspace_manipulation/#source-colorspace-manipulation","text":"All VidGear's VideoCapture Gears, namely CamGear, PiGear, ScreenGear, and VideoGear - internally supports Source ColorSpace manipulation. There are two ways to alter source colorspace:","title":"Source ColorSpace manipulation"},{"location":"bonus/colorspace_manipulation/#using-colorspace-parameter","text":"Primarily, the safest way is by colorspace (string) parameter of the respective VideoCapture API, that can be used to easily alter the colorspace of the input source, during initialization. But on the downside, colorspace parameter value CANNOT be changed/altered at runtime. All possible values for this parameter are discussed below \u27b6","title":"Using colorspace parameter"},{"location":"bonus/colorspace_manipulation/#using-color_space-global-variable","text":"Alternatively, a more direct approach is by using color_space (integer) global variable the respective VideoCapture API, can be used for directly changing the source colorspace at runtime. It can be used in conjunction with colorspace parameter easily. Supported Colorspace Conversions Any conversion from default Source colorspace (i.e. BGR in case of OpenCV) , to any other colorspace and vice-versa (use None to revert) , is supported. Important Information Using color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . Any incorrect or None-type value, will immediately revert the colorspace to default (i.e. BGR ) . Using color_space global variable with Threaded Queue Mode may have minor lag, User discretion is advised. Tip It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Using color_space global variable"},{"location":"bonus/colorspace_manipulation/#supported-colorspace-parameter-values","text":"All supported string values for colorspace parameter are as follows: You can check all OpenCV Colorspace Conversion Codes here \u27b6 . Supported Conversion Values Description COLOR_BGR2BGRA BGR to BGRA COLOR_BGR2RGBA BGR to RGBA COLOR_BGR2RGB BGR to RGB backward conversions to RGB/BGR COLOR_BGR2GRAY BGR to GRAY COLOR_BGR2BGR565 BGR to BGR565 COLOR_BGR2BGR555 BGR to BGR555 COLOR_BGR2XYZ BGR to CIE XYZ COLOR_BGR2YCrCb BGR to luma-chroma (aka YCC) COLOR_BGR2HSV BGR to HSV (hue saturation value) COLOR_BGR2Lab BGR to CIE Lab COLOR_BGR2Luv BGR to CIE Luv COLOR_BGR2HLS BGR to HLS (hue lightness saturation) COLOR_BGR2HSV_FULL BGR to HSV_FULL COLOR_BGR2HLS_FULL BGR to HLS_FULL COLOR_BGR2YUV BGR to YUV COLOR_BGR2YUV_I420 BGR to YUV 4:2:0 family COLOR_BGR2YUV_IYUV BGR to IYUV COLOR_BGR2YUV_YV12 BGR to YUV_YV12 None Back to default colorspace (i.e. BGR)","title":"Supported colorspace parameter values"},{"location":"bonus/colorspace_manipulation/#usage-examples","text":"","title":"Usage examples"},{"location":"bonus/colorspace_manipulation/#using-camgear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using CamGear with Direct Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-pigear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using PiGear with Direct Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-videogear-with-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using VideoGear with Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-screengear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using ScreenGear with Direct Colorspace Manipulation"},{"location":"bonus/reference/camgear/","text":"All CamGear Class parameters are explained here \u27b6 \u00b6 CamGear API supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture Class with direct access to almost all of its available parameters, and also internally employs pafy with youtube-dl backend for enabling seamless live YouTube streaming . CamGear relies exclusively on Threaded Queue mode for threaded, error-free and synchronized frame handling. read ( self ) \u00b6 Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/camgear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __threaded_queue_mode : if len ( self . __queue ) > 0 : return self . __queue . popleft () return self . frame start ( self ) \u00b6 Launches the internal Threaded Frames Extractor daemon Returns: A reference to the CamGear class object. Source code in vidgear/gears/camgear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"CamGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self stop ( self ) \u00b6 Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/camgear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" if self . __logging : logger . debug ( \"Terminating processes.\" ) # terminate Threaded queue mode separately if self . __threaded_queue_mode and not ( self . __queue is None ): if len ( self . __queue ) > 0 : self . __queue . clear () self . __threaded_queue_mode = False self . frame = None # indicate that the thread should be terminate self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : self . __thread . join () # properly handle thread exit if self . __youtube_mode : # kill thread-lock in youtube mode self . __thread = None","title":"camgear.py"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear","text":"CamGear API supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture Class with direct access to almost all of its available parameters, and also internally employs pafy with youtube-dl backend for enabling seamless live YouTube streaming . CamGear relies exclusively on Threaded Queue mode for threaded, error-free and synchronized frame handling.","title":"vidgear.gears.camgear.CamGear"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.read","text":"Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/camgear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __threaded_queue_mode : if len ( self . __queue ) > 0 : return self . __queue . popleft () return self . frame","title":"read()"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.start","text":"Launches the internal Threaded Frames Extractor daemon Returns: A reference to the CamGear class object. Source code in vidgear/gears/camgear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"CamGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self","title":"start()"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.stop","text":"Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/camgear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" if self . __logging : logger . debug ( \"Terminating processes.\" ) # terminate Threaded queue mode separately if self . __threaded_queue_mode and not ( self . __queue is None ): if len ( self . __queue ) > 0 : self . __queue . clear () self . __threaded_queue_mode = False self . frame = None # indicate that the thread should be terminate self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : self . __thread . join () # properly handle thread exit if self . __youtube_mode : # kill thread-lock in youtube mode self . __thread = None","title":"stop()"},{"location":"bonus/reference/helper/","text":"\u00b6 logger_handler \u00b6 Returns a color formatted logger handler Returns: A logger handler Source code in vidgear/gears/helper.py def logger_handler (): \"\"\" ### logger_handler Returns a color formatted logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" %(bold_blue)s%(name)s%(reset)s :: %(log_color)s%(levelname)s%(reset)s :: %(message)s \" , datefmt = None , reset = True , log_colors = { \"INFO\" : \"bold_green\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_purple\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, ) # define handler handler = log . StreamHandler () handler . setFormatter ( formatter ) return handler \u00b6 check_CV_version \u00b6 Returns: OpenCV's version first bit Source code in vidgear/gears/helper.py def check_CV_version (): \"\"\" ### check_CV_version **Returns:** OpenCV's version first bit \"\"\" if parse_version ( cv2 . __version__ ) >= parse_version ( \"4\" ): return 4 else : return 3 \u00b6 mkdir_safe \u00b6 Safely creates directory at given path. Parameters: Name Type Description Default dir_path string path to the directory required logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def mkdir_safe ( dir_path , logging = False ): \"\"\" ### mkdir_safe Safely creates directory at given path. Parameters: dir_path (string): path to the directory logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir_path ) if logging : logger . debug ( \"Created directory at ` {} `\" . format ( dir_path )) except OSError as e : if e . errno != errno . EEXIST : raise if logging : logger . debug ( \"Directory already exists at ` {} `\" . format ( dir_path )) \u00b6 delete_safe \u00b6 Safely deletes files with given extensions at given path. Parameters: Name Type Description Default dir_path string path to the directory required extensions list list of extensions to be deleted [] logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def delete_safe ( dir_path , extensions = [], logging = False ): \"\"\" ### delete_safe Safely deletes files with given extensions at given path. Parameters: dir_path (string): path to the directory extensions (list): list of extensions to be deleted logging (bool): enables logging for its operations \"\"\" if not extensions or not os . path . exists ( dir_path ): logger . warning ( \"Invalid input provided for deleting!\" ) return if logging : logger . debug ( \"Clearing Assets at ` {} `!\" . format ( dir_path )) for ext in extensions : files_ext = [ os . path . join ( dir_path , f ) for f in os . listdir ( dir_path ) if f . endswith ( ext ) ] for file in files_ext : os . remove ( file ) if logging : logger . debug ( \"Deleted file: ` {} `\" . format ( file )) \u00b6 capPropId \u00b6 Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: Name Type Description Default property string inputs OpenCV property as string. required Returns: Resultant integer value. Source code in vidgear/gears/helper.py def capPropId ( property ): \"\"\" ### capPropId Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: property (string): inputs OpenCV property as string. **Returns:** Resultant integer value. \"\"\" integer_value = 0 try : integer_value = getattr ( cv2 , property ) except Exception as e : logger . exception ( str ( e )) logger . critical ( \"` {} ` is not a valid OpenCV property!\" . format ( property )) return None return integer_value \u00b6 reducer \u00b6 Reduces frame size by given percentage Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/helper.py def reducer ( frame = None , percentage = 0 ): \"\"\" ### reducer Reduces frame size by given percentage Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = cv2 . INTER_LANCZOS4 ) \u00b6 dict2Args \u00b6 Converts dictionary attributes to list(args) Parameters: Name Type Description Default param_dict dict Parameters dictionary required Returns: Arguments list Source code in vidgear/gears/helper.py def dict2Args ( param_dict ): \"\"\" ### dict2Args Converts dictionary attributes to list(args) Parameters: param_dict (dict): Parameters dictionary **Returns:** Arguments list \"\"\" args = [] for key in param_dict . keys (): if key in [ \"-clones\" ] or key . startswith ( \"-core\" ): if isinstance ( param_dict [ key ], list ): args . extend ( param_dict [ key ]) else : logger . warning ( \" {} with invalid datatype:` {} `, Skipped!\" . format ( \"Core parameter\" if key . startswith ( \"-core\" ) else \"Clone\" , param_dict [ key ], ) ) else : args . append ( key ) args . append ( str ( param_dict [ key ])) return args \u00b6 get_valid_ffmpeg_path \u00b6 Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' logging bool enables logging for its operations False Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , logging = False ): \"\"\" ### get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ logging (bool): enables logging for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () if logging : logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred if logging : logger . exception ( str ( e )) logger . debug ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False if logging : logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False if logging : logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" if logging : logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , logging = logging ) else False \u00b6 download_ffmpeg_binaries \u00b6 Generates FFmpeg Static Binaries for windows(if not available) Parameters: Name Type Description Default path string path for downloading custom FFmpeg executables required os_windows boolean is running on Windows OS? False os_bit string 32-bit or 64-bit OS? '' Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def download_ffmpeg_binaries ( path , os_windows = False , os_bit = \"\" ): \"\"\" ### download_ffmpeg_binaries Generates FFmpeg Static Binaries for windows(if not available) Parameters: path (string): path for downloading custom FFmpeg executables os_windows (boolean): is running on Windows OS? os_bit (string): 32-bit or 64-bit OS? **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if os_windows and os_bit : # initialize variables file_url = \"https://ffmpeg.zeranoe.com/builds/ {} /static/ffmpeg-latest- {} -static.zip\" . format ( os_bit , os_bit ) file_name = os . path . join ( os . path . abspath ( path ), \"ffmpeg-latest- {} -static.zip\" . format ( os_bit ) ) file_path = os . path . join ( os . path . abspath ( path ), \"ffmpeg-latest- {} -static/bin/ffmpeg.exe\" . format ( os_bit ), ) base_path , _ = os . path . split ( file_name ) # extract file base path # check if file already exists if os . path . isfile ( file_path ): final_path += file_path # skip download if does else : # import libs import zipfile # check if given path has write access assert os . access ( path , os . W_OK ), ( \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \" + path ) # remove leftovers if exists if os . path . isfile ( file_name ): os . remove ( file_name ) # download and write file to the given path with open ( file_name , \"wb\" ) as f : logger . debug ( \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries now. Please wait...\" ) try : response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () except Exception as e : logger . exception ( str ( e )) logger . warning ( \"Downloading Failed. Trying GitHub mirror now!\" ) file_url = \"https://raw.githubusercontent.com/abhiTronix/ffmpeg-static-builds/master/windows/ffmpeg-latest- {} -static.zip\" . format ( os_bit , os_bit ) response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 4096 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () logger . debug ( \"Extracting executables.\" ) with zipfile . ZipFile ( file_name , \"r\" ) as zip_ref : zip_ref . extractall ( base_path ) # perform cleaning os . remove ( file_name ) logger . debug ( \"FFmpeg binaries for Windows configured successfully!\" ) final_path += file_path # return final path return final_path \u00b6 validate_ffmpeg \u00b6 Validate FFmeg Binaries. returns True if tests are passed. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def validate_ffmpeg ( path , logging = False ): \"\"\" ### validate_ffmpeg Validate FFmeg Binaries. returns `True` if tests are passed. Parameters: path (string): absolute path of FFmpeg binaries logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" try : # get the FFmpeg version version = check_output ([ path , \"-version\" ]) firstline = version . split ( b \" \\n \" )[ 0 ] version = firstline . split ( b \" \" )[ 2 ] . strip () if logging : # log if test are passed logger . debug ( \"FFmpeg validity Test Passed!\" ) logger . debug ( \"Found valid FFmpeg Version: ` {} ` installed on this system\" . format ( version ) ) except Exception as e : # log if test are failed if logging : logger . exception ( str ( e )) logger . warning ( \"FFmpeg validity Test Failed!\" ) return False return True \u00b6 check_output \u00b6 Returns stdin output from subprocess module Source code in vidgear/gears/helper.py def check_output ( * args , ** kwargs ): \"\"\" ### check_output Returns stdin output from subprocess module \"\"\" # import libs import subprocess as sp # handle additional params retrieve_stderr = kwargs . pop ( \"force_retrieve_stderr\" , False ) # execute command in subprocess process = sp . Popen ( stdout = sp . PIPE , stderr = sp . DEVNULL if not ( retrieve_stderr ) else sp . PIPE , * args , ** kwargs ) output , stderr = process . communicate () retcode = process . poll () # handle return code if retcode and not ( retrieve_stderr ): cmd = kwargs . get ( \"args\" ) if cmd is None : cmd = args [ 0 ] error = sp . CalledProcessError ( retcode , cmd ) error . output = output raise error return output if not ( retrieve_stderr ) else stderr \u00b6 generate_auth_certificates \u00b6 Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: Name Type Description Default path string path for generating CURVE key-pairs required overwrite boolean overwrite existing key-pairs or not? False logging bool enables logging for its operations False Returns: A valid CURVE key-pairs path as string. Source code in vidgear/gears/helper.py def generate_auth_certificates ( path , overwrite = False , logging = False ): \"\"\" ### generate_auth_certificates Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: path (string): path for generating CURVE key-pairs overwrite (boolean): overwrite existing key-pairs or not? logging (bool): enables logging for its operations **Returns:** A valid CURVE key-pairs path as string. \"\"\" # import necessary libs import shutil import zmq.auth # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # generate keys dir keys_dir = os . path . join ( path , \"keys\" ) mkdir_safe ( keys_dir , logging = logging ) # generate separate public and private key dirs public_keys_dir = os . path . join ( keys_dir , \"public_keys\" ) secret_keys_dir = os . path . join ( keys_dir , \"private_keys\" ) # check if overwriting is allowed if overwrite : # delete previous certificates for dirs in [ public_keys_dir , secret_keys_dir ]: if os . path . exists ( dirs ): shutil . rmtree ( dirs ) mkdir_safe ( dirs , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ): shutil . move ( os . path . join ( keys_dir , key_file ), public_keys_dir ) elif key_file . endswith ( \".key_secret\" ): shutil . move ( os . path . join ( keys_dir , key_file ), secret_keys_dir ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): os . remove ( redundant_key ) else : # otherwise validate available keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # check if all valid keys are found if status_private_keys and status_public_keys : return ( keys_dir , secret_keys_dir , public_keys_dir ) # check if valid public keys are found if not ( status_public_keys ): mkdir_safe ( public_keys_dir , logging = logging ) # check if valid private keys are found if not ( status_private_keys ): mkdir_safe ( secret_keys_dir , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ) and not ( status_public_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( public_keys_dir , \".\" ) ) elif key_file . endswith ( \".key_secret\" ) and not ( status_private_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( secret_keys_dir , \".\" ) ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): os . remove ( redundant_key ) # validate newly generated keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # raise error is validation test fails if not ( status_private_keys ) or not ( status_public_keys ): raise RuntimeError ( \"[Helper:ERROR] :: Unable to generate valid ZMQ authentication certificates at ` {} `!\" . format ( keys_dir ) ) # finally return valid key paths return ( keys_dir , secret_keys_dir , public_keys_dir ) \u00b6 validate_audio \u00b6 Validates audio by retrieving audio-bitrate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required file_path string absolute path to file to be validated. None Returns: A string value, confirming whether audio is present, or not?. Source code in vidgear/gears/helper.py def validate_audio ( path , file_path = None ): \"\"\" ### validate_audio Validates audio by retrieving audio-bitrate from file. Parameters: path (string): absolute path of FFmpeg binaries file_path (string): absolute path to file to be validated. **Returns:** A string value, confirming whether audio is present, or not?. \"\"\" if file_path is None or not ( file_path ): logger . warning ( \"File path is empty!\" ) return \"\" # extract audio sample-rate from metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , file_path ], force_retrieve_stderr = True ) audio_bitrate = re . findall ( r \"fltp,\\s[0-9]+\\s\\w\\w[/]s\" , metadata . decode ( \"utf-8\" )) if audio_bitrate : filtered = audio_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] final_bitrate = \" {}{} \" . format ( int ( filtered [ 0 ] . strip ()), \"k\" if ( filtered [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) return final_bitrate else : return \"\" \u00b6 extract_time \u00b6 Extract time from give string value. Parameters: Name Type Description Default value string string value. required Returns: Time (in seconds) as integer. Source code in vidgear/gears/helper.py def extract_time ( value ): \"\"\" ### extract_time Extract time from give string value. Parameters: value (string): string value. **Returns:** Time _(in seconds)_ as integer. \"\"\" if not ( value ): logger . warning ( \"Value is empty!\" ) return 0 else : stripped_data = value . strip () t_duration = re . findall ( r \"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d)\" , stripped_data ) return ( sum ( int ( x ) * 60 ** i for i , x in enumerate ( reversed ( t_duration [ 0 ] . split ( \":\" ))) ) if t_duration else 0 ) \u00b6 validate_video \u00b6 Validates video by retrieving resolution/size and framerate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required video_path string absolute path to Video. None Returns: A dictionary of retieved Video resolution (as tuple(width, height)) and framerate (as float) . Source code in vidgear/gears/helper.py def validate_video ( path , video_path = None ): \"\"\" ### validate_video Validates video by retrieving resolution/size and framerate from file. Parameters: path (string): absolute path of FFmpeg binaries video_path (string): absolute path to Video. **Returns:** A dictionary of retieved Video resolution _(as tuple(width, height))_ and framerate _(as float)_. \"\"\" if video_path is None or not ( video_path ): logger . warning ( \"Video path is empty!\" ) return None # extract metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , video_path ], force_retrieve_stderr = True ) # clean and search stripped_data = [ x . decode ( \"utf-8\" ) . strip () for x in metadata . split ( b \" \\n \" )] result = {} for data in stripped_data : output_a = re . findall ( r \"(\\d+)x(\\d+)\" , data ) output_b = re . findall ( r \"\\d+(?:\\.\\d+)?\\sfps\" , data ) if len ( result ) == 2 : break if output_b and not \"framerate\" in result : result [ \"framerate\" ] = re . findall ( r \"[\\d\\.\\d]+\" , output_b [ 0 ])[ 0 ] if output_a and not \"resolution\" in result : result [ \"resolution\" ] = output_a [ - 1 ] # return values return result if ( len ( result ) == 2 ) else None \u00b6 is_valid_url \u00b6 Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required url string URL to be validated None logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def is_valid_url ( path , url = None , logging = False ): \"\"\" ### is_valid_url Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: path (string): absolute path of FFmpeg binaries url (string): URL to be validated logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if url is None or not ( url ): logger . warning ( \"URL is empty!\" ) return False # extract URL scheme extracted_scheme_url = url . split ( \"://\" , 1 )[ 0 ] # extract all FFmpeg supported protocols protocols = check_output ([ path , \"-hide_banner\" , \"-protocols\" ]) splitted = protocols . split ( b \" \\n \" ) supported_protocols = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ 2 : len ( splitted ) - 1 ] ] # Test and return result whether scheme is supported if extracted_scheme_url and extracted_scheme_url in supported_protocols : if logging : logger . debug ( \"URL scheme ` {} ` is supported by FFmpeg.\" . format ( extracted_scheme_url ) ) return True else : logger . warning ( \"URL scheme ` {} ` is not supported by FFmpeg!\" . format ( extracted_scheme_url ) ) return False \u00b6 get_video_bitrate \u00b6 Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: Name Type Description Default width int video-width required height int video-height required fps float video-framerate required bpp float bit-per-pixels value required Returns: Video bitrate (in Kbps) as integer. Source code in vidgear/gears/helper.py def get_video_bitrate ( width , height , fps , bpp ): \"\"\" ### get_video_bitrate Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: width (int): video-width height (int): video-height fps (float): video-framerate bpp (float): bit-per-pixels value **Returns:** Video bitrate _(in Kbps)_ as integer. \"\"\" return round (( width * height * bpp * fps ) / 1000 )","title":"helper.py"},{"location":"bonus/reference/helper/#vidgear.gears.helper.logger_handler","text":"","title":"vidgear.gears.helper.logger_handler"},{"location":"bonus/reference/helper/#logger_handler","text":"Returns a color formatted logger handler Returns: A logger handler Source code in vidgear/gears/helper.py def logger_handler (): \"\"\" ### logger_handler Returns a color formatted logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" %(bold_blue)s%(name)s%(reset)s :: %(log_color)s%(levelname)s%(reset)s :: %(message)s \" , datefmt = None , reset = True , log_colors = { \"INFO\" : \"bold_green\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_purple\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, ) # define handler handler = log . StreamHandler () handler . setFormatter ( formatter ) return handler","title":"logger_handler"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_CV_version","text":"","title":"vidgear.gears.helper.check_CV_version"},{"location":"bonus/reference/helper/#check_cv_version","text":"Returns: OpenCV's version first bit Source code in vidgear/gears/helper.py def check_CV_version (): \"\"\" ### check_CV_version **Returns:** OpenCV's version first bit \"\"\" if parse_version ( cv2 . __version__ ) >= parse_version ( \"4\" ): return 4 else : return 3","title":"check_CV_version"},{"location":"bonus/reference/helper/#vidgear.gears.helper.mkdir_safe","text":"","title":"vidgear.gears.helper.mkdir_safe"},{"location":"bonus/reference/helper/#mkdir_safe","text":"Safely creates directory at given path. Parameters: Name Type Description Default dir_path string path to the directory required logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def mkdir_safe ( dir_path , logging = False ): \"\"\" ### mkdir_safe Safely creates directory at given path. Parameters: dir_path (string): path to the directory logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir_path ) if logging : logger . debug ( \"Created directory at ` {} `\" . format ( dir_path )) except OSError as e : if e . errno != errno . EEXIST : raise if logging : logger . debug ( \"Directory already exists at ` {} `\" . format ( dir_path ))","title":"mkdir_safe"},{"location":"bonus/reference/helper/#vidgear.gears.helper.delete_safe","text":"","title":"vidgear.gears.helper.delete_safe"},{"location":"bonus/reference/helper/#delete_safe","text":"Safely deletes files with given extensions at given path. Parameters: Name Type Description Default dir_path string path to the directory required extensions list list of extensions to be deleted [] logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def delete_safe ( dir_path , extensions = [], logging = False ): \"\"\" ### delete_safe Safely deletes files with given extensions at given path. Parameters: dir_path (string): path to the directory extensions (list): list of extensions to be deleted logging (bool): enables logging for its operations \"\"\" if not extensions or not os . path . exists ( dir_path ): logger . warning ( \"Invalid input provided for deleting!\" ) return if logging : logger . debug ( \"Clearing Assets at ` {} `!\" . format ( dir_path )) for ext in extensions : files_ext = [ os . path . join ( dir_path , f ) for f in os . listdir ( dir_path ) if f . endswith ( ext ) ] for file in files_ext : os . remove ( file ) if logging : logger . debug ( \"Deleted file: ` {} `\" . format ( file ))","title":"delete_safe"},{"location":"bonus/reference/helper/#vidgear.gears.helper.capPropId","text":"","title":"vidgear.gears.helper.capPropId"},{"location":"bonus/reference/helper/#cappropid","text":"Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: Name Type Description Default property string inputs OpenCV property as string. required Returns: Resultant integer value. Source code in vidgear/gears/helper.py def capPropId ( property ): \"\"\" ### capPropId Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: property (string): inputs OpenCV property as string. **Returns:** Resultant integer value. \"\"\" integer_value = 0 try : integer_value = getattr ( cv2 , property ) except Exception as e : logger . exception ( str ( e )) logger . critical ( \"` {} ` is not a valid OpenCV property!\" . format ( property )) return None return integer_value","title":"capPropId"},{"location":"bonus/reference/helper/#vidgear.gears.helper.reducer","text":"","title":"vidgear.gears.helper.reducer"},{"location":"bonus/reference/helper/#reducer","text":"Reduces frame size by given percentage Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/helper.py def reducer ( frame = None , percentage = 0 ): \"\"\" ### reducer Reduces frame size by given percentage Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = cv2 . INTER_LANCZOS4 )","title":"reducer"},{"location":"bonus/reference/helper/#vidgear.gears.helper.dict2Args","text":"","title":"vidgear.gears.helper.dict2Args"},{"location":"bonus/reference/helper/#dict2args","text":"Converts dictionary attributes to list(args) Parameters: Name Type Description Default param_dict dict Parameters dictionary required Returns: Arguments list Source code in vidgear/gears/helper.py def dict2Args ( param_dict ): \"\"\" ### dict2Args Converts dictionary attributes to list(args) Parameters: param_dict (dict): Parameters dictionary **Returns:** Arguments list \"\"\" args = [] for key in param_dict . keys (): if key in [ \"-clones\" ] or key . startswith ( \"-core\" ): if isinstance ( param_dict [ key ], list ): args . extend ( param_dict [ key ]) else : logger . warning ( \" {} with invalid datatype:` {} `, Skipped!\" . format ( \"Core parameter\" if key . startswith ( \"-core\" ) else \"Clone\" , param_dict [ key ], ) ) else : args . append ( key ) args . append ( str ( param_dict [ key ])) return args","title":"dict2Args"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_valid_ffmpeg_path","text":"","title":"vidgear.gears.helper.get_valid_ffmpeg_path"},{"location":"bonus/reference/helper/#get_valid_ffmpeg_path","text":"Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' logging bool enables logging for its operations False Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , logging = False ): \"\"\" ### get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ logging (bool): enables logging for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () if logging : logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred if logging : logger . exception ( str ( e )) logger . debug ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False if logging : logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False if logging : logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" if logging : logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , logging = logging ) else False","title":"get_valid_ffmpeg_path"},{"location":"bonus/reference/helper/#vidgear.gears.helper.download_ffmpeg_binaries","text":"","title":"vidgear.gears.helper.download_ffmpeg_binaries"},{"location":"bonus/reference/helper/#download_ffmpeg_binaries","text":"Generates FFmpeg Static Binaries for windows(if not available) Parameters: Name Type Description Default path string path for downloading custom FFmpeg executables required os_windows boolean is running on Windows OS? False os_bit string 32-bit or 64-bit OS? '' Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def download_ffmpeg_binaries ( path , os_windows = False , os_bit = \"\" ): \"\"\" ### download_ffmpeg_binaries Generates FFmpeg Static Binaries for windows(if not available) Parameters: path (string): path for downloading custom FFmpeg executables os_windows (boolean): is running on Windows OS? os_bit (string): 32-bit or 64-bit OS? **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if os_windows and os_bit : # initialize variables file_url = \"https://ffmpeg.zeranoe.com/builds/ {} /static/ffmpeg-latest- {} -static.zip\" . format ( os_bit , os_bit ) file_name = os . path . join ( os . path . abspath ( path ), \"ffmpeg-latest- {} -static.zip\" . format ( os_bit ) ) file_path = os . path . join ( os . path . abspath ( path ), \"ffmpeg-latest- {} -static/bin/ffmpeg.exe\" . format ( os_bit ), ) base_path , _ = os . path . split ( file_name ) # extract file base path # check if file already exists if os . path . isfile ( file_path ): final_path += file_path # skip download if does else : # import libs import zipfile # check if given path has write access assert os . access ( path , os . W_OK ), ( \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \" + path ) # remove leftovers if exists if os . path . isfile ( file_name ): os . remove ( file_name ) # download and write file to the given path with open ( file_name , \"wb\" ) as f : logger . debug ( \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries now. Please wait...\" ) try : response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () except Exception as e : logger . exception ( str ( e )) logger . warning ( \"Downloading Failed. Trying GitHub mirror now!\" ) file_url = \"https://raw.githubusercontent.com/abhiTronix/ffmpeg-static-builds/master/windows/ffmpeg-latest- {} -static.zip\" . format ( os_bit , os_bit ) response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 4096 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () logger . debug ( \"Extracting executables.\" ) with zipfile . ZipFile ( file_name , \"r\" ) as zip_ref : zip_ref . extractall ( base_path ) # perform cleaning os . remove ( file_name ) logger . debug ( \"FFmpeg binaries for Windows configured successfully!\" ) final_path += file_path # return final path return final_path","title":"download_ffmpeg_binaries"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_ffmpeg","text":"","title":"vidgear.gears.helper.validate_ffmpeg"},{"location":"bonus/reference/helper/#validate_ffmpeg","text":"Validate FFmeg Binaries. returns True if tests are passed. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def validate_ffmpeg ( path , logging = False ): \"\"\" ### validate_ffmpeg Validate FFmeg Binaries. returns `True` if tests are passed. Parameters: path (string): absolute path of FFmpeg binaries logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" try : # get the FFmpeg version version = check_output ([ path , \"-version\" ]) firstline = version . split ( b \" \\n \" )[ 0 ] version = firstline . split ( b \" \" )[ 2 ] . strip () if logging : # log if test are passed logger . debug ( \"FFmpeg validity Test Passed!\" ) logger . debug ( \"Found valid FFmpeg Version: ` {} ` installed on this system\" . format ( version ) ) except Exception as e : # log if test are failed if logging : logger . exception ( str ( e )) logger . warning ( \"FFmpeg validity Test Failed!\" ) return False return True","title":"validate_ffmpeg"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_output","text":"","title":"vidgear.gears.helper.check_output"},{"location":"bonus/reference/helper/#check_output","text":"Returns stdin output from subprocess module Source code in vidgear/gears/helper.py def check_output ( * args , ** kwargs ): \"\"\" ### check_output Returns stdin output from subprocess module \"\"\" # import libs import subprocess as sp # handle additional params retrieve_stderr = kwargs . pop ( \"force_retrieve_stderr\" , False ) # execute command in subprocess process = sp . Popen ( stdout = sp . PIPE , stderr = sp . DEVNULL if not ( retrieve_stderr ) else sp . PIPE , * args , ** kwargs ) output , stderr = process . communicate () retcode = process . poll () # handle return code if retcode and not ( retrieve_stderr ): cmd = kwargs . get ( \"args\" ) if cmd is None : cmd = args [ 0 ] error = sp . CalledProcessError ( retcode , cmd ) error . output = output raise error return output if not ( retrieve_stderr ) else stderr","title":"check_output"},{"location":"bonus/reference/helper/#vidgear.gears.helper.generate_auth_certificates","text":"","title":"vidgear.gears.helper.generate_auth_certificates"},{"location":"bonus/reference/helper/#generate_auth_certificates","text":"Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: Name Type Description Default path string path for generating CURVE key-pairs required overwrite boolean overwrite existing key-pairs or not? False logging bool enables logging for its operations False Returns: A valid CURVE key-pairs path as string. Source code in vidgear/gears/helper.py def generate_auth_certificates ( path , overwrite = False , logging = False ): \"\"\" ### generate_auth_certificates Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: path (string): path for generating CURVE key-pairs overwrite (boolean): overwrite existing key-pairs or not? logging (bool): enables logging for its operations **Returns:** A valid CURVE key-pairs path as string. \"\"\" # import necessary libs import shutil import zmq.auth # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # generate keys dir keys_dir = os . path . join ( path , \"keys\" ) mkdir_safe ( keys_dir , logging = logging ) # generate separate public and private key dirs public_keys_dir = os . path . join ( keys_dir , \"public_keys\" ) secret_keys_dir = os . path . join ( keys_dir , \"private_keys\" ) # check if overwriting is allowed if overwrite : # delete previous certificates for dirs in [ public_keys_dir , secret_keys_dir ]: if os . path . exists ( dirs ): shutil . rmtree ( dirs ) mkdir_safe ( dirs , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ): shutil . move ( os . path . join ( keys_dir , key_file ), public_keys_dir ) elif key_file . endswith ( \".key_secret\" ): shutil . move ( os . path . join ( keys_dir , key_file ), secret_keys_dir ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): os . remove ( redundant_key ) else : # otherwise validate available keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # check if all valid keys are found if status_private_keys and status_public_keys : return ( keys_dir , secret_keys_dir , public_keys_dir ) # check if valid public keys are found if not ( status_public_keys ): mkdir_safe ( public_keys_dir , logging = logging ) # check if valid private keys are found if not ( status_private_keys ): mkdir_safe ( secret_keys_dir , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ) and not ( status_public_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( public_keys_dir , \".\" ) ) elif key_file . endswith ( \".key_secret\" ) and not ( status_private_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( secret_keys_dir , \".\" ) ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): os . remove ( redundant_key ) # validate newly generated keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # raise error is validation test fails if not ( status_private_keys ) or not ( status_public_keys ): raise RuntimeError ( \"[Helper:ERROR] :: Unable to generate valid ZMQ authentication certificates at ` {} `!\" . format ( keys_dir ) ) # finally return valid key paths return ( keys_dir , secret_keys_dir , public_keys_dir )","title":"generate_auth_certificates"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_audio","text":"","title":"vidgear.gears.helper.validate_audio"},{"location":"bonus/reference/helper/#validate_audio","text":"Validates audio by retrieving audio-bitrate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required file_path string absolute path to file to be validated. None Returns: A string value, confirming whether audio is present, or not?. Source code in vidgear/gears/helper.py def validate_audio ( path , file_path = None ): \"\"\" ### validate_audio Validates audio by retrieving audio-bitrate from file. Parameters: path (string): absolute path of FFmpeg binaries file_path (string): absolute path to file to be validated. **Returns:** A string value, confirming whether audio is present, or not?. \"\"\" if file_path is None or not ( file_path ): logger . warning ( \"File path is empty!\" ) return \"\" # extract audio sample-rate from metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , file_path ], force_retrieve_stderr = True ) audio_bitrate = re . findall ( r \"fltp,\\s[0-9]+\\s\\w\\w[/]s\" , metadata . decode ( \"utf-8\" )) if audio_bitrate : filtered = audio_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] final_bitrate = \" {}{} \" . format ( int ( filtered [ 0 ] . strip ()), \"k\" if ( filtered [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) return final_bitrate else : return \"\"","title":"validate_audio"},{"location":"bonus/reference/helper/#vidgear.gears.helper.extract_time","text":"","title":"vidgear.gears.helper.extract_time"},{"location":"bonus/reference/helper/#extract_time","text":"Extract time from give string value. Parameters: Name Type Description Default value string string value. required Returns: Time (in seconds) as integer. Source code in vidgear/gears/helper.py def extract_time ( value ): \"\"\" ### extract_time Extract time from give string value. Parameters: value (string): string value. **Returns:** Time _(in seconds)_ as integer. \"\"\" if not ( value ): logger . warning ( \"Value is empty!\" ) return 0 else : stripped_data = value . strip () t_duration = re . findall ( r \"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d)\" , stripped_data ) return ( sum ( int ( x ) * 60 ** i for i , x in enumerate ( reversed ( t_duration [ 0 ] . split ( \":\" ))) ) if t_duration else 0 )","title":"extract_time"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_video","text":"","title":"vidgear.gears.helper.validate_video"},{"location":"bonus/reference/helper/#validate_video","text":"Validates video by retrieving resolution/size and framerate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required video_path string absolute path to Video. None Returns: A dictionary of retieved Video resolution (as tuple(width, height)) and framerate (as float) . Source code in vidgear/gears/helper.py def validate_video ( path , video_path = None ): \"\"\" ### validate_video Validates video by retrieving resolution/size and framerate from file. Parameters: path (string): absolute path of FFmpeg binaries video_path (string): absolute path to Video. **Returns:** A dictionary of retieved Video resolution _(as tuple(width, height))_ and framerate _(as float)_. \"\"\" if video_path is None or not ( video_path ): logger . warning ( \"Video path is empty!\" ) return None # extract metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , video_path ], force_retrieve_stderr = True ) # clean and search stripped_data = [ x . decode ( \"utf-8\" ) . strip () for x in metadata . split ( b \" \\n \" )] result = {} for data in stripped_data : output_a = re . findall ( r \"(\\d+)x(\\d+)\" , data ) output_b = re . findall ( r \"\\d+(?:\\.\\d+)?\\sfps\" , data ) if len ( result ) == 2 : break if output_b and not \"framerate\" in result : result [ \"framerate\" ] = re . findall ( r \"[\\d\\.\\d]+\" , output_b [ 0 ])[ 0 ] if output_a and not \"resolution\" in result : result [ \"resolution\" ] = output_a [ - 1 ] # return values return result if ( len ( result ) == 2 ) else None","title":"validate_video"},{"location":"bonus/reference/helper/#vidgear.gears.helper.is_valid_url","text":"","title":"vidgear.gears.helper.is_valid_url"},{"location":"bonus/reference/helper/#is_valid_url","text":"Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required url string URL to be validated None logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def is_valid_url ( path , url = None , logging = False ): \"\"\" ### is_valid_url Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: path (string): absolute path of FFmpeg binaries url (string): URL to be validated logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if url is None or not ( url ): logger . warning ( \"URL is empty!\" ) return False # extract URL scheme extracted_scheme_url = url . split ( \"://\" , 1 )[ 0 ] # extract all FFmpeg supported protocols protocols = check_output ([ path , \"-hide_banner\" , \"-protocols\" ]) splitted = protocols . split ( b \" \\n \" ) supported_protocols = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ 2 : len ( splitted ) - 1 ] ] # Test and return result whether scheme is supported if extracted_scheme_url and extracted_scheme_url in supported_protocols : if logging : logger . debug ( \"URL scheme ` {} ` is supported by FFmpeg.\" . format ( extracted_scheme_url ) ) return True else : logger . warning ( \"URL scheme ` {} ` is not supported by FFmpeg!\" . format ( extracted_scheme_url ) ) return False","title":"is_valid_url"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_video_bitrate","text":"","title":"vidgear.gears.helper.get_video_bitrate"},{"location":"bonus/reference/helper/#get_video_bitrate","text":"Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: Name Type Description Default width int video-width required height int video-height required fps float video-framerate required bpp float bit-per-pixels value required Returns: Video bitrate (in Kbps) as integer. Source code in vidgear/gears/helper.py def get_video_bitrate ( width , height , fps , bpp ): \"\"\" ### get_video_bitrate Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: width (int): video-width height (int): video-height fps (float): video-framerate bpp (float): bit-per-pixels value **Returns:** Video bitrate _(in Kbps)_ as integer. \"\"\" return round (( width * height * bpp * fps ) / 1000 )","title":"get_video_bitrate"},{"location":"bonus/reference/helper_async/","text":"\u00b6 logger_handler \u00b6 Returns a color formatted logger handler Returns: A asyncio package logger handler Source code in vidgear/gears/asyncio/helper.py def logger_handler (): \"\"\" ### logger_handler Returns a color formatted logger handler **Returns:** A asyncio package logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" %(bold_blue)s%(name)s%(reset)s :: %(log_color)s%(levelname)s%(reset)s :: %(message)s \" , datefmt = None , reset = True , log_colors = { \"INFO\" : \"bold_green\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_purple\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, ) # define handler handler = log . StreamHandler () handler . setFormatter ( formatter ) return handler \u00b6 mkdir_safe \u00b6 Safely creates directory at given path. Parameters: Name Type Description Default logging bool enables logging for its operations False Source code in vidgear/gears/asyncio/helper.py def mkdir_safe ( dir , logging = False ): \"\"\" ### mkdir_safe Safely creates directory at given path. Parameters: logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir ) if logging : logger . debug ( \"Created directory at ` {} `\" . format ( dir )) except OSError as e : if e . errno != errno . EEXIST : raise if logging : logger . debug ( \"Directory already exists at ` {} `\" . format ( dir )) \u00b6 reducer \u00b6 Asynchronous method that reduces frame size by given percentage. Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/asyncio/helper.py async def reducer ( frame = None , percentage = 0 ): \"\"\" ### reducer Asynchronous method that reduces frame size by given percentage. Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = cv2 . INTER_LANCZOS4 ) \u00b6 generate_webdata \u00b6 Auto-Generates, and Auto-validates default data for WebGear API. Parameters: Name Type Description Default path string path for generating data required overwrite_default boolean overwrite existing data or not? False logging bool enables logging for its operations False Returns: A valid data path as string. Source code in vidgear/gears/asyncio/helper.py def generate_webdata ( path , overwrite_default = False , logging = False ): \"\"\" ### generate_webdata Auto-Generates, and Auto-validates default data for WebGear API. Parameters: path (string): path for generating data overwrite_default (boolean): overwrite existing data or not? logging (bool): enables logging for its operations **Returns:** A valid data path as string. \"\"\" # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # self-generate dirs template_dir = os . path . join ( path , \"templates\" ) # generates HTML templates dir static_dir = os . path . join ( path , \"static\" ) # generates static dir # generate js & css static and favicon img subdirs js_static_dir = os . path . join ( static_dir , \"js\" ) css_static_dir = os . path . join ( static_dir , \"css\" ) favicon_dir = os . path . join ( static_dir , \"img\" ) mkdir_safe ( static_dir , logging = logging ) mkdir_safe ( template_dir , logging = logging ) mkdir_safe ( js_static_dir , logging = logging ) mkdir_safe ( css_static_dir , logging = logging ) mkdir_safe ( favicon_dir , logging = logging ) if len ( logger . handlers ) > 1 : logger . handlers . clear () logger . addHandler ( logger_handler ()) logger . setLevel ( log . DEBUG ) # check if overwriting is enabled if overwrite_default : logger . critical ( \"Overwriting existing WebGear data-files with default data-files from the server!\" ) download_webdata ( template_dir , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , files = [ \"bootstrap.min.css\" , \"cover.css\" ], logging = logging ) download_webdata ( js_static_dir , files = [ \"bootstrap.min.js\" , \"jquery-3.4.1.slim.min.js\" , \"popper.min.js\" ], logging = logging , ) download_webdata ( favicon_dir , files = [ \"favicon-32x32.png\" ], logging = logging ) else : # validate important data-files if validate_webdata ( template_dir , [ \"index.html\" , \"404.html\" , \"500.html\" ]): if logging : logger . debug ( \"Found valid WebGear data-files successfully.\" ) else : # otherwise download default files logger . critical ( \"Failed to detect critical WebGear data-files: index.html, 404.html & 500.html!\" ) logger . warning ( \"Re-downloading default data-files from the server.\" ) download_webdata ( template_dir , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , files = [ \"bootstrap.min.css\" , \"cover.css\" ], logging = logging , ) download_webdata ( js_static_dir , files = [ \"bootstrap.min.js\" , \"jquery-3.4.1.slim.min.js\" , \"popper.min.js\" ], logging = logging , ) download_webdata ( favicon_dir , files = [ \"favicon-32x32.png\" ], logging = logging ) return path \u00b6 download_webdata \u00b6 Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: Name Type Description Default path string path for downloading data required files list list of files to be downloaded [] logging bool enables logging for its operations False Returns: A valid path as string. Source code in vidgear/gears/asyncio/helper.py def download_webdata ( path , files = [], logging = False ): \"\"\" ### download_webdata Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: path (string): path for downloading data files (list): list of files to be downloaded logging (bool): enables logging for its operations **Returns:** A valid path as string. \"\"\" basename = os . path . basename ( path ) if logging : logger . debug ( \"Downloading {} data-files at ` {} `\" . format ( basename , path )) for file in files : # get filename file_name = os . path . join ( path , file ) # get URL if basename == \"templates\" : file_url = \"https://raw.githubusercontent.com/abhiTronix/webgear_data/master/ {} / {} \" . format ( basename , file ) else : file_url = \"https://raw.githubusercontent.com/abhiTronix/webgear_data/master/static/ {} / {} \" . format ( basename , file ) # download and write file to the given path if logging : logger . debug ( \"Downloading {} data-file: {} .\" . format ( basename , file )) response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) with open ( file_name , \"wb\" ) as f : for data in response . iter_content ( chunk_size = 256 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () if logging : logger . debug ( \"Verifying downloaded data:\" ) if validate_webdata ( path , files = files , logging = logging ): if logging : logger . info ( \"Successful!\" ) return path else : raise RuntimeError ( \"[Helper:ERROR] :: Failed to download required {} data-files at: {} , Check your Internet connectivity!\" . format ( basename , path ) )","title":"helper.py"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.logger_handler","text":"","title":"vidgear.gears.asyncio.helper.logger_handler"},{"location":"bonus/reference/helper_async/#logger_handler","text":"Returns a color formatted logger handler Returns: A asyncio package logger handler Source code in vidgear/gears/asyncio/helper.py def logger_handler (): \"\"\" ### logger_handler Returns a color formatted logger handler **Returns:** A asyncio package logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" %(bold_blue)s%(name)s%(reset)s :: %(log_color)s%(levelname)s%(reset)s :: %(message)s \" , datefmt = None , reset = True , log_colors = { \"INFO\" : \"bold_green\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_purple\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, ) # define handler handler = log . StreamHandler () handler . setFormatter ( formatter ) return handler","title":"logger_handler"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.mkdir_safe","text":"","title":"vidgear.gears.asyncio.helper.mkdir_safe"},{"location":"bonus/reference/helper_async/#mkdir_safe","text":"Safely creates directory at given path. Parameters: Name Type Description Default logging bool enables logging for its operations False Source code in vidgear/gears/asyncio/helper.py def mkdir_safe ( dir , logging = False ): \"\"\" ### mkdir_safe Safely creates directory at given path. Parameters: logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir ) if logging : logger . debug ( \"Created directory at ` {} `\" . format ( dir )) except OSError as e : if e . errno != errno . EEXIST : raise if logging : logger . debug ( \"Directory already exists at ` {} `\" . format ( dir ))","title":"mkdir_safe"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.reducer","text":"","title":"vidgear.gears.asyncio.helper.reducer"},{"location":"bonus/reference/helper_async/#reducer","text":"Asynchronous method that reduces frame size by given percentage. Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/asyncio/helper.py async def reducer ( frame = None , percentage = 0 ): \"\"\" ### reducer Asynchronous method that reduces frame size by given percentage. Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = cv2 . INTER_LANCZOS4 )","title":"reducer"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.generate_webdata","text":"","title":"vidgear.gears.asyncio.helper.generate_webdata"},{"location":"bonus/reference/helper_async/#generate_webdata","text":"Auto-Generates, and Auto-validates default data for WebGear API. Parameters: Name Type Description Default path string path for generating data required overwrite_default boolean overwrite existing data or not? False logging bool enables logging for its operations False Returns: A valid data path as string. Source code in vidgear/gears/asyncio/helper.py def generate_webdata ( path , overwrite_default = False , logging = False ): \"\"\" ### generate_webdata Auto-Generates, and Auto-validates default data for WebGear API. Parameters: path (string): path for generating data overwrite_default (boolean): overwrite existing data or not? logging (bool): enables logging for its operations **Returns:** A valid data path as string. \"\"\" # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # self-generate dirs template_dir = os . path . join ( path , \"templates\" ) # generates HTML templates dir static_dir = os . path . join ( path , \"static\" ) # generates static dir # generate js & css static and favicon img subdirs js_static_dir = os . path . join ( static_dir , \"js\" ) css_static_dir = os . path . join ( static_dir , \"css\" ) favicon_dir = os . path . join ( static_dir , \"img\" ) mkdir_safe ( static_dir , logging = logging ) mkdir_safe ( template_dir , logging = logging ) mkdir_safe ( js_static_dir , logging = logging ) mkdir_safe ( css_static_dir , logging = logging ) mkdir_safe ( favicon_dir , logging = logging ) if len ( logger . handlers ) > 1 : logger . handlers . clear () logger . addHandler ( logger_handler ()) logger . setLevel ( log . DEBUG ) # check if overwriting is enabled if overwrite_default : logger . critical ( \"Overwriting existing WebGear data-files with default data-files from the server!\" ) download_webdata ( template_dir , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , files = [ \"bootstrap.min.css\" , \"cover.css\" ], logging = logging ) download_webdata ( js_static_dir , files = [ \"bootstrap.min.js\" , \"jquery-3.4.1.slim.min.js\" , \"popper.min.js\" ], logging = logging , ) download_webdata ( favicon_dir , files = [ \"favicon-32x32.png\" ], logging = logging ) else : # validate important data-files if validate_webdata ( template_dir , [ \"index.html\" , \"404.html\" , \"500.html\" ]): if logging : logger . debug ( \"Found valid WebGear data-files successfully.\" ) else : # otherwise download default files logger . critical ( \"Failed to detect critical WebGear data-files: index.html, 404.html & 500.html!\" ) logger . warning ( \"Re-downloading default data-files from the server.\" ) download_webdata ( template_dir , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , files = [ \"bootstrap.min.css\" , \"cover.css\" ], logging = logging , ) download_webdata ( js_static_dir , files = [ \"bootstrap.min.js\" , \"jquery-3.4.1.slim.min.js\" , \"popper.min.js\" ], logging = logging , ) download_webdata ( favicon_dir , files = [ \"favicon-32x32.png\" ], logging = logging ) return path","title":"generate_webdata"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.download_webdata","text":"","title":"vidgear.gears.asyncio.helper.download_webdata"},{"location":"bonus/reference/helper_async/#download_webdata","text":"Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: Name Type Description Default path string path for downloading data required files list list of files to be downloaded [] logging bool enables logging for its operations False Returns: A valid path as string. Source code in vidgear/gears/asyncio/helper.py def download_webdata ( path , files = [], logging = False ): \"\"\" ### download_webdata Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: path (string): path for downloading data files (list): list of files to be downloaded logging (bool): enables logging for its operations **Returns:** A valid path as string. \"\"\" basename = os . path . basename ( path ) if logging : logger . debug ( \"Downloading {} data-files at ` {} `\" . format ( basename , path )) for file in files : # get filename file_name = os . path . join ( path , file ) # get URL if basename == \"templates\" : file_url = \"https://raw.githubusercontent.com/abhiTronix/webgear_data/master/ {} / {} \" . format ( basename , file ) else : file_url = \"https://raw.githubusercontent.com/abhiTronix/webgear_data/master/static/ {} / {} \" . format ( basename , file ) # download and write file to the given path if logging : logger . debug ( \"Downloading {} data-file: {} .\" . format ( basename , file )) response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) with open ( file_name , \"wb\" ) as f : for data in response . iter_content ( chunk_size = 256 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () if logging : logger . debug ( \"Verifying downloaded data:\" ) if validate_webdata ( path , files = files , logging = logging ): if logging : logger . info ( \"Successful!\" ) return path else : raise RuntimeError ( \"[Helper:ERROR] :: Failed to download required {} data-files at: {} , Check your Internet connectivity!\" . format ( basename , path ) )","title":"download_webdata"},{"location":"bonus/reference/netgear/","text":"All NetGear Class parameters are explained here \u27b6 \u00b6 NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middle-ware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. Info NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns (i.e. zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc . Modes of Operation Primary Modes NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. The mode sends back confirmation when the frame is received successfully in few patterns. Exclusive Modes In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes: Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames . Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. close ( self ) \u00b6 Safely terminates the threads, and NetGear resources. Source code in vidgear/gears/netgear.py def close ( self ): \"\"\" Safely terminates the threads, and NetGear resources. \"\"\" if self . __logging : # log it logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # check whether queue mode is empty if not ( self . __queue is None ) and self . __queue : self . __queue . clear () # call immediate termination self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : # properly handle thread exit self . __thread . join () self . __thread = None if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) # properly close the socket self . __msg_socket . close ( linger = 0 ) if self . __logging : logger . debug ( \"Terminated Successfully!\" ) else : # indicate that process should be terminated self . __terminate = True # check if all attempts of reconnecting failed, then skip to closure if ( self . __pattern < 2 and not self . __max_retries ) or ( self . __multiclient_mode and not self . __port_buffer ): try : # properly close the socket self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () except self . __ZMQError : pass finally : return if self . __multiserver_mode : # check if multiserver_mode # send termination flag to client with its unique port term_dict = dict ( terminate_flag = True , port = self . __port ) else : # otherwise send termination flag to client term_dict = dict ( terminate_flag = True ) try : if self . __multiclient_mode : if self . __port_buffer : for _ in self . __port_buffer : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within half timeout if self . __pattern < 2 : if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , self . __zmq . POLLIN ): self . __msg_socket . recv () else : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within half timeout if self . __pattern < 2 : if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , self . __zmq . POLLIN ): self . __msg_socket . recv () except Exception as e : if not isinstance ( e , self . __ZMQError ): logger . exception ( str ( e )) finally : # properly close the socket self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () if self . __logging : logger . debug ( \"Terminated Successfully!\" ) recv ( self , return_data = None ) \u00b6 A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: Name Type Description Default return_data any inputs return data (of any datatype) , for sending back to Server. None Returns: A n-dimensional numpy array. Source code in vidgear/gears/netgear.py def recv ( self , return_data = None ): \"\"\" A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: return_data (any): inputs return data _(of any datatype)_, for sending back to Server. **Returns:** A n-dimensional numpy array. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\" ) # handle bi-directional return data if ( self . __bi_mode or self . __multiclient_mode ) and not ( return_data is None ): self . __return_data = return_data # check whether or not termination flag is enabled while not self . __terminate : try : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : time . sleep ( 0.00001 ) continue except KeyboardInterrupt : self . __terminate = True break # otherwise return NoneType return None send ( self , frame , message = None ) \u00b6 A Server end method, that sends the data and frames over the network to Client(s). Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). required message any input for sending additional data (of any datatype except numpy.ndarray ) to Client(s). None Returns: Data (of any datatype) in selected exclusive modes, otherwise None-type. Source code in vidgear/gears/netgear.py def send ( self , frame , message = None ): \"\"\" A Server end method, that sends the data and frames over the network to Client(s). Parameters: frame (numpy.ndarray): inputs numpy array(frame). message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s). **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type. \"\"\" # check whether `receive_mode` is disabled if self . __receive_mode : # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\" ) if not ( message is None ) and isinstance ( message , np . ndarray ): logger . warning ( \"Skipped unsupported `message` of datatype: {} !\" . format ( type ( message ) . __name__ ) ) message = None # define exit_flag and assign value exit_flag = True if ( frame is None or self . __terminate ) else False # check whether exit_flag is False if not ( exit_flag ) and not ( frame . flags [ \"C_CONTIGUOUS\" ]): # check whether the incoming frame is contiguous frame = np . ascontiguousarray ( frame , dtype = frame . dtype ) # handle encoding if not ( self . __compression is None ): retval , frame = cv2 . imencode ( self . __compression , frame , self . __compression_params ) # check if it works if not ( retval ): # otherwise raise error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: Frame compression failed with encoding: {} and parameters: {} .\" . format ( self . __compression , self . __compression_params ) ) # check if multiserver_mode is activated if self . __multiserver_mode : # prepare the exclusive json dict and assign values with unique port msg_dict = dict ( terminate_flag = exit_flag , compression = str ( self . __compression ) if not ( self . __compression is None ) else \"\" , port = self . __port , pattern = str ( self . __pattern ), message = message , dtype = str ( frame . dtype ), shape = frame . shape , ) else : # otherwise prepare normal json dict and assign values msg_dict = dict ( terminate_flag = exit_flag , compression = str ( self . __compression ) if not ( self . __compression is None ) else \"\" , message = message , pattern = str ( self . __pattern ), dtype = str ( frame . dtype ), shape = frame . shape , ) # send the json dict self . __msg_socket . send_json ( msg_dict , self . __msg_flag | self . __zmq . SNDMORE ) # send the frame array with correct flags self . __msg_socket . send ( frame , flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track ) # check if synchronous patterns, then wait for confirmation if self . __pattern < 2 : # check if bi-directional data transmission is enabled if self . __bi_mode or self . __multiclient_mode : # handles return data recvd_data = None if self . __multiclient_mode : recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == self . __zmq . POLLIN : # handle return data recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): if self . __multiclient_mode : logger . error ( \"All Clients failed to respond on multiple attempts.\" ) else : logger . error ( \"Client failed to respond on multiple attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , self . __zmq . POLLIN ) return None # save the unique port addresses if ( self . __multiclient_mode and not recv_json [ \"port\" ] in self . __port_buffer ): self . __port_buffer . append ( recv_json [ \"port\" ]) if recv_json [ \"return_type\" ] == \"ndarray\" : recv_array = self . __msg_socket . recv ( flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track , ) recvd_data = np . frombuffer ( recv_array , dtype = recv_json [ \"array_dtype\" ] ) . reshape ( recv_json [ \"array_shape\" ]) # check if encoding was enabled if recv_json [ \"compression\" ]: recvd_data = cv2 . imdecode ( recvd_data , self . __ex_compression_params ) # check if valid frame returned if recvd_data is None : self . __terminate = True # otherwise raise error and exit raise RuntimeError ( \"[NetGear:ERROR] :: Received compressed frame ` {} ` decoding failed with flag: {} .\" . format ( recv_json [ \"compression\" ], self . __ex_compression_params , ) ) else : recvd_data = recv_json [ \"data\" ] return ( ( recv_json [ \"port\" ], recvd_data ) if self . __multiclient_mode else recvd_data ) else : if self . __multiclient_mode : recv_confirmation = self . __msg_socket . recv () else : # otherwise log normally socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == self . __zmq . POLLIN : recv_confirmation = self . __msg_socket . recv () else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): logger . error ( \"Client failed to respond on repeated attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , self . __zmq . POLLIN ) return None # log confirmation if self . __logging : logger . debug ( recv_confirmation )","title":"netgear.py"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear","text":"NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middle-ware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. Info NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns (i.e. zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc . Modes of Operation Primary Modes NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. The mode sends back confirmation when the frame is received successfully in few patterns. Exclusive Modes In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes: Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames . Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network.","title":"vidgear.gears.netgear.NetGear"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.close","text":"Safely terminates the threads, and NetGear resources. Source code in vidgear/gears/netgear.py def close ( self ): \"\"\" Safely terminates the threads, and NetGear resources. \"\"\" if self . __logging : # log it logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # check whether queue mode is empty if not ( self . __queue is None ) and self . __queue : self . __queue . clear () # call immediate termination self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : # properly handle thread exit self . __thread . join () self . __thread = None if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) # properly close the socket self . __msg_socket . close ( linger = 0 ) if self . __logging : logger . debug ( \"Terminated Successfully!\" ) else : # indicate that process should be terminated self . __terminate = True # check if all attempts of reconnecting failed, then skip to closure if ( self . __pattern < 2 and not self . __max_retries ) or ( self . __multiclient_mode and not self . __port_buffer ): try : # properly close the socket self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () except self . __ZMQError : pass finally : return if self . __multiserver_mode : # check if multiserver_mode # send termination flag to client with its unique port term_dict = dict ( terminate_flag = True , port = self . __port ) else : # otherwise send termination flag to client term_dict = dict ( terminate_flag = True ) try : if self . __multiclient_mode : if self . __port_buffer : for _ in self . __port_buffer : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within half timeout if self . __pattern < 2 : if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , self . __zmq . POLLIN ): self . __msg_socket . recv () else : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within half timeout if self . __pattern < 2 : if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , self . __zmq . POLLIN ): self . __msg_socket . recv () except Exception as e : if not isinstance ( e , self . __ZMQError ): logger . exception ( str ( e )) finally : # properly close the socket self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () if self . __logging : logger . debug ( \"Terminated Successfully!\" )","title":"close()"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.recv","text":"A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: Name Type Description Default return_data any inputs return data (of any datatype) , for sending back to Server. None Returns: A n-dimensional numpy array. Source code in vidgear/gears/netgear.py def recv ( self , return_data = None ): \"\"\" A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: return_data (any): inputs return data _(of any datatype)_, for sending back to Server. **Returns:** A n-dimensional numpy array. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\" ) # handle bi-directional return data if ( self . __bi_mode or self . __multiclient_mode ) and not ( return_data is None ): self . __return_data = return_data # check whether or not termination flag is enabled while not self . __terminate : try : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : time . sleep ( 0.00001 ) continue except KeyboardInterrupt : self . __terminate = True break # otherwise return NoneType return None","title":"recv()"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.send","text":"A Server end method, that sends the data and frames over the network to Client(s). Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). required message any input for sending additional data (of any datatype except numpy.ndarray ) to Client(s). None Returns: Data (of any datatype) in selected exclusive modes, otherwise None-type. Source code in vidgear/gears/netgear.py def send ( self , frame , message = None ): \"\"\" A Server end method, that sends the data and frames over the network to Client(s). Parameters: frame (numpy.ndarray): inputs numpy array(frame). message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s). **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type. \"\"\" # check whether `receive_mode` is disabled if self . __receive_mode : # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\" ) if not ( message is None ) and isinstance ( message , np . ndarray ): logger . warning ( \"Skipped unsupported `message` of datatype: {} !\" . format ( type ( message ) . __name__ ) ) message = None # define exit_flag and assign value exit_flag = True if ( frame is None or self . __terminate ) else False # check whether exit_flag is False if not ( exit_flag ) and not ( frame . flags [ \"C_CONTIGUOUS\" ]): # check whether the incoming frame is contiguous frame = np . ascontiguousarray ( frame , dtype = frame . dtype ) # handle encoding if not ( self . __compression is None ): retval , frame = cv2 . imencode ( self . __compression , frame , self . __compression_params ) # check if it works if not ( retval ): # otherwise raise error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: Frame compression failed with encoding: {} and parameters: {} .\" . format ( self . __compression , self . __compression_params ) ) # check if multiserver_mode is activated if self . __multiserver_mode : # prepare the exclusive json dict and assign values with unique port msg_dict = dict ( terminate_flag = exit_flag , compression = str ( self . __compression ) if not ( self . __compression is None ) else \"\" , port = self . __port , pattern = str ( self . __pattern ), message = message , dtype = str ( frame . dtype ), shape = frame . shape , ) else : # otherwise prepare normal json dict and assign values msg_dict = dict ( terminate_flag = exit_flag , compression = str ( self . __compression ) if not ( self . __compression is None ) else \"\" , message = message , pattern = str ( self . __pattern ), dtype = str ( frame . dtype ), shape = frame . shape , ) # send the json dict self . __msg_socket . send_json ( msg_dict , self . __msg_flag | self . __zmq . SNDMORE ) # send the frame array with correct flags self . __msg_socket . send ( frame , flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track ) # check if synchronous patterns, then wait for confirmation if self . __pattern < 2 : # check if bi-directional data transmission is enabled if self . __bi_mode or self . __multiclient_mode : # handles return data recvd_data = None if self . __multiclient_mode : recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == self . __zmq . POLLIN : # handle return data recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): if self . __multiclient_mode : logger . error ( \"All Clients failed to respond on multiple attempts.\" ) else : logger . error ( \"Client failed to respond on multiple attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , self . __zmq . POLLIN ) return None # save the unique port addresses if ( self . __multiclient_mode and not recv_json [ \"port\" ] in self . __port_buffer ): self . __port_buffer . append ( recv_json [ \"port\" ]) if recv_json [ \"return_type\" ] == \"ndarray\" : recv_array = self . __msg_socket . recv ( flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track , ) recvd_data = np . frombuffer ( recv_array , dtype = recv_json [ \"array_dtype\" ] ) . reshape ( recv_json [ \"array_shape\" ]) # check if encoding was enabled if recv_json [ \"compression\" ]: recvd_data = cv2 . imdecode ( recvd_data , self . __ex_compression_params ) # check if valid frame returned if recvd_data is None : self . __terminate = True # otherwise raise error and exit raise RuntimeError ( \"[NetGear:ERROR] :: Received compressed frame ` {} ` decoding failed with flag: {} .\" . format ( recv_json [ \"compression\" ], self . __ex_compression_params , ) ) else : recvd_data = recv_json [ \"data\" ] return ( ( recv_json [ \"port\" ], recvd_data ) if self . __multiclient_mode else recvd_data ) else : if self . __multiclient_mode : recv_confirmation = self . __msg_socket . recv () else : # otherwise log normally socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == self . __zmq . POLLIN : recv_confirmation = self . __msg_socket . recv () else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): logger . error ( \"Client failed to respond on repeated attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , self . __zmq . POLLIN ) return None # log confirmation if self . __logging : logger . debug ( recv_confirmation )","title":"send()"},{"location":"bonus/reference/netgear_async/","text":"All NetGear_Async Class parameters are explained here \u27b6 \u00b6 NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async can generate double performance as compared to NetGear API at about \u2153rd of memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but it doesn't support any NetGear's Exclusive Modes yet. Furthermore, NetGear_Async allows us to define our own custom Server Source to manipulate frames easily before sending them across the network. In addition to all this, NetGear_Async also provides a special internal wrapper around VideoGear API] , which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any connected device/source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . close ( self , skip_loop = False ) \u00b6 Terminates all NetGear Asynchronous processes gracefully. Parameters: Name Type Description Default skip_loop Boolean (optional)used only if closing executor loop throws an error. False Source code in vidgear/gears/asyncio/netgear_async.py def close ( self , skip_loop = False ): \"\"\" Terminates all NetGear Asynchronous processes gracefully. Parameters: skip_loop (Boolean): (optional)used only if closing executor loop throws an error. \"\"\" # log termination if self . __logging : logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # indicate that process should be terminated self . __terminate = True else : # indicate that process should be terminated self . __terminate = True # terminate stream if not ( self . __stream is None ): self . __stream . stop () # close event loop if specified if not ( skip_loop ): self . loop . close () launch ( self ) \u00b6 Launches an asynchronous generators and loop executors for respective task. Source code in vidgear/gears/asyncio/netgear_async.py def launch ( self ): \"\"\" Launches an asynchronous generators and loop executors for respective task. \"\"\" # check if receive mode enabled if self . __receive_mode : if self . __logging : logger . debug ( \"Launching NetGear asynchronous generator!\" ) # run loop executor for Receiver asynchronous generator self . loop . run_in_executor ( None , self . recv_generator ) # return instance return self else : # Otherwise launch Server handler if self . __logging : logger . debug ( \"Creating NetGear asynchronous server handler!\" ) # create task for Server Handler self . task = asyncio . ensure_future ( self . __server_handler (), loop = self . loop ) # return instance return self recv_generator ( self ) \u00b6 A default Asynchronous Frame Generator for NetGear's Receiver-end. Source code in vidgear/gears/asyncio/netgear_async.py async def recv_generator ( self ): \"\"\" A default Asynchronous Frame Generator for NetGear's Receiver-end. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise Value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\" ) # initialize and define messaging socket self . __msg_socket = self . __msg_context . socket ( self . __pattern [ 1 ]) # define exclusive socket options for patterns if self . __msg_pattern == 2 : self . __msg_socket . set_hwm ( 1 ) self . __msg_socket . setsockopt ( zmq . SUBSCRIBE , b \"\" ) try : # bind socket to the assigned protocol, address and port self . __msg_socket . bind ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ) # finally log progress if self . __logging : logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) logger . debug ( \"Receive Mode is activated successfully!\" ) except Exception as e : logger . exception ( str ( e )) raise ValueError ( \"[NetGear:ERROR] :: Failed to bind address: {} and pattern: {} !\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) # loop until terminated while not self . __terminate : # get message withing timeout limit recvd_msg = await asyncio . wait_for ( self . __msg_socket . recv_multipart (), timeout = self . __timeout ) # check if bidirectional patterns if self . __msg_pattern < 2 : # send confirmation await self . __msg_socket . send_multipart ([ b \"Message Received!\" ]) # terminate if exit` flag received if recvd_msg [ 0 ] == b \"exit\" : break # retrieve frame from message frame = msgpack . unpackb ( recvd_msg [ 0 ], object_hook = m . decode ) # yield received frame yield frame # sleep for sometime await asyncio . sleep ( 0.00001 )","title":"netgear_async.py"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async","text":"NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async can generate double performance as compared to NetGear API at about \u2153rd of memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but it doesn't support any NetGear's Exclusive Modes yet. Furthermore, NetGear_Async allows us to define our own custom Server Source to manipulate frames easily before sending them across the network. In addition to all this, NetGear_Async also provides a special internal wrapper around VideoGear API] , which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any connected device/source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc .","title":"vidgear.gears.asyncio.netgear_async.NetGear_Async"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.close","text":"Terminates all NetGear Asynchronous processes gracefully. Parameters: Name Type Description Default skip_loop Boolean (optional)used only if closing executor loop throws an error. False Source code in vidgear/gears/asyncio/netgear_async.py def close ( self , skip_loop = False ): \"\"\" Terminates all NetGear Asynchronous processes gracefully. Parameters: skip_loop (Boolean): (optional)used only if closing executor loop throws an error. \"\"\" # log termination if self . __logging : logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # indicate that process should be terminated self . __terminate = True else : # indicate that process should be terminated self . __terminate = True # terminate stream if not ( self . __stream is None ): self . __stream . stop () # close event loop if specified if not ( skip_loop ): self . loop . close ()","title":"close()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.launch","text":"Launches an asynchronous generators and loop executors for respective task. Source code in vidgear/gears/asyncio/netgear_async.py def launch ( self ): \"\"\" Launches an asynchronous generators and loop executors for respective task. \"\"\" # check if receive mode enabled if self . __receive_mode : if self . __logging : logger . debug ( \"Launching NetGear asynchronous generator!\" ) # run loop executor for Receiver asynchronous generator self . loop . run_in_executor ( None , self . recv_generator ) # return instance return self else : # Otherwise launch Server handler if self . __logging : logger . debug ( \"Creating NetGear asynchronous server handler!\" ) # create task for Server Handler self . task = asyncio . ensure_future ( self . __server_handler (), loop = self . loop ) # return instance return self","title":"launch()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.recv_generator","text":"A default Asynchronous Frame Generator for NetGear's Receiver-end. Source code in vidgear/gears/asyncio/netgear_async.py async def recv_generator ( self ): \"\"\" A default Asynchronous Frame Generator for NetGear's Receiver-end. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise Value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\" ) # initialize and define messaging socket self . __msg_socket = self . __msg_context . socket ( self . __pattern [ 1 ]) # define exclusive socket options for patterns if self . __msg_pattern == 2 : self . __msg_socket . set_hwm ( 1 ) self . __msg_socket . setsockopt ( zmq . SUBSCRIBE , b \"\" ) try : # bind socket to the assigned protocol, address and port self . __msg_socket . bind ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ) # finally log progress if self . __logging : logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) logger . debug ( \"Receive Mode is activated successfully!\" ) except Exception as e : logger . exception ( str ( e )) raise ValueError ( \"[NetGear:ERROR] :: Failed to bind address: {} and pattern: {} !\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) # loop until terminated while not self . __terminate : # get message withing timeout limit recvd_msg = await asyncio . wait_for ( self . __msg_socket . recv_multipart (), timeout = self . __timeout ) # check if bidirectional patterns if self . __msg_pattern < 2 : # send confirmation await self . __msg_socket . send_multipart ([ b \"Message Received!\" ]) # terminate if exit` flag received if recvd_msg [ 0 ] == b \"exit\" : break # retrieve frame from message frame = msgpack . unpackb ( recvd_msg [ 0 ], object_hook = m . decode ) # yield received frame yield frame # sleep for sometime await asyncio . sleep ( 0.00001 )","title":"recv_generator()"},{"location":"bonus/reference/pigear/","text":"All PiGear Class parameters are explained here \u27b6 \u00b6 PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded wrapper around complete picamera python library, and also provides us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear supports multiple camera modules, such as in case of Raspberry Pi Compute module IO boards. Best of all, PiGear provides excellent error-handling with features like a Threaded Internal Timer - that keeps active track of any frozen-threads/hardware-failures robustly, and exit safely if it does occurs, i.e. If you're running PiGear API in your script, and someone accidentally pulls Camera module cable out, instead of going into possible kernel panic, PiGear will exit safely to save resources. read ( self ) \u00b6 Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/pigear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check if there are any thread exceptions if not ( self . __exceptions is None ): if isinstance ( self . __exceptions , bool ): # clear frame self . frame = None # notify user about hardware failure raise SystemError ( \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\" ) else : # clear frame self . frame = None # re-raise error for debugging error_msg = ( \"[PiGear:ERROR] :: Camera Module API failure occured: {} \" . format ( self . __exceptions [ 1 ] ) ) raise RuntimeError ( error_msg ) . with_traceback ( self . __exceptions [ 2 ]) # return the frame return self . frame start ( self ) \u00b6 Launches the internal Threaded Frames Extractor daemon Returns: A reference to the CamGear class object. Source code in vidgear/gears/pigear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" # Start frame producer thread self . __thread = Thread ( target = self . __update , name = \"PiGear\" , args = ()) self . __thread . daemon = True self . __thread . start () # Start internal timer thread self . __timer = Thread ( target = self . __timeit , name = \"PiTimer\" , args = ()) self . __timer . daemon = True self . __timer . start () return self stop ( self ) \u00b6 Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/pigear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" if self . __logging : logger . debug ( \"Terminating PiGear Processes.\" ) # make sure that the threads should be terminated self . __terminate = True # stop timer thread if not ( self . __timer is None ): self . __timer . join () # handle camera thread if not ( self . __thread is None ): # check if hardware failure occured if not ( self . __exceptions is None ) and isinstance ( self . __exceptions , bool ): # force release picamera resources self . stream . close () self . __rawCapture . close () self . __camera . close () # properly handle thread exit self . __thread . join () self . __thread . wait () # wait if still process is still processing some information self . __thread = None else : # properly handle thread exit self . __thread . join ()","title":"pigear.py"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear","text":"PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded wrapper around complete picamera python library, and also provides us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear supports multiple camera modules, such as in case of Raspberry Pi Compute module IO boards. Best of all, PiGear provides excellent error-handling with features like a Threaded Internal Timer - that keeps active track of any frozen-threads/hardware-failures robustly, and exit safely if it does occurs, i.e. If you're running PiGear API in your script, and someone accidentally pulls Camera module cable out, instead of going into possible kernel panic, PiGear will exit safely to save resources.","title":"vidgear.gears.pigear.PiGear"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.read","text":"Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/pigear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check if there are any thread exceptions if not ( self . __exceptions is None ): if isinstance ( self . __exceptions , bool ): # clear frame self . frame = None # notify user about hardware failure raise SystemError ( \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\" ) else : # clear frame self . frame = None # re-raise error for debugging error_msg = ( \"[PiGear:ERROR] :: Camera Module API failure occured: {} \" . format ( self . __exceptions [ 1 ] ) ) raise RuntimeError ( error_msg ) . with_traceback ( self . __exceptions [ 2 ]) # return the frame return self . frame","title":"read()"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.start","text":"Launches the internal Threaded Frames Extractor daemon Returns: A reference to the CamGear class object. Source code in vidgear/gears/pigear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" # Start frame producer thread self . __thread = Thread ( target = self . __update , name = \"PiGear\" , args = ()) self . __thread . daemon = True self . __thread . start () # Start internal timer thread self . __timer = Thread ( target = self . __timeit , name = \"PiTimer\" , args = ()) self . __timer . daemon = True self . __timer . start () return self","title":"start()"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.stop","text":"Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/pigear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" if self . __logging : logger . debug ( \"Terminating PiGear Processes.\" ) # make sure that the threads should be terminated self . __terminate = True # stop timer thread if not ( self . __timer is None ): self . __timer . join () # handle camera thread if not ( self . __thread is None ): # check if hardware failure occured if not ( self . __exceptions is None ) and isinstance ( self . __exceptions , bool ): # force release picamera resources self . stream . close () self . __rawCapture . close () self . __camera . close () # properly handle thread exit self . __thread . join () self . __thread . wait () # wait if still process is still processing some information self . __thread = None else : # properly handle thread exit self . __thread . join ()","title":"stop()"},{"location":"bonus/reference/screengear/","text":"All ScreenGear Class parameters are explained here \u27b6 \u00b6 ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors. ScreenGear API implements a multi-threaded wrapper around python-mss python library, and also flexibly supports its internal parameter. Furthermore, ScreenGear API relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. read ( self ) \u00b6 Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/screengear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check whether or not termination flag is enabled while not self . __terminate : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : continue # otherwise return NoneType return None start ( self ) \u00b6 Launches the internal Threaded Frames Extractor daemon Returns: A reference to the ScreenGear class object. Source code in vidgear/gears/screengear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the ScreenGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"ScreenGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self stop ( self ) \u00b6 Safely terminates the thread, and release the resources. Source code in vidgear/gears/screengear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the resources. \"\"\" if self . __logging : logger . debug ( \"Terminating ScreenGear Processes.\" ) # indicate that the thread should be terminated self . __terminate = True # terminate Threaded queue mode seperately if not ( self . __queue is None ): self . __queue . clear () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : self . __thread . join ()","title":"screengear.py"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear","text":"ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors. ScreenGear API implements a multi-threaded wrapper around python-mss python library, and also flexibly supports its internal parameter. Furthermore, ScreenGear API relies on Threaded Queue mode for threaded, error-free and synchronized frame handling.","title":"vidgear.gears.screengear.ScreenGear"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.read","text":"Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/screengear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check whether or not termination flag is enabled while not self . __terminate : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : continue # otherwise return NoneType return None","title":"read()"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.start","text":"Launches the internal Threaded Frames Extractor daemon Returns: A reference to the ScreenGear class object. Source code in vidgear/gears/screengear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the ScreenGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"ScreenGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self","title":"start()"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.stop","text":"Safely terminates the thread, and release the resources. Source code in vidgear/gears/screengear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the resources. \"\"\" if self . __logging : logger . debug ( \"Terminating ScreenGear Processes.\" ) # indicate that the thread should be terminated self . __terminate = True # terminate Threaded queue mode seperately if not ( self . __queue is None ): self . __queue . clear () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : self . __thread . join ()","title":"stop()"},{"location":"bonus/reference/stabilizer/","text":"All Stabilizer Class parameters are explained here \u27b6 \u00b6 This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free & ultra-fast frame handling. clean ( self ) \u00b6 Cleans Stabilizer resources Source code in vidgear/gears/stabilizer.py def clean ( self ): \"\"\" Cleans Stabilizer resources \"\"\" # check if deque present if self . __frame_queue : # clear frame deque self . __frame_queue . clear () # clear frame indexes deque self . __frame_queue_indexes . clear () stabilize ( self , frame ) \u00b6 This method takes an unstabilized video frame, and returns a stabilized one. Parameters: Name Type Description Default frame numpy.ndarray inputs unstabilized video frames. required Source code in vidgear/gears/stabilizer.py def stabilize ( self , frame ): \"\"\" This method takes an unstabilized video frame, and returns a stabilized one. Parameters: frame (numpy.ndarray): inputs unstabilized video frames. \"\"\" # check if frame is None if frame is None : # return if it does return # save frame size for zooming if self . __crop_n_zoom and self . __frame_size == None : self . __frame_size = frame . shape [: 2 ] # initiate transformations capturing if not self . __frame_queue : # for first frame previous_gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # convert to gray previous_gray = self . __clahe . apply ( previous_gray ) # optimize gray frame self . __previous_keypoints = cv2 . goodFeaturesToTrack ( previous_gray , maxCorners = 200 , qualityLevel = 0.05 , minDistance = 30.0 , blockSize = 3 , mask = None , useHarrisDetector = False , k = 0.04 , ) # track features using GFTT self . __frame_height , self . frame_width = frame . shape [ : 2 ] # save input frame height and width self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( 0 ) # save frame index to deque self . __previous_gray = previous_gray [ : ] # save gray frame clone for further processing elif self . __frame_queue_indexes [ - 1 ] <= self . __smoothing_radius - 1 : # for rest of frames self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations if self . __frame_queue_indexes [ - 1 ] == self . __smoothing_radius - 1 : # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation else : # start applying transformations self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation # return transformation applied stabilized frame return self . __apply_transformations ()","title":"stabilizer.py"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer","text":"This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free & ultra-fast frame handling.","title":"vidgear.gears.stabilizer.Stabilizer"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.clean","text":"Cleans Stabilizer resources Source code in vidgear/gears/stabilizer.py def clean ( self ): \"\"\" Cleans Stabilizer resources \"\"\" # check if deque present if self . __frame_queue : # clear frame deque self . __frame_queue . clear () # clear frame indexes deque self . __frame_queue_indexes . clear ()","title":"clean()"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.stabilize","text":"This method takes an unstabilized video frame, and returns a stabilized one. Parameters: Name Type Description Default frame numpy.ndarray inputs unstabilized video frames. required Source code in vidgear/gears/stabilizer.py def stabilize ( self , frame ): \"\"\" This method takes an unstabilized video frame, and returns a stabilized one. Parameters: frame (numpy.ndarray): inputs unstabilized video frames. \"\"\" # check if frame is None if frame is None : # return if it does return # save frame size for zooming if self . __crop_n_zoom and self . __frame_size == None : self . __frame_size = frame . shape [: 2 ] # initiate transformations capturing if not self . __frame_queue : # for first frame previous_gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # convert to gray previous_gray = self . __clahe . apply ( previous_gray ) # optimize gray frame self . __previous_keypoints = cv2 . goodFeaturesToTrack ( previous_gray , maxCorners = 200 , qualityLevel = 0.05 , minDistance = 30.0 , blockSize = 3 , mask = None , useHarrisDetector = False , k = 0.04 , ) # track features using GFTT self . __frame_height , self . frame_width = frame . shape [ : 2 ] # save input frame height and width self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( 0 ) # save frame index to deque self . __previous_gray = previous_gray [ : ] # save gray frame clone for further processing elif self . __frame_queue_indexes [ - 1 ] <= self . __smoothing_radius - 1 : # for rest of frames self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations if self . __frame_queue_indexes [ - 1 ] == self . __smoothing_radius - 1 : # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation else : # start applying transformations self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation # return transformation applied stabilized frame return self . __apply_transformations ()","title":"stabilize()"},{"location":"bonus/reference/streamgear/","text":"All StreamGear Class parameters are explained here \u27b6 \u00b6 StreamGear is built for Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) with FFmpeg to generate the chunked-encoded media segments of the content, in just few lines of python code. StreamGear provides a standalone, highly extensible and flexible wrapper around FFmpeg - a leading multimedia framework and access to almost all of its parameter for seamlessly generating these streams. SteamGear API automatically transcodes source videos/audio files & real-time frames, and breaks them into a sequence of multiple smaller chunks/segments (typically 2-4 seconds in length) at different quality levels (i.e. different bitrates or spatial resolutions) . It also creates a media presentation description (MPD in-case of DASH) that describes these segment information (timing, URL, media characteristics like video resolution and bit rates) , and is provided to the client prior to the streaming session. Thereby, segments are served on a web-server and can be downloaded through HTTP standard compliant GET requests. This makes it possible to stream videos at different quality levels, and to switch in the middle of a video from one quality level to another one. SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. stream ( self , frame , rgb_mode = False ) \u00b6 Pipelines ndarray frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR) . False Source code in vidgear/gears/streamgear.py def stream ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" # check if function is called in correct context if self . __video_source : raise RuntimeError ( \"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\" ) # None-Type frames will be skipped if frame is None : return # extract height, width and number of channels of frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate_stream : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __sourceframerate = ( 25.0 if not ( self . __inputframerate ) else self . __inputframerate ) if self . __logging : logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same number of channels!\" ) # initiate FFmpeg process on first run if self . __initiate_stream : # launch pre-processing self . __PreProcess ( channels = channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame to pipeline try : self . __process . stdin . write ( frame . tostring ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only terminate ( self ) \u00b6 Safely terminates StreamGear. Source code in vidgear/gears/streamgear.py def terminate ( self ): \"\"\" Safely terminates StreamGear. \"\"\" # return if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): return # close `stdin` output if self . __process . stdin : self . __process . stdin . close () # wait if still process is still processing some information self . __process . wait () self . __process = None # log it logger . critical ( \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\" . format ( self . __format . upper () ) ) transcode_source ( self ) \u00b6 Transcodes entire Video Source (with audio) into multi-bitrate streamable assets Source code in vidgear/gears/streamgear.py def transcode_source ( self ): \"\"\" Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets \"\"\" # check if function is called in correct context if not ( self . __video_source ): raise RuntimeError ( \"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\" ) # assign height, width and framerate self . __inputheight = int ( self . __aspect_source [ 1 ]) self . __inputwidth = int ( self . __aspect_source [ 0 ]) self . __sourceframerate = float ( self . __fps_source ) # launch pre-processing self . __PreProcess ()","title":"streamgear.py"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear","text":"StreamGear is built for Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) with FFmpeg to generate the chunked-encoded media segments of the content, in just few lines of python code. StreamGear provides a standalone, highly extensible and flexible wrapper around FFmpeg - a leading multimedia framework and access to almost all of its parameter for seamlessly generating these streams. SteamGear API automatically transcodes source videos/audio files & real-time frames, and breaks them into a sequence of multiple smaller chunks/segments (typically 2-4 seconds in length) at different quality levels (i.e. different bitrates or spatial resolutions) . It also creates a media presentation description (MPD in-case of DASH) that describes these segment information (timing, URL, media characteristics like video resolution and bit rates) , and is provided to the client prior to the streaming session. Thereby, segments are served on a web-server and can be downloaded through HTTP standard compliant GET requests. This makes it possible to stream videos at different quality levels, and to switch in the middle of a video from one quality level to another one. SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon.","title":"vidgear.gears.streamgear.StreamGear"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.stream","text":"Pipelines ndarray frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR) . False Source code in vidgear/gears/streamgear.py def stream ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" # check if function is called in correct context if self . __video_source : raise RuntimeError ( \"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\" ) # None-Type frames will be skipped if frame is None : return # extract height, width and number of channels of frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate_stream : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __sourceframerate = ( 25.0 if not ( self . __inputframerate ) else self . __inputframerate ) if self . __logging : logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same number of channels!\" ) # initiate FFmpeg process on first run if self . __initiate_stream : # launch pre-processing self . __PreProcess ( channels = channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame to pipeline try : self . __process . stdin . write ( frame . tostring ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only","title":"stream()"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.terminate","text":"Safely terminates StreamGear. Source code in vidgear/gears/streamgear.py def terminate ( self ): \"\"\" Safely terminates StreamGear. \"\"\" # return if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): return # close `stdin` output if self . __process . stdin : self . __process . stdin . close () # wait if still process is still processing some information self . __process . wait () self . __process = None # log it logger . critical ( \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\" . format ( self . __format . upper () ) )","title":"terminate()"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.transcode_source","text":"Transcodes entire Video Source (with audio) into multi-bitrate streamable assets Source code in vidgear/gears/streamgear.py def transcode_source ( self ): \"\"\" Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets \"\"\" # check if function is called in correct context if not ( self . __video_source ): raise RuntimeError ( \"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\" ) # assign height, width and framerate self . __inputheight = int ( self . __aspect_source [ 1 ]) self . __inputwidth = int ( self . __aspect_source [ 0 ]) self . __sourceframerate = float ( self . __fps_source ) # launch pre-processing self . __PreProcess ()","title":"transcode_source()"},{"location":"bonus/reference/videogear/","text":"All VideoGear Class parameters are explained here \u27b6 \u00b6 VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using just fewer lines of code. read ( self ) \u00b6 Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/videogear.py def read ( self ): \"\"\" Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __stablization_mode : frame = self . stream . read () if frame is None : break frame_stab = self . __stabilizer_obj . stabilize ( frame ) if not ( frame_stab is None ): return frame_stab return self . stream . read () start ( self ) \u00b6 Launches the internal Threaded Frames Extractor daemon of API in use. Returns: A reference to the selected class object. Source code in vidgear/gears/videogear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon of API in use. **Returns:** A reference to the selected class object. \"\"\" self . stream . start () return self stop ( self ) \u00b6 Safely terminates the thread, and release the respective VideoStream resources. Source code in vidgear/gears/videogear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the respective VideoStream resources. \"\"\" self . stream . stop () # logged if self . __logging : logger . debug ( \"Terminating VideoGear.\" ) # clean queue if self . __stablization_mode : self . __stabilizer_obj . clean ()","title":"videogear.py"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear","text":"VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using just fewer lines of code.","title":"vidgear.gears.videogear.VideoGear"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.read","text":"Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/videogear.py def read ( self ): \"\"\" Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __stablization_mode : frame = self . stream . read () if frame is None : break frame_stab = self . __stabilizer_obj . stabilize ( frame ) if not ( frame_stab is None ): return frame_stab return self . stream . read ()","title":"read()"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.start","text":"Launches the internal Threaded Frames Extractor daemon of API in use. Returns: A reference to the selected class object. Source code in vidgear/gears/videogear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon of API in use. **Returns:** A reference to the selected class object. \"\"\" self . stream . start () return self","title":"start()"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.stop","text":"Safely terminates the thread, and release the respective VideoStream resources. Source code in vidgear/gears/videogear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the respective VideoStream resources. \"\"\" self . stream . stop () # logged if self . __logging : logger . debug ( \"Terminating VideoGear.\" ) # clean queue if self . __stablization_mode : self . __stabilizer_obj . clean ()","title":"stop()"},{"location":"bonus/reference/webgear/","text":"All WebGear Class parameters are explained here \u27b6 \u00b6 WebGear is a powerful ASGI Video-streamer API, that is built upon Starlette - a lightweight ASGI python framework/toolkit, which is ideal for building high-performance asyncio services. WebGear API provides a highly extensible and flexible asyncio wrapper around Starlette ASGI application, and provides easy access to its complete framework. Thereby, WebGear API can flexibly interact with the Starlette's ecosystem of shared middleware and mountable applications, and its various Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. In layman's terms, WebGear can acts as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. It addition to this, WebGear API also provides a special internal wrapper around VideoGear API, which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any device/source, such as streaming Stabilization enabled Video in real-time. __call__ ( self ) special \u00b6 Implements a custom Callable method for WebGear application. Source code in vidgear/gears/asyncio/webgear.py def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"Routing tables are not valid!\" ) # initiate stream if self . __logging : logger . debug ( \"Initiating Video Streaming.\" ) self . stream . start () # return Starlette application if self . __logging : logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , exception_handlers = self . __exception_handlers , on_shutdown = [ self . shutdown ], ) shutdown ( self ) \u00b6 Implements a Callable to be run on application shutdown Source code in vidgear/gears/asyncio/webgear.py def shutdown ( self ): \"\"\" Implements a Callable to be run on application shutdown \"\"\" if not ( self . stream is None ): if self . __logging : logger . debug ( \"Closing Video Streaming.\" ) # stops producer self . __isrunning = False # stops VideoGear stream self . stream . stop () # prevent any re-iteration self . stream = None","title":"webgear.py"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear","text":"WebGear is a powerful ASGI Video-streamer API, that is built upon Starlette - a lightweight ASGI python framework/toolkit, which is ideal for building high-performance asyncio services. WebGear API provides a highly extensible and flexible asyncio wrapper around Starlette ASGI application, and provides easy access to its complete framework. Thereby, WebGear API can flexibly interact with the Starlette's ecosystem of shared middleware and mountable applications, and its various Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. In layman's terms, WebGear can acts as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. It addition to this, WebGear API also provides a special internal wrapper around VideoGear API, which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any device/source, such as streaming Stabilization enabled Video in real-time.","title":"vidgear.gears.asyncio.webgear.WebGear"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__call__","text":"Implements a custom Callable method for WebGear application. Source code in vidgear/gears/asyncio/webgear.py def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"Routing tables are not valid!\" ) # initiate stream if self . __logging : logger . debug ( \"Initiating Video Streaming.\" ) self . stream . start () # return Starlette application if self . __logging : logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , exception_handlers = self . __exception_handlers , on_shutdown = [ self . shutdown ], )","title":"__call__()"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.shutdown","text":"Implements a Callable to be run on application shutdown Source code in vidgear/gears/asyncio/webgear.py def shutdown ( self ): \"\"\" Implements a Callable to be run on application shutdown \"\"\" if not ( self . stream is None ): if self . __logging : logger . debug ( \"Closing Video Streaming.\" ) # stops producer self . __isrunning = False # stops VideoGear stream self . stream . stop () # prevent any re-iteration self . stream = None","title":"shutdown()"},{"location":"bonus/reference/writegear/","text":"All WriteGear Class parameters: Compression Mode here\u27b6 and Non-Compression Mode here\u27b6 \u00b6 WriteGear API provides a complete, flexible and robust wrapper around FFmpeg , a leading multimedia framework. With WriteGear, we can process real-time frames into a lossless compressed video-file with any suitable specification in just few easy lines of codes. These specifications include setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, etc. , and also performing complex tasks such as multiplexing video with audio in real-time, while handling all errors robustly. Best of all, WriteGear grants the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function , without relying on any Third-party library. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API which provides some basic tools for video frames encoding but without compression. Modes of Operation WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. close ( self ) \u00b6 Safely terminates various WriteGear process. Source code in vidgear/gears/writegear.py def close ( self ): \"\"\" Safely terminates various WriteGear process. \"\"\" if self . __logging : logger . debug ( \"Terminating WriteGear Processes.\" ) if self . __compression : # if Compression Mode is enabled if self . __process is None or not ( self . __process . poll () is None ): return # no process was initiated at first place if self . __process . stdin : self . __process . stdin . close () # close `stdin` output if self . __force_termination : self . __process . terminate () self . __process . wait () # wait if still process is still processing some information self . __process = None else : # if Compression Mode is disabled if self . __process is None : return # no process was initiated at first place self . __process . release () # close it execute_ffmpeg_cmd ( self , cmd = None ) \u00b6 Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: Name Type Description Default cmd list inputs list data-type command. None Source code in vidgear/gears/writegear.py def execute_ffmpeg_cmd ( self , cmd = None ): \"\"\" Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: cmd (list): inputs list data-type command. \"\"\" # check if valid command if cmd is None or not ( cmd ): logger . warning ( \"Input FFmpeg command is empty, Nothing to execute!\" ) return else : if not ( isinstance ( cmd , list )): raise ValueError ( \"[WriteGear:ERROR] :: Invalid input FFmpeg command datatype! Kindly read docs.\" ) # check if Compression Mode is enabled if not ( self . __compression ): raise RuntimeError ( \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function!\" ) # add configured FFmpeg path cmd = [ self . __ffmpeg ] + cmd try : # write to pipeline if self . __logging : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode sp . run ( cmd , stdin = sp . PIPE , stdout = sp . PIPE , stderr = None ) else : sp . run ( cmd , stdin = sp . PIPE , stdout = sp . DEVNULL , stderr = sp . STDOUT ) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only write ( self , frame , rgb_mode = False ) \u00b6 Pipelines ndarray frames to respective API (FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode) . Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR) . False Source code in vidgear/gears/writegear.py def write ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to respective API _(FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode)_. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" if frame is None : # None-Type frames will be skipped return # get height, width and number of channels of current frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels if self . __logging : logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[WriteGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[WriteGear:ERROR] :: All frames must have same number of channels!\" ) if self . __compression : # checks if compression mode is enabled # initiate FFmpeg process on first run if self . __initiate : # start pre-processing and initiate process self . __Preprocess ( channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame try : self . __process . stdin . write ( frame . tostring ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only else : # otherwise initiate OpenCV's VideoWriter Class if self . __initiate : # start VideoWriter Class process self . __startCV_Process () # Check status of the process assert self . __process is not None if self . __logging : # log OpenCV warning logger . info ( \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet, switch to `compression_mode` to use them!\" ) # write the frame self . __process . write ( frame )","title":"writegear.py"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear","text":"WriteGear API provides a complete, flexible and robust wrapper around FFmpeg , a leading multimedia framework. With WriteGear, we can process real-time frames into a lossless compressed video-file with any suitable specification in just few easy lines of codes. These specifications include setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, etc. , and also performing complex tasks such as multiplexing video with audio in real-time, while handling all errors robustly. Best of all, WriteGear grants the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function , without relying on any Third-party library. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API which provides some basic tools for video frames encoding but without compression. Modes of Operation WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc.","title":"vidgear.gears.writegear.WriteGear"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.close","text":"Safely terminates various WriteGear process. Source code in vidgear/gears/writegear.py def close ( self ): \"\"\" Safely terminates various WriteGear process. \"\"\" if self . __logging : logger . debug ( \"Terminating WriteGear Processes.\" ) if self . __compression : # if Compression Mode is enabled if self . __process is None or not ( self . __process . poll () is None ): return # no process was initiated at first place if self . __process . stdin : self . __process . stdin . close () # close `stdin` output if self . __force_termination : self . __process . terminate () self . __process . wait () # wait if still process is still processing some information self . __process = None else : # if Compression Mode is disabled if self . __process is None : return # no process was initiated at first place self . __process . release () # close it","title":"close()"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.execute_ffmpeg_cmd","text":"Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: Name Type Description Default cmd list inputs list data-type command. None Source code in vidgear/gears/writegear.py def execute_ffmpeg_cmd ( self , cmd = None ): \"\"\" Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: cmd (list): inputs list data-type command. \"\"\" # check if valid command if cmd is None or not ( cmd ): logger . warning ( \"Input FFmpeg command is empty, Nothing to execute!\" ) return else : if not ( isinstance ( cmd , list )): raise ValueError ( \"[WriteGear:ERROR] :: Invalid input FFmpeg command datatype! Kindly read docs.\" ) # check if Compression Mode is enabled if not ( self . __compression ): raise RuntimeError ( \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function!\" ) # add configured FFmpeg path cmd = [ self . __ffmpeg ] + cmd try : # write to pipeline if self . __logging : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode sp . run ( cmd , stdin = sp . PIPE , stdout = sp . PIPE , stderr = None ) else : sp . run ( cmd , stdin = sp . PIPE , stdout = sp . DEVNULL , stderr = sp . STDOUT ) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only","title":"execute_ffmpeg_cmd()"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.write","text":"Pipelines ndarray frames to respective API (FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode) . Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR) . False Source code in vidgear/gears/writegear.py def write ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to respective API _(FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode)_. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" if frame is None : # None-Type frames will be skipped return # get height, width and number of channels of current frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels if self . __logging : logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[WriteGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[WriteGear:ERROR] :: All frames must have same number of channels!\" ) if self . __compression : # checks if compression mode is enabled # initiate FFmpeg process on first run if self . __initiate : # start pre-processing and initiate process self . __Preprocess ( channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame try : self . __process . stdin . write ( frame . tostring ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only else : # otherwise initiate OpenCV's VideoWriter Class if self . __initiate : # start VideoWriter Class process self . __startCV_Process () # Check status of the process assert self . __process is not None if self . __logging : # log OpenCV warning logger . info ( \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet, switch to `compression_mode` to use them!\" ) # write the frame self . __process . write ( frame )","title":"write()"},{"location":"contribution/PR/","text":"Submitting Pull Request(PR) Guidelines: \u00b6 The following guidelines tells you how to submit a valid PR for vidGear: Working on your first Pull Request for VidGear? If you don't know how to contribute to an Open Source Project on GitHub, then You can learn about it from here . If you're stuck at something, please join our Gitter community channel . We will help you get started! Kindly follow the EXEMPLARY tag for some finest PR examples. Forking and Cloning \u00b6 First fork on GitHub? You can easily learn about it from Fork a repo wiki. Pull Request Requirements Any Pull Request failed to comply following requirements will be rejected: The testing branch of your Forked repository MUST be up-to-date with VidGear, before starting working on Pull Request. Your new working branch for Pull Request MUST be a sub-branch of testing branch of your Forked repository only. All Pull Requests MUST be pushed against VidGear's testing branch only. You can clone your forked remote git to local, and create your PR working branch as a sub-branch of testing branch as follows: # clone your forked repository(change with your username) and get inside git clone https://github.com/ { YOUR USERNAME } /vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # Now create your new branch with suitable name(such as \"subbranch_of_testing\") git checkout -b subbranch_of_testing Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual. Submission Checklist \u00b6 There are some important checks you need to perform while submitting your Pull Request(s) for VidGear library: Submit an issue and Link your Pull Request: For more information on Linking a pull request to an issue, See this wiki doc If you would like to implement a new feature/improvement for VidGear, please submit an issue with a proposal template for your work first and then submit your Pull Request. You can link an issue to a pull request manually or using a supported keyword in the pull request description. When you link a pull request to the issue the pull request addresses, collaborators can see that someone is working on the issue. Perform PR Integrity Checks: Search GitHub for an open or closed PR that relates to your submission. Duplicate contributions will be rejected. Submit the pull request from the first day of your development and create it as a draft pull request. Click ready for review when finished and passed all the checks. Check if your purposed code matches the overall direction, simplicity and structure of the VidGear APIs and improves it. Make sure your PR must pass through all unit tests including VidGear's CI tests . If it's somehow failing, then ask maintainer for a review. It is important to state that you retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache license . Test, Format & lint locally: Make sure to locally test, format and lint the modified code every time you commit. The details are discussed above. Make sensible commit messages: If your PR fixes a separate issue number, remember to include \"resolves #issue_number\" in the commit message. Learn more about it here . Keep commit message concise as much as possible at every submit. You can make a supplement to the previous commit with git commit --amend command. If we suggest changes, make the required updates, rebase your branch and push the changes to your GitHub repository, which will automatically update your PR. Draft the PR according to template: Remember to completely fill the whole template for PR. Incomplete ones will be subjected to re-edit! Add a brief but descriptive title for your PR. Explain what the PR adds, fixes or improves. In case of bug fixes, add new unit test case which would fail against your bug fix. Provide CLI commands and output or screenshots where you can. Testing, Formatting & Linting \u00b6 All Pull Request(s) must be tested, formatted & linted against our library standards as discussed below: Requirements \u00b6 Testing VidGear requires additional test dependencies and dataset, which can be handled manually as follows: Install additional python libraries: You can easily install these dependencies via pip: Note for Windows The mpegdash library has not yet been updated and bugs on windows machines. Kindly instead try the forked DEV-version of mpegdash as follows: python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev/mpegdash-0.3.0.dev0-py3-none-any.whl pip install --upgrade six, flake8, black, pytest, pytest-asyncio, mpegdash Download Tests Dataset: To perform tests, you also need to download additional dataset (to your temp dir) by running prepare_dataset.sh bash script as follows: chmod +x scripts/bash/prepare_dataset.sh # On linux and MacOS .scripts/bash/prepare_dataset.sh # On Windows sh scripts/bash/prepare_dataset.sh Running Tests \u00b6 All tests can be run with pytest ( in VidGear's root folder ) as follows: pytest -sv #-sv for verbose output. Formatting & Linting \u00b6 For formatting and linting, following libraries are used: Flake8: You must run flake8 linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity: flake8 . --count --select = E9,F63,F7,F82 --show-source --statistics Black: Vidgear follows black formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: black { source_file_or_directory } Frequently Asked Questions \u00b6 Q1. Why do my changes taking so long to be Reviewed and/or Merged? Submission Aftermaths After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository. The changes will remain in testing branch until next VidGear version is released, then it will be merged into master branch. After a successful Merge, your newer contributions will be given priority over others. Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request. Q2. What if I want to submit my Work that is Still In Progress? You can do it. But please use one of these two prefixes to let reviewers know about the state of your work: [WIP] (Work in Progress) : is used when you are not yet finished with your pull request, but you would like it to be reviewed. The pull request won't be merged until you say it is ready. [WCM] (Waiting Code Merge) : is used when you're documenting a new feature or change that hasn't been accepted yet into the core code. The pull request will not be merged until it is merged in the core code (or closed if the change is rejected) . Q3. Would you accept a huge Pull Request with Lots of Changes? First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the VidGear Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!","title":"Submitting Pull Request(PR) Guidelines"},{"location":"contribution/PR/#submitting-pull-requestpr-guidelines","text":"The following guidelines tells you how to submit a valid PR for vidGear: Working on your first Pull Request for VidGear? If you don't know how to contribute to an Open Source Project on GitHub, then You can learn about it from here . If you're stuck at something, please join our Gitter community channel . We will help you get started! Kindly follow the EXEMPLARY tag for some finest PR examples.","title":"Submitting Pull Request(PR) Guidelines:"},{"location":"contribution/PR/#forking-and-cloning","text":"First fork on GitHub? You can easily learn about it from Fork a repo wiki. Pull Request Requirements Any Pull Request failed to comply following requirements will be rejected: The testing branch of your Forked repository MUST be up-to-date with VidGear, before starting working on Pull Request. Your new working branch for Pull Request MUST be a sub-branch of testing branch of your Forked repository only. All Pull Requests MUST be pushed against VidGear's testing branch only. You can clone your forked remote git to local, and create your PR working branch as a sub-branch of testing branch as follows: # clone your forked repository(change with your username) and get inside git clone https://github.com/ { YOUR USERNAME } /vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # Now create your new branch with suitable name(such as \"subbranch_of_testing\") git checkout -b subbranch_of_testing Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual.","title":"Forking and Cloning"},{"location":"contribution/PR/#submission-checklist","text":"There are some important checks you need to perform while submitting your Pull Request(s) for VidGear library: Submit an issue and Link your Pull Request: For more information on Linking a pull request to an issue, See this wiki doc If you would like to implement a new feature/improvement for VidGear, please submit an issue with a proposal template for your work first and then submit your Pull Request. You can link an issue to a pull request manually or using a supported keyword in the pull request description. When you link a pull request to the issue the pull request addresses, collaborators can see that someone is working on the issue. Perform PR Integrity Checks: Search GitHub for an open or closed PR that relates to your submission. Duplicate contributions will be rejected. Submit the pull request from the first day of your development and create it as a draft pull request. Click ready for review when finished and passed all the checks. Check if your purposed code matches the overall direction, simplicity and structure of the VidGear APIs and improves it. Make sure your PR must pass through all unit tests including VidGear's CI tests . If it's somehow failing, then ask maintainer for a review. It is important to state that you retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache license . Test, Format & lint locally: Make sure to locally test, format and lint the modified code every time you commit. The details are discussed above. Make sensible commit messages: If your PR fixes a separate issue number, remember to include \"resolves #issue_number\" in the commit message. Learn more about it here . Keep commit message concise as much as possible at every submit. You can make a supplement to the previous commit with git commit --amend command. If we suggest changes, make the required updates, rebase your branch and push the changes to your GitHub repository, which will automatically update your PR. Draft the PR according to template: Remember to completely fill the whole template for PR. Incomplete ones will be subjected to re-edit! Add a brief but descriptive title for your PR. Explain what the PR adds, fixes or improves. In case of bug fixes, add new unit test case which would fail against your bug fix. Provide CLI commands and output or screenshots where you can.","title":"Submission Checklist"},{"location":"contribution/PR/#testing-formatting-linting","text":"All Pull Request(s) must be tested, formatted & linted against our library standards as discussed below:","title":"Testing, Formatting &amp; Linting"},{"location":"contribution/PR/#requirements","text":"Testing VidGear requires additional test dependencies and dataset, which can be handled manually as follows: Install additional python libraries: You can easily install these dependencies via pip: Note for Windows The mpegdash library has not yet been updated and bugs on windows machines. Kindly instead try the forked DEV-version of mpegdash as follows: python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev/mpegdash-0.3.0.dev0-py3-none-any.whl pip install --upgrade six, flake8, black, pytest, pytest-asyncio, mpegdash Download Tests Dataset: To perform tests, you also need to download additional dataset (to your temp dir) by running prepare_dataset.sh bash script as follows: chmod +x scripts/bash/prepare_dataset.sh # On linux and MacOS .scripts/bash/prepare_dataset.sh # On Windows sh scripts/bash/prepare_dataset.sh","title":"Requirements"},{"location":"contribution/PR/#running-tests","text":"All tests can be run with pytest ( in VidGear's root folder ) as follows: pytest -sv #-sv for verbose output.","title":"Running Tests"},{"location":"contribution/PR/#formatting-linting","text":"For formatting and linting, following libraries are used: Flake8: You must run flake8 linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity: flake8 . --count --select = E9,F63,F7,F82 --show-source --statistics Black: Vidgear follows black formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: black { source_file_or_directory }","title":"Formatting &amp; Linting"},{"location":"contribution/PR/#frequently-asked-questions","text":"Q1. Why do my changes taking so long to be Reviewed and/or Merged? Submission Aftermaths After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository. The changes will remain in testing branch until next VidGear version is released, then it will be merged into master branch. After a successful Merge, your newer contributions will be given priority over others. Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request. Q2. What if I want to submit my Work that is Still In Progress? You can do it. But please use one of these two prefixes to let reviewers know about the state of your work: [WIP] (Work in Progress) : is used when you are not yet finished with your pull request, but you would like it to be reviewed. The pull request won't be merged until you say it is ready. [WCM] (Waiting Code Merge) : is used when you're documenting a new feature or change that hasn't been accepted yet into the core code. The pull request will not be merged until it is merged in the core code (or closed if the change is rejected) . Q3. Would you accept a huge Pull Request with Lots of Changes? First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the VidGear Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!","title":"Frequently Asked Questions"},{"location":"contribution/issue/","text":"Submitting an Issue Guidelines \u00b6 If you've found a new bug or you've come up with some new feature which can improve the quality of the VidGear, then related issues are welcomed! But, Before you do, please read the following guidelines: First Issue on GitHub? You can easily learn about it from creating an issue wiki. Info Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon. Search the Docs and Previous Issues \u00b6 Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel. Also, go comprehensively through our dedicated FAQ & Troubleshooting section . Gather Required Information \u00b6 All VidGear APIs provides a logging boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter True in the respective API for getting debug output, and paste it with your Issue. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. Check and paste, exact VidGear version by running command python -c \"import vidgear; print(vidgear.__version__)\" . Follow the Issue Template \u00b6 Please stick to the issue template. Any improper/insufficient reports will be marked with MISSING : INFORMATION and MISSING : TEMPLATE like labels, and if we don't hear back from you we may close the issue. Raise the Issue \u00b6 Add a brief but descriptive title for your issue. Keep the issue phrasing in context of the problem. Attach source-code/screenshots if you have one. Finally, raise it by choosing the appropriate Issue Template: Bug report , Proposal , Question .","title":"Submitting an Issue Guidelines"},{"location":"contribution/issue/#submitting-an-issue-guidelines","text":"If you've found a new bug or you've come up with some new feature which can improve the quality of the VidGear, then related issues are welcomed! But, Before you do, please read the following guidelines: First Issue on GitHub? You can easily learn about it from creating an issue wiki. Info Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon.","title":"Submitting an Issue Guidelines"},{"location":"contribution/issue/#search-the-docs-and-previous-issues","text":"Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel. Also, go comprehensively through our dedicated FAQ & Troubleshooting section .","title":"Search the Docs and Previous Issues"},{"location":"contribution/issue/#gather-required-information","text":"All VidGear APIs provides a logging boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter True in the respective API for getting debug output, and paste it with your Issue. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. Check and paste, exact VidGear version by running command python -c \"import vidgear; print(vidgear.__version__)\" .","title":"Gather Required Information"},{"location":"contribution/issue/#follow-the-issue-template","text":"Please stick to the issue template. Any improper/insufficient reports will be marked with MISSING : INFORMATION and MISSING : TEMPLATE like labels, and if we don't hear back from you we may close the issue.","title":"Follow the Issue Template"},{"location":"contribution/issue/#raise-the-issue","text":"Add a brief but descriptive title for your issue. Keep the issue phrasing in context of the problem. Attach source-code/screenshots if you have one. Finally, raise it by choosing the appropriate Issue Template: Bug report , Proposal , Question .","title":"Raise the Issue"},{"location":"gears/camgear/overview/","text":"CamGear API \u00b6 Functional block diagram depicts CamGear API's generalized workflow Overview \u00b6 CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs . CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters and also internally employs pafy with youtube-dl backend for seamless live YouTube streaming . CamGear relies exclusively on Threaded Queue mode for threaded, error-free and synchronized frame handling. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. You can use framerate class variable to retrieve framerate of the input source. Its usage example can be found here \u27b6 \u2009 Importing \u00b6 You can import CamGear API in your program as follows: from vidgear.gears import CamGear \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/camgear/overview/#camgear-api","text":"Functional block diagram depicts CamGear API's generalized workflow","title":"CamGear API"},{"location":"gears/camgear/overview/#overview","text":"CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs . CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters and also internally employs pafy with youtube-dl backend for seamless live YouTube streaming . CamGear relies exclusively on Threaded Queue mode for threaded, error-free and synchronized frame handling. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. You can use framerate class variable to retrieve framerate of the input source. Its usage example can be found here \u27b6","title":"Overview"},{"location":"gears/camgear/overview/#importing","text":"You can import CamGear API in your program as follows: from vidgear.gears import CamGear","title":"Importing"},{"location":"gears/camgear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/camgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/camgear/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/camgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/camgear/params/","text":"CamGear API Parameters \u00b6 source \u00b6 CamGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: CamGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: CamGear ( source = '/home/foo.mp4' ) YouTube Video's URL ( string ): Valid Youtube video URL as input when YouTube Mode is enabled( i.e. y_tube=True ), for e.g \"https://youtu.be/dQw4w9WgXcQ\" as follows: Valid YouTube URL format All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} CamGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Network Address ( string ): Valid ( http(s), rtp, rstp, rtmp, mms, etc. ) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: CamGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. You can easily check it by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: CamGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) y_tube \u00b6 This parameter controls the YouTube Mode, .i.e if enabled( y_tube=True ), the CamGear API will interpret the given source input as YouTube URL address. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Its complete usage example is given here \u27b6 . colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 backend \u00b6 This parameter manually selects the backend of the OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: CamGear ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u00b6 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to CamGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it CamGear ( source = 0 , ** options ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 0 , logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the CamGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: CamGear ( source = 0 , time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/camgear/params/#camgear-api-parameters","text":"","title":"CamGear API Parameters"},{"location":"gears/camgear/params/#source","text":"CamGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: CamGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: CamGear ( source = '/home/foo.mp4' ) YouTube Video's URL ( string ): Valid Youtube video URL as input when YouTube Mode is enabled( i.e. y_tube=True ), for e.g \"https://youtu.be/dQw4w9WgXcQ\" as follows: Valid YouTube URL format All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} CamGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Network Address ( string ): Valid ( http(s), rtp, rstp, rtmp, mms, etc. ) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: CamGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. You can easily check it by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: CamGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/camgear/params/#y_tube","text":"This parameter controls the YouTube Mode, .i.e if enabled( y_tube=True ), the CamGear API will interpret the given source input as YouTube URL address. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Its complete usage example is given here \u27b6 .","title":"y_tube"},{"location":"gears/camgear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/camgear/params/#backend","text":"This parameter manually selects the backend of the OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: CamGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/camgear/params/#options","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to CamGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it CamGear ( source = 0 , ** options )","title":"options"},{"location":"gears/camgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 0 , logging = True )","title":"logging"},{"location":"gears/camgear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the CamGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: CamGear ( source = 0 , time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/camgear/usage/","text":"CamGear API Usage Examples: \u00b6 \u2009 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with CamGear API: # import required libraries from vidgear.gears import CamGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = 'myvideo.avi' ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Camgear with Youtube Videos \u00b6 CamGear API provides direct support for Live + Normal YouTube Video frames pipelining . All you have to do is to provide the desired YouTube Video's URL to its source parameter and enable the y_tube parameter. The complete usage example is as follows: Update Requirements If you're using pip installed opencv-python , then you must need to install the latest opencv-python or opencv-contrib-python binaries on your machine, along with latest youtube-dl and pafy . You can do it as follows: pip install -U opencv-python #or install opencv-contrib-python similarly pip install -U youtube-dl pafy Bug in Live YouTube Stream Due to a bug with OpenCV's FFmpeg, some Live Youtube-Stream URLs playback freezes after a few seconds, and CamGear API exit with an error: /io/opencv/modules/videoio/src/cap_images.cpp:235: error: (-5:Bad argument) CAP_IMAGES: error, expected '0?[1-9][du]' pattern . This bug occurs with only some live YouTube streams (not all) and hasn't been fixed yet. The only workaround for this bug is suggested here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # Add YouTube Video URL as input source (for e.g https://youtu.be/dQw4w9WgXcQ) and enable `y_Tube` stream = CamGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using CamGear with Variable Camera Properties \u00b6 CamGear API also flexibly support various Source Tweak Parameters available within OpenCV's VideoCapture API . These tweak parameters can be used to manipulate input source Camera-Device properties (such as its brightness, saturation, size, iso, gain etc.) seemlessly, and can be easily applied in CamGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All the supported Source Tweak Parameters can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # To open live video stream on webcam at first index(i.e. 0) device and apply source tweak parameters stream = CamGear ( source = 0 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Camgear with Direct Colorspace Manipulation \u00b6 CamGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import CamGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV` stream = CamGear ( source = 0 , colorspace = 'COLOR_BGR2HSV' , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): #directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY #Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB #Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None #Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Usage Examples"},{"location":"gears/camgear/usage/#camgear-api-usage-examples","text":"","title":"CamGear API Usage Examples:"},{"location":"gears/camgear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with CamGear API: # import required libraries from vidgear.gears import CamGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = 'myvideo.avi' ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/camgear/usage/#using-camgear-with-youtube-videos","text":"CamGear API provides direct support for Live + Normal YouTube Video frames pipelining . All you have to do is to provide the desired YouTube Video's URL to its source parameter and enable the y_tube parameter. The complete usage example is as follows: Update Requirements If you're using pip installed opencv-python , then you must need to install the latest opencv-python or opencv-contrib-python binaries on your machine, along with latest youtube-dl and pafy . You can do it as follows: pip install -U opencv-python #or install opencv-contrib-python similarly pip install -U youtube-dl pafy Bug in Live YouTube Stream Due to a bug with OpenCV's FFmpeg, some Live Youtube-Stream URLs playback freezes after a few seconds, and CamGear API exit with an error: /io/opencv/modules/videoio/src/cap_images.cpp:235: error: (-5:Bad argument) CAP_IMAGES: error, expected '0?[1-9][du]' pattern . This bug occurs with only some live YouTube streams (not all) and hasn't been fixed yet. The only workaround for this bug is suggested here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # Add YouTube Video URL as input source (for e.g https://youtu.be/dQw4w9WgXcQ) and enable `y_Tube` stream = CamGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Camgear with Youtube Videos"},{"location":"gears/camgear/usage/#using-camgear-with-variable-camera-properties","text":"CamGear API also flexibly support various Source Tweak Parameters available within OpenCV's VideoCapture API . These tweak parameters can be used to manipulate input source Camera-Device properties (such as its brightness, saturation, size, iso, gain etc.) seemlessly, and can be easily applied in CamGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All the supported Source Tweak Parameters can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # To open live video stream on webcam at first index(i.e. 0) device and apply source tweak parameters stream = CamGear ( source = 0 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using CamGear with Variable Camera Properties"},{"location":"gears/camgear/usage/#using-camgear-with-direct-colorspace-manipulation","text":"CamGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import CamGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV` stream = CamGear ( source = 0 , colorspace = 'COLOR_BGR2HSV' , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): #directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY #Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB #Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None #Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Camgear with Direct Colorspace Manipulation"},{"location":"gears/camgear/advanced/source_params/","text":"Source Tweak Parameters for CamGear API \u00b6 Overview \u00b6 The CamGear API's option dictionary parameter, provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture Class . These tweak parameters can be used to manipulate input source Camera-Device properties (such as its brightness, saturation, size, iso, gain etc.) seemlessly. Thereby, All Source Tweak Parameters supported by CamGear API are disscussed in this document. Remember, Not all parameters are supported by all cameras devices, which is one of the most troublesome thing with OpenCV library. Each camera type, from android cameras, to USB cameras , to professional ones, offers a different interface to modify its parameters. Therefore, there are many branches in OpenCV code to support as many of them, but of course, not all possible devices are covered, and thereby works. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . You can easily check parameter values supported by your webcam, by hooking it to a Linux machine, and using the command v4l2-ctl -d 0 --list-formats-ext (where 0 is an index of the given camera) to list the supported video parameters and their values. If that doesn't works, refer to its datasheet (if available) . Supported Source Tweak Parameters \u00b6 All Source Tweak Parameters supported by CamGear API are as follows: These parameters can be passed to CamGear's option dictionary parameter by formatting them as its string attributes. Its complete usage example is here \u27b6 \u2009 Values Description CAP_PROP_POS_MSEC Current position of the video file in milliseconds. CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0=start of the film, 1=end of the film. CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CAP_PROP_FPS Frame rate. CAP_PROP_FOURCC 4-character code of codec. see VideoWriter::fourcc . CAP_PROP_FRAME_COUNT Number of frames in the video file. CAP_PROP_FORMAT Format of the Mat objects returned by VideoCapture::retrieve() . CAP_PROP_MODE Backend-specific value indicating the current capture mode. CAP_PROP_BRIGHTNESS Brightness of the image (only for those cameras that support). CAP_PROP_CONTRAST Contrast of the image (only for cameras). CAP_PROP_SATURATION Saturation of the image (only for cameras). CAP_PROP_HUE Hue of the image (only for cameras). CAP_PROP_GAIN Gain of the image (only for those cameras that support). CAP_PROP_EXPOSURE Exposure (only for those cameras that support). CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CAP_PROP_WHITE_BALANCE_BLUE_U Currently unsupported. CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently). CAP_PROP_MONOCHROME CAP_PROP_SHARPNESS CAP_PROP_AUTO_EXPOSURE DC1394: exposure control done by camera, user can adjust reference level using this feature. CAP_PROP_GAMMA CAP_PROP_TEMPERATURE CAP_PROP_TRIGGER CAP_PROP_TRIGGER_DELAY CAP_PROP_WHITE_BALANCE_RED_V CAP_PROP_ZOOM CAP_PROP_FOCUS CAP_PROP_GUID CAP_PROP_ISO_SPEED CAP_PROP_BACKLIGHT CAP_PROP_PAN CAP_PROP_TILT CAP_PROP_ROLL CAP_PROP_IRIS CAP_PROP_SETTINGS Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored) CAP_PROP_BUFFERSIZE CAP_PROP_AUTOFOCUS CAP_PROP_SAR_NUM Sample aspect ratio: num/den (num) CAP_PROP_SAR_DEN Sample aspect ratio: num/den (den) CAP_PROP_BACKEND Current backend (enum VideoCaptureAPIs). Read-only property. CAP_PROP_CHANNEL Video input or Channel Number (only for those cameras that support) CAP_PROP_AUTO_WB enable/ disable auto white-balance CAP_PROP_WB_TEMPERATURE white-balance color temperature","title":"Source Tweak Parameters"},{"location":"gears/camgear/advanced/source_params/#source-tweak-parameters-for-camgear-api","text":"","title":"Source Tweak Parameters for CamGear API"},{"location":"gears/camgear/advanced/source_params/#overview","text":"The CamGear API's option dictionary parameter, provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture Class . These tweak parameters can be used to manipulate input source Camera-Device properties (such as its brightness, saturation, size, iso, gain etc.) seemlessly. Thereby, All Source Tweak Parameters supported by CamGear API are disscussed in this document. Remember, Not all parameters are supported by all cameras devices, which is one of the most troublesome thing with OpenCV library. Each camera type, from android cameras, to USB cameras , to professional ones, offers a different interface to modify its parameters. Therefore, there are many branches in OpenCV code to support as many of them, but of course, not all possible devices are covered, and thereby works. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . You can easily check parameter values supported by your webcam, by hooking it to a Linux machine, and using the command v4l2-ctl -d 0 --list-formats-ext (where 0 is an index of the given camera) to list the supported video parameters and their values. If that doesn't works, refer to its datasheet (if available) .","title":"Overview"},{"location":"gears/camgear/advanced/source_params/#supported-source-tweak-parameters","text":"All Source Tweak Parameters supported by CamGear API are as follows: These parameters can be passed to CamGear's option dictionary parameter by formatting them as its string attributes. Its complete usage example is here \u27b6 \u2009 Values Description CAP_PROP_POS_MSEC Current position of the video file in milliseconds. CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0=start of the film, 1=end of the film. CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CAP_PROP_FPS Frame rate. CAP_PROP_FOURCC 4-character code of codec. see VideoWriter::fourcc . CAP_PROP_FRAME_COUNT Number of frames in the video file. CAP_PROP_FORMAT Format of the Mat objects returned by VideoCapture::retrieve() . CAP_PROP_MODE Backend-specific value indicating the current capture mode. CAP_PROP_BRIGHTNESS Brightness of the image (only for those cameras that support). CAP_PROP_CONTRAST Contrast of the image (only for cameras). CAP_PROP_SATURATION Saturation of the image (only for cameras). CAP_PROP_HUE Hue of the image (only for cameras). CAP_PROP_GAIN Gain of the image (only for those cameras that support). CAP_PROP_EXPOSURE Exposure (only for those cameras that support). CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CAP_PROP_WHITE_BALANCE_BLUE_U Currently unsupported. CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently). CAP_PROP_MONOCHROME CAP_PROP_SHARPNESS CAP_PROP_AUTO_EXPOSURE DC1394: exposure control done by camera, user can adjust reference level using this feature. CAP_PROP_GAMMA CAP_PROP_TEMPERATURE CAP_PROP_TRIGGER CAP_PROP_TRIGGER_DELAY CAP_PROP_WHITE_BALANCE_RED_V CAP_PROP_ZOOM CAP_PROP_FOCUS CAP_PROP_GUID CAP_PROP_ISO_SPEED CAP_PROP_BACKLIGHT CAP_PROP_PAN CAP_PROP_TILT CAP_PROP_ROLL CAP_PROP_IRIS CAP_PROP_SETTINGS Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored) CAP_PROP_BUFFERSIZE CAP_PROP_AUTOFOCUS CAP_PROP_SAR_NUM Sample aspect ratio: num/den (num) CAP_PROP_SAR_DEN Sample aspect ratio: num/den (den) CAP_PROP_BACKEND Current backend (enum VideoCaptureAPIs). Read-only property. CAP_PROP_CHANNEL Video input or Channel Number (only for those cameras that support) CAP_PROP_AUTO_WB enable/ disable auto white-balance CAP_PROP_WB_TEMPERATURE white-balance color temperature","title":"Supported Source Tweak Parameters"},{"location":"gears/netgear/overview/","text":"NetGear API \u00b6 NetGear API generalized Overview \u00b6 NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. Lazy Pirate pattern in NetGear API NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns( zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Netgear API also provides max_retries and request_timeout like attributes for controlling this polling. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc . \u2009 Modes of Operation \u00b6 Primary Modes \u00b6 NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Activate this mode by setting parameter receive_mode = True . Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. The mode sends back confirmation when the frame is received successfully in few patterns. Activate this mode by setting parameter receive_mode = True . Exclusive Modes \u00b6 In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes: Also, check this compatibility chart for these modes interoperability. Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Each new Server on the network can be identified on the client's end by using its unique port address. Also, it exhibits a feature where if all the connected servers on the network get disconnected, the client itself automatically exits to save resources. You can learn about this mode here \u27b6 . Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Each Client on the network can be uniquely identified on the Server's end by using its unique port address. This mode is ideal for applications, where broadcasting/streaming video-frames & data from a single broadcaster to multiple connected users is required. You can learn about this mode here \u27b6 . Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames . Using this mode, the user can now send or receive any data(of any datatype) between Server and Client easily in real-time. You can learn more about this mode here \u27b6 . Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. You can learn more about this mode here \u27b6 . \u2009 Important Information When compiling/installing pyzmq with pip on Linux, it is generally recommended that zeromq binaries to be installed separately, via homebrew, apt, yum, etc. as follows: # Debian-based sudo apt-get install libzmq3-dev # RHEL-based sudo yum install libzmq3-devel # OSX-based brew install zeromq If zeromq binaries are not found, pyzmq will try to build libzmq as a Python Extension, though this is not guaranteed to work! It is advised to enable logging ( logging = True ) on the first run, to easily identify any runtime errors. Kindly go through each given Usage Examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using send() function in Receive Mode) , will result in ValueError . \u2009 Importing \u00b6 You can import NetGear API in your program as follows: from vidgear.gears import NetGear Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/netgear/overview/#netgear-api","text":"NetGear API generalized","title":"NetGear API"},{"location":"gears/netgear/overview/#overview","text":"NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. Lazy Pirate pattern in NetGear API NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns( zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Netgear API also provides max_retries and request_timeout like attributes for controlling this polling. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc .","title":"Overview"},{"location":"gears/netgear/overview/#modes-of-operation","text":"","title":"Modes of Operation"},{"location":"gears/netgear/overview/#primary-modes","text":"NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Activate this mode by setting parameter receive_mode = True . Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. The mode sends back confirmation when the frame is received successfully in few patterns. Activate this mode by setting parameter receive_mode = True .","title":"Primary Modes"},{"location":"gears/netgear/overview/#exclusive-modes","text":"In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes: Also, check this compatibility chart for these modes interoperability. Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Each new Server on the network can be identified on the client's end by using its unique port address. Also, it exhibits a feature where if all the connected servers on the network get disconnected, the client itself automatically exits to save resources. You can learn about this mode here \u27b6 . Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Each Client on the network can be uniquely identified on the Server's end by using its unique port address. This mode is ideal for applications, where broadcasting/streaming video-frames & data from a single broadcaster to multiple connected users is required. You can learn about this mode here \u27b6 . Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames . Using this mode, the user can now send or receive any data(of any datatype) between Server and Client easily in real-time. You can learn more about this mode here \u27b6 . Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. You can learn more about this mode here \u27b6 . \u2009 Important Information When compiling/installing pyzmq with pip on Linux, it is generally recommended that zeromq binaries to be installed separately, via homebrew, apt, yum, etc. as follows: # Debian-based sudo apt-get install libzmq3-dev # RHEL-based sudo yum install libzmq3-devel # OSX-based brew install zeromq If zeromq binaries are not found, pyzmq will try to build libzmq as a Python Extension, though this is not guaranteed to work! It is advised to enable logging ( logging = True ) on the first run, to easily identify any runtime errors. Kindly go through each given Usage Examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using send() function in Receive Mode) , will result in ValueError .","title":"Exclusive Modes"},{"location":"gears/netgear/overview/#importing","text":"You can import NetGear API in your program as follows: from vidgear.gears import NetGear","title":"Importing"},{"location":"gears/netgear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/netgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/netgear/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/netgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/netgear/params/","text":"NetGear API Parameters \u00b6 address \u00b6 This parameter sets the valid Network IP address for Server/Client. Network addresses are unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode , i.e 'localhost' for Send Mode and '*' for Receive Mode on a local machine. Usage: NetGear ( address = \"192.168.0.145\" ) port \u00b6 This parameter sets the valid Network Port for Server/Client. Network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Exclusive Mode Exception In Multi-Servers Mode : A unique port number MUST be assigned to each Server on the network using this parameter. At Client end, a List/Tuple of all available Server(s) ports MUST be assigned, using this same parameter. See its usage example here \u27b6 . In Multi-Client Mode : A unique port number MUST be assigned to each Client on the network using this parameter. At Server end, a List/Tuple of all available Client(s) ports MUST be assigned, using this same parameter. See its usage example here \u27b6 . Data-Type: String or List/Tuple Default Value: Its default value is '5555' Usage: NetGear ( port = \"5575\" ) protocol \u00b6 This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear ( protocol = \"ipc\" ) pattern \u00b6 This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). All supported ZMQ patterns for NetGear are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. Usage: NetGear ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern receive_mode \u00b6 This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear ( receive_mode = True ) # activates Recieve Mode options \u00b6 This parameter provides the flexibility to alter various NetGear API's internal properties, modes, and some PyZMQ flags. Data-Type: Dictionary Default Value: Its default value is {} Usage: Supported dictionary attributes for NetGear API multiserver_mode ( boolean ) : This internal attribute activates the exclusive Multi-Servers Mode , if enabled( True ). multiclient_mode ( boolean ) : This internal attribute activates the exclusive Multi-Clients Mode , if enabled( True ). secure_mode ( integer ) : This internal attribute selects the exclusive Secure Mode . Its possible values are: 0 (i.e. Grassland(no security)) or 1 (i.e. StoneHouse) or 2 (i.e. IronHouse) . bidirectional_mode ( boolean ) : This internal attribute activates the exclusive Bidirectional Mode , if enabled( True ). custom_cert_location ( string ) : In Secure Mode, This internal attribute assigns user-defined location/path to directory for generating/storing Public+Secret Keypair necessary for encryption. More information can be found here \u27b6 overwrite_cert ( boolean ) : In Secure Mode, This internal attribute decides whether to overwrite existing Public+Secret Keypair/Certificates or not, at the Server-end only . More information can be found here \u27b6 compression_format ( string ): This internal attribute activates frame compression with selected encoding format. The possible values are .jpg , .png , .bmp . More information can be found here \u27b6 compression_param ( integer & list/tuple ): This internal attribute allow us to pass different format-specific Encoding parameters and Decoding flags . More information can be found here \u27b6 max_retries ( integer ): This internal attribute controls the maximum retries before Server/Client exit itself, if it's unable to get any response/reply from the socket before a certain amount of time, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 3 . request_timeout ( integer ): This internal attribute controls the timeout value (in seconds) , after which the Server/Client exit itself if it's unable to get any response/reply from the socket, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 10 seconds. flag ( integer ): This PyZMQ attribute value can be either 0 or zmq.NOBLOCK ( i.e. 1) . More information can be found here \u27b6 . copy ( boolean ): This PyZMQ attribute selects if message be received in a copying or non-copying manner. If False a object is returned, if True a string copy of the message is returned. track ( boolean ): This PyZMQ attribute check if the message is tracked for notification that ZMQ has finished with it. ( ignored if copy=True ). The desired attributes can be passed to NetGear API as follows: # formatting parameters as dictionary attributes options = { 'secure_mode' : 2 , 'custom_cert_location' : '/home/foo/foo1/foo2' , 'overwrite_cert' : True , \"flag\" : 0 , \"copy\" : False , \"track\" : False } # assigning it NetGear ( logging = True , ** options ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"Parameters"},{"location":"gears/netgear/params/#netgear-api-parameters","text":"","title":"NetGear API Parameters"},{"location":"gears/netgear/params/#address","text":"This parameter sets the valid Network IP address for Server/Client. Network addresses are unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode , i.e 'localhost' for Send Mode and '*' for Receive Mode on a local machine. Usage: NetGear ( address = \"192.168.0.145\" )","title":"address"},{"location":"gears/netgear/params/#port","text":"This parameter sets the valid Network Port for Server/Client. Network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Exclusive Mode Exception In Multi-Servers Mode : A unique port number MUST be assigned to each Server on the network using this parameter. At Client end, a List/Tuple of all available Server(s) ports MUST be assigned, using this same parameter. See its usage example here \u27b6 . In Multi-Client Mode : A unique port number MUST be assigned to each Client on the network using this parameter. At Server end, a List/Tuple of all available Client(s) ports MUST be assigned, using this same parameter. See its usage example here \u27b6 . Data-Type: String or List/Tuple Default Value: Its default value is '5555' Usage: NetGear ( port = \"5575\" )","title":"port"},{"location":"gears/netgear/params/#protocol","text":"This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear ( protocol = \"ipc\" )","title":"protocol"},{"location":"gears/netgear/params/#pattern","text":"This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). All supported ZMQ patterns for NetGear are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. Usage: NetGear ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern","title":"pattern"},{"location":"gears/netgear/params/#receive_mode","text":"This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear ( receive_mode = True ) # activates Recieve Mode","title":"receive_mode"},{"location":"gears/netgear/params/#options","text":"This parameter provides the flexibility to alter various NetGear API's internal properties, modes, and some PyZMQ flags. Data-Type: Dictionary Default Value: Its default value is {} Usage: Supported dictionary attributes for NetGear API multiserver_mode ( boolean ) : This internal attribute activates the exclusive Multi-Servers Mode , if enabled( True ). multiclient_mode ( boolean ) : This internal attribute activates the exclusive Multi-Clients Mode , if enabled( True ). secure_mode ( integer ) : This internal attribute selects the exclusive Secure Mode . Its possible values are: 0 (i.e. Grassland(no security)) or 1 (i.e. StoneHouse) or 2 (i.e. IronHouse) . bidirectional_mode ( boolean ) : This internal attribute activates the exclusive Bidirectional Mode , if enabled( True ). custom_cert_location ( string ) : In Secure Mode, This internal attribute assigns user-defined location/path to directory for generating/storing Public+Secret Keypair necessary for encryption. More information can be found here \u27b6 overwrite_cert ( boolean ) : In Secure Mode, This internal attribute decides whether to overwrite existing Public+Secret Keypair/Certificates or not, at the Server-end only . More information can be found here \u27b6 compression_format ( string ): This internal attribute activates frame compression with selected encoding format. The possible values are .jpg , .png , .bmp . More information can be found here \u27b6 compression_param ( integer & list/tuple ): This internal attribute allow us to pass different format-specific Encoding parameters and Decoding flags . More information can be found here \u27b6 max_retries ( integer ): This internal attribute controls the maximum retries before Server/Client exit itself, if it's unable to get any response/reply from the socket before a certain amount of time, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 3 . request_timeout ( integer ): This internal attribute controls the timeout value (in seconds) , after which the Server/Client exit itself if it's unable to get any response/reply from the socket, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 10 seconds. flag ( integer ): This PyZMQ attribute value can be either 0 or zmq.NOBLOCK ( i.e. 1) . More information can be found here \u27b6 . copy ( boolean ): This PyZMQ attribute selects if message be received in a copying or non-copying manner. If False a object is returned, if True a string copy of the message is returned. track ( boolean ): This PyZMQ attribute check if the message is tracked for notification that ZMQ has finished with it. ( ignored if copy=True ). The desired attributes can be passed to NetGear API as follows: # formatting parameters as dictionary attributes options = { 'secure_mode' : 2 , 'custom_cert_location' : '/home/foo/foo1/foo2' , 'overwrite_cert' : True , \"flag\" : 0 , \"copy\" : False , \"track\" : False } # assigning it NetGear ( logging = True , ** options )","title":"options"},{"location":"gears/netgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"logging"},{"location":"gears/netgear/usage/","text":"NetGear API Usage Examples: \u00b6 Danger Kindly go through each given examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. NetGear provides auto-termination feature, where if you terminate server end manually, the connected client(s) end will also terminate themselves to save resources. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode ( for e.g using send() function in Receive Mode ), will result in ValueError . Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with NetGear API: Server's End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () #Define Netgear Server with default parameters server = NetGear () # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client's End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 #define Netgear Client with `receive_mode = True` and default parameter client = NetGear ( receive_mode = True ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Define Netgear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # define various tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define Netgear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using NetGear with OpenCV \u00b6 You can easily use NetGear directly with any Video Processing library such as OpenCV itself. The complete usage example is as follows: Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Define Netgear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 0 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the received frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # define tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Define Netgear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 0 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Using NetGear with Other VideoCapture Gears \u00b6 You can use any VideoCapture Gear in the similar manner. Let's implement given usage example with ScreenGear: Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Define Netgear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u00b6 Now, Open the terminal on another Server System (let's say you want to transmit Monitor Screen Frames from a Laptop) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import NetGear # define various tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Start capturing live Monitor screen frames with default settings stream = ScreenGear () . start () # Define Netgear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Usage Examples"},{"location":"gears/netgear/usage/#netgear-api-usage-examples","text":"Danger Kindly go through each given examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. NetGear provides auto-termination feature, where if you terminate server end manually, the connected client(s) end will also terminate themselves to save resources. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode ( for e.g using send() function in Receive Mode ), will result in ValueError .","title":"NetGear API Usage Examples:"},{"location":"gears/netgear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/usage/#servers-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () #Define Netgear Server with default parameters server = NetGear () # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#clients-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 #define Netgear Client with `receive_mode = True` and default parameter client = NetGear ( receive_mode = True ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#using-netgear-with-variable-parameters","text":"","title":"Using NetGear with Variable Parameters"},{"location":"gears/netgear/usage/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Define Netgear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # define various tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define Netgear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#using-netgear-with-opencv","text":"You can easily use NetGear directly with any Video Processing library such as OpenCV itself. The complete usage example is as follows:","title":"Using NetGear with OpenCV"},{"location":"gears/netgear/usage/#clients-end_2","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Define Netgear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 0 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the received frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_2","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # define tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Define Netgear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 0 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#using-netgear-with-other-videocapture-gears","text":"You can use any VideoCapture Gear in the similar manner. Let's implement given usage example with ScreenGear:","title":"Using NetGear with Other VideoCapture Gears"},{"location":"gears/netgear/usage/#clients-end_3","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Define Netgear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_3","text":"Now, Open the terminal on another Server System (let's say you want to transmit Monitor Screen Frames from a Laptop) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import NetGear # define various tweak flags options = { 'flag' : 0 , 'copy' : False , 'track' : False } # Start capturing live Monitor screen frames with default settings stream = ScreenGear () . start () # Define Netgear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/bidirectional_mode/","text":"Advanced Usage: Bidirectional Mode for NetGear API \u00b6 Overview \u00b6 Bi-directional Mode enables seamless support for Bidirectional data transmission between Client/Consumer and Sender/Publisher along with Video frames, through its synchronous messaging patterns such as zmq.PAIR (ZMQ Pair Pattern) & zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern). In Bi-directional Mode, We can utilize its message parameter of send() method at Server's end for sending data to Client, and return_data parameter of recv() method at Client end to return data back to Server, all while transferring frames in real-time. This mode can be easily activated in NetGear API through bidirectional_mode attribute of its option dictionary parameter, during initialization. Important Information In Bi-directional Mode, zmq.PAIR (ZMQ Pair) & zmq.REQ/zmq.REP (ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in ValueError . Bidirectional Mode is NOT compatibile with Multi-Servers mode and Multi-Clients mode exclusive modes. Thereby, if Bidirectional mode is enabled with any of these modes, it will be DISABLED automatically. Bi-directional Mode may lead to additional LATENCY depending upon the bytes of the data being transfer bidirectionally. User discretion is advised! With Bidirectional Mode, you can also send data of ANY 1 Data-type along with frame bidirectionally. Features \u00b6 Enables easy-to-use seamless bi-directional data transmission between two systems. Supports zmq.PAIR & zmq.REQ/zmq.REP messaging patterns. Support for sending data of almost any 1 datatype. Auto-enables reconnection if Server or Client disconnects prematurely. Method Parameters \u00b6 To send data bidirectionally, NetGear API provides two exclusive parameters for its methods: message : It enables us to send data to Client, directly through send() method at Server's end. return_data : It enables us to send data back to Server, directly through recv() method at Client's end. Usage Examples \u00b6 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with Bidirectional Mode in NetGear API: Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () # activate Bidirectional mode options = { 'bidirectional_mode' : True } #Define NetGear Server with defined parameters server = NetGear ( logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = 'Hello, I am a Server.' # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { 'bidirectional_mode' : True } #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , logging = True , ** options ) # loop over while True : #prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Bidirectional Mode with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { 'bidirectional_mode' : True } # Define NetGear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : #prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print recieved server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u00b6 Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import PiGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate Bidirectional mode options = { 'bidirectional_mode' : True } # Define NetGear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = 'Hello, I am a Server.' # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using Bidirectional Mode for Video-Frames Transfer \u00b6 In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. This feature is great for building applications like Real-Time Video Chat. We're using VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance. Remember, sending large HQ video-frames may required more network bandwidth and packet size, which may add to video latency! Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () # activate Bidirectional mode options = { 'bidirectional_mode' : True } #Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) #reduce frame by 30% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = 'Hello, I am a Server.' # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode options = { 'bidirectional_mode' : True } # again open the same video stream stream = VideoGear ( source = 'test.mp4' ) . start () #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) #reduce frame by 30% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close client client . close () Using Bidirectional Mode for Video-Frames Transfer with Frame Compression \u00b6 See complete usage example here \u27b6 Additional data of numpy.ndarray data-type is ONLY SUPPORTED at Client's end with its return_data parameter. \u21a9 \u21a9","title":"Bidirectional Mode"},{"location":"gears/netgear/advanced/bidirectional_mode/#advanced-usage-bidirectional-mode-for-netgear-api","text":"","title":"Advanced Usage: Bidirectional Mode for NetGear API"},{"location":"gears/netgear/advanced/bidirectional_mode/#overview","text":"Bi-directional Mode enables seamless support for Bidirectional data transmission between Client/Consumer and Sender/Publisher along with Video frames, through its synchronous messaging patterns such as zmq.PAIR (ZMQ Pair Pattern) & zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern). In Bi-directional Mode, We can utilize its message parameter of send() method at Server's end for sending data to Client, and return_data parameter of recv() method at Client end to return data back to Server, all while transferring frames in real-time. This mode can be easily activated in NetGear API through bidirectional_mode attribute of its option dictionary parameter, during initialization. Important Information In Bi-directional Mode, zmq.PAIR (ZMQ Pair) & zmq.REQ/zmq.REP (ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in ValueError . Bidirectional Mode is NOT compatibile with Multi-Servers mode and Multi-Clients mode exclusive modes. Thereby, if Bidirectional mode is enabled with any of these modes, it will be DISABLED automatically. Bi-directional Mode may lead to additional LATENCY depending upon the bytes of the data being transfer bidirectionally. User discretion is advised! With Bidirectional Mode, you can also send data of ANY 1 Data-type along with frame bidirectionally.","title":"Overview"},{"location":"gears/netgear/advanced/bidirectional_mode/#features","text":"Enables easy-to-use seamless bi-directional data transmission between two systems. Supports zmq.PAIR & zmq.REQ/zmq.REP messaging patterns. Support for sending data of almost any 1 datatype. Auto-enables reconnection if Server or Client disconnects prematurely.","title":"Features"},{"location":"gears/netgear/advanced/bidirectional_mode/#method-parameters","text":"To send data bidirectionally, NetGear API provides two exclusive parameters for its methods: message : It enables us to send data to Client, directly through send() method at Server's end. return_data : It enables us to send data back to Server, directly through recv() method at Client's end.","title":"Method Parameters"},{"location":"gears/netgear/advanced/bidirectional_mode/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/bidirectional_mode/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Bidirectional Mode in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () # activate Bidirectional mode options = { 'bidirectional_mode' : True } #Define NetGear Server with defined parameters server = NetGear ( logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = 'Hello, I am a Server.' # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { 'bidirectional_mode' : True } #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , logging = True , ** options ) # loop over while True : #prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-with-variable-parameters","text":"","title":"Using Bidirectional Mode with Variable Parameters"},{"location":"gears/netgear/advanced/bidirectional_mode/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { 'bidirectional_mode' : True } # Define NetGear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : #prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print recieved server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_1","text":"Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import PiGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate Bidirectional mode options = { 'bidirectional_mode' : True } # Define NetGear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = 'Hello, I am a Server.' # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer","text":"In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. This feature is great for building applications like Real-Time Video Chat. We're using VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance. Remember, sending large HQ video-frames may required more network bandwidth and packet size, which may add to video latency!","title":"Using Bidirectional Mode for Video-Frames Transfer"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () # activate Bidirectional mode options = { 'bidirectional_mode' : True } #Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) #reduce frame by 30% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = 'Hello, I am a Server.' # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end_1","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode options = { 'bidirectional_mode' : True } # again open the same video stream stream = VideoGear ( source = 'test.mp4' ) . start () #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) #reduce frame by 30% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","text":"See complete usage example here \u27b6 Additional data of numpy.ndarray data-type is ONLY SUPPORTED at Client's end with its return_data parameter. \u21a9 \u21a9","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression"},{"location":"gears/netgear/advanced/compression/","text":"Advanced Usage: Frame Compression for NetGear API \u00b6 Overview \u00b6 NetGear API supports real-time Frame Compression (Encoding/Decoding capabilities) , for optimizing performance while sending frames over the network. This compression works by encoding the frame before sending it at Server's end, and thereby, smartly decoding it on the Client's end, all in real-time. In Frame Compression, NetGear API utilizes OpenCV's imencode & imdecode methods in conjunction with its flexible APIs at Server and Client end respectively. Furthermore, this aid us to achieve better control over the compression of the frame being sent over the network, and thereby helps in optimizing the performance, but only at the cost of quality. Frame Compression can be easily activated in NetGear API through compression_format & compression_param attributes of its option dictionary parameter, during initialization. Important Information Frame Compression only supports three JPG or JPEG , PNG & BMP encoding formats as of now. Any Incorrect/Invalid encoding format will DISABLE this Frame Compression! Incorrect Format-specific parameters through compression_param attribute are skipped automatically. Features \u00b6 Enables real-time Frame Compression for further optimizing performance. Client End intelligently decodes frame only w.r.t the encoding used at Server End. Encoding and decoding supports all Format-specific flags. Support for JPG , PNG & BMP encoding formats. Compatible with any messaging pattern and exclusive Multi-Server mode. Supported Attributes \u00b6 For implementing Frame Compression, NetGear API currently provide following attribute for its option dictionary parameter: compression_format ( string ): This attribute activates compression with selected encoding format. Its possible valid values are: '.jpg' / '.jpeg' or '.png' or '.bmp' , and its usage is as follows: Any Incorrect/Invalid encoding format value on compression_format attribute will DISABLE this Frame Compression! Even if you assign different compression_format value at Client's end, NetGear will auto-select the Server's encoding format instead. options = { 'compression_format' : '.jpg' } #activates jpeg encoding compression_param : This attribute allow us to pass different compression-format specific encoding/decoding flags. Its possible value are as follows: Encoding : Assigning Encoding Parameters (list) at Server end only: options = { 'compression_format' : '.jpg' , 'compression_param' :[ cv2 . IMWRITE_JPEG_QUALITY , 80 ]} # activate jpeg encoding optimizations and compression quality 80 All supported Encoding( Imwrite ) Flags can be found here \u27b6 Decoding : Assigning Decoding flag (integer) at Client end only: options = { 'compression_param' : cv2 . IMREAD_UNCHANGED } # decode image as is with alpha channel All supported Decoding( Imread ) Flags can be found here \u27b6 Usage Examples \u00b6 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with Frame Compression in NetGear API: Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () # activate jpeg encoding and specify other related parameters options = { 'compression_format' : '.jpg' , 'compression_param' :[ cv2 . IMWRITE_JPEG_QUALITY , 50 ]} #Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define decode image as 3 channel BGR color image options = { 'compression_format' : '.jpg' , 'compression_param' : cv2 . IMREAD_COLOR } #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Frame Compression with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { 'compression_format' : '.jpg' , 'compression_param' :[ cv2 . IMWRITE_JPEG_QUALITY , 80 , cv2 . IMWRITE_JPEG_PROGRESSIVE , True , cv2 . IMWRITE_JPEG_OPTIMIZE , True ,]} # Define NetGear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # define decode image as 3 channel BGR color image options = { 'compression_format' : '.jpg' , 'compression_param' : cv2 . IMREAD_COLOR } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using Bidirectional Mode for Video-Frames Transfer with Frame Compression \u00b6 NetGear now supports Dual Frame Compression for transferring video-frames with its exclusive Bidirectional Mode for achieving unmatchable performance bidirectionally. You can easily pass the required encoding/decoding parameters by formatting them as tuple for altering Frame Compression while sending/receiving video-frames at both ends. In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using Bidirectional Mode. Furthermore, we're going to use optimal Dual Frame Compression Setting for Sending and Receiving frames at both Server and Client end. This feature is great for building applications like Real-Time Video Chat. This Dual Frame Compression feature also available for Multi-Clients Mode at Client(s) end only. We're also using VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance. Remember, sending large HQ video-frames may required more network bandwidth and packet size, which may add to video latency! Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () # activate Bidirectional mode and Dual Frame Compression options = { 'bidirectional_mode' : True , 'compression_format' : '.jpg' , 'compression_param' : ( cv2 . IMREAD_COLOR , [ cv2 . IMWRITE_JPEG_QUALITY , 60 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True ,])} #Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) #reduce frame by 20% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = 'Hello, I am a Server.' # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode and Dual Frame Compression options = { 'bidirectional_mode' : True , 'compression_format' : '.jpg' , 'compression_param' : ( cv2 . IMREAD_COLOR , [ cv2 . IMWRITE_JPEG_QUALITY , 60 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True ,])} # again open the same video stream stream = VideoGear ( source = 'test.mp4' ) . start () #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) #reduce frame by 20% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close client client . close ()","title":"Frame Compression"},{"location":"gears/netgear/advanced/compression/#advanced-usage-frame-compression-for-netgear-api","text":"","title":"Advanced Usage: Frame Compression for NetGear API"},{"location":"gears/netgear/advanced/compression/#overview","text":"NetGear API supports real-time Frame Compression (Encoding/Decoding capabilities) , for optimizing performance while sending frames over the network. This compression works by encoding the frame before sending it at Server's end, and thereby, smartly decoding it on the Client's end, all in real-time. In Frame Compression, NetGear API utilizes OpenCV's imencode & imdecode methods in conjunction with its flexible APIs at Server and Client end respectively. Furthermore, this aid us to achieve better control over the compression of the frame being sent over the network, and thereby helps in optimizing the performance, but only at the cost of quality. Frame Compression can be easily activated in NetGear API through compression_format & compression_param attributes of its option dictionary parameter, during initialization. Important Information Frame Compression only supports three JPG or JPEG , PNG & BMP encoding formats as of now. Any Incorrect/Invalid encoding format will DISABLE this Frame Compression! Incorrect Format-specific parameters through compression_param attribute are skipped automatically.","title":"Overview"},{"location":"gears/netgear/advanced/compression/#features","text":"Enables real-time Frame Compression for further optimizing performance. Client End intelligently decodes frame only w.r.t the encoding used at Server End. Encoding and decoding supports all Format-specific flags. Support for JPG , PNG & BMP encoding formats. Compatible with any messaging pattern and exclusive Multi-Server mode.","title":"Features"},{"location":"gears/netgear/advanced/compression/#supported-attributes","text":"For implementing Frame Compression, NetGear API currently provide following attribute for its option dictionary parameter: compression_format ( string ): This attribute activates compression with selected encoding format. Its possible valid values are: '.jpg' / '.jpeg' or '.png' or '.bmp' , and its usage is as follows: Any Incorrect/Invalid encoding format value on compression_format attribute will DISABLE this Frame Compression! Even if you assign different compression_format value at Client's end, NetGear will auto-select the Server's encoding format instead. options = { 'compression_format' : '.jpg' } #activates jpeg encoding compression_param : This attribute allow us to pass different compression-format specific encoding/decoding flags. Its possible value are as follows: Encoding : Assigning Encoding Parameters (list) at Server end only: options = { 'compression_format' : '.jpg' , 'compression_param' :[ cv2 . IMWRITE_JPEG_QUALITY , 80 ]} # activate jpeg encoding optimizations and compression quality 80 All supported Encoding( Imwrite ) Flags can be found here \u27b6 Decoding : Assigning Decoding flag (integer) at Client end only: options = { 'compression_param' : cv2 . IMREAD_UNCHANGED } # decode image as is with alpha channel All supported Decoding( Imread ) Flags can be found here \u27b6","title":"Supported Attributes"},{"location":"gears/netgear/advanced/compression/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/compression/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Frame Compression in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/compression/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () # activate jpeg encoding and specify other related parameters options = { 'compression_format' : '.jpg' , 'compression_param' :[ cv2 . IMWRITE_JPEG_QUALITY , 50 ]} #Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define decode image as 3 channel BGR color image options = { 'compression_format' : '.jpg' , 'compression_param' : cv2 . IMREAD_COLOR } #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/compression/#using-frame-compression-with-variable-parameters","text":"","title":"Using Frame Compression with Variable Parameters"},{"location":"gears/netgear/advanced/compression/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { 'compression_format' : '.jpg' , 'compression_param' :[ cv2 . IMWRITE_JPEG_QUALITY , 80 , cv2 . IMWRITE_JPEG_PROGRESSIVE , True , cv2 . IMWRITE_JPEG_OPTIMIZE , True ,]} # Define NetGear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/compression/#server-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # define decode image as 3 channel BGR color image options = { 'compression_format' : '.jpg' , 'compression_param' : cv2 . IMREAD_COLOR } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","text":"NetGear now supports Dual Frame Compression for transferring video-frames with its exclusive Bidirectional Mode for achieving unmatchable performance bidirectionally. You can easily pass the required encoding/decoding parameters by formatting them as tuple for altering Frame Compression while sending/receiving video-frames at both ends. In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using Bidirectional Mode. Furthermore, we're going to use optimal Dual Frame Compression Setting for Sending and Receiving frames at both Server and Client end. This feature is great for building applications like Real-Time Video Chat. This Dual Frame Compression feature also available for Multi-Clients Mode at Client(s) end only. We're also using VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance. Remember, sending large HQ video-frames may required more network bandwidth and packet size, which may add to video latency!","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression"},{"location":"gears/netgear/advanced/compression/#server-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () # activate Bidirectional mode and Dual Frame Compression options = { 'bidirectional_mode' : True , 'compression_format' : '.jpg' , 'compression_param' : ( cv2 . IMREAD_COLOR , [ cv2 . IMWRITE_JPEG_QUALITY , 60 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True ,])} #Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) #reduce frame by 20% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = 'Hello, I am a Server.' # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#client-end_1","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode and Dual Frame Compression options = { 'bidirectional_mode' : True , 'compression_format' : '.jpg' , 'compression_param' : ( cv2 . IMREAD_COLOR , [ cv2 . IMWRITE_JPEG_QUALITY , 60 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True ,])} # again open the same video stream stream = VideoGear ( source = 'test.mp4' ) . start () #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) #reduce frame by 20% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/multi_client/","text":"Advanced Usage: Multi-Clients Mode for NetGear API \u00b6 Overview \u00b6 NetGear's Multi-Clients Mode generalised In this exclusive mode, NetGear API robustly handles Multiple Clients at once, thereby providing seamless access to frames and unidirectional data transfer to multiple Clients/Consumers across the network in real-time. This mode works almost contrary to Multi-Servers Mode but data transfer only works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) . Each new client connects to a single server, and can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ), and it can be easily activated in NetGear API through multiclient_mode attribute of its option dictionary parameter, during initialization. Multi-Clients Mode Requirements A unique PORT address MUST be assigned to each Client on the network using its port parameter. A list/tuple of PORT addresses of all unique Cients MUST be assigned at Server's end using its port parameter for a successful connection. 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported pattern values for this Mode. Thereby, calling any other pattern value will result in ValueError . The address parameter value of each Client MUST exactly match the Server. Key Features \u00b6 Enables Multiple Client(s) connection with a single Client. Ability to send any additional data of any datatype along with frames in real-time. Number of Clients can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Client on the network can be identified at Server's end by their unique port addresses. NetGear API actively tracks the state of each connected Client. If the server gets disconnected, all the clients will automatically exit to save resources. Usage Examples \u00b6 Important Information Frame/Data transmission will NOT START untill all given Client(s) are connected to the Server. For sake of simplicity, in these examples we will use only two unique Clients, but, the number of these Clients can be extended to several numbers depending upon your network bandwidth. A single Server will be transferring frames to a all Clients at the same time in these usage examples. Multi-Clients and Multi-Servers exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . Bare-Minimum Usage \u00b6 In this example, we will capturing live video-frames from a source (a.k.a Servers) , with a webcam connected to it. Then, those captured frame will be transferred over the network to a two independent system (a.k.a Client) at the same time, and will be displayed in Output Window at real-time. All this by using this Multi-Clients Mode in NetGear API. Server's End \u00b6 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiclient_mode mode options = { 'multiclient_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = '192.168.x.x' , port = ( 5567 , 5577 ), protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : #print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client-1's End \u00b6 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5567' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u00b6 Finally, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5577' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Bare-Minimum Usage with OpenCV \u00b6 In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API. Server's End \u00b6 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiclient_mode mode options = { 'multiclient_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = '192.168.x.x' , port = ( 5567 , 5577 ), protocol = 'tcp' , pattern = 2 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : #print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Client-1's End \u00b6 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5567' , protocol = 'tcp' , pattern = 2 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u00b6 Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5577' , protocol = 'tcp' , pattern = 2 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Multi-Clients Mode with Custom Data Transfer \u00b6 Info With Multi-Clients Mode, you can also send additional data of any data-type (such as list, tuple, string, int, ndarray etc.) along with frame, from all connected Clients(s) back to a Server unidirectionally. In Multi-Clients Mode, unidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) ! In this example, We will be transferring video-frames from a single Server (consisting of Raspberry Pi with Camera Module) over the network to two independent Client for displaying them in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) from both the Client(s) back to our Server, which will be printed onto the terminal. Server's End \u00b6 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import PiGear from vidgear.gears import NetGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiclient_mode mode options = { 'multiclient_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = '192.168.x.x' , port = ( 5577 , 5578 ), protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : #print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client-1's End \u00b6 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5577' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : #prepare data to be sent target_data = \"Hi, I am 5577 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u00b6 Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5578' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : #prepare data to be sent target_data = \"Hi, I am 5578 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5578 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Multi-Clients Mode"},{"location":"gears/netgear/advanced/multi_client/#advanced-usage-multi-clients-mode-for-netgear-api","text":"","title":"Advanced Usage: Multi-Clients Mode for NetGear API"},{"location":"gears/netgear/advanced/multi_client/#overview","text":"NetGear's Multi-Clients Mode generalised In this exclusive mode, NetGear API robustly handles Multiple Clients at once, thereby providing seamless access to frames and unidirectional data transfer to multiple Clients/Consumers across the network in real-time. This mode works almost contrary to Multi-Servers Mode but data transfer only works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) . Each new client connects to a single server, and can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ), and it can be easily activated in NetGear API through multiclient_mode attribute of its option dictionary parameter, during initialization. Multi-Clients Mode Requirements A unique PORT address MUST be assigned to each Client on the network using its port parameter. A list/tuple of PORT addresses of all unique Cients MUST be assigned at Server's end using its port parameter for a successful connection. 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported pattern values for this Mode. Thereby, calling any other pattern value will result in ValueError . The address parameter value of each Client MUST exactly match the Server.","title":"Overview"},{"location":"gears/netgear/advanced/multi_client/#key-features","text":"Enables Multiple Client(s) connection with a single Client. Ability to send any additional data of any datatype along with frames in real-time. Number of Clients can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Client on the network can be identified at Server's end by their unique port addresses. NetGear API actively tracks the state of each connected Client. If the server gets disconnected, all the clients will automatically exit to save resources.","title":"Key Features"},{"location":"gears/netgear/advanced/multi_client/#usage-examples","text":"Important Information Frame/Data transmission will NOT START untill all given Client(s) are connected to the Server. For sake of simplicity, in these examples we will use only two unique Clients, but, the number of these Clients can be extended to several numbers depending upon your network bandwidth. A single Server will be transferring frames to a all Clients at the same time in these usage examples. Multi-Clients and Multi-Servers exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError .","title":"Usage Examples"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage","text":"In this example, we will capturing live video-frames from a source (a.k.a Servers) , with a webcam connected to it. Then, those captured frame will be transferred over the network to a two independent system (a.k.a Client) at the same time, and will be displayed in Output Window at real-time. All this by using this Multi-Clients Mode in NetGear API.","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/multi_client/#servers-end","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiclient_mode mode options = { 'multiclient_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = '192.168.x.x' , port = ( 5567 , 5577 ), protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : #print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5567' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end","text":"Finally, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5577' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage-with-opencv","text":"In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/netgear/advanced/multi_client/#servers-end_1","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiclient_mode mode options = { 'multiclient_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = '192.168.x.x' , port = ( 5567 , 5577 ), protocol = 'tcp' , pattern = 2 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : #print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_1","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5567' , protocol = 'tcp' , pattern = 2 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_1","text":"Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5577' , protocol = 'tcp' , pattern = 2 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_client/#using-multi-clients-mode-with-custom-data-transfer","text":"Info With Multi-Clients Mode, you can also send additional data of any data-type (such as list, tuple, string, int, ndarray etc.) along with frame, from all connected Clients(s) back to a Server unidirectionally. In Multi-Clients Mode, unidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) ! In this example, We will be transferring video-frames from a single Server (consisting of Raspberry Pi with Camera Module) over the network to two independent Client for displaying them in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) from both the Client(s) back to our Server, which will be printed onto the terminal.","title":"Using Multi-Clients Mode with Custom Data Transfer"},{"location":"gears/netgear/advanced/multi_client/#servers-end_2","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import PiGear from vidgear.gears import NetGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiclient_mode mode options = { 'multiclient_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = '192.168.x.x' , port = ( 5577 , 5578 ), protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : #print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_2","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5577' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : #prepare data to be sent target_data = \"Hi, I am 5577 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_2","text":"Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { 'multiclient_mode' : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters client = NetGear ( address = '192.168.x.x' , port = '5578' , protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over while True : #prepare data to be sent target_data = \"Hi, I am 5578 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5578 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_server/","text":"Advanced Usage: Multi-Servers Mode for NetGear API \u00b6 Overview \u00b6 NetGear's Multi-Servers Mode generalised In this exclusive mode, NetGear API robustly handles Multiple Servers at once, thereby providing seamless access to frames and unidirectional data transfer from multiple Publishers/Servers across the network in real-time. Each new server connects to a single client, and can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ), and it can be easily activated in NetGear API through multiserver_mode attribute of its option dictionary parameter, during initialization. Multi-Servers Mode Requirements A unique PORT address MUST be assigned to each Server on the network using its port parameter. A list/tuple of PORT addresses of all unique Servers MUST be assigned at Client's end using its port parameter for a successful connection. 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported pattern values for this Mode. Thereby, calling any other pattern value will result in ValueError . The address parameter value of each Server MUST exactly match the Client. Key Features \u00b6 Enables Multiple Server(s) connection with a single Client. Ability to send any additional data of any 1 datatype along with frames in real-time. Number of Servers can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Server on the network can be identified at Client's end by their unique port addresses. NetGear API actively tracks the state of each connected Server. If all the connected servers on the network get disconnected, the client itself automatically exits to save resources. Usage Examples \u00b6 Important Information For sake of simplicity, in these examples we will use only two unique Servers, but, the number of these Servers can be extended to several numbers depending upon your system hardware limits. All of Servers will be transferring frames to a single Client system at the same time, which will be displaying received frames as a montage (multiple frames concatenated together) . For building Frames Montage at Client's end, We are going to use imutils python library function to build montages, by concatenating together frames recieved from different servers. Therefore, Kindly install this library with pip install imutils terminal command. Multi-Servers and Multi-Clients exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . Bare-Minimum Usage \u00b6 In this example, we will capturing live video-frames on two independent sources (a.k.a Servers) , each with a webcam connected to it. Then, those frames will be transferred over the network to a single system (a.k.a Client) at the same time, and will be displayed as a real-time montage. All this by using this Multi-Servers Mode in NetGear API. Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from Multiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5566,5567) in our case) and other parameters client = NetGear ( address = '192.168.x.x' , port = ( 5566 , 5567 ), protocol = 'tcp' , pattern = 1 , receive_mode = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server-1's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5566' , protocol = 'tcp' , pattern = 1 , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Server-2's End \u00b6 Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5567' , protocol = 'tcp' , pattern = 1 , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Bare-Minimum Usage with OpenCV \u00b6 In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API. Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5566,5567) in our case) and other parameters client = NetGear ( address = '192.168.x.x' , port = ( 5566 , 5567 ), protocol = 'tcp' , pattern = 2 , receive_mode = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server-1's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5566' , protocol = 'tcp' , pattern = 2 , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Server-2's End \u00b6 Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5567' , protocol = 'tcp' , pattern = 2 , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Using Multi-Servers Mode with Custom Data Transfer \u00b6 Info With Multi-Servers Mode, you can send additional data of any data-type (such as list, tuple, string, int etc.) along with frame, from all connected Server(s) to a single Client unidirectionally. But numpy.ndarray data-type is NOT supported as data. In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) , from all two Servers (consisting of a Raspberry Pi with Camera Module & a Laptop with webcam) to a single Client over the network in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal. Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters client = NetGear ( address = '192.168.x.x' , port = ( 5577 , 5578 ), protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame and received data unique_address , extracted_data , frame = data # {do something with the extracted frame and data here} # let's display extracted data on our extracted frame cv2 . putText ( frame , extracted_data , ( 10 , frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 ) # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server-1's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = VideoGear ( source = 0 ) . start () # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5577' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-1 at Port: 5577\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Server-2's End \u00b6 Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.1.xxx' , port = '5578' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-2 at Port: 5578\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream. stream . stop () # safely close server server . close () Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its message parameter. \u21a9","title":"Multi-Servers Mode"},{"location":"gears/netgear/advanced/multi_server/#advanced-usage-multi-servers-mode-for-netgear-api","text":"","title":"Advanced Usage: Multi-Servers Mode for NetGear API"},{"location":"gears/netgear/advanced/multi_server/#overview","text":"NetGear's Multi-Servers Mode generalised In this exclusive mode, NetGear API robustly handles Multiple Servers at once, thereby providing seamless access to frames and unidirectional data transfer from multiple Publishers/Servers across the network in real-time. Each new server connects to a single client, and can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ), and it can be easily activated in NetGear API through multiserver_mode attribute of its option dictionary parameter, during initialization. Multi-Servers Mode Requirements A unique PORT address MUST be assigned to each Server on the network using its port parameter. A list/tuple of PORT addresses of all unique Servers MUST be assigned at Client's end using its port parameter for a successful connection. 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported pattern values for this Mode. Thereby, calling any other pattern value will result in ValueError . The address parameter value of each Server MUST exactly match the Client.","title":"Overview"},{"location":"gears/netgear/advanced/multi_server/#key-features","text":"Enables Multiple Server(s) connection with a single Client. Ability to send any additional data of any 1 datatype along with frames in real-time. Number of Servers can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Server on the network can be identified at Client's end by their unique port addresses. NetGear API actively tracks the state of each connected Server. If all the connected servers on the network get disconnected, the client itself automatically exits to save resources.","title":"Key Features"},{"location":"gears/netgear/advanced/multi_server/#usage-examples","text":"Important Information For sake of simplicity, in these examples we will use only two unique Servers, but, the number of these Servers can be extended to several numbers depending upon your system hardware limits. All of Servers will be transferring frames to a single Client system at the same time, which will be displaying received frames as a montage (multiple frames concatenated together) . For building Frames Montage at Client's end, We are going to use imutils python library function to build montages, by concatenating together frames recieved from different servers. Therefore, Kindly install this library with pip install imutils terminal command. Multi-Servers and Multi-Clients exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError .","title":"Usage Examples"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage","text":"In this example, we will capturing live video-frames on two independent sources (a.k.a Servers) , each with a webcam connected to it. Then, those frames will be transferred over the network to a single system (a.k.a Client) at the same time, and will be displayed as a real-time montage. All this by using this Multi-Servers Mode in NetGear API.","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/multi_server/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from Multiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5566,5567) in our case) and other parameters client = NetGear ( address = '192.168.x.x' , port = ( 5566 , 5567 ), protocol = 'tcp' , pattern = 1 , receive_mode = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5566' , protocol = 'tcp' , pattern = 1 , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end","text":"Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5567' , protocol = 'tcp' , pattern = 1 , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server-2's End"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage-with-opencv","text":"In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/netgear/advanced/multi_server/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5566,5567) in our case) and other parameters client = NetGear ( address = '192.168.x.x' , port = ( 5566 , 5567 ), protocol = 'tcp' , pattern = 2 , receive_mode = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5566' , protocol = 'tcp' , pattern = 2 , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_1","text":"Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5567' , protocol = 'tcp' , pattern = 2 , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server-2's End"},{"location":"gears/netgear/advanced/multi_server/#using-multi-servers-mode-with-custom-data-transfer","text":"Info With Multi-Servers Mode, you can send additional data of any data-type (such as list, tuple, string, int etc.) along with frame, from all connected Server(s) to a single Client unidirectionally. But numpy.ndarray data-type is NOT supported as data. In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) , from all two Servers (consisting of a Raspberry Pi with Camera Module & a Laptop with webcam) to a single Client over the network in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal.","title":"Using Multi-Servers Mode with Custom Data Transfer"},{"location":"gears/netgear/advanced/multi_server/#clients-end_2","text":"Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters client = NetGear ( address = '192.168.x.x' , port = ( 5577 , 5578 ), protocol = 'tcp' , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame and received data unique_address , extracted_data , frame = data # {do something with the extracted frame and data here} # let's display extracted data on our extracted frame cv2 . putText ( frame , extracted_data , ( 10 , frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 ) # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_2","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = VideoGear ( source = 0 ) . start () # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.x.x' , port = '5577' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-1 at Port: 5577\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_2","text":"Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiserver_mode options = { 'multiserver_mode' : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters server = NetGear ( address = '192.168.1.xxx' , port = '5578' , protocol = 'tcp' , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-2 at Port: 5578\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream. stream . stop () # safely close server server . close () Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its message parameter. \u21a9","title":"Server-2's End"},{"location":"gears/netgear/advanced/secure_mode/","text":"Advanced Usage: Secure Mode for NetGear API \u00b6 Overview \u00b6 Secure Mode provides easy access to powerful, smart & secure ZeroMQ's Security Layers in NetGear API that enables strong encryption on data, and unbreakable authentication between the Server and the Client with the help of custom Certificates/keys and brings cheap, standardized privacy and authentication for distributed systems over the network. Secure Mode uses a new wire protocol, ZMTP 3.0 , that adds a security handshake to all ZeroMQ connections and a new security protocol, CurveZMQ , that implements \"perfect forward security\" between two ZeroMQ peers over a TCP connection. Secure Mode can be easily activated in NetGear API through secure_mode attribute of its option dictionary parameter, during initialization. Furthermore, for managing this mode, NetGear API provides additional custom_cert_location & overwrite_cert like attribute too. Supported ZMQ Security Layers \u00b6 Secure mode, as of now, supports the two most powerful ZMQ security layers: Stonehouse: which switches to the CURVE security protocol, that giving us strong encryption on data, and (as far as we know) unbreakable authentication. Stonehouse is the minimum you would use over public networks and assures clients that they are speaking to an authentic server while allowing any client to connect. This security layer is less secure but at the same time faster than IronHouse security mechanism. Ironhouse: which further extends Stonehouse layer with client public key authentication. This is the strongest security model present in ZeroMQ, protecting against every attack we know about, except end-point attacks . This security layer enhanced security comes at a price of additional latency. Secure Mode Requirements The secure_mode attribute value at the Client's end MUST match exactly the Server's end (i.e. IronHouse security layer is only compatible with IronHouse , and NOT with StoneHouse ) . The Public+Secret Keypairs generated at the Server end MUST be made available at Client's end too for successful authentication. If mismatched, connection failure will occur. By Default, the Public+Secret Keypairs will be generated/stored at the Home directory of your machine, in the .vidgear/keys folder (for e.g /home/foo/.vidgear/keys on Linux) . But you can also use 'custom_cert_location' attribute, to set a your own Custom location/path of directory to generate/store these Keypairs. DO NOT share generated public+secret Keypairs with anyone outside the network to avoid any potential security breach. At the Server End, You can easily use the 'overwrite_cert' attribute for regenerating new Keypairs on initialization. But make sure newly generated Keypairs at the Server End, MUST be made available at Client's End too. IronHouse is the strongest Security Layer available, but it involves certain security checks that lead to ADDITIONAL LATENCY . This feature only supports libzmq library version >= 4.0. Features \u00b6 Supports the two most powerful ZMQ security layers: StoneHouse & IronHouse. Auto-generates, auto-validates & auto-stores the required Public+Secret Keypairs safely. Compatible with all messaging pattern, primary and exclusive modes. Strong data encryption & Unbreakable authentication. Able to protect against any man-in-the-middle (MITM) attacks. Minimum hassle and very easy to enable and integrate. Supported Attributes \u00b6 For implementing Secure Mode, NetGear API currently provide following attribute for its option dictionary parameter: secure_mode ( integer ) : This attribute activates and sets the ZMQ security Mechanism. Its possible values are: 1 ( StoneHouse ) & 2 ( IronHouse ), and its default value is 0 ( Grassland(no security) ). Its usage is as follows: options = { 'secure_mode' : 2 } #activates IronHouse Security Mechanism custom_cert_location ( string ): This attribute sets a custom location/path to directory to generate/store Public+Secret Keypair/Certificates for enabling encryption. This attribute will force NetGear to create .vidgear folder (only if not available) at the assigned custom path (instead of home directory) , and then use that directory for storing new Keypairs/Certificates. It can be used as follows: options = { 'secure_mode' : 2 , 'custom_cert_location' : '/home/foo/foo1/foo2' } # set custom Keypair location to '/home/foo/foo1/foo2' overwrite_cert ( bool ): [For Server-end only] This attribute sets whether to overwrite existing Public+Secret Keypair/Certificates and re-generate new ones, to protect against any potential security breach. If set to True a new Keypair/Certificates will be generated during NetGear initialization in place of old ones. Its usage is as follows: options = { 'secure_mode' : 2 , 'overwrite_cert' : True } #a new Keypair will be generated !!!! warning \" overwrite_cert param is disabled for client-end\" Usage Examples \u00b6 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with Secure Mode in NetGear API: Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () #activate StoneHouse security mechanism options = { 'secure_mode' : 1 } #Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate StoneHouse security mechanism options = { 'secure_mode' : 1 } #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Secure Mode with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You need to paste the Public+Secret Keypairs (generated at the Server End) , in the .vidgear/keys folder here at the Home directory of your Client machine, for a successful authentication! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate IronHouse security mechanism options = { 'secure_mode' : 2 } # Define NetGear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You also need to copy the Public+Secret Keypairs (generated here on running this example code) , present in the .vidgear/keys folder here at the Home directory of your Server machine (Required at Client's end for a successful authentication) . You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # activate IronHouse security mechanism, and [BEWARE!!!] generating new Keypairs for this example !!! options = { 'secure_mode' : 2 , 'overwrite_cert' : True } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 2 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Secure Mode"},{"location":"gears/netgear/advanced/secure_mode/#advanced-usage-secure-mode-for-netgear-api","text":"","title":"Advanced Usage: Secure Mode for NetGear API"},{"location":"gears/netgear/advanced/secure_mode/#overview","text":"Secure Mode provides easy access to powerful, smart & secure ZeroMQ's Security Layers in NetGear API that enables strong encryption on data, and unbreakable authentication between the Server and the Client with the help of custom Certificates/keys and brings cheap, standardized privacy and authentication for distributed systems over the network. Secure Mode uses a new wire protocol, ZMTP 3.0 , that adds a security handshake to all ZeroMQ connections and a new security protocol, CurveZMQ , that implements \"perfect forward security\" between two ZeroMQ peers over a TCP connection. Secure Mode can be easily activated in NetGear API through secure_mode attribute of its option dictionary parameter, during initialization. Furthermore, for managing this mode, NetGear API provides additional custom_cert_location & overwrite_cert like attribute too.","title":"Overview"},{"location":"gears/netgear/advanced/secure_mode/#supported-zmq-security-layers","text":"Secure mode, as of now, supports the two most powerful ZMQ security layers: Stonehouse: which switches to the CURVE security protocol, that giving us strong encryption on data, and (as far as we know) unbreakable authentication. Stonehouse is the minimum you would use over public networks and assures clients that they are speaking to an authentic server while allowing any client to connect. This security layer is less secure but at the same time faster than IronHouse security mechanism. Ironhouse: which further extends Stonehouse layer with client public key authentication. This is the strongest security model present in ZeroMQ, protecting against every attack we know about, except end-point attacks . This security layer enhanced security comes at a price of additional latency. Secure Mode Requirements The secure_mode attribute value at the Client's end MUST match exactly the Server's end (i.e. IronHouse security layer is only compatible with IronHouse , and NOT with StoneHouse ) . The Public+Secret Keypairs generated at the Server end MUST be made available at Client's end too for successful authentication. If mismatched, connection failure will occur. By Default, the Public+Secret Keypairs will be generated/stored at the Home directory of your machine, in the .vidgear/keys folder (for e.g /home/foo/.vidgear/keys on Linux) . But you can also use 'custom_cert_location' attribute, to set a your own Custom location/path of directory to generate/store these Keypairs. DO NOT share generated public+secret Keypairs with anyone outside the network to avoid any potential security breach. At the Server End, You can easily use the 'overwrite_cert' attribute for regenerating new Keypairs on initialization. But make sure newly generated Keypairs at the Server End, MUST be made available at Client's End too. IronHouse is the strongest Security Layer available, but it involves certain security checks that lead to ADDITIONAL LATENCY . This feature only supports libzmq library version >= 4.0.","title":"Supported ZMQ Security Layers"},{"location":"gears/netgear/advanced/secure_mode/#features","text":"Supports the two most powerful ZMQ security layers: StoneHouse & IronHouse. Auto-generates, auto-validates & auto-stores the required Public+Secret Keypairs safely. Compatible with all messaging pattern, primary and exclusive modes. Strong data encryption & Unbreakable authentication. Able to protect against any man-in-the-middle (MITM) attacks. Minimum hassle and very easy to enable and integrate.","title":"Features"},{"location":"gears/netgear/advanced/secure_mode/#supported-attributes","text":"For implementing Secure Mode, NetGear API currently provide following attribute for its option dictionary parameter: secure_mode ( integer ) : This attribute activates and sets the ZMQ security Mechanism. Its possible values are: 1 ( StoneHouse ) & 2 ( IronHouse ), and its default value is 0 ( Grassland(no security) ). Its usage is as follows: options = { 'secure_mode' : 2 } #activates IronHouse Security Mechanism custom_cert_location ( string ): This attribute sets a custom location/path to directory to generate/store Public+Secret Keypair/Certificates for enabling encryption. This attribute will force NetGear to create .vidgear folder (only if not available) at the assigned custom path (instead of home directory) , and then use that directory for storing new Keypairs/Certificates. It can be used as follows: options = { 'secure_mode' : 2 , 'custom_cert_location' : '/home/foo/foo1/foo2' } # set custom Keypair location to '/home/foo/foo1/foo2' overwrite_cert ( bool ): [For Server-end only] This attribute sets whether to overwrite existing Public+Secret Keypair/Certificates and re-generate new ones, to protect against any potential security breach. If set to True a new Keypair/Certificates will be generated during NetGear initialization in place of old ones. Its usage is as follows: options = { 'secure_mode' : 2 , 'overwrite_cert' : True } #a new Keypair will be generated !!!! warning \" overwrite_cert param is disabled for client-end\"","title":"Supported Attributes"},{"location":"gears/netgear/advanced/secure_mode/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/secure_mode/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Secure Mode in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/secure_mode/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = 'test.mp4' ) . start () #activate StoneHouse security mechanism options = { 'secure_mode' : 1 } #Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/secure_mode/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate StoneHouse security mechanism options = { 'secure_mode' : 1 } #define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/secure_mode/#using-secure-mode-with-variable-parameters","text":"","title":"Using Secure Mode with Variable Parameters"},{"location":"gears/netgear/advanced/secure_mode/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You need to paste the Public+Secret Keypairs (generated at the Server End) , in the .vidgear/keys folder here at the Home directory of your Client machine, for a successful authentication! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate IronHouse security mechanism options = { 'secure_mode' : 2 } # Define NetGear Client at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with yours !!!) client = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/secure_mode/#server-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You also need to copy the Public+Secret Keypairs (generated here on running this example code) , present in the .vidgear/keys folder here at the Home directory of your Server machine (Required at Client's end for a successful authentication) . You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # activate IronHouse security mechanism, and [BEWARE!!!] generating new Keypairs for this example !!! options = { 'secure_mode' : 2 , 'overwrite_cert' : True } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters (!!! change following IP address '192.168.x.xxx' with client's IP address !!!) server = NetGear ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 2 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear_async/overview/","text":"NetGear_Async API \u00b6 Overview \u00b6 NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async can generate double performance as compared to NetGear API at about \u2153rd of memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but it doesn't support any NetGear's Exclusive Modes yet. Furthermore, NetGear_Async allows us to define our own custom Server Source to manipulate frames easily before sending them across the network(see this usage example ). In addition to all this, NetGear_Async also provides a special internal wrapper around VideoGear API , which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any connected device/source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . \u2009 Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API. \u2009 Importing \u00b6 You can import NetGear_Async API in your program as follows: from vidgear.gears import NetGear_Async \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/netgear_async/overview/#netgear_async-api","text":"","title":"NetGear_Async API"},{"location":"gears/netgear_async/overview/#overview","text":"NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async can generate double performance as compared to NetGear API at about \u2153rd of memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but it doesn't support any NetGear's Exclusive Modes yet. Furthermore, NetGear_Async allows us to define our own custom Server Source to manipulate frames easily before sending them across the network(see this usage example ). In addition to all this, NetGear_Async also provides a special internal wrapper around VideoGear API , which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any connected device/source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . \u2009 Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API.","title":"Overview"},{"location":"gears/netgear_async/overview/#importing","text":"You can import NetGear_Async API in your program as follows: from vidgear.gears import NetGear_Async","title":"Importing"},{"location":"gears/netgear_async/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/netgear_async/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/netgear_async/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/netgear_async/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/netgear_async/params/","text":"NetGear_Async API Parameters \u00b6 address \u00b6 This parameter sets the valid network address of the server/client. Network addresses unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode, i.e 'localhost' for Send Mode and '*' for Receive Mode. Usage: NetGear_Async ( address = \"192.168.0.145\" ) port \u00b6 This parameter sets the valid Network Port of the Server/Client. A network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Data-Type: String Default Value: Its default value is '5555' Usage: NetGear_Async ( port = \"5575\" ) protocol \u00b6 This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear_Async ( protocol = \"ipc\" ) pattern \u00b6 This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). All supported ZMQ patterns for NetGear_Async are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. 3 ( .i.e. zmq.PUSH/zmq.PULL ): Its sockets let you distribute messages to multiple workers, arranged in a pipeline. A Push socket will distribute sent messages to its Pull clients evenly. This is equivalent to the producer/consumer model but the results computed by the consumer are not sent upstream but downstream to another pull/consumer socket. Usage: NetGear_Async ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern receive_mode \u00b6 This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear_Async ( receive_mode = True ) # activates Recieve Mode timeout \u00b6 In NetGear_Async, the Receiver-end keeps tracks if frames are received from Server-end within this specified timeout value (in seconds) , Otherwise TimeoutError will be raised, which helps to close the Receiver-end safely if the Server has lost connection prematurely. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before Client'send exit itself with a TimeoutError to save resources. Its minimum value is 0.0 and no maximum value. Data-Type: Float/Integer Default Value: Its default value is 10.0 . Usage: NetGear_Async ( timeout = 5.0 ) # sets 5secs timeout Parameters for VideoGear backend \u00b6 enablePiCamera \u00b6 This parameter select access to PiGear or CamGear API respectively. This means the if enablePiCamera flag is True , PiGear API will be accessed and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( enablePiCamera = True ) # enable access to PiGear API Parameters for Stabilizer backend \u00b6 stabilize \u00b6 This parameter set this flag to enable access to Stabilizer Class , i.e. flag can be set to True ( to enable ) or unset to False ( to disable ) this mode. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( stabilize = True ) # enable stablization options \u00b6 This parameter can be used to pass user-defined parameters supported by Stabilizer Class . These parameters can be passed by formatting them as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters with CamGear backend \u00b6 source \u00b6 CamGear API will throw RuntimeError if source provided is invalid! This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: NetGear_Async ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: NetGear_Async ( source = '/home/foo.mp4' ) YouTube Video's URL ( string ): Valid Youtube video URL as input when YouTube Mode is enabled( i.e. y_tube=True ), for e.g \"https://youtu.be/dQw4w9WgXcQ\" as follows: Valid YouTube URL format All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} NetGear_Async ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Network Address ( string ): Valid ( http(s), rtp, rstp, rtmp, mms, etc. ) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: NetGear_Async ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. You can easily check it by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: NetGear_Async ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) y_tube \u00b6 This parameter controls the YouTube Mode, .i.e if enabled( y_tube=True ), the CamGear API will interpret the given source input as YouTube URL address. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) backend \u00b6 This parameter manually selects the backend of the OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: NetGear_Async ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u00b6 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH \" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS \" : 60 } # assigning it NetGear_Async ( source = 0 , ** options ) Parameters with PiGear backend \u00b6 camera_num \u00b6 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board in your project Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( enablePiCamera = True , camera_num = 0 ) resolution \u00b6 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: NetGear_Async ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u00b6 This parameter sets the framerate of the source. For more information read here \u27b6 . Data-Type: integer/float Default Value: Its default value is 30 . Usage: NetGear_Async ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate ( integer ) : sets the framerate. Its default value is 30 . For more information read here \u27b6 . options \u00b6 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs \u27b6 The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # assigning it NetGear_Async ( enablePiCamera = True , ** options ) User-specific attributes: Additionaly, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains a Internal Threaded Timer that keeps active track of the frozen-threads/failures and will exit safely at a particular timeout value. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before the Internal Threaded Timer exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . It usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u00b6 colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 NetGear_Async ( colorspace = \"COLOR_BGR2HSV\" ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/netgear_async/params/#netgear_async-api-parameters","text":"","title":"NetGear_Async API Parameters"},{"location":"gears/netgear_async/params/#address","text":"This parameter sets the valid network address of the server/client. Network addresses unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode, i.e 'localhost' for Send Mode and '*' for Receive Mode. Usage: NetGear_Async ( address = \"192.168.0.145\" )","title":"address"},{"location":"gears/netgear_async/params/#port","text":"This parameter sets the valid Network Port of the Server/Client. A network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Data-Type: String Default Value: Its default value is '5555' Usage: NetGear_Async ( port = \"5575\" )","title":"port"},{"location":"gears/netgear_async/params/#protocol","text":"This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear_Async ( protocol = \"ipc\" )","title":"protocol"},{"location":"gears/netgear_async/params/#pattern","text":"This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). All supported ZMQ patterns for NetGear_Async are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. 3 ( .i.e. zmq.PUSH/zmq.PULL ): Its sockets let you distribute messages to multiple workers, arranged in a pipeline. A Push socket will distribute sent messages to its Pull clients evenly. This is equivalent to the producer/consumer model but the results computed by the consumer are not sent upstream but downstream to another pull/consumer socket. Usage: NetGear_Async ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern","title":"pattern"},{"location":"gears/netgear_async/params/#receive_mode","text":"This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear_Async ( receive_mode = True ) # activates Recieve Mode","title":"receive_mode"},{"location":"gears/netgear_async/params/#timeout","text":"In NetGear_Async, the Receiver-end keeps tracks if frames are received from Server-end within this specified timeout value (in seconds) , Otherwise TimeoutError will be raised, which helps to close the Receiver-end safely if the Server has lost connection prematurely. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before Client'send exit itself with a TimeoutError to save resources. Its minimum value is 0.0 and no maximum value. Data-Type: Float/Integer Default Value: Its default value is 10.0 . Usage: NetGear_Async ( timeout = 5.0 ) # sets 5secs timeout","title":"timeout"},{"location":"gears/netgear_async/params/#parameters-for-videogear-backend","text":"","title":"Parameters for VideoGear backend"},{"location":"gears/netgear_async/params/#enablepicamera","text":"This parameter select access to PiGear or CamGear API respectively. This means the if enablePiCamera flag is True , PiGear API will be accessed and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( enablePiCamera = True ) # enable access to PiGear API","title":"enablePiCamera"},{"location":"gears/netgear_async/params/#parameters-for-stabilizer-backend","text":"","title":"Parameters for Stabilizer backend"},{"location":"gears/netgear_async/params/#stabilize","text":"This parameter set this flag to enable access to Stabilizer Class , i.e. flag can be set to True ( to enable ) or unset to False ( to disable ) this mode. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( stabilize = True ) # enable stablization","title":"stabilize"},{"location":"gears/netgear_async/params/#options","text":"This parameter can be used to pass user-defined parameters supported by Stabilizer Class . These parameters can be passed by formatting them as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/netgear_async/params/#parameters-with-camgear-backend","text":"","title":"Parameters with CamGear backend"},{"location":"gears/netgear_async/params/#source","text":"CamGear API will throw RuntimeError if source provided is invalid! This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: NetGear_Async ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: NetGear_Async ( source = '/home/foo.mp4' ) YouTube Video's URL ( string ): Valid Youtube video URL as input when YouTube Mode is enabled( i.e. y_tube=True ), for e.g \"https://youtu.be/dQw4w9WgXcQ\" as follows: Valid YouTube URL format All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} NetGear_Async ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Network Address ( string ): Valid ( http(s), rtp, rstp, rtmp, mms, etc. ) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: NetGear_Async ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. You can easily check it by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: NetGear_Async ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/netgear_async/params/#y_tube","text":"This parameter controls the YouTube Mode, .i.e if enabled( y_tube=True ), the CamGear API will interpret the given source input as YouTube URL address. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True )","title":"y_tube"},{"location":"gears/netgear_async/params/#backend","text":"This parameter manually selects the backend of the OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: NetGear_Async ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/netgear_async/params/#options_1","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH \" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS \" : 60 } # assigning it NetGear_Async ( source = 0 , ** options )","title":"options"},{"location":"gears/netgear_async/params/#parameters-with-pigear-backend","text":"","title":"Parameters with PiGear backend"},{"location":"gears/netgear_async/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board in your project Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( enablePiCamera = True , camera_num = 0 )","title":"camera_num"},{"location":"gears/netgear_async/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: NetGear_Async ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/netgear_async/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 . Data-Type: integer/float Default Value: Its default value is 30 . Usage: NetGear_Async ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate ( integer ) : sets the framerate. Its default value is 30 . For more information read here \u27b6 .","title":"framerate"},{"location":"gears/netgear_async/params/#options_2","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs \u27b6 The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # assigning it NetGear_Async ( enablePiCamera = True , ** options ) User-specific attributes: Additionaly, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains a Internal Threaded Timer that keeps active track of the frozen-threads/failures and will exit safely at a particular timeout value. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before the Internal Threaded Timer exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . It usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/netgear_async/params/#common-parameters","text":"","title":"Common Parameters"},{"location":"gears/netgear_async/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 NetGear_Async ( colorspace = \"COLOR_BGR2HSV\" )","title":"colorspace"},{"location":"gears/netgear_async/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"logging"},{"location":"gears/netgear_async/params/#time_delay","text":"This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/netgear_async/usage/","text":"NetGear_Async API Usage Examples: \u00b6 Requirement \u00b6 NetGear_Async API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ] Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with NetGear_Async API: Server's End \u00b6 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio #initialize Server with suitable source server = NetGear_Async ( source = '/home/foo/foo1.mp4' ) . launch () if __name__ == '__main__' : #set event loop asyncio . set_event_loop ( server . loop ) try : #run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass finally : # finally close the server server . close () Client's End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio #define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () #Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF #await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == '__main__' : #Set event loop to client's asyncio . set_event_loop ( client . loop ) try : #run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear_Async with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio #define and launch Client with `receive_mode=True`. #change following IP address '192.168.x.xxx' with yours client = NetGear_Async ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 2 , receive_mode = True , logging = True ) . launch () #Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF #await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == '__main__' : #Set event loop to client's asyncio . set_event_loop ( client . loop ) try : #run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio #initialize Server with suitable source server = NetGear_Async ( source = 0 , address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 2 , logging = True ) . launch () if __name__ == '__main__' : #set event loop asyncio . set_event_loop ( server . loop ) try : #run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass finally : # finally close the server server . close () Using NetGear_Async with a Custom Source(OpenCV) \u00b6 NetGear_Async allows you to easily define your own custom Source at Server-end that you want to use to manipulate your frames before sending them onto the network. Let's implement a bare-minimum example with a Custom Source using NetGear_Async API and OpenCV: Server's End \u00b6 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio #initialize Server server = NetGear_Async ( logging = True ) #Create a async frame generator as custom source async def my_frame_generator (): #Open any video stream such as live webcam video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check if frame empty if not grabbed : #if True break the infinite loop break # do something with the frame to be sent here # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0.00001 ) if __name__ == '__main__' : #set event loop asyncio . set_event_loop ( server . loop ) #Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () #Launch the Server server . launch () try : #run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass finally : # finally close the server server . close () Client's End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio #define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True , logging = True ) . launch () #Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF #await before continuing await asyncio . sleep ( 0.01 ) if __name__ == '__main__' : #Set event loop to client's asyncio . set_event_loop ( client . loop ) try : #run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear_Async with Other Gears \u00b6 NetGear_Async can be used with any other Gears without any compatibility issues. Let's implement a bare-minimum example where we are sending Stabilized frames from Server-end and saving them at Client's end with WriteGear as follows: Server's End \u00b6 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio #initialize Server with suitable source and enable stabilization server = NetGear_Async ( source = '/home/foo/foo1.mp4' , stabilize = True , logging = True ) . launch () if __name__ == '__main__' : #set event loop asyncio . set_event_loop ( server . loop ) try : #run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass finally : # finally close the server server . close () Client's End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears import WriteGear import cv2 , asyncio #define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () #Define writer with output filename 'Output.mp4' writer = WriteGear ( output_filename = 'Output.mp4' , logging = True ) #Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # write a modified frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF #await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == '__main__' : #Set event loop to client's asyncio . set_event_loop ( client . loop ) try : #run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/netgear_async/usage/#netgear_async-api-usage-examples","text":"","title":"NetGear_Async API Usage Examples:"},{"location":"gears/netgear_async/usage/#requirement","text":"NetGear_Async API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ]","title":"Requirement"},{"location":"gears/netgear_async/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with NetGear_Async API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear_async/usage/#servers-end","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio #initialize Server with suitable source server = NetGear_Async ( source = '/home/foo/foo1.mp4' ) . launch () if __name__ == '__main__' : #set event loop asyncio . set_event_loop ( server . loop ) try : #run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio #define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () #Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF #await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == '__main__' : #Set event loop to client's asyncio . set_event_loop ( client . loop ) try : #run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-variable-parameters","text":"","title":"Using NetGear_Async with Variable Parameters"},{"location":"gears/netgear_async/usage/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio #define and launch Client with `receive_mode=True`. #change following IP address '192.168.x.xxx' with yours client = NetGear_Async ( address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 2 , receive_mode = True , logging = True ) . launch () #Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF #await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == '__main__' : #Set event loop to client's asyncio . set_event_loop ( client . loop ) try : #run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#servers-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio #initialize Server with suitable source server = NetGear_Async ( source = 0 , address = '192.168.x.xxx' , port = '5454' , protocol = 'tcp' , pattern = 2 , logging = True ) . launch () if __name__ == '__main__' : #set event loop asyncio . set_event_loop ( server . loop ) try : #run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-a-custom-sourceopencv","text":"NetGear_Async allows you to easily define your own custom Source at Server-end that you want to use to manipulate your frames before sending them onto the network. Let's implement a bare-minimum example with a Custom Source using NetGear_Async API and OpenCV:","title":"Using NetGear_Async with a Custom Source(OpenCV)"},{"location":"gears/netgear_async/usage/#servers-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio #initialize Server server = NetGear_Async ( logging = True ) #Create a async frame generator as custom source async def my_frame_generator (): #Open any video stream such as live webcam video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check if frame empty if not grabbed : #if True break the infinite loop break # do something with the frame to be sent here # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0.00001 ) if __name__ == '__main__' : #set event loop asyncio . set_event_loop ( server . loop ) #Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () #Launch the Server server . launch () try : #run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end_2","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio #define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True , logging = True ) . launch () #Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF #await before continuing await asyncio . sleep ( 0.01 ) if __name__ == '__main__' : #Set event loop to client's asyncio . set_event_loop ( client . loop ) try : #run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-other-gears","text":"NetGear_Async can be used with any other Gears without any compatibility issues. Let's implement a bare-minimum example where we are sending Stabilized frames from Server-end and saving them at Client's end with WriteGear as follows:","title":"Using NetGear_Async with Other Gears"},{"location":"gears/netgear_async/usage/#servers-end_3","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio #initialize Server with suitable source and enable stabilization server = NetGear_Async ( source = '/home/foo/foo1.mp4' , stabilize = True , logging = True ) . launch () if __name__ == '__main__' : #set event loop asyncio . set_event_loop ( server . loop ) try : #run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end_3","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears import WriteGear import cv2 , asyncio #define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () #Define writer with output filename 'Output.mp4' writer = WriteGear ( output_filename = 'Output.mp4' , logging = True ) #Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # write a modified frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF #await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == '__main__' : #Set event loop to client's asyncio . set_event_loop ( client . loop ) try : #run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): #wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () # safely close writer writer . close ()","title":"Client's End"},{"location":"gears/pigear/overview/","text":"PiGear API \u00b6 Raspberry Pi Camera Module Overview \u00b6 PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded wrapper around complete picamera python library, and also provides us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear supports multiple camera modules, such as in case of Raspberry Pi Compute module IO boards. Best of all, PiGear provides excellent error-handling with features like a Threaded Internal Timer - that keeps active track of any frozen-threads/hardware-failures robustly, and exit safely if it does occurs, i.e. If you're running PiGear API in your script, and someone accidentally pulls Camera module cable out, instead of going into possible kernel panic, PiGear will exit safely to save resources. Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u00b6 You can import PiGear API in your program as follows: from vidgear.gears import PiGear \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/pigear/overview/#pigear-api","text":"Raspberry Pi Camera Module","title":"PiGear API"},{"location":"gears/pigear/overview/#overview","text":"PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded wrapper around complete picamera python library, and also provides us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear supports multiple camera modules, such as in case of Raspberry Pi Compute module IO boards. Best of all, PiGear provides excellent error-handling with features like a Threaded Internal Timer - that keeps active track of any frozen-threads/hardware-failures robustly, and exit safely if it does occurs, i.e. If you're running PiGear API in your script, and someone accidentally pulls Camera module cable out, instead of going into possible kernel panic, PiGear will exit safely to save resources. Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/pigear/overview/#importing","text":"You can import PiGear API in your program as follows: from vidgear.gears import PiGear","title":"Importing"},{"location":"gears/pigear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/pigear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/pigear/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/pigear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/pigear/params/","text":"PiGear API Parameters \u00b6 \u2009 camera_num \u00b6 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. Important Warning This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board in your project. Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( camera_num = 0 ) resolution \u00b6 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: PiGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u00b6 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: PiGear ( framerate = 60 ) # sets 60fps framerate ( integer ) : sets the framerate. Its default value is 30 . For more information read here \u27b6 . colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 PiGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 options \u00b6 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # assigning it PiGear ( logging = True , ** options ) User-specific attributes: Additionaly, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains a Internal Threaded Timer that keeps active track of the frozen-threads/failures and will exit safely at a particular timeout value. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before the Internal Threaded Timer exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . It usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: PiGear ( logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/pigear/params/#pigear-api-parameters","text":"","title":"PiGear API Parameters"},{"location":"gears/pigear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. Important Warning This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board in your project. Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( camera_num = 0 )","title":"camera_num"},{"location":"gears/pigear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: PiGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/pigear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: PiGear ( framerate = 60 ) # sets 60fps framerate ( integer ) : sets the framerate. Its default value is 30 . For more information read here \u27b6 .","title":"framerate"},{"location":"gears/pigear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 PiGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/pigear/params/#options","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # assigning it PiGear ( logging = True , ** options ) User-specific attributes: Additionaly, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains a Internal Threaded Timer that keeps active track of the frozen-threads/failures and will exit safely at a particular timeout value. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before the Internal Threaded Timer exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . It usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/pigear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: PiGear ( logging = True )","title":"logging"},{"location":"gears/pigear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/pigear/usage/","text":"PiGear API Usage Examples: \u00b6 Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise it won't work. \u2009 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with PiGear API: # import required libraries from vidgear.gears import PiGear import cv2 # open pi video stream with default parameters stream = PiGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using PiGear with Variable Camera Properties \u00b6 PiGear API supports all tweak parameters and attributes available within Picamera library . These parameters can be easily applied to source stream in PiGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All supported parameters are listed in PiCamera Docs \u27b6 # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using PiGear with Direct Colorspace Manipulation \u00b6 PiGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters and change colorspace to `HSV` stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , colorspace = 'COLOR_BGR2HSV' , logging = True , ** options ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): #directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY #Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB #Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None #Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Usage Examples"},{"location":"gears/pigear/usage/#pigear-api-usage-examples","text":"Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise it won't work.","title":"PiGear API Usage Examples:"},{"location":"gears/pigear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with PiGear API: # import required libraries from vidgear.gears import PiGear import cv2 # open pi video stream with default parameters stream = PiGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/pigear/usage/#using-pigear-with-variable-camera-properties","text":"PiGear API supports all tweak parameters and attributes available within Picamera library . These parameters can be easily applied to source stream in PiGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All supported parameters are listed in PiCamera Docs \u27b6 # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using PiGear with Variable Camera Properties"},{"location":"gears/pigear/usage/#using-pigear-with-direct-colorspace-manipulation","text":"PiGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # open pi video stream with defined parameters and change colorspace to `HSV` stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , colorspace = 'COLOR_BGR2HSV' , logging = True , ** options ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): #directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY #Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB #Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None #Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using PiGear with Direct Colorspace Manipulation"},{"location":"gears/screengear/overview/","text":"ScreenGear API \u00b6 ScreenGear in action Overview \u00b6 ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors. ScreenGear API implements a multi-threaded wrapper around python-mss python library, and also flexibly supports its internal parameter. Furthermore, ScreenGear API relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u00b6 You can import ScreenGear API in your program as follows: from vidgear.gears import ScreenGear \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/screengear/overview/#screengear-api","text":"ScreenGear in action","title":"ScreenGear API"},{"location":"gears/screengear/overview/#overview","text":"ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors. ScreenGear API implements a multi-threaded wrapper around python-mss python library, and also flexibly supports its internal parameter. Furthermore, ScreenGear API relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/screengear/overview/#importing","text":"You can import ScreenGear API in your program as follows: from vidgear.gears import ScreenGear","title":"Importing"},{"location":"gears/screengear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/screengear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/screengear/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/screengear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/screengear/params/","text":"ScreenGear API Parameters \u00b6 monitor \u00b6 This parameter sets the index of the monitor screen, where to grab live frames from. More information can be found here \u27b6 . Its value can be assign to 0 , to fetch frames from all connected monitor screens. monitor value cannot be negative, Otherwise, ScreenGear API will throw ValueError . Data-Type: Integer Default Value: Its default value is 1 (means the current monitor will be used) . Usage: ScreenGear ( monitor = 2 ) # to fetch frames from second screen colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 . ScreenGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 options \u00b6 This parameter provides the flexibility to manually set the dimensions of capture screen w.r.t selected monitor value. Supported Dimensional Parameters Supported Dimensional Parameters for selected monitor value are as follows: left: the x-coordinate of the upper-left corner of the region top: the y-coordinate of the upper-left corner of the region width: the width of the region height: the height of the region Data-Type: Dictionary Default Value: Its default value is {} Usage: The desired dimensional parameters can be passed to ScreenGear API by formatting them as attributes, as follows: More information about screen dimensioning can be found here \u27b6 # formatting dimensional parameters as dictionary attributes options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # assigning it w.r.t monitor=1 ScreenGear ( monitor = 1 , ** options ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: ScreenGear ( logging = True )","title":"Parameters"},{"location":"gears/screengear/params/#screengear-api-parameters","text":"","title":"ScreenGear API Parameters"},{"location":"gears/screengear/params/#monitor","text":"This parameter sets the index of the monitor screen, where to grab live frames from. More information can be found here \u27b6 . Its value can be assign to 0 , to fetch frames from all connected monitor screens. monitor value cannot be negative, Otherwise, ScreenGear API will throw ValueError . Data-Type: Integer Default Value: Its default value is 1 (means the current monitor will be used) . Usage: ScreenGear ( monitor = 2 ) # to fetch frames from second screen","title":"monitor"},{"location":"gears/screengear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 . ScreenGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/screengear/params/#options","text":"This parameter provides the flexibility to manually set the dimensions of capture screen w.r.t selected monitor value. Supported Dimensional Parameters Supported Dimensional Parameters for selected monitor value are as follows: left: the x-coordinate of the upper-left corner of the region top: the y-coordinate of the upper-left corner of the region width: the width of the region height: the height of the region Data-Type: Dictionary Default Value: Its default value is {} Usage: The desired dimensional parameters can be passed to ScreenGear API by formatting them as attributes, as follows: More information about screen dimensioning can be found here \u27b6 # formatting dimensional parameters as dictionary attributes options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # assigning it w.r.t monitor=1 ScreenGear ( monitor = 1 , ** options )","title":"options"},{"location":"gears/screengear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: ScreenGear ( logging = True )","title":"logging"},{"location":"gears/screengear/usage/","text":"ScreenGear API Usage Examples: \u00b6 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with ScreenGear API: # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with default parameters stream = ScreenGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Variable Screen Dimensions \u00b6 ScreenGear API provides us the flexibility to directly set the dimensions of capture screen w.r.t selected monitor value. These dimensions can be easily applied to ScreenGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: # import required libraries from vidgear.gears import ScreenGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # open video stream with defined parameters stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Direct Colorspace Manipulation \u00b6 ScreenGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import ScreenGear import cv2 # Change colorspace to `HSV` stream = ScreenGear ( colorspace = 'COLOR_BGR2HSV' , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): #directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY #Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB #Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None #Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with WriteGear API \u00b6 ScreenGear can be used in conjunction with WriteGear API directly without any compatibility issues. The suitable example is as follows: # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import WriteGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open video stream with defined parameters stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/screengear/usage/#screengear-api-usage-examples","text":"","title":"ScreenGear API Usage Examples:"},{"location":"gears/screengear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with ScreenGear API: # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with default parameters stream = ScreenGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/screengear/usage/#using-screengear-with-variable-screen-dimensions","text":"ScreenGear API provides us the flexibility to directly set the dimensions of capture screen w.r.t selected monitor value. These dimensions can be easily applied to ScreenGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: # import required libraries from vidgear.gears import ScreenGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # open video stream with defined parameters stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Variable Screen Dimensions"},{"location":"gears/screengear/usage/#using-screengear-with-direct-colorspace-manipulation","text":"ScreenGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import ScreenGear import cv2 # Change colorspace to `HSV` stream = ScreenGear ( colorspace = 'COLOR_BGR2HSV' , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): #directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY #Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB #Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None #Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Direct Colorspace Manipulation"},{"location":"gears/screengear/usage/#using-screengear-with-writegear-api","text":"ScreenGear can be used in conjunction with WriteGear API directly without any compatibility issues. The suitable example is as follows: # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import WriteGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open video stream with defined parameters stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using ScreenGear with WriteGear API"},{"location":"gears/stabilizer/overview/","text":"Stabilizer Class \u00b6 Original Video Courtesy @SIGGRAPH2013 This video frames are transcoded with StreamGear API and hosted on GitHub Repository and served with raw.githack.com Overview \u00b6 Stabilizer is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free & ultra-fast frame handling. \u2009 Features \u00b6 Real-time stabilization with low latency and no extra resources. Works exceptionally well with low-frequency jitter. Integrated with VideoGear API, therefore, can be applied to any incoming stream. Also seamlessly works standalone. \u2009 Important The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors. \u2009 Importing \u00b6 You can import Stabilizer Class in your program as follows: from vidgear.gears.stabilizer import Stabilizer \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/stabilizer/overview/#stabilizer-class","text":"Original Video Courtesy @SIGGRAPH2013 This video frames are transcoded with StreamGear API and hosted on GitHub Repository and served with raw.githack.com","title":"Stabilizer Class"},{"location":"gears/stabilizer/overview/#overview","text":"Stabilizer is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free & ultra-fast frame handling.","title":"Overview"},{"location":"gears/stabilizer/overview/#features","text":"Real-time stabilization with low latency and no extra resources. Works exceptionally well with low-frequency jitter. Integrated with VideoGear API, therefore, can be applied to any incoming stream. Also seamlessly works standalone. \u2009 Important The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors.","title":"Features"},{"location":"gears/stabilizer/overview/#importing","text":"You can import Stabilizer Class in your program as follows: from vidgear.gears.stabilizer import Stabilizer","title":"Importing"},{"location":"gears/stabilizer/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/stabilizer/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/stabilizer/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/stabilizer/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/stabilizer/params/","text":"Stabilizer Class Parameters \u00b6 smoothing_radius \u00b6 This parameter can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Data-Type: Integer Default Value: Its default value is 25 . Usage: You can easily pass this parameter as follows: Stabilizer ( smoothing_radius = 30 ) border_size \u00b6 This parameter enables the feature to extend border size that compensates for stabilized output video frames motions. Data-Type: Integer Default Value: Its default value is 0 (no borders). Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 ) crop_n_zoom \u00b6 This parameter enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the border_size parameter, i.e. when this parameter is enabled, border_size will be used for cropping border instead of extending them. Data-Type: Boolean Default Value: Its default value is False . Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 , crop_n_zoom = True ) border_type \u00b6 This parameter can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Altering border_type parameter is DISABLED while crop_n_zoom is enabled! Data-Type: String Default Value: Its default value is 'black' . Usage: You can easily pass this parameter as follows: Stabilizer ( border_type = 'reflect' ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: Stabilizer ( logging = True )","title":"Parameters"},{"location":"gears/stabilizer/params/#stabilizer-class-parameters","text":"","title":"Stabilizer Class Parameters"},{"location":"gears/stabilizer/params/#smoothing_radius","text":"This parameter can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Data-Type: Integer Default Value: Its default value is 25 . Usage: You can easily pass this parameter as follows: Stabilizer ( smoothing_radius = 30 )","title":"smoothing_radius"},{"location":"gears/stabilizer/params/#border_size","text":"This parameter enables the feature to extend border size that compensates for stabilized output video frames motions. Data-Type: Integer Default Value: Its default value is 0 (no borders). Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 )","title":"border_size"},{"location":"gears/stabilizer/params/#crop_n_zoom","text":"This parameter enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the border_size parameter, i.e. when this parameter is enabled, border_size will be used for cropping border instead of extending them. Data-Type: Boolean Default Value: Its default value is False . Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 , crop_n_zoom = True )","title":"crop_n_zoom"},{"location":"gears/stabilizer/params/#border_type","text":"This parameter can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Altering border_type parameter is DISABLED while crop_n_zoom is enabled! Data-Type: String Default Value: Its default value is 'black' . Usage: You can easily pass this parameter as follows: Stabilizer ( border_type = 'reflect' )","title":"border_type"},{"location":"gears/stabilizer/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: Stabilizer ( logging = True )","title":"logging"},{"location":"gears/stabilizer/usage/","text":"Stabilizer Class Usage Examples: \u00b6 \u2009 The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. \u2009 Bare-Minimum Usage with VideoCapture Gears \u00b6 Following is the bare-minimum code you need to get started with Stabilizer Class and various VideoCapture Gears: You can use any VideoCapture Gear instead of CamGear in the similar manner, as shown in this usage example. # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () #initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized_frame frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Bare-Minimum Usage with OpenCV \u00b6 The VidGear's stabilizer class can also work standalone easily with any Computer Vision library such as OpenCV itself. Following is the bare-minimum code you need to get started with Stabilizer Class and OpenCV: # import required libraries from vidgear.gears.stabilizer import Stabilizer import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) #initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the frame here} # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () #clear stabilizer resources stab . clean () # safely close video stream stream . release () Using Stabilizer with Variable Parameters \u00b6 Stabilizer class provide certain parameters which you can use to manipulate its internal properties. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () #initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized_frame frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Stabilizer with WriteGear \u00b6 VideoGear's stabilizer can be used in conjunction with WriteGear API directly without any compatibility issues. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream stream = CamGear ( source = \"unstabilized_stream.mp4\" ) . start () #initiate stabilizer object with default parameters stab = Stabilizer () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () #clear stabilizer resources stab . clean () # safely close video stream stream . stop () # safely close writer writer . close () Using VideoGear with Stabilizer backend \u00b6 VideoGear API provides a special internal wrapper around Stabilizer class, that enables easy stabilization for various video-streams (real-time or not) with minimum effort and using just fewer lines of code. The complete usage example can be found here \u27b6","title":"Usage Examples"},{"location":"gears/stabilizer/usage/#stabilizer-class-usage-examples","text":"The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames.","title":"Stabilizer Class Usage Examples:"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-videocapture-gears","text":"Following is the bare-minimum code you need to get started with Stabilizer Class and various VideoCapture Gears: You can use any VideoCapture Gear instead of CamGear in the similar manner, as shown in this usage example. # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () #initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized_frame frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with VideoCapture Gears"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-opencv","text":"The VidGear's stabilizer class can also work standalone easily with any Computer Vision library such as OpenCV itself. Following is the bare-minimum code you need to get started with Stabilizer Class and OpenCV: # import required libraries from vidgear.gears.stabilizer import Stabilizer import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) #initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the frame here} # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () #clear stabilizer resources stab . clean () # safely close video stream stream . release ()","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-variable-parameters","text":"Stabilizer class provide certain parameters which you can use to manipulate its internal properties. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () #initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized_frame frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Stabilizer with Variable Parameters"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-writegear","text":"VideoGear's stabilizer can be used in conjunction with WriteGear API directly without any compatibility issues. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream stream = CamGear ( source = \"unstabilized_stream.mp4\" ) . start () #initiate stabilizer object with default parameters stab = Stabilizer () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () #clear stabilizer resources stab . clean () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Stabilizer with WriteGear"},{"location":"gears/stabilizer/usage/#using-videogear-with-stabilizer-backend","text":"VideoGear API provides a special internal wrapper around Stabilizer class, that enables easy stabilization for various video-streams (real-time or not) with minimum effort and using just fewer lines of code. The complete usage example can be found here \u27b6","title":"Using VideoGear with Stabilizer backend"},{"location":"gears/streamgear/ffmpeg_install/","text":"FFmpeg Installation Instructions \u00b6 StreamGear must requires FFmpeg executables for transcoding Media Chunks. You can following machine-specific instructions for its installation: StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. Enable logging ( logging=True ) for debugging FFmpeg validation process. Linux FFmpeg Installation \u00b6 The StreamGear API supports Auto-Detection and Manual Configuration methods on a Linux machine: A. Auto-Detection \u00b6 This is a recommended approach on Linux Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError ! Windows FFmpeg Installation \u00b6 The StreamGear API supports Auto-Installation and Manual Configuration methods on Windows systems. A. Auto-Installation \u00b6 This is a recommended approach on Windows Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system StreamGear API auto-generates the required FFmpeg Static Binaries, according to your system specifications, into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, StreamGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then StreamGear API will exit with RuntimeError ! B. Manual Configuration \u00b6 Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: http://ffmpeg.zeranoe.com/builds/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError ! MacOS FFmpeg Installation \u00b6 The StreamGear API supports Auto-Detection and Manual Configuration methods on a macOS machine. A. Auto-Detection \u00b6 This is a recommended approach on MacOS Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#ffmpeg-installation-instructions","text":"StreamGear must requires FFmpeg executables for transcoding Media Chunks. You can following machine-specific instructions for its installation: StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. Enable logging ( logging=True ) for debugging FFmpeg validation process.","title":"FFmpeg Installation Instructions"},{"location":"gears/streamgear/ffmpeg_install/#linux-ffmpeg-installation","text":"The StreamGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:","title":"Linux FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection","text":"This is a recommended approach on Linux Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6","title":"A. Auto-Detection"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration","text":"Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/ffmpeg_install/#windows-ffmpeg-installation","text":"The StreamGear API supports Auto-Installation and Manual Configuration methods on Windows systems.","title":"Windows FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-installation","text":"This is a recommended approach on Windows Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system StreamGear API auto-generates the required FFmpeg Static Binaries, according to your system specifications, into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, StreamGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then StreamGear API will exit with RuntimeError !","title":"A. Auto-Installation"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_1","text":"Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: http://ffmpeg.zeranoe.com/builds/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/ffmpeg_install/#macos-ffmpeg-installation","text":"The StreamGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.","title":"MacOS FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection_1","text":"This is a recommended approach on MacOS Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6","title":"A. Auto-Detection"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_2","text":"Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/overview/","text":"StreamGear API \u00b6 StreamGear API's generalized workflow Overview \u00b6 StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. StreamGear provides a standalone, highly extensible and flexible wrapper around FFmpeg - a leading multimedia framework, for generating chunked-encoded media segments of the content. SteamGear API automatically transcodes source videos/audio files & real-time frames, and breaks them into a sequence of multiple smaller chunks/segments (typically 2-4 seconds in length) at different quality levels (i.e. different bitrates or spatial resolutions) . It also creates a Manifest file (MPD in-case of DASH) that describes these segment information (timing, URL, media characteristics like video resolution and bit rates) , and is provided to the client prior to the streaming session. Thereby, segments are served on a web server and can be downloaded through HTTP standard compliant GET requests. This makes it possible to stream videos at different quality levels, and to switch in the middle of a video from one quality level to another one \u2013 if bandwidth permits \u2013 on a per segment basis. SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. Also, Multiple DRM support is yet to be implemented. \u2009 Important StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. It is advised to enable logging ( logging=True ) on the first run for easily identifying any runtime errors. \u2009 Mode of Operations \u00b6 StreamGear primarily works in two independent modes for transcoding which serves different purposes. These modes are as follows: A. Single-Source Mode \u00b6 In this mode, StreamGear transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well, when you're transcoding lossless long-duration videos(with audio) for streaming and required no extra efforts or interruptions. But on the downside, the provided source cannot be changed or manipulated before sending onto FFmpeg Pipeline for processing. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. Learn more about this mode here \u27b6 B. Real-time Frames Mode \u00b6 When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller chunks/segments for streaming. In this mode, StreamGear supports real-time numpy.ndarray frames, and process them over FFmpeg pipeline. But on the downside, audio has to added manually (as separate source) for streams. Learn more about this mode here \u27b6 \u2009 Importing \u00b6 You can import StreamGear API in your program as follows: from vidgear.gears import StreamGear \u2009 Watch Demo \u00b6 Watch StreamGear transcoded MPEG-DASH Stream: Powered by clappr & shaka-player This video assets (Manifest and segments) are hosted on GitHub Repository and served with raw.githack.com \u2009 Recommended Stream Players \u00b6 GUI Players \u00b6 MPV Player : (recommended) MPV is a free, open source, and cross-platform media player. It supports a wide variety of media file formats, audio and video codecs, and subtitle types. VLC Player : VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols. Parole : (UNIX only) Parole is a modern simple media player based on the GStreamer framework for Unix and Unix-like operating systems. Command-Line Players \u00b6 MP4Client : GPAC provides a highly configurable multimedia player called MP4Client. GPAC itself is an open source multimedia framework developed for research and academic purposes, and used in many media production chains. ffplay : FFplay is a very simple and portable media player using the FFmpeg libraries and the SDL library. It is mostly used as a testbed for the various FFmpeg APIs. Online Players \u00b6 To run Online players locally, you'll need a HTTP server. For creating one yourself, See this well-curated list \u27b6 Clapper : Clappr is an extensible media player for the web. Shaka Player : Shaka Player is an open-source JavaScript library for playing adaptive media in a browser. MediaElementPlayer : MediaElementPlayer is a complete HTML/CSS audio/video player. \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/streamgear/overview/#streamgear-api","text":"StreamGear API's generalized workflow","title":"StreamGear API"},{"location":"gears/streamgear/overview/#overview","text":"StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. StreamGear provides a standalone, highly extensible and flexible wrapper around FFmpeg - a leading multimedia framework, for generating chunked-encoded media segments of the content. SteamGear API automatically transcodes source videos/audio files & real-time frames, and breaks them into a sequence of multiple smaller chunks/segments (typically 2-4 seconds in length) at different quality levels (i.e. different bitrates or spatial resolutions) . It also creates a Manifest file (MPD in-case of DASH) that describes these segment information (timing, URL, media characteristics like video resolution and bit rates) , and is provided to the client prior to the streaming session. Thereby, segments are served on a web server and can be downloaded through HTTP standard compliant GET requests. This makes it possible to stream videos at different quality levels, and to switch in the middle of a video from one quality level to another one \u2013 if bandwidth permits \u2013 on a per segment basis. SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. Also, Multiple DRM support is yet to be implemented. \u2009 Important StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. It is advised to enable logging ( logging=True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/streamgear/overview/#mode-of-operations","text":"StreamGear primarily works in two independent modes for transcoding which serves different purposes. These modes are as follows:","title":"Mode of Operations"},{"location":"gears/streamgear/overview/#a-single-source-mode","text":"In this mode, StreamGear transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well, when you're transcoding lossless long-duration videos(with audio) for streaming and required no extra efforts or interruptions. But on the downside, the provided source cannot be changed or manipulated before sending onto FFmpeg Pipeline for processing. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. Learn more about this mode here \u27b6","title":"A. Single-Source Mode"},{"location":"gears/streamgear/overview/#b-real-time-frames-mode","text":"When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller chunks/segments for streaming. In this mode, StreamGear supports real-time numpy.ndarray frames, and process them over FFmpeg pipeline. But on the downside, audio has to added manually (as separate source) for streams. Learn more about this mode here \u27b6","title":"B. Real-time Frames Mode"},{"location":"gears/streamgear/overview/#importing","text":"You can import StreamGear API in your program as follows: from vidgear.gears import StreamGear","title":"Importing"},{"location":"gears/streamgear/overview/#watch-demo","text":"Watch StreamGear transcoded MPEG-DASH Stream: Powered by clappr & shaka-player This video assets (Manifest and segments) are hosted on GitHub Repository and served with raw.githack.com","title":"Watch Demo"},{"location":"gears/streamgear/overview/#recommended-stream-players","text":"","title":"Recommended Stream Players"},{"location":"gears/streamgear/overview/#gui-players","text":"MPV Player : (recommended) MPV is a free, open source, and cross-platform media player. It supports a wide variety of media file formats, audio and video codecs, and subtitle types. VLC Player : VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols. Parole : (UNIX only) Parole is a modern simple media player based on the GStreamer framework for Unix and Unix-like operating systems.","title":"GUI Players"},{"location":"gears/streamgear/overview/#command-line-players","text":"MP4Client : GPAC provides a highly configurable multimedia player called MP4Client. GPAC itself is an open source multimedia framework developed for research and academic purposes, and used in many media production chains. ffplay : FFplay is a very simple and portable media player using the FFmpeg libraries and the SDL library. It is mostly used as a testbed for the various FFmpeg APIs.","title":"Command-Line Players"},{"location":"gears/streamgear/overview/#online-players","text":"To run Online players locally, you'll need a HTTP server. For creating one yourself, See this well-curated list \u27b6 Clapper : Clappr is an extensible media player for the web. Shaka Player : Shaka Player is an open-source JavaScript library for playing adaptive media in a browser. MediaElementPlayer : MediaElementPlayer is a complete HTML/CSS audio/video player.","title":"Online Players"},{"location":"gears/streamgear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/streamgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/streamgear/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/streamgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/streamgear/params/","text":"StreamGear API Parameters \u00b6 output \u00b6 This parameter sets the valid filename/path for storing the StreamGear assets (Manifest file(such as Media Presentation Description(MPD) in-case of DASH) & Transcoded sequence of segments) . StreamGear API will throw ValueError if output provided is empty or invalid. StreamGear generated sequence of multiple chunks/segments are also stored in the same directory. You can easily delete all previous assets at output location, by using -clear_prev_assets attribute of stream_params dictionary parameter. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory. In this case, StreamGear API will automatically assign a unique filename for Manifest file. This can be defined as follows: streamer = StreamGear ( output = '/home/foo/foo1' ) # Define streamer with manifest saving directory path Filename (with/without path) : Valid filename( with valid extension ) of the output Manifest file. In case filename is provided without path, then current working directory will be used. streamer = StreamGear ( output = 'output_foo.mpd' ) # Define streamer with manifest file name Make sure to provide valid filename with valid file-extension for selected format value (such as output.mpd in case of MPEG-DASH) , otherwise StreamGear will throw AssertionError . URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for directly storing assets to a network server. For example, you can use a http protocol URL as follows: streamer = StreamGear ( output = 'http://195.167.1.101/live/test.mpd' ) #Define streamer formats \u00b6 This parameter select the adaptive HTTP streaming format. HTTP streaming works by breaking the overall stream into a sequence of small HTTP-based file downloads, each downloading one short chunk of an overall potentially unbounded transport stream. For now, the only supported format is: 'dash' (i.e MPEG-DASH ) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. Data-Type: String Default Value: Its default value is 'dash' Usage: StreamGear ( output = 'output_foo.mpd' , format = \"dash\" ) custom_ffmpeg \u00b6 This parameter assigns the custom path/directory where the custom/downloaded FFmpeg executables are located. Behavior on Windows If a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then StreamGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" StreamGear ( output = 'output_foo.mpd' , custom_ffmpeg = \"/foo/foo1/ffmpeg\" ) stream_params \u00b6 This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly change its internal settings for transcoding and seamlessly generating high-quality streams. All supported parameters can formatting as attributes for this dictionary parameter: Kindly read FFmpeg Docs carefully, before passing any additional values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u00b6 A. Exclusive Parameters \u00b6 StreamGear API provides some exclusive internal parameters to easily generate Streaming Assets and effortlessly tweak its internal properties. These parameters are discussed below: -streams (list of dicts) : This important attribute makes it simple and pretty straight-forward to define additional multiple streams as list of dictionaries of different quality levels (i.e. different bitrates or spatial resolutions) for streaming. Important -streams attribute facts On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input Video, at the index 0 . You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. To construct the additional stream dictionaries, you'll will need following sub-attributes: -resolution (string) : It is compulsory to define the required resolution/dimension/size for the stream, otherwise given stream will be rejected. Its value can be a \"{width}x{height}\" as follows: \"-streams\" = [{ \"-resolution\" : \"1280x720\" }] # to produce a 1280x720 resolution/scale \u2002 -video_bitrate (string) : It is an optional (can be ignored if -framerate parameter is defined) sub-attribute that generally determines the bandwidth and quality of stream, i.e. the higher the bitrate, the better the quality and the larger will be bandwidth and more will be strain on network. It value is generally in kbps (kilobits per second) for OBS (Open Broadcasting Softwares). You can easily define this attribute as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"2000k\" }] # to produce a 1280x720 resolution and 2000kbps bitrate stream \u2002 -framerate (float/int) : It is another optional (can be ignored if -video_bitrate parameter is defined) sub-attribute that defines the assumed framerate for the stream. Thereby, StreamGear automatically appropriate calculates the suitable video-bitrate using its value along with -bpps and -resolution values , so you don't have to. It's value can be float/integer as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-framerate\" : \"60.0\" }] # to produce a 1280x720 resolution and 60fps framerate stream \u2002 Usage: You can easily define any number of streams using -streams attribute as follows: Usage example can be found here \u27b6 stream_params = { \"-streams\" : [{ \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : \"30.0\" }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : \"60.0\" }, # Stream3: 640x360 at 60fps ]} \u2002 -video_source (string) : This attribute takes valid Video path as input and activates Single-Source Mode , for transcoding it into multiple smaller chunks/segments for streaming after successful validation. Its value be one of the following: Usage example can be found here \u27b6 Video Filename : Valid path to Video file as follows: stream_params = { \"-video_source\" : \"/home/foo/foo1.mp4\" } # set input video source: /home/foo/foo1.mp4 Video URL : Valid URL of a network video stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-video_source\" : \"http://livefeed.com:5050\" } # set input video source: http://livefeed.com:5050 \u2002 -audio (dict) : This attribute takes external custom audio path as audio-input for all StreamGear streams. Its value be one of the following: Make sure this audio-source is compatible with provided video -source, otherwise you encounter multiple errors, or even no output at all! Usage example can be found here \u27b6 Audio Filename : Valid path to Audio file as follows: stream_params = { \"-audio\" : \"/home/foo/foo1.aac\" } # set input audio source: /home/foo/foo1.aac Audio URL : Valid URL of a network audio stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-audio\" : \"https://exampleaudio.org/example-160.mp3\" } # set input audio source: https://exampleaudio.org/example-160.mp3 \u2002 -input_framerate (float/int) : (optional) specifies the assumed input video source framerate, and only works in Real-time Frames Mode . It can be used as follows: Usage example can be found here \u27b6 stream_params = { \"-input_framerate\" : 60.0 } # set input video source framerate to 60fps \u2002 -bpp (float/int) : (optional) This attribute controls constant Bits-Per-Pixel (BPP) value, which is kind of a constant value to ensure good quality of high motion scenes ,and thereby used in calculating desired video-bitrate for streams. Higher the BPP, better will be motion quality. Its default value is 0.1 . Going over 0.1 helps to fill gaps between current bitrate and upload limit/ingest cap. Its value can be anything above 0.001 , can be used as follows: Important BPP tips for streaming -bpp a sensitive value, try 0.001, and then make increments in 0.0001 to fine tune If your desired resolution/fps/audio combination is below maximum service bitrate, raise BPP to match it for extra quality. It is generally better to lower resolution (and/or fps) and raise BPP than raise resolution and loose on BPP. stream_params = { \"-bpp\" : 0.05 } # sets BPP to 0.05 \u2002 -gop (float/int) : (optional) specifies the Keyframe interval, also known as GOP length. This attributes manually sets both minimum and maximum distance between I-frames for accurate fixed GOP length. It can be used as follows: By default, StreamGear automatically sets recommended fixed GOP value (i.e. every two seconds) w.r.t input framerate and selected encoder. stream_params = { \"-gop\" : 70 } # set GOP length to 70 \u2002 -clones (list) : (optional) sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Usage is as follows: stream_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} \u2002 -ffmpeg_download_path (string) : (optional) sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: stream_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" \u2002 -clear_prev_assets (bool) : (optional) specify whether to force-delete any previous copies of StreamGear Assets (i.e. Manifest files(.mpd) & streaming chunks(.m4s)) present at path specified by output parameter. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: stream_params = { \"-clear_prev_assets\" : True } # will delete all previous assets \u2002 B. FFmpeg Parameters \u00b6 Almost all FFmpeg parameter can be passed as dictionary attributes in stream_params . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters In addition to these parameters, almost any FFmpeg parameter (supported by installed FFmpeg) is also supported. But make sure to read FFmpeg Docs carefully first. stream_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } \u2002 Supported Encoders and Decoders \u00b6 All the encoders and decoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: # for checking encoder ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows # for checking decoders ffmpeg -decoders # use `ffmpeg.exe -decoders` on windows logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: StreamGear ( logging = True ) In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9","title":"Parameters"},{"location":"gears/streamgear/params/#streamgear-api-parameters","text":"","title":"StreamGear API Parameters"},{"location":"gears/streamgear/params/#output","text":"This parameter sets the valid filename/path for storing the StreamGear assets (Manifest file(such as Media Presentation Description(MPD) in-case of DASH) & Transcoded sequence of segments) . StreamGear API will throw ValueError if output provided is empty or invalid. StreamGear generated sequence of multiple chunks/segments are also stored in the same directory. You can easily delete all previous assets at output location, by using -clear_prev_assets attribute of stream_params dictionary parameter. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory. In this case, StreamGear API will automatically assign a unique filename for Manifest file. This can be defined as follows: streamer = StreamGear ( output = '/home/foo/foo1' ) # Define streamer with manifest saving directory path Filename (with/without path) : Valid filename( with valid extension ) of the output Manifest file. In case filename is provided without path, then current working directory will be used. streamer = StreamGear ( output = 'output_foo.mpd' ) # Define streamer with manifest file name Make sure to provide valid filename with valid file-extension for selected format value (such as output.mpd in case of MPEG-DASH) , otherwise StreamGear will throw AssertionError . URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for directly storing assets to a network server. For example, you can use a http protocol URL as follows: streamer = StreamGear ( output = 'http://195.167.1.101/live/test.mpd' ) #Define streamer","title":"output"},{"location":"gears/streamgear/params/#formats","text":"This parameter select the adaptive HTTP streaming format. HTTP streaming works by breaking the overall stream into a sequence of small HTTP-based file downloads, each downloading one short chunk of an overall potentially unbounded transport stream. For now, the only supported format is: 'dash' (i.e MPEG-DASH ) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. Data-Type: String Default Value: Its default value is 'dash' Usage: StreamGear ( output = 'output_foo.mpd' , format = \"dash\" )","title":"formats"},{"location":"gears/streamgear/params/#custom_ffmpeg","text":"This parameter assigns the custom path/directory where the custom/downloaded FFmpeg executables are located. Behavior on Windows If a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then StreamGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" StreamGear ( output = 'output_foo.mpd' , custom_ffmpeg = \"/foo/foo1/ffmpeg\" )","title":"custom_ffmpeg"},{"location":"gears/streamgear/params/#stream_params","text":"This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly change its internal settings for transcoding and seamlessly generating high-quality streams. All supported parameters can formatting as attributes for this dictionary parameter: Kindly read FFmpeg Docs carefully, before passing any additional values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} .","title":"stream_params"},{"location":"gears/streamgear/params/#supported-parameters","text":"","title":"Supported Parameters"},{"location":"gears/streamgear/params/#a-exclusive-parameters","text":"StreamGear API provides some exclusive internal parameters to easily generate Streaming Assets and effortlessly tweak its internal properties. These parameters are discussed below: -streams (list of dicts) : This important attribute makes it simple and pretty straight-forward to define additional multiple streams as list of dictionaries of different quality levels (i.e. different bitrates or spatial resolutions) for streaming. Important -streams attribute facts On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input Video, at the index 0 . You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. To construct the additional stream dictionaries, you'll will need following sub-attributes: -resolution (string) : It is compulsory to define the required resolution/dimension/size for the stream, otherwise given stream will be rejected. Its value can be a \"{width}x{height}\" as follows: \"-streams\" = [{ \"-resolution\" : \"1280x720\" }] # to produce a 1280x720 resolution/scale \u2002 -video_bitrate (string) : It is an optional (can be ignored if -framerate parameter is defined) sub-attribute that generally determines the bandwidth and quality of stream, i.e. the higher the bitrate, the better the quality and the larger will be bandwidth and more will be strain on network. It value is generally in kbps (kilobits per second) for OBS (Open Broadcasting Softwares). You can easily define this attribute as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"2000k\" }] # to produce a 1280x720 resolution and 2000kbps bitrate stream \u2002 -framerate (float/int) : It is another optional (can be ignored if -video_bitrate parameter is defined) sub-attribute that defines the assumed framerate for the stream. Thereby, StreamGear automatically appropriate calculates the suitable video-bitrate using its value along with -bpps and -resolution values , so you don't have to. It's value can be float/integer as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-framerate\" : \"60.0\" }] # to produce a 1280x720 resolution and 60fps framerate stream \u2002 Usage: You can easily define any number of streams using -streams attribute as follows: Usage example can be found here \u27b6 stream_params = { \"-streams\" : [{ \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : \"30.0\" }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : \"60.0\" }, # Stream3: 640x360 at 60fps ]} \u2002 -video_source (string) : This attribute takes valid Video path as input and activates Single-Source Mode , for transcoding it into multiple smaller chunks/segments for streaming after successful validation. Its value be one of the following: Usage example can be found here \u27b6 Video Filename : Valid path to Video file as follows: stream_params = { \"-video_source\" : \"/home/foo/foo1.mp4\" } # set input video source: /home/foo/foo1.mp4 Video URL : Valid URL of a network video stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-video_source\" : \"http://livefeed.com:5050\" } # set input video source: http://livefeed.com:5050 \u2002 -audio (dict) : This attribute takes external custom audio path as audio-input for all StreamGear streams. Its value be one of the following: Make sure this audio-source is compatible with provided video -source, otherwise you encounter multiple errors, or even no output at all! Usage example can be found here \u27b6 Audio Filename : Valid path to Audio file as follows: stream_params = { \"-audio\" : \"/home/foo/foo1.aac\" } # set input audio source: /home/foo/foo1.aac Audio URL : Valid URL of a network audio stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-audio\" : \"https://exampleaudio.org/example-160.mp3\" } # set input audio source: https://exampleaudio.org/example-160.mp3 \u2002 -input_framerate (float/int) : (optional) specifies the assumed input video source framerate, and only works in Real-time Frames Mode . It can be used as follows: Usage example can be found here \u27b6 stream_params = { \"-input_framerate\" : 60.0 } # set input video source framerate to 60fps \u2002 -bpp (float/int) : (optional) This attribute controls constant Bits-Per-Pixel (BPP) value, which is kind of a constant value to ensure good quality of high motion scenes ,and thereby used in calculating desired video-bitrate for streams. Higher the BPP, better will be motion quality. Its default value is 0.1 . Going over 0.1 helps to fill gaps between current bitrate and upload limit/ingest cap. Its value can be anything above 0.001 , can be used as follows: Important BPP tips for streaming -bpp a sensitive value, try 0.001, and then make increments in 0.0001 to fine tune If your desired resolution/fps/audio combination is below maximum service bitrate, raise BPP to match it for extra quality. It is generally better to lower resolution (and/or fps) and raise BPP than raise resolution and loose on BPP. stream_params = { \"-bpp\" : 0.05 } # sets BPP to 0.05 \u2002 -gop (float/int) : (optional) specifies the Keyframe interval, also known as GOP length. This attributes manually sets both minimum and maximum distance between I-frames for accurate fixed GOP length. It can be used as follows: By default, StreamGear automatically sets recommended fixed GOP value (i.e. every two seconds) w.r.t input framerate and selected encoder. stream_params = { \"-gop\" : 70 } # set GOP length to 70 \u2002 -clones (list) : (optional) sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Usage is as follows: stream_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} \u2002 -ffmpeg_download_path (string) : (optional) sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: stream_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" \u2002 -clear_prev_assets (bool) : (optional) specify whether to force-delete any previous copies of StreamGear Assets (i.e. Manifest files(.mpd) & streaming chunks(.m4s)) present at path specified by output parameter. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: stream_params = { \"-clear_prev_assets\" : True } # will delete all previous assets","title":"A. Exclusive Parameters"},{"location":"gears/streamgear/params/#b-ffmpeg-parameters","text":"Almost all FFmpeg parameter can be passed as dictionary attributes in stream_params . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters In addition to these parameters, almost any FFmpeg parameter (supported by installed FFmpeg) is also supported. But make sure to read FFmpeg Docs carefully first. stream_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" }","title":"B. FFmpeg Parameters"},{"location":"gears/streamgear/params/#supported-encoders-and-decoders","text":"All the encoders and decoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: # for checking encoder ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows # for checking decoders ffmpeg -decoders # use `ffmpeg.exe -decoders` on windows","title":"Supported Encoders and Decoders"},{"location":"gears/streamgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: StreamGear ( logging = True ) In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9","title":"logging"},{"location":"gears/streamgear/usage/","text":"StreamGear API Usage Examples: \u00b6 Important Information StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. By default, when no additional streams are defined, StreamGear generates a primary stream of same resolution and framerate 1 as the input video (at the index 0 ) . It is advised to enable logging ( logging=True ) on the first run for easily identifying any runtime errors. Always use terminate() function at the very end of the main code. \u2009 A. Single-Source Mode \u00b6 Single-Source Mode generalized workflow In this mode, StreamGear transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well, when you're transcoding lossless long-duration videos(with audio) for streaming and required no extra efforts or interruptions. But on the downside, the provided source cannot be changed or manipulated before sending onto FFmpeg Pipeline for processing. This mode provide transcode_source() function to process audio-video files into streamable chunks. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. Warning Using stream() function instead of transcode_source() in Single-Source Mode will instantly result in RuntimeError ! Any invalid value to the -video_source attribute will result in AssertionError ! \u2009 A.1 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with StreamGear API in Single-Source Mode: If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input stream_params = { \"-video_source\" : \"foo.mp4\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () After running these bare-minimum commands, StreamGear will produce a Manifest file ( dash.mpd ) with steamable chunks that contains information about a Primary Stream of same resolution and framerate as the input. \u2009 A.2 Usage with Additional Streams \u00b6 In addition to Primary Stream, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically (More detailed information can be found here \u27b6 ) . The complete example is as follows: If input video-source contains any audio stream/channel, then it automatically gets assigned to all generated streams without any extra efforts. Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and also define various streams stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () \u2009 A.3 Usage with Custom Audio \u00b6 By default, if input video-source (i.e. -video_source ) contains any audio, then it gets automatically mapped to all generated streams. But, if you want to add any custom audio, you can easily do it by using exclusive -audio attribute of stream_params dictionary parameter. You just need to input the path of your audio file to this attribute as string, and StreamGear API will automatically validate and map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () \u2009 A.4 Usage with Variable FFmpeg Parameters \u00b6 For seamlessly generating these streaming assets, StreamGear provides a highly extensible and flexible wrapper around FFmpeg , and access to almost all of its parameter. Hence, you can access almost any parameter available with FFmpeg itself as dictionary attributes in stream_params dictionary parameter , and use it to manipulate transcoding as you like. For this example, let us use our own H.265/HEVC video and AAC audio encoder, and set custom audio bitrate, and various other optimizations: This example is just conveying the idea on how to use FFmpeg's encoders/parameters with StreamGear API. You can use any FFmpeg parameter in the similar manner. Kindly read FFmpeg Docs carefully, before passing any FFmpeg values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Always use -streams attribute to define additional streams safely, any duplicate or incorrect stream definition can break things! # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various other parameters stream_params = { \"-video_source\" : \"foo.mp4\" , # define Video-Source \"-vcodec\" : \"libx265\" , # assigns H.265/HEVC video encoder \"-x265-params\" : \"lossless=1\" , # enables Lossless encoding \"-crf\" : 25 , # Constant Rate Factor: 25 \"-bpp\" : \"0.15\" , # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream2: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" , # define input audio-source: \"/home/foo/foo1.aac\", \"-acodec\" : \"libfdk_aac\" , # assign lossless AAC audio encoder \"-vbr\" : 4 , # Variable Bit Rate: `4` } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , logging = True , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () B. Real-time Frames Mode \u00b6 Real-time Frames Mode generalized workflow When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes real-time numpy.ndarray video-frames (as opposed to a entire file) into a sequence of multiple smaller chunks/segments for streaming. In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. This mode provide stream() function for directly trancoding video-frames into streamable chunks over the FFmpeg pipeline. Warning Using transcode_source() function instead of stream() in Real-time Frames Mode will instantly result in RuntimeError ! NEVER assign anything to -video_source attribute of stream_params dictionary parameter, otherwise Single-Source Mode may get activated, and as a result, using stream() function will throw RuntimeError ! In this mode, Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25.0 fps. \u2009 B.1 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with StreamGear API in Real-time Frames Mode: We are using CamGear in this Bare-Minimum example, but any VideoCapture Gear will work in the similar manner. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () After running these bare-minimum commands, StreamGear will produce a Manifest file ( dash.mpd ) with steamable chunks that contains information about a Primary Stream of same resolution and framerate 1 as input (without any audio) . \u2009 B.2 Bare-Minimum Usage with RGB Mode \u00b6 In Real-time Frames Mode, StreamGear API provide rgb_mode boolean parameter with its stream() function, which if enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) , thereby also known as RGB Mode . The complete usage example is as follows: # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {simulating RGB frame for this example} frame_rgb = frame [:,:,:: - 1 ] # send frame to streamer streamer . stream ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.3 Bare-Minimum Usage with controlled Input-framerate \u00b6 In Real-time Frames Mode, StreamGear API provides exclusive -input_framerate attribute for its stream_params dictionary parameter, that allow us to set the assumed constant framerate for incoming frames. In this example, we will retrieve framerate from webcam video-stream, and set it as value for -input_framerate attribute in StreamGear: Remember, the Primary Stream framerate default to -input_framerate attribute value (if defined) in Real-time Frames Mode. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` value stream_params = { \"-input_framerate\" : stream . framerate } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.4 Bare-Minimum Usage with OpenCV \u00b6 You can easily use StreamGear API directly with any other Video Processing library( For e.g. OpenCV itself ) in Real-time Frames Mode. The complete usage example is as follows: This just a bare-minimum example with OpenCV, but any other Real-time Frames Mode feature/example will work in the similar manner. # import required libraries from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # send frame to streamer streamer . stream ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close streamer streamer . terminate () \u2009 B.5 Usage with Additional Streams \u00b6 Similar to Single-Source Mode, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter (More detailed information can be found here \u27b6 ) in Real-time Frames Mode. The complete example is as follows: Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # define various streams stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.6 Usage with Audio-Input \u00b6 In Real-time Frames Mode, if you want to add audio to your streams, you've to use exclusive -audio attribute of stream_params dictionary parameter. You need to input the path of your audio to this attribute as string value, and StreamGear API will automatically validate and map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.7 Usage with Hardware Video-Encoder \u00b6 In Real-time Frames Mode, you can also easily change encoder as per your requirement just by passing -vcodec FFmpeg parameter as an attribute in stream_params dictionary parameter. In addition to this, you can also specify the additional properties/features/optimizations for your system's GPU similarly. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY-NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import VideoGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = VideoGear ( source = 0 ) . start () # activate Single-Source Mode and various streams with custom Video Encoder and optimizations stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-vcodec\" : \"h264_vaapi\" , # define custom Video encoder \"-vaapi_device\" : \"/dev/dri/renderD128\" , # define device location \"-vf\" : \"format=nv12,hwupload\" , # define video pixformat } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9 \u21a9 \u21a9","title":"Usage Examples"},{"location":"gears/streamgear/usage/#streamgear-api-usage-examples","text":"Important Information StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. By default, when no additional streams are defined, StreamGear generates a primary stream of same resolution and framerate 1 as the input video (at the index 0 ) . It is advised to enable logging ( logging=True ) on the first run for easily identifying any runtime errors. Always use terminate() function at the very end of the main code.","title":"StreamGear API Usage Examples:"},{"location":"gears/streamgear/usage/#a-single-source-mode","text":"Single-Source Mode generalized workflow In this mode, StreamGear transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well, when you're transcoding lossless long-duration videos(with audio) for streaming and required no extra efforts or interruptions. But on the downside, the provided source cannot be changed or manipulated before sending onto FFmpeg Pipeline for processing. This mode provide transcode_source() function to process audio-video files into streamable chunks. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. Warning Using stream() function instead of transcode_source() in Single-Source Mode will instantly result in RuntimeError ! Any invalid value to the -video_source attribute will result in AssertionError !","title":"A. Single-Source Mode"},{"location":"gears/streamgear/usage/#a1-bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with StreamGear API in Single-Source Mode: If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input stream_params = { \"-video_source\" : \"foo.mp4\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () After running these bare-minimum commands, StreamGear will produce a Manifest file ( dash.mpd ) with steamable chunks that contains information about a Primary Stream of same resolution and framerate as the input.","title":"A.1 Bare-Minimum Usage"},{"location":"gears/streamgear/usage/#a2-usage-with-additional-streams","text":"In addition to Primary Stream, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically (More detailed information can be found here \u27b6 ) . The complete example is as follows: If input video-source contains any audio stream/channel, then it automatically gets assigned to all generated streams without any extra efforts. Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and also define various streams stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"A.2 Usage with Additional Streams"},{"location":"gears/streamgear/usage/#a3-usage-with-custom-audio","text":"By default, if input video-source (i.e. -video_source ) contains any audio, then it gets automatically mapped to all generated streams. But, if you want to add any custom audio, you can easily do it by using exclusive -audio attribute of stream_params dictionary parameter. You just need to input the path of your audio file to this attribute as string, and StreamGear API will automatically validate and map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"A.3 Usage with Custom Audio"},{"location":"gears/streamgear/usage/#a4-usage-with-variable-ffmpeg-parameters","text":"For seamlessly generating these streaming assets, StreamGear provides a highly extensible and flexible wrapper around FFmpeg , and access to almost all of its parameter. Hence, you can access almost any parameter available with FFmpeg itself as dictionary attributes in stream_params dictionary parameter , and use it to manipulate transcoding as you like. For this example, let us use our own H.265/HEVC video and AAC audio encoder, and set custom audio bitrate, and various other optimizations: This example is just conveying the idea on how to use FFmpeg's encoders/parameters with StreamGear API. You can use any FFmpeg parameter in the similar manner. Kindly read FFmpeg Docs carefully, before passing any FFmpeg values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Always use -streams attribute to define additional streams safely, any duplicate or incorrect stream definition can break things! # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various other parameters stream_params = { \"-video_source\" : \"foo.mp4\" , # define Video-Source \"-vcodec\" : \"libx265\" , # assigns H.265/HEVC video encoder \"-x265-params\" : \"lossless=1\" , # enables Lossless encoding \"-crf\" : 25 , # Constant Rate Factor: 25 \"-bpp\" : \"0.15\" , # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream2: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" , # define input audio-source: \"/home/foo/foo1.aac\", \"-acodec\" : \"libfdk_aac\" , # assign lossless AAC audio encoder \"-vbr\" : 4 , # Variable Bit Rate: `4` } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , logging = True , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"A.4 Usage with Variable FFmpeg Parameters"},{"location":"gears/streamgear/usage/#b-real-time-frames-mode","text":"Real-time Frames Mode generalized workflow When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes real-time numpy.ndarray video-frames (as opposed to a entire file) into a sequence of multiple smaller chunks/segments for streaming. In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. This mode provide stream() function for directly trancoding video-frames into streamable chunks over the FFmpeg pipeline. Warning Using transcode_source() function instead of stream() in Real-time Frames Mode will instantly result in RuntimeError ! NEVER assign anything to -video_source attribute of stream_params dictionary parameter, otherwise Single-Source Mode may get activated, and as a result, using stream() function will throw RuntimeError ! In this mode, Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25.0 fps.","title":"B. Real-time Frames Mode"},{"location":"gears/streamgear/usage/#b1-bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with StreamGear API in Real-time Frames Mode: We are using CamGear in this Bare-Minimum example, but any VideoCapture Gear will work in the similar manner. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () After running these bare-minimum commands, StreamGear will produce a Manifest file ( dash.mpd ) with steamable chunks that contains information about a Primary Stream of same resolution and framerate 1 as input (without any audio) .","title":"B.1 Bare-Minimum Usage"},{"location":"gears/streamgear/usage/#b2-bare-minimum-usage-with-rgb-mode","text":"In Real-time Frames Mode, StreamGear API provide rgb_mode boolean parameter with its stream() function, which if enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) , thereby also known as RGB Mode . The complete usage example is as follows: # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {simulating RGB frame for this example} frame_rgb = frame [:,:,:: - 1 ] # send frame to streamer streamer . stream ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.2 Bare-Minimum Usage with RGB Mode"},{"location":"gears/streamgear/usage/#b3-bare-minimum-usage-with-controlled-input-framerate","text":"In Real-time Frames Mode, StreamGear API provides exclusive -input_framerate attribute for its stream_params dictionary parameter, that allow us to set the assumed constant framerate for incoming frames. In this example, we will retrieve framerate from webcam video-stream, and set it as value for -input_framerate attribute in StreamGear: Remember, the Primary Stream framerate default to -input_framerate attribute value (if defined) in Real-time Frames Mode. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` value stream_params = { \"-input_framerate\" : stream . framerate } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.3 Bare-Minimum Usage with controlled Input-framerate"},{"location":"gears/streamgear/usage/#b4-bare-minimum-usage-with-opencv","text":"You can easily use StreamGear API directly with any other Video Processing library( For e.g. OpenCV itself ) in Real-time Frames Mode. The complete usage example is as follows: This just a bare-minimum example with OpenCV, but any other Real-time Frames Mode feature/example will work in the similar manner. # import required libraries from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # send frame to streamer streamer . stream ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close streamer streamer . terminate ()","title":"B.4 Bare-Minimum Usage with OpenCV"},{"location":"gears/streamgear/usage/#b5-usage-with-additional-streams","text":"Similar to Single-Source Mode, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter (More detailed information can be found here \u27b6 ) in Real-time Frames Mode. The complete example is as follows: Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # define various streams stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.5 Usage with Additional Streams"},{"location":"gears/streamgear/usage/#b6-usage-with-audio-input","text":"In Real-time Frames Mode, if you want to add audio to your streams, you've to use exclusive -audio attribute of stream_params dictionary parameter. You need to input the path of your audio to this attribute as string value, and StreamGear API will automatically validate and map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.6 Usage with Audio-Input"},{"location":"gears/streamgear/usage/#b7-usage-with-hardware-video-encoder","text":"In Real-time Frames Mode, you can also easily change encoder as per your requirement just by passing -vcodec FFmpeg parameter as an attribute in stream_params dictionary parameter. In addition to this, you can also specify the additional properties/features/optimizations for your system's GPU similarly. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY-NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import VideoGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = VideoGear ( source = 0 ) . start () # activate Single-Source Mode and various streams with custom Video Encoder and optimizations stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-vcodec\" : \"h264_vaapi\" , # define custom Video encoder \"-vaapi_device\" : \"/dev/dri/renderD128\" , # define device location \"-vf\" : \"format=nv12,hwupload\" , # define video pixformat } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9 \u21a9 \u21a9","title":"B.7 Usage with Hardware Video-Encoder"},{"location":"gears/videogear/overview/","text":"VideoGear API \u00b6 VideoGear API's generalized workflow Overview \u00b6 VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also act as a Common API, that provides an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using way fewer lines of code. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. You can use framerate class variable to retrieve framerate of the input source. \u2009 Importing \u00b6 You can import VideoGear API in your program as follows: from vidgear.gears import VideoGear \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/videogear/overview/#videogear-api","text":"VideoGear API's generalized workflow","title":"VideoGear API"},{"location":"gears/videogear/overview/#overview","text":"VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also act as a Common API, that provides an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using way fewer lines of code. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. You can use framerate class variable to retrieve framerate of the input source.","title":"Overview"},{"location":"gears/videogear/overview/#importing","text":"You can import VideoGear API in your program as follows: from vidgear.gears import VideoGear","title":"Importing"},{"location":"gears/videogear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/videogear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/videogear/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/videogear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/videogear/params/","text":"VideoGear API Parameters \u00b6 \u2009 enablePiCamera \u00b6 This parameter select access to PiGear or CamGear API respectively. This means the if enablePiCamera flag is True , PiGear API will be accessed and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . Parameters for Stabilizer Class \u00b6 stabilize \u00b6 This parameter set this flag to enable access to Stabilizer Class , i.e. flag can be set to True ( to enable ) or unset to False ( to disable ) this mode. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 . options \u00b6 This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be passed by formatting them as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters with CamGear backend \u00b6 source \u00b6 CamGear API will throw RuntimeError if source provided is invalid! This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: VideoGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: VideoGear ( source = '/home/foo.mp4' ) YouTube Video's URL ( string ): Valid Youtube video URL as input when YouTube Mode is enabled( i.e. y_tube=True ), for e.g \"https://youtu.be/dQw4w9WgXcQ\" as follows: Valid YouTube URL format All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} VideoGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Network Address ( string ): Valid ( http(s), rtp, rstp, rtmp, mms, etc. ) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: VideoGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. You can easily check it by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: VideoGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) y_tube \u00b6 This parameter controls the YouTube Mode, .i.e if enabled( y_tube=True ), the CamGear API will interpret the given source input as YouTube URL address. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) backend \u00b6 This parameter manually selects the backend of the OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: VideoGear ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u00b6 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH \" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS \" : 60 } # assigning it VideoGear ( source = 0 , ** options ) Parameters with PiGear backend \u00b6 camera_num \u00b6 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board in your project. Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( enablePiCamera = True , camera_num = 0 ) resolution \u00b6 This parameter sets the resolution (i.e. (width,height) ) of the source. More Information about resolution parameter For more information read here \u27b6 . Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: VideoGear ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u00b6 This parameter sets the framerate of the source. For more information read here \u27b6 . Data-Type: integer/float Default Value: Its default value is 30 . Usage: VideoGear ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate ( integer ) : sets the framerate. Its default value is 30 . For more information read here \u27b6 . options \u00b6 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs \u27b6 The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # assigning it VideoGear ( enablePiCamera = True , ** options ) User-specific attributes: Additionaly, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains a Internal Threaded Timer that keeps active track of the frozen-threads/failures and will exit safely at a particular timeout value. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before the Internal Threaded Timer exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . It usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u00b6 colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 VideoGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/videogear/params/#videogear-api-parameters","text":"","title":"VideoGear API Parameters"},{"location":"gears/videogear/params/#enablepicamera","text":"This parameter select access to PiGear or CamGear API respectively. This means the if enablePiCamera flag is True , PiGear API will be accessed and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/videogear/params/#parameters-for-stabilizer-class","text":"","title":"Parameters for Stabilizer Class"},{"location":"gears/videogear/params/#stabilize","text":"This parameter set this flag to enable access to Stabilizer Class , i.e. flag can be set to True ( to enable ) or unset to False ( to disable ) this mode. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/videogear/params/#options","text":"This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be passed by formatting them as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/videogear/params/#parameters-with-camgear-backend","text":"","title":"Parameters with CamGear backend"},{"location":"gears/videogear/params/#source","text":"CamGear API will throw RuntimeError if source provided is invalid! This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: VideoGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: VideoGear ( source = '/home/foo.mp4' ) YouTube Video's URL ( string ): Valid Youtube video URL as input when YouTube Mode is enabled( i.e. y_tube=True ), for e.g \"https://youtu.be/dQw4w9WgXcQ\" as follows: Valid YouTube URL format All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} VideoGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Network Address ( string ): Valid ( http(s), rtp, rstp, rtmp, mms, etc. ) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: VideoGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. You can easily check it by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: VideoGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/videogear/params/#y_tube","text":"This parameter controls the YouTube Mode, .i.e if enabled( y_tube=True ), the CamGear API will interpret the given source input as YouTube URL address. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True )","title":"y_tube"},{"location":"gears/videogear/params/#backend","text":"This parameter manually selects the backend of the OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: VideoGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/videogear/params/#options_1","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH \" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS \" : 60 } # assigning it VideoGear ( source = 0 , ** options )","title":"options"},{"location":"gears/videogear/params/#parameters-with-pigear-backend","text":"","title":"Parameters with PiGear backend"},{"location":"gears/videogear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board in your project. Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( enablePiCamera = True , camera_num = 0 )","title":"camera_num"},{"location":"gears/videogear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. More Information about resolution parameter For more information read here \u27b6 . Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: VideoGear ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/videogear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 . Data-Type: integer/float Default Value: Its default value is 30 . Usage: VideoGear ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate ( integer ) : sets the framerate. Its default value is 30 . For more information read here \u27b6 .","title":"framerate"},{"location":"gears/videogear/params/#options_2","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs \u27b6 The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # assigning it VideoGear ( enablePiCamera = True , ** options ) User-specific attributes: Additionaly, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains a Internal Threaded Timer that keeps active track of the frozen-threads/failures and will exit safely at a particular timeout value. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before the Internal Threaded Timer exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . It usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/videogear/params/#common-parameters","text":"","title":"Common Parameters"},{"location":"gears/videogear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 VideoGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/videogear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( logging = True )","title":"logging"},{"location":"gears/videogear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/videogear/usage/","text":"VideoGear API Usage Examples: \u00b6 \u2009 Bare-Minimum Usage with CamGear backend \u00b6 Following is the bare-minimum code you need to access CamGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file), and disable enablePiCamera flag (default is also `False`). stream = VideoGear ( enablePiCamera = False , source = 'myvideo.avi' ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Bare-Minimum Usage with PiGear backend \u00b6 Following is the bare-minimum code you need to access PiGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # enable enablePiCamera boolean flag to access PiGear API backend stream = VideoGear ( enablePiCamera = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using VideoGear with Video Stabilizer backend \u00b6 VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class, and the stabilization can be activated with its stabilize boolean parameter during initialization. Thereby, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using just fewer lines of code. The complete usage example is as follows: For a more detailed information on Video Stabilization, read here \u27b6 # import required libraries from vidgear.gears import VideoGear import numpy as np import cv2 # open any valid video stream with stabilization enabled(`stabilize = True`) stream_stab = VideoGear ( source = \"test.mp4\" , stabilize = True ) . start () # open same stream without stablization for comparision stream_org = VideoGear ( source = \"test.mp4\" , stabilize = False ) . start () # loop over while True : # read stabilized frames frame_stab = stream_stab . read () # check for stabilized frame if None-type if frame_stab is None : break # read un-stabilized frame frame_org = stream_org . read () # concatenate both frames output_frame = np . concatenate (( frame_org , frame_stab ), axis = 1 ) # put text over concatenated frame cv2 . putText ( output_frame , \"Before\" , ( 10 , output_frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) cv2 . putText ( output_frame , \"After\" , ( output_frame . shape [ 1 ] // 2 + 10 , output_frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) # Show output window cv2 . imshow ( \"Stabilization Benchmarks\" , output_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close both video streams stream_org . stop () stream_stab . stop () Using VideoGear with Variable PiCamera Properties \u00b6 VideoGear contains special enablePiCamera flag that provide internal access to both CamGear and PiGear APIs, and thereby only one of them can be accessed at a given instance. Therefore, the additional parameters of VideoGear API are also based on API ( PiGear API or CamGear API ) being accessed. The complete usage example of VideoGear API with Variable PiCamera Properties is as follows: This example is basically a VideoGear API implementation of this PiGear usage example . Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner. # import required libraries from vidgear.gears import VideoGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # activate enablePiCamera and open pi video stream with defined parameters stream = VideoGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using VideoGear with Colorspace Manipulation \u00b6 VideoGear API also supports Colorspace Manipulation but not direct like other VideoCapture Gears. Important color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . More details can be found here \u27b6 Any incorrect or None-type value on colorspace parameter will be skipped. In following example code, we will convert source colorspace to HSV on initialization: # import required libraries from vidgear.gears import VideoGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV` stream = VideoGear ( source = 0 , colorspace = 'COLOR_BGR2HSV' , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Usage Examples"},{"location":"gears/videogear/usage/#videogear-api-usage-examples","text":"","title":"VideoGear API Usage Examples:"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-camgear-backend","text":"Following is the bare-minimum code you need to access CamGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file), and disable enablePiCamera flag (default is also `False`). stream = VideoGear ( enablePiCamera = False , source = 'myvideo.avi' ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with CamGear backend"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-pigear-backend","text":"Following is the bare-minimum code you need to access PiGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # enable enablePiCamera boolean flag to access PiGear API backend stream = VideoGear ( enablePiCamera = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with PiGear backend"},{"location":"gears/videogear/usage/#using-videogear-with-video-stabilizer-backend","text":"VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class, and the stabilization can be activated with its stabilize boolean parameter during initialization. Thereby, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using just fewer lines of code. The complete usage example is as follows: For a more detailed information on Video Stabilization, read here \u27b6 # import required libraries from vidgear.gears import VideoGear import numpy as np import cv2 # open any valid video stream with stabilization enabled(`stabilize = True`) stream_stab = VideoGear ( source = \"test.mp4\" , stabilize = True ) . start () # open same stream without stablization for comparision stream_org = VideoGear ( source = \"test.mp4\" , stabilize = False ) . start () # loop over while True : # read stabilized frames frame_stab = stream_stab . read () # check for stabilized frame if None-type if frame_stab is None : break # read un-stabilized frame frame_org = stream_org . read () # concatenate both frames output_frame = np . concatenate (( frame_org , frame_stab ), axis = 1 ) # put text over concatenated frame cv2 . putText ( output_frame , \"Before\" , ( 10 , output_frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) cv2 . putText ( output_frame , \"After\" , ( output_frame . shape [ 1 ] // 2 + 10 , output_frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) # Show output window cv2 . imshow ( \"Stabilization Benchmarks\" , output_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close both video streams stream_org . stop () stream_stab . stop ()","title":"Using VideoGear with Video Stabilizer backend"},{"location":"gears/videogear/usage/#using-videogear-with-variable-picamera-properties","text":"VideoGear contains special enablePiCamera flag that provide internal access to both CamGear and PiGear APIs, and thereby only one of them can be accessed at a given instance. Therefore, the additional parameters of VideoGear API are also based on API ( PiGear API or CamGear API ) being accessed. The complete usage example of VideoGear API with Variable PiCamera Properties is as follows: This example is basically a VideoGear API implementation of this PiGear usage example . Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner. # import required libraries from vidgear.gears import VideoGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # activate enablePiCamera and open pi video stream with defined parameters stream = VideoGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using VideoGear with Variable PiCamera Properties"},{"location":"gears/videogear/usage/#using-videogear-with-colorspace-manipulation","text":"VideoGear API also supports Colorspace Manipulation but not direct like other VideoCapture Gears. Important color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . More details can be found here \u27b6 Any incorrect or None-type value on colorspace parameter will be skipped. In following example code, we will convert source colorspace to HSV on initialization: # import required libraries from vidgear.gears import VideoGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV` stream = VideoGear ( source = 0 , colorspace = 'COLOR_BGR2HSV' , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using VideoGear with Colorspace Manipulation"},{"location":"gears/webgear/advanced/","text":"WebGear API Advanced Usage: \u00b6 This is a continuation of the WebGear doc \u27b6 . Thereby, It's advised to first get familiarize with this API, and its requirements . Performance Enhancements \u00b6 Previously, on running bare-minimum usage example , you will notice a significant performance throttling, lag and frame drop in output Stream on the browser. To cope with this throttling problem, WebGear provides certain performance enhancing attributes for its option dictionary parameter. Performance Enhancing Attributes frame_size_reduction : (int/float) This attribute controls the size reduction(in percentage) of the frame to be streamed on Server. Its value has the most significant effect on WebGear performance: More its value, smaller will be frame size and faster will be live streaming. The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40~60 . Its usage is as follows: options = { \"frame_size_reduction\" : 50 } #frame-size will be reduced by 50% Various Encoding Parameters: In WebGear API, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) compression format, in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: frame_jpeg_quality : (int) It controls the JPEG encoder quality. Its value varies from 0 to 100 (the higher is the better quality but performance will be lower). Its default value is 95 . Its usage is as follows: options = { \"frame_jpeg_quality\" : 80 } #JPEG will be encoded at 80% quality. frame_jpeg_optimize : (bool) It enables various JPEG compression optimizations such as Chroma sub-sampling, Quantization table, etc. These optimizations based on JPEG libs which are used while compiling OpenCV binaries, and recent versions of OpenCV uses TurboJPEG library , which is highly recommended for performance. Its default value is False . Its usage is as follows: options = { \"frame_jpeg_optimize\" : True } #JPEG optimizations are enabled. frame_jpeg_progressive : (bool) It enables Progressive JPEG encoding instead of the Baseline . Progressive Mode, displays an image in such a way that it shows a blurry/low-quality photo in its entirety, and then becomes clearer as the image downloads, whereas in Baseline Mode, an image created using the JPEG compression algorithm that will start to display the image as the data is made available, line by line. Progressive Mode, can drastically improve the performance in WebGear but at the expense of additional CPU load, thereby suitable for powerful systems only. Its default value is False meaning baseline mode is in-use. Its usage is as follows: options = { \"frame_jpeg_progressive\" : True } #Progressive JPEG encoding enabled. Bare-Minimum Usage with Performance Enhancements \u00b6 Let's re-implement our previous Bare-Minimum usage example with these Performance Enhancing Attributes: Running Programmatically \u00b6 You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: If you want see output on different machine on the same network, then you need to note down the IP-address of host system, and finally you need to replace this address (along with selected port) on the target machine's browser. # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear #various performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False } #initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown () which can be accessed on any browser on the network at http://localhost:8000/ . Running from Terminal \u00b6 Now lets, run this same example directly through the terminal commandline: If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes. python3 -m vidgear.gears.asyncio --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"frame_jpeg_quality\": 80, \"frame_jpeg_optimize\": True, \"frame_jpeg_progressive\": False}' which can also be accessed on any browser on the network at http://localhost:8000/ . Using WebGear with Custom Mounting Points \u00b6 With our highly extensible WebGear API, you can add your own mounting points, where additional files located, as follows: #import libs import uvicorn from starlette.routing import Mount from starlette.staticfiles import StaticFiles from vidgear.gears.asyncio import WebGear #various performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False } #initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) #enable source i.e. `test.mp4` and enable `logging` for debugging #append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory web . routes . append ( Mount ( '/test' , app = StaticFiles ( directory = '/home/foo/.vidgear/test' ), name = \"test\" )) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown () Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script jquery-3.3.1.slim.min.js in this folder and want to integrate it, then, we can do something like this: < script src = \"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\" ></ script > Using WebGear with Custom Webpage Routes \u00b6 With Webgear's flexible API, you can even add your additional HTML Static webpages without any extra efforts. Suppose we want to add a simple hello world webpage to our WebGear server. So let's create a bare-minimum hello.html file with HTML code as follows: < html > < header > < title > This is Hello world page </ title > </ header > < body > < h1 > Hello World </ h1 > < p > how ya doing? </ p > </ body > </ html > Then in our application code, we can integrate this webpage route, as follows: #import libs import uvicorn , asyncio from starlette.templating import Jinja2Templates from starlette.routing import Route from vidgear.gears.asyncio import WebGear #Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located template = Jinja2Templates ( directory = '/home/foo/.vidgear/custom_template' ) #render and return our webpage template async def hello_world ( request ): page = \"hello.html\" context = { \"request\" : request } return template . TemplateResponse ( page , context ) #add various performance tweaks as usual options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False } #initialize WebGear app with a valid source web = WebGear ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) #enable source i.e. `test.mp4` and enable `logging` for debugging #append new route to point our rendered webpage web . routes . append ( Route ( '/hello' , endpoint = hello_world )) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/hello address. Rules for Altering WebGear Files and Folders \u00b6 WebGear gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to keep the following rules in mind: Rules for Altering Data Files \u00b6 You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions. You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files i.e index.html , 404.html & 500.html present in templates folder at the default location , otherwise, it will trigger Auto-generation process , and it will overwrite the existing files with Server ones. You're allowed to add your own additional .html , .css , .js , etc. files in the respective folders at the default location and custom mounted Data folders . Rules for Altering Data Folders \u00b6 You're allowed to add/mount any number of additional folder as shown in this example above . You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename templates folder where critical data-files i.e index.html , 404.html & 500.html are located, otherwise, it will trigger Auto-generation process . Bonus Usage Examples \u00b6 Because of WebGear API's flexible internal wapper around VideoGear , it can easily access any parameter of CamGear and PiGear videocapture APIs. Following usage examples are just an idea of what can be done with WebGear API, you can try various VideoGear , CamGear and PiGear parameters directly in WebGear API in the similar manner. Using WebGear with Pi Camera Module \u00b6 Here's a bare-minimum example of using WebGear API with the Raspberry Pi camera module while tweaking its various properties in just one-liner: #import libs import uvicorn from vidgear.gears.asyncio import WebGear #various webgear performance and Rasbperry camera tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } #initialize WebGear app web = WebGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown () Using WebGear with real-time Video Stabilization enabled \u00b6 Here's an example of using WebGear API with real-time Video Stabilization enabled: #import libs import uvicorn from vidgear.gears.asyncio import WebGear #various webgear performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False } #initialize WebGear app with a raw source and enable video stabilization(`stabilize=True`) web = WebGear ( source = \"foo.mp4\" , stabilize = True , logging = True , ** options ) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown ()","title":"Advanced Usage"},{"location":"gears/webgear/advanced/#webgear-api-advanced-usage","text":"This is a continuation of the WebGear doc \u27b6 . Thereby, It's advised to first get familiarize with this API, and its requirements .","title":"WebGear API Advanced Usage:"},{"location":"gears/webgear/advanced/#performance-enhancements","text":"Previously, on running bare-minimum usage example , you will notice a significant performance throttling, lag and frame drop in output Stream on the browser. To cope with this throttling problem, WebGear provides certain performance enhancing attributes for its option dictionary parameter. Performance Enhancing Attributes frame_size_reduction : (int/float) This attribute controls the size reduction(in percentage) of the frame to be streamed on Server. Its value has the most significant effect on WebGear performance: More its value, smaller will be frame size and faster will be live streaming. The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40~60 . Its usage is as follows: options = { \"frame_size_reduction\" : 50 } #frame-size will be reduced by 50% Various Encoding Parameters: In WebGear API, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) compression format, in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: frame_jpeg_quality : (int) It controls the JPEG encoder quality. Its value varies from 0 to 100 (the higher is the better quality but performance will be lower). Its default value is 95 . Its usage is as follows: options = { \"frame_jpeg_quality\" : 80 } #JPEG will be encoded at 80% quality. frame_jpeg_optimize : (bool) It enables various JPEG compression optimizations such as Chroma sub-sampling, Quantization table, etc. These optimizations based on JPEG libs which are used while compiling OpenCV binaries, and recent versions of OpenCV uses TurboJPEG library , which is highly recommended for performance. Its default value is False . Its usage is as follows: options = { \"frame_jpeg_optimize\" : True } #JPEG optimizations are enabled. frame_jpeg_progressive : (bool) It enables Progressive JPEG encoding instead of the Baseline . Progressive Mode, displays an image in such a way that it shows a blurry/low-quality photo in its entirety, and then becomes clearer as the image downloads, whereas in Baseline Mode, an image created using the JPEG compression algorithm that will start to display the image as the data is made available, line by line. Progressive Mode, can drastically improve the performance in WebGear but at the expense of additional CPU load, thereby suitable for powerful systems only. Its default value is False meaning baseline mode is in-use. Its usage is as follows: options = { \"frame_jpeg_progressive\" : True } #Progressive JPEG encoding enabled.","title":"Performance Enhancements"},{"location":"gears/webgear/advanced/#bare-minimum-usage-with-performance-enhancements","text":"Let's re-implement our previous Bare-Minimum usage example with these Performance Enhancing Attributes:","title":"Bare-Minimum Usage with Performance Enhancements"},{"location":"gears/webgear/advanced/#running-programmatically","text":"You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: If you want see output on different machine on the same network, then you need to note down the IP-address of host system, and finally you need to replace this address (along with selected port) on the target machine's browser. # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear #various performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False } #initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown () which can be accessed on any browser on the network at http://localhost:8000/ .","title":"Running Programmatically"},{"location":"gears/webgear/advanced/#running-from-terminal","text":"Now lets, run this same example directly through the terminal commandline: If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes. python3 -m vidgear.gears.asyncio --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"frame_jpeg_quality\": 80, \"frame_jpeg_optimize\": True, \"frame_jpeg_progressive\": False}' which can also be accessed on any browser on the network at http://localhost:8000/ .","title":"Running from Terminal"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-mounting-points","text":"With our highly extensible WebGear API, you can add your own mounting points, where additional files located, as follows: #import libs import uvicorn from starlette.routing import Mount from starlette.staticfiles import StaticFiles from vidgear.gears.asyncio import WebGear #various performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False } #initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) #enable source i.e. `test.mp4` and enable `logging` for debugging #append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory web . routes . append ( Mount ( '/test' , app = StaticFiles ( directory = '/home/foo/.vidgear/test' ), name = \"test\" )) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown () Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script jquery-3.3.1.slim.min.js in this folder and want to integrate it, then, we can do something like this: < script src = \"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\" ></ script >","title":"Using WebGear with Custom Mounting Points"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-webpage-routes","text":"With Webgear's flexible API, you can even add your additional HTML Static webpages without any extra efforts. Suppose we want to add a simple hello world webpage to our WebGear server. So let's create a bare-minimum hello.html file with HTML code as follows: < html > < header > < title > This is Hello world page </ title > </ header > < body > < h1 > Hello World </ h1 > < p > how ya doing? </ p > </ body > </ html > Then in our application code, we can integrate this webpage route, as follows: #import libs import uvicorn , asyncio from starlette.templating import Jinja2Templates from starlette.routing import Route from vidgear.gears.asyncio import WebGear #Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located template = Jinja2Templates ( directory = '/home/foo/.vidgear/custom_template' ) #render and return our webpage template async def hello_world ( request ): page = \"hello.html\" context = { \"request\" : request } return template . TemplateResponse ( page , context ) #add various performance tweaks as usual options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False } #initialize WebGear app with a valid source web = WebGear ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) #enable source i.e. `test.mp4` and enable `logging` for debugging #append new route to point our rendered webpage web . routes . append ( Route ( '/hello' , endpoint = hello_world )) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/hello address.","title":"Using WebGear with Custom Webpage Routes"},{"location":"gears/webgear/advanced/#rules-for-altering-webgear-files-and-folders","text":"WebGear gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to keep the following rules in mind:","title":"Rules for Altering WebGear Files and Folders"},{"location":"gears/webgear/advanced/#rules-for-altering-data-files","text":"You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions. You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files i.e index.html , 404.html & 500.html present in templates folder at the default location , otherwise, it will trigger Auto-generation process , and it will overwrite the existing files with Server ones. You're allowed to add your own additional .html , .css , .js , etc. files in the respective folders at the default location and custom mounted Data folders .","title":"Rules for Altering Data Files"},{"location":"gears/webgear/advanced/#rules-for-altering-data-folders","text":"You're allowed to add/mount any number of additional folder as shown in this example above . You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename templates folder where critical data-files i.e index.html , 404.html & 500.html are located, otherwise, it will trigger Auto-generation process .","title":"Rules for Altering Data Folders"},{"location":"gears/webgear/advanced/#bonus-usage-examples","text":"Because of WebGear API's flexible internal wapper around VideoGear , it can easily access any parameter of CamGear and PiGear videocapture APIs. Following usage examples are just an idea of what can be done with WebGear API, you can try various VideoGear , CamGear and PiGear parameters directly in WebGear API in the similar manner.","title":"Bonus Usage Examples"},{"location":"gears/webgear/advanced/#using-webgear-with-pi-camera-module","text":"Here's a bare-minimum example of using WebGear API with the Raspberry Pi camera module while tweaking its various properties in just one-liner: #import libs import uvicorn from vidgear.gears.asyncio import WebGear #various webgear performance and Rasbperry camera tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } #initialize WebGear app web = WebGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown ()","title":"Using WebGear with Pi Camera Module"},{"location":"gears/webgear/advanced/#using-webgear-with-real-time-video-stabilization-enabled","text":"Here's an example of using WebGear API with real-time Video Stabilization enabled: #import libs import uvicorn from vidgear.gears.asyncio import WebGear #various webgear performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False } #initialize WebGear app with a raw source and enable video stabilization(`stabilize=True`) web = WebGear ( source = \"foo.mp4\" , stabilize = True , logging = True , ** options ) #run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) #close app safely web . shutdown ()","title":"Using WebGear with real-time Video Stabilization enabled"},{"location":"gears/webgear/overview/","text":"WebGear API \u00b6 WebGear Video Server at http://localhost:8000/ address. Overview \u00b6 WebGear is a powerful ASGI Video-streamer API, that is built upon Starlette - a lightweight ASGI framework/toolkit, which is ideal for building high-performance asyncio services. WebGear API provides a highly extensible and flexible asyncio wrapper around Starlette ASGI application, and provides easy access to its complete framework. Thereby, WebGear API can flexibly interact with the Starlette's ecosystem of shared middleware and mountable applications, and its various Response classes , Routing tables , Static Files , Templating engine(with Jinja2) , etc. In layman's terms, WebGear can acts as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. It addition to this, WebGear API also provides a special internal wrapper around VideoGear API , which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any device/source, such as streaming Stabilization enabled Video in real-time. \u2009 Data-Files Auto-Generation WorkFlow \u00b6 On initializing WebGear API, it automatically checks for three critical data-files i.e index.html , 404.html & 500.html inside templates folder at the default location , which give rise to possible scenario: If data-files found: it will proceed normally for instantiating the Starlette application. If data-files not found: it will trigger the Auto-Generation process Default Location \u00b6 A default location is the path of the directory where data files/folders are downloaded/generated/saved. By default, the .vidgear the folder at the home directory of your machine (for e.g /home/foo/.vidgear on Linux) serves as the default location . But you can also use WebGear's custom_data_location dictionary attribute to change/alter default location path to somewhere else. Tip You can set logging=True during initialization, for easily identifying the selected default location , which will be something like this (on a Linux machine) : WebGear :: DEBUG :: ` /home/foo/.vidgear ` is the default location for saving WebGear data-files. Auto-Generation process \u00b6 On triggering this process, WebGear API creates templates and static folders along with js , css , img sub-folders at the assigned default location . Thereby at this default location , the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order: .vidgear \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u251c\u2500\u2500 bootstrap.min.css \u2502 \u2502 \u2514\u2500\u2500 cover.css \u2502 \u251c\u2500\u2500 img \u2502 \u2502 \u2514\u2500\u2500 favicon-32x32.png \u2502 \u2514\u2500\u2500 js \u2502 \u251c\u2500\u2500 bootstrap.min.js \u2502 \u251c\u2500\u2500 jquery-3.4.1.slim.min.js \u2502 \u2514\u2500\u2500 popper.min.js \u2514\u2500\u2500 templates \u251c\u2500\u2500 404 .html \u251c\u2500\u2500 500 .html \u251c\u2500\u2500 base.html \u2514\u2500\u2500 index.html 5 directories, 10 files Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally. Important Tips You can also force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process, and any other file/folder will NOT be affected. It is advised to enable logging( logging=True ) on the first run for easily identifying any runtime errors \u2009 Importing \u00b6 You can import WebGear API in your program as follows: from vidgear.gears import WebGear \u2009 WebGear's Default Template \u00b6 The WebGear API by default uses simple & elegant Bootstrap's Cover template , by @mdo , which looks like something as follows: Index.html \u00b6 Can be accessed by visiting WebGear app server, running at http://localhost:8000/ : 404.html \u00b6 Appears when respective URL is not found, for example http://localhost:8000/ok : 500.html \u00b6 Appears when an API Error is encountered: If logging is enabled and an error occurs, then instead of displaying this 500 handler, WebGear will respond with a traceback response. Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 Reference \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/webgear/overview/#webgear-api","text":"WebGear Video Server at http://localhost:8000/ address.","title":"WebGear API"},{"location":"gears/webgear/overview/#overview","text":"WebGear is a powerful ASGI Video-streamer API, that is built upon Starlette - a lightweight ASGI framework/toolkit, which is ideal for building high-performance asyncio services. WebGear API provides a highly extensible and flexible asyncio wrapper around Starlette ASGI application, and provides easy access to its complete framework. Thereby, WebGear API can flexibly interact with the Starlette's ecosystem of shared middleware and mountable applications, and its various Response classes , Routing tables , Static Files , Templating engine(with Jinja2) , etc. In layman's terms, WebGear can acts as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. It addition to this, WebGear API also provides a special internal wrapper around VideoGear API , which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any device/source, such as streaming Stabilization enabled Video in real-time.","title":"Overview"},{"location":"gears/webgear/overview/#data-files-auto-generation-workflow","text":"On initializing WebGear API, it automatically checks for three critical data-files i.e index.html , 404.html & 500.html inside templates folder at the default location , which give rise to possible scenario: If data-files found: it will proceed normally for instantiating the Starlette application. If data-files not found: it will trigger the Auto-Generation process","title":"Data-Files Auto-Generation WorkFlow"},{"location":"gears/webgear/overview/#default-location","text":"A default location is the path of the directory where data files/folders are downloaded/generated/saved. By default, the .vidgear the folder at the home directory of your machine (for e.g /home/foo/.vidgear on Linux) serves as the default location . But you can also use WebGear's custom_data_location dictionary attribute to change/alter default location path to somewhere else. Tip You can set logging=True during initialization, for easily identifying the selected default location , which will be something like this (on a Linux machine) : WebGear :: DEBUG :: ` /home/foo/.vidgear ` is the default location for saving WebGear data-files.","title":"Default Location"},{"location":"gears/webgear/overview/#auto-generation-process","text":"On triggering this process, WebGear API creates templates and static folders along with js , css , img sub-folders at the assigned default location . Thereby at this default location , the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order: .vidgear \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u251c\u2500\u2500 bootstrap.min.css \u2502 \u2502 \u2514\u2500\u2500 cover.css \u2502 \u251c\u2500\u2500 img \u2502 \u2502 \u2514\u2500\u2500 favicon-32x32.png \u2502 \u2514\u2500\u2500 js \u2502 \u251c\u2500\u2500 bootstrap.min.js \u2502 \u251c\u2500\u2500 jquery-3.4.1.slim.min.js \u2502 \u2514\u2500\u2500 popper.min.js \u2514\u2500\u2500 templates \u251c\u2500\u2500 404 .html \u251c\u2500\u2500 500 .html \u251c\u2500\u2500 base.html \u2514\u2500\u2500 index.html 5 directories, 10 files Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally. Important Tips You can also force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process, and any other file/folder will NOT be affected. It is advised to enable logging( logging=True ) on the first run for easily identifying any runtime errors","title":"Auto-Generation process"},{"location":"gears/webgear/overview/#importing","text":"You can import WebGear API in your program as follows: from vidgear.gears import WebGear","title":"Importing"},{"location":"gears/webgear/overview/#webgears-default-template","text":"The WebGear API by default uses simple & elegant Bootstrap's Cover template , by @mdo , which looks like something as follows:","title":"WebGear's Default Template"},{"location":"gears/webgear/overview/#indexhtml","text":"Can be accessed by visiting WebGear app server, running at http://localhost:8000/ :","title":"Index.html"},{"location":"gears/webgear/overview/#404html","text":"Appears when respective URL is not found, for example http://localhost:8000/ok :","title":"404.html"},{"location":"gears/webgear/overview/#500html","text":"Appears when an API Error is encountered: If logging is enabled and an error occurs, then instead of displaying this 500 handler, WebGear will respond with a traceback response.","title":"500.html"},{"location":"gears/webgear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/webgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/webgear/overview/#reference","text":"See here \ud83d\ude80","title":"Reference"},{"location":"gears/webgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/webgear/params/","text":"WebGear API Parameters \u00b6 options \u00b6 This parameter can be used to pass user-defined parameter to WebGear API by formatting them as this parameter's attribute. Data-Type: Dictionary Default Value: Its default value is {} WebGear Specific attributes \u00b6 custom_data_location (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows: options = { \"custom_data_location\" : \"/home/foo/foo1\" } #setdefault location to '/home/foo/foo1' # assign it WebGear ( logging = True , ** options ) overwrite_default_files (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows: options = { \"overwrite_default_files\" : True } #force trigger the Auto-generation process # assign it WebGear ( logging = True , ** options ) Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten. frame_size_reduction (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server._ The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40-60 . Its usage is as follows: options = { \"frame_size_reduction\" : 50 } #frame-size will be reduced by 50% # assign it WebGear ( logging = True , ** options ) Various Encoding Parameters: In WebGear, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) video compression format in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: frame_jpeg_quality (integer) : It controls the JPEG encoder quality and value varies from 0 to 100 (the higher is the better quality but performance will be lower). Its default value is 95 . Its usage is as follows: options = { \"frame_jpeg_quality\" : 80 } #JPEG will be encoded at 80% quality. # assign it WebGear ( logging = True , ** options ) frame_jpeg_optimize (boolean) : It enables various JPEG compression optimizations such as Chroma subsampling, Quantization table, etc. Its default value is False . Its usage is as follows: options = { \"frame_jpeg_optimize\" : True } #JPEG optimizations are enabled. # assign it WebGear ( logging = True , ** options ) frame_jpeg_progressive (boolean) : It enables Progressive JPEG encoding instead of the Baseline . Progressive Mode. Its default value is False means baseline mode is in-use. Its usage is as follows: options = { \"frame_jpeg_progressive\" : True } #Progressive JPEG encoding enabled. # assign it WebGear ( logging = True , ** options ) Stabilizer Specific attributes \u00b6 SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: # smoothing radius 50 options = { 'SMOOTHING_RADIUS' : 30 } # assign it WebGear ( ** options ) BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: # bordersize 15px options = { 'BORDER_SIZE' : 15 } # assign it WebGear ( ** options ) CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects ) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: # bordersize 10px and crop-zoom enabled options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } # assign it WebGear ( ** options ) BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here \u27b6 . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. # border-type \"black\" options = { 'BORDER_TYPE' : 'black' } # assign it WebGear ( ** options ) CamGear Specific attributes \u00b6 All supported parameters are listed here \u27b6 The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH \" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS \" : 60 } # assigning it WebGear ( source = 0 , ** options ) PiGear Specific attributes \u00b6 All supported parameters are listed in PiCamera Docs ! The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # assigning it WebGear ( enablePiCamera = True , ** options ) User-specific attributes: Additionaly, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains a Internal Threaded Timer that keeps active track of the frozen-threads/failures and will exit safely at a particular timeout value. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before the Internal Threaded Timer exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . It usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds # assign it WebGear ( enablePiCamera = True , ** options ) Parameters for VideoGear backend \u00b6 enablePiCamera \u00b6 This parameter select access to PiGear or CamGear API respectively. This means the if enablePiCamera flag is True , PiGear API will be accessed and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . Parameters for Stabilizer backend \u00b6 stabilize \u00b6 This parameter set this flag to enable access to Stabilizer Class , i.e. flag can be set to True ( to enable ) or unset to False ( to disable ) this mode. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( stabilize = True ) # enable stabilization Its complete usage example is given here \u27b6 . Parameters with CamGear backend \u00b6 source \u00b6 CamGear API will throw RuntimeError if source provided is invalid! This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: WebGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: WebGear ( source = '/home/foo.mp4' ) YouTube Video's URL ( string ): Valid Youtube video URL as input when YouTube Mode is enabled( i.e. y_tube=True ), for e.g \"https://youtu.be/dQw4w9WgXcQ\" as follows: Valid YouTube URL format All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} WebGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Network Address ( string ): Valid ( http(s), rtp, rstp, rtmp, mms, etc. ) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: WebGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. You can easily check it by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: WebGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) y_tube \u00b6 This parameter controls the YouTube Mode, .i.e if enabled( y_tube=True ), the CamGear API will interpret the given source input as YouTube URL address. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) backend \u00b6 This parameter manually selects the backend of the OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 . Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: WebGear ( source = 0 , backend = cv2 . CAP_DSHOW ) Parameters with PiGear backend \u00b6 camera_num \u00b6 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board in your project. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( enablePiCamera = True , camera_num = 0 ) resolution \u00b6 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: WebGear ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u00b6 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: WebGear ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate ( integer ) : sets the framerate. Its default value is 30 . For more information read here \u27b6 . Common Parameters \u00b6 colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 WebGear ( colorspace = \"COLOR_BGR2HSV\" ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/webgear/params/#webgear-api-parameters","text":"","title":"WebGear API Parameters"},{"location":"gears/webgear/params/#options","text":"This parameter can be used to pass user-defined parameter to WebGear API by formatting them as this parameter's attribute. Data-Type: Dictionary Default Value: Its default value is {}","title":"options"},{"location":"gears/webgear/params/#webgear-specific-attributes","text":"custom_data_location (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows: options = { \"custom_data_location\" : \"/home/foo/foo1\" } #setdefault location to '/home/foo/foo1' # assign it WebGear ( logging = True , ** options ) overwrite_default_files (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows: options = { \"overwrite_default_files\" : True } #force trigger the Auto-generation process # assign it WebGear ( logging = True , ** options ) Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten. frame_size_reduction (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server._ The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40-60 . Its usage is as follows: options = { \"frame_size_reduction\" : 50 } #frame-size will be reduced by 50% # assign it WebGear ( logging = True , ** options ) Various Encoding Parameters: In WebGear, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) video compression format in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: frame_jpeg_quality (integer) : It controls the JPEG encoder quality and value varies from 0 to 100 (the higher is the better quality but performance will be lower). Its default value is 95 . Its usage is as follows: options = { \"frame_jpeg_quality\" : 80 } #JPEG will be encoded at 80% quality. # assign it WebGear ( logging = True , ** options ) frame_jpeg_optimize (boolean) : It enables various JPEG compression optimizations such as Chroma subsampling, Quantization table, etc. Its default value is False . Its usage is as follows: options = { \"frame_jpeg_optimize\" : True } #JPEG optimizations are enabled. # assign it WebGear ( logging = True , ** options ) frame_jpeg_progressive (boolean) : It enables Progressive JPEG encoding instead of the Baseline . Progressive Mode. Its default value is False means baseline mode is in-use. Its usage is as follows: options = { \"frame_jpeg_progressive\" : True } #Progressive JPEG encoding enabled. # assign it WebGear ( logging = True , ** options )","title":"WebGear Specific attributes"},{"location":"gears/webgear/params/#stabilizer-specific-attributes","text":"SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: # smoothing radius 50 options = { 'SMOOTHING_RADIUS' : 30 } # assign it WebGear ( ** options ) BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: # bordersize 15px options = { 'BORDER_SIZE' : 15 } # assign it WebGear ( ** options ) CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects ) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: # bordersize 10px and crop-zoom enabled options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } # assign it WebGear ( ** options ) BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here \u27b6 . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. # border-type \"black\" options = { 'BORDER_TYPE' : 'black' } # assign it WebGear ( ** options )","title":"Stabilizer Specific attributes"},{"location":"gears/webgear/params/#camgear-specific-attributes","text":"All supported parameters are listed here \u27b6 The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH \" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS \" : 60 } # assigning it WebGear ( source = 0 , ** options )","title":"CamGear Specific attributes"},{"location":"gears/webgear/params/#pigear-specific-attributes","text":"All supported parameters are listed in PiCamera Docs ! The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 } # assigning it WebGear ( enablePiCamera = True , ** options ) User-specific attributes: Additionaly, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains a Internal Threaded Timer that keeps active track of the frozen-threads/failures and will exit safely at a particular timeout value. This parameter can be used to control that given timeout value , i.e. the maximum waiting time (in seconds) before the Internal Threaded Timer exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . It usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds # assign it WebGear ( enablePiCamera = True , ** options )","title":"PiGear Specific attributes"},{"location":"gears/webgear/params/#parameters-for-videogear-backend","text":"","title":"Parameters for VideoGear backend"},{"location":"gears/webgear/params/#enablepicamera","text":"This parameter select access to PiGear or CamGear API respectively. This means the if enablePiCamera flag is True , PiGear API will be accessed and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/webgear/params/#parameters-for-stabilizer-backend","text":"","title":"Parameters for Stabilizer backend"},{"location":"gears/webgear/params/#stabilize","text":"This parameter set this flag to enable access to Stabilizer Class , i.e. flag can be set to True ( to enable ) or unset to False ( to disable ) this mode. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( stabilize = True ) # enable stabilization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/webgear/params/#parameters-with-camgear-backend","text":"","title":"Parameters with CamGear backend"},{"location":"gears/webgear/params/#source","text":"CamGear API will throw RuntimeError if source provided is invalid! This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: WebGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: WebGear ( source = '/home/foo.mp4' ) YouTube Video's URL ( string ): Valid Youtube video URL as input when YouTube Mode is enabled( i.e. y_tube=True ), for e.g \"https://youtu.be/dQw4w9WgXcQ\" as follows: Valid YouTube URL format All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} WebGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True ) Network Address ( string ): Valid ( http(s), rtp, rstp, rtmp, mms, etc. ) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: WebGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. You can easily check it by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: WebGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/webgear/params/#y_tube","text":"This parameter controls the YouTube Mode, .i.e if enabled( y_tube=True ), the CamGear API will interpret the given source input as YouTube URL address. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( source = 'https://youtu.be/dQw4w9WgXcQ' , y_tube = True )","title":"y_tube"},{"location":"gears/webgear/params/#backend","text":"This parameter manually selects the backend of the OpenCV's VideoCapture class (only if specified) . Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 . Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: WebGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/webgear/params/#parameters-with-pigear-backend","text":"","title":"Parameters with PiGear backend"},{"location":"gears/webgear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board in your project. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( enablePiCamera = True , camera_num = 0 )","title":"camera_num"},{"location":"gears/webgear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: WebGear ( enablePiCamera = True , resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/webgear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: WebGear ( enablePiCamera = True , framerate = 60 ) # sets 60fps framerate ( integer ) : sets the framerate. Its default value is 30 . For more information read here \u27b6 .","title":"framerate"},{"location":"gears/webgear/params/#common-parameters","text":"","title":"Common Parameters"},{"location":"gears/webgear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 WebGear ( colorspace = \"COLOR_BGR2HSV\" )","title":"colorspace"},{"location":"gears/webgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( logging = True )","title":"logging"},{"location":"gears/webgear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/webgear/usage/","text":"WebGear API Usage Examples: \u00b6 Requirements \u00b6 Installation with Asyncio Support \u00b6 WebGear API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ] ASGI Server \u00b6 You'll also need to install an ASGI Server to run following WebGear usage examples, and by default WebGear ships the state-of-the-art uvicorn Server. But you can also use other ASGI server such as daphne , or hypercorn with it. Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with WebGear API: If you experience any performance-throttling/lag while running this bare-minimum example, then Kindly see advanced Performance Tweaks \u27b6 . If you want see output on different machine on the same network, then you need to note down the IP-address of host system, and finally you need to replace this address (along with selected port) on the target machine's browser. Running Programmatically \u00b6 You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # initialize WebGear app web = WebGear ( source = \"test.mp4\" ) # run this app on Uvicorn server uvicorn . run ( web (), host = 'localhost' , port = 8000 ) # close app safely web . shutdown () That's all. Now, just run that, and a live video stream can be accessed on any browser at http://localhost:8000/ address. Running from Terminal \u00b6 You can access and run WebGear Server directly from the terminal commandline as follows: Make sure your PYTHON_PATH is set to python 3.6+ versions only. The following command will run a WebGear VideoStreamer server at http://localhost:8000/ : python3 -m vidgear.gears.asyncio --source test.avi which can be accessed on any browser on the network. Advanced Usage from Terminal You can run python3 - m vidgear . gears - h help command to see all the advanced settings, as follows: If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes as shown in this example . usage: python -m vidgear.gears.asyncio [ -h ] [ -s SOURCE ] [ -ep ENABLEPICAMERA ] [ -S STABILIZE ] [ -cn CAMERA_NUM ] [ -yt Y_TUBE ] [ -b BACKEND ] [ -cs COLORSPACE ] [ -r RESOLUTION ] [ -f FRAMERATE ] [ -td TIME_DELAY ] [ -ip IPADDRESS ] [ -pt PORT ] [ -l LOGGING ] [ -op OPTIONS ] Runs WebGear VideoStreaming Server through terminal. optional arguments: -h, --help show this help message and exit -s SOURCE, --source SOURCE Path to input source for CamGear API. -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA Sets the flag to access PiGear ( if True ) or otherwise CamGear API respectively. -S STABILIZE, --stabilize STABILIZE Enables/disables real-time video stabilization. -cn CAMERA_NUM, --camera_num CAMERA_NUM Sets the camera module index that will be used by PiGear API. -yt Y_TUBE, --y_tube Y_TUBE Enables YouTube Mode in CamGear API. -b BACKEND, --backend BACKEND Sets the backend of the video source in CamGear API. -cs COLORSPACE, --colorspace COLORSPACE Sets the colorspace of the output video stream. -r RESOLUTION, --resolution RESOLUTION Sets the resolution ( width,height ) for camera module in PiGear API. -f FRAMERATE, --framerate FRAMERATE Sets the framerate for camera module in PiGear API. -td TIME_DELAY, --time_delay TIME_DELAY Sets the time delay ( in seconds ) before start reading the frames. -ip IPADDRESS, --ipaddress IPADDRESS Uvicorn binds the socket to this ipaddress. -pt PORT, --port PORT Uvicorn binds the socket to this port. -l LOGGING, --logging LOGGING Enables/disables error logging, essential for debugging. -op OPTIONS, --options OPTIONS Sets the parameters supported by APIs ( whichever being accessed ) to the input videostream, But make sure to wrap your dict value in single or double quotes.","title":"Usage Examples"},{"location":"gears/webgear/usage/#webgear-api-usage-examples","text":"","title":"WebGear API Usage Examples:"},{"location":"gears/webgear/usage/#requirements","text":"","title":"Requirements"},{"location":"gears/webgear/usage/#installation-with-asyncio-support","text":"WebGear API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ]","title":"Installation with Asyncio Support"},{"location":"gears/webgear/usage/#asgi-server","text":"You'll also need to install an ASGI Server to run following WebGear usage examples, and by default WebGear ships the state-of-the-art uvicorn Server. But you can also use other ASGI server such as daphne , or hypercorn with it.","title":"ASGI Server"},{"location":"gears/webgear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with WebGear API: If you experience any performance-throttling/lag while running this bare-minimum example, then Kindly see advanced Performance Tweaks \u27b6 . If you want see output on different machine on the same network, then you need to note down the IP-address of host system, and finally you need to replace this address (along with selected port) on the target machine's browser.","title":"Bare-Minimum Usage"},{"location":"gears/webgear/usage/#running-programmatically","text":"You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # initialize WebGear app web = WebGear ( source = \"test.mp4\" ) # run this app on Uvicorn server uvicorn . run ( web (), host = 'localhost' , port = 8000 ) # close app safely web . shutdown () That's all. Now, just run that, and a live video stream can be accessed on any browser at http://localhost:8000/ address.","title":"Running Programmatically"},{"location":"gears/webgear/usage/#running-from-terminal","text":"You can access and run WebGear Server directly from the terminal commandline as follows: Make sure your PYTHON_PATH is set to python 3.6+ versions only. The following command will run a WebGear VideoStreamer server at http://localhost:8000/ : python3 -m vidgear.gears.asyncio --source test.avi which can be accessed on any browser on the network. Advanced Usage from Terminal You can run python3 - m vidgear . gears - h help command to see all the advanced settings, as follows: If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes as shown in this example . usage: python -m vidgear.gears.asyncio [ -h ] [ -s SOURCE ] [ -ep ENABLEPICAMERA ] [ -S STABILIZE ] [ -cn CAMERA_NUM ] [ -yt Y_TUBE ] [ -b BACKEND ] [ -cs COLORSPACE ] [ -r RESOLUTION ] [ -f FRAMERATE ] [ -td TIME_DELAY ] [ -ip IPADDRESS ] [ -pt PORT ] [ -l LOGGING ] [ -op OPTIONS ] Runs WebGear VideoStreaming Server through terminal. optional arguments: -h, --help show this help message and exit -s SOURCE, --source SOURCE Path to input source for CamGear API. -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA Sets the flag to access PiGear ( if True ) or otherwise CamGear API respectively. -S STABILIZE, --stabilize STABILIZE Enables/disables real-time video stabilization. -cn CAMERA_NUM, --camera_num CAMERA_NUM Sets the camera module index that will be used by PiGear API. -yt Y_TUBE, --y_tube Y_TUBE Enables YouTube Mode in CamGear API. -b BACKEND, --backend BACKEND Sets the backend of the video source in CamGear API. -cs COLORSPACE, --colorspace COLORSPACE Sets the colorspace of the output video stream. -r RESOLUTION, --resolution RESOLUTION Sets the resolution ( width,height ) for camera module in PiGear API. -f FRAMERATE, --framerate FRAMERATE Sets the framerate for camera module in PiGear API. -td TIME_DELAY, --time_delay TIME_DELAY Sets the time delay ( in seconds ) before start reading the frames. -ip IPADDRESS, --ipaddress IPADDRESS Uvicorn binds the socket to this ipaddress. -pt PORT, --port PORT Uvicorn binds the socket to this port. -l LOGGING, --logging LOGGING Enables/disables error logging, essential for debugging. -op OPTIONS, --options OPTIONS Sets the parameters supported by APIs ( whichever being accessed ) to the input videostream, But make sure to wrap your dict value in single or double quotes.","title":"Running from Terminal"},{"location":"gears/writegear/introduction/","text":"WriteGear API \u00b6 WriteGear API generalized workflow Overview \u00b6 WriteGear provides a complete, flexible and easily-extensible wrapper around FFmpeg - a leading multimedia framework - for encoding real-time frames into a lossless compressed video-file with any suitable specification (such as framerate, bitrate, codec, etc. ) while handling all errors robustly, all in just few easy lines of python code. Best of all, WriteGear grants the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc ) , without relying on any Third-party library. It's able to perform complex tasks such as multiplexing video with audio in real-time (see this doc . In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API which provides some basic tools for video frames encoding but without compression. \u2009 Modes of Operation \u00b6 WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Compression Mode must require FFmpeg, Follow these Installation Instructions \u27b6 for its installation. \u2009 Importing \u00b6 You can import WriteGear API in your program as follows: from vidgear.gears import WriteGear","title":"Introduction"},{"location":"gears/writegear/introduction/#writegear-api","text":"WriteGear API generalized workflow","title":"WriteGear API"},{"location":"gears/writegear/introduction/#overview","text":"WriteGear provides a complete, flexible and easily-extensible wrapper around FFmpeg - a leading multimedia framework - for encoding real-time frames into a lossless compressed video-file with any suitable specification (such as framerate, bitrate, codec, etc. ) while handling all errors robustly, all in just few easy lines of python code. Best of all, WriteGear grants the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc ) , without relying on any Third-party library. It's able to perform complex tasks such as multiplexing video with audio in real-time (see this doc . In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API which provides some basic tools for video frames encoding but without compression.","title":"Overview"},{"location":"gears/writegear/introduction/#modes-of-operation","text":"WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Compression Mode must require FFmpeg, Follow these Installation Instructions \u27b6 for its installation.","title":"Modes of Operation"},{"location":"gears/writegear/introduction/#importing","text":"You can import WriteGear API in your program as follows: from vidgear.gears import WriteGear","title":"Importing"},{"location":"gears/writegear/compression/overview/","text":"WriteGear API: Compression Mode \u00b6 WriteGear API's Compression Mode generalized workflow Overview \u00b6 When compression_mode parameter is enabled (.i.e compression_mode = True ) , WriteGear API utilizes powerful FFmpeg encoders to encode lossless & compressed multimedia files, Thereby, also known as Compression Mode. In Compression mode, WriteGear API provide a complete, flexible & robust wrapper around FFmpeg - a leading multimedia framework. This mode can process real-time video frames into a lossless compressed format with any suitable specification in just few easy lines of codes. These specifications include setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, etc. , and also performing complex tasks such as multiplexing video with audio in real-time (see this usage example ) , while handling all errors robustly. Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . In Compression Mode, you can speed up the execution time by disabling logging (.i.e logging = False ), and by tweaking output_params parameter values (for e.g. using '-preset: ultrafast' in case of 'libx264' encoder). Look into FFmpeg docs \u27b6 for such hacks. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Custom FFmpeg Commands in WriteGear API \u00b6 WriteGear API now provides the execute_ffmpeg_cmd Function in Compression Mode, that enables the user to pass any custom Terminal command (that works on the terminal) as an input to its internal FFmpeg Pipeline by formating it as a list. This function opens endless possibilities of exploiting any FFmpeg supported parameter within WriteGear, without relying on a third-party library/API to do the same, and while doing that it robustly handles all errors/warnings quietly. A complete guide on execute_ffmpeg_cmd Function can be found here \u27b6","title":"Overview"},{"location":"gears/writegear/compression/overview/#writegear-api-compression-mode","text":"WriteGear API's Compression Mode generalized workflow","title":"WriteGear API: Compression Mode"},{"location":"gears/writegear/compression/overview/#overview","text":"When compression_mode parameter is enabled (.i.e compression_mode = True ) , WriteGear API utilizes powerful FFmpeg encoders to encode lossless & compressed multimedia files, Thereby, also known as Compression Mode. In Compression mode, WriteGear API provide a complete, flexible & robust wrapper around FFmpeg - a leading multimedia framework. This mode can process real-time video frames into a lossless compressed format with any suitable specification in just few easy lines of codes. These specifications include setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, etc. , and also performing complex tasks such as multiplexing video with audio in real-time (see this usage example ) , while handling all errors robustly. Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . In Compression Mode, you can speed up the execution time by disabling logging (.i.e logging = False ), and by tweaking output_params parameter values (for e.g. using '-preset: ultrafast' in case of 'libx264' encoder). Look into FFmpeg docs \u27b6 for such hacks. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/writegear/compression/overview/#custom-ffmpeg-commands-in-writegear-api","text":"WriteGear API now provides the execute_ffmpeg_cmd Function in Compression Mode, that enables the user to pass any custom Terminal command (that works on the terminal) as an input to its internal FFmpeg Pipeline by formating it as a list. This function opens endless possibilities of exploiting any FFmpeg supported parameter within WriteGear, without relying on a third-party library/API to do the same, and while doing that it robustly handles all errors/warnings quietly. A complete guide on execute_ffmpeg_cmd Function can be found here \u27b6","title":"Custom FFmpeg Commands in WriteGear API"},{"location":"gears/writegear/compression/params/","text":"WriteGear API Parameters: Compression Mode \u00b6 output_filename \u00b6 This parameter sets the valid filename/path for saving the output video. Warning WriteGear API will throw ValueError if output_filename provided is empty or invalid. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer Make sure to provide valid filename with valid file-extension based on the encoder in use. URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for building a Video-Streaming Server with FFmpeg in WriteGear API. For example, you can stream on a rtmp protocol URL as follows: writer = WriteGear ( output_filename = 'rtmp://localhost/live/test' ) #Define writer compression_mode \u00b6 This parameter selects the WriteGear's primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = True ) custom_ffmpeg \u00b6 This parameter assigns the custom path/directory where the custom FFmpeg executables are located in Compression Mode only. Compression Mode Behavior on Windows In Compression Mode, if a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then WriteGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # if ffmpeg executables are located at \"/foo/foo1/FFmpeg\" WriteGear ( output_filename = 'output.mp4' , custom_ffmpeg = \"/foo/foo1/FFmpeg\" ) output_params \u00b6 This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly for encoding in Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and encoders for compression mode discussed below: Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u00b6 FFmpeg Parameters: All parameters based on selected encoder in use, are supported, and can be passed as dictionary attributes in output_param . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: DO NOT provide additional video-source with -i FFmpeg parameter in output_params , otherwise it will interfere with frame you input later, and it will break things! Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } Special Internal Parameters: In addition to FFmpeg parameters, WriteGear API also supports some Special Parameters to tweak its internal properties. These parameters are discussed below: -ffmpeg_download_path (string) : sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: output_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" -input_framerate (float/int) : sets the constant framerate of the output. It can be used as follows: output_params = { \"-input_framerate\" : 60.0 } # set the constant framerate to 60fps Its usage example can be found here \u27b6 -output_dimensions (tuple/list) : sets the custom dimensions( size/resolution ) of the output video (otherwise input video-frame size will be used) . Its value can either be a tuple => (width,height) or a list => [width, height] , Its usage is as follows: output_params = { \"-output_dimensions\" : ( 1280 , 720 )} #to produce a 1280x720 resolution/scale output video * -clones (list) : sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Its usage is as follows: output_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} -disable_force_termination (bool) : sets a special flag to disable the default forced-termination behaviour in WriteGear API when -i FFmpeg parameter is used (For more details, see issue: #149 ) . Its usage is as follows: output_params = { \"-disable_force_termination\" : True } # disable the default forced-termination behaviour Supported Encoders \u00b6 All the encoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"Parameters"},{"location":"gears/writegear/compression/params/#writegear-api-parameters-compression-mode","text":"","title":"WriteGear API Parameters: Compression Mode"},{"location":"gears/writegear/compression/params/#output_filename","text":"This parameter sets the valid filename/path for saving the output video. Warning WriteGear API will throw ValueError if output_filename provided is empty or invalid. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer Make sure to provide valid filename with valid file-extension based on the encoder in use. URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for building a Video-Streaming Server with FFmpeg in WriteGear API. For example, you can stream on a rtmp protocol URL as follows: writer = WriteGear ( output_filename = 'rtmp://localhost/live/test' ) #Define writer","title":"output_filename"},{"location":"gears/writegear/compression/params/#compression_mode","text":"This parameter selects the WriteGear's primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = True )","title":"compression_mode"},{"location":"gears/writegear/compression/params/#custom_ffmpeg","text":"This parameter assigns the custom path/directory where the custom FFmpeg executables are located in Compression Mode only. Compression Mode Behavior on Windows In Compression Mode, if a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then WriteGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # if ffmpeg executables are located at \"/foo/foo1/FFmpeg\" WriteGear ( output_filename = 'output.mp4' , custom_ffmpeg = \"/foo/foo1/FFmpeg\" )","title":"custom_ffmpeg"},{"location":"gears/writegear/compression/params/#output_params","text":"This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly for encoding in Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and encoders for compression mode discussed below: Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} .","title":"output_params"},{"location":"gears/writegear/compression/params/#supported-parameters","text":"FFmpeg Parameters: All parameters based on selected encoder in use, are supported, and can be passed as dictionary attributes in output_param . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: DO NOT provide additional video-source with -i FFmpeg parameter in output_params , otherwise it will interfere with frame you input later, and it will break things! Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } Special Internal Parameters: In addition to FFmpeg parameters, WriteGear API also supports some Special Parameters to tweak its internal properties. These parameters are discussed below: -ffmpeg_download_path (string) : sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: output_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" -input_framerate (float/int) : sets the constant framerate of the output. It can be used as follows: output_params = { \"-input_framerate\" : 60.0 } # set the constant framerate to 60fps Its usage example can be found here \u27b6 -output_dimensions (tuple/list) : sets the custom dimensions( size/resolution ) of the output video (otherwise input video-frame size will be used) . Its value can either be a tuple => (width,height) or a list => [width, height] , Its usage is as follows: output_params = { \"-output_dimensions\" : ( 1280 , 720 )} #to produce a 1280x720 resolution/scale output video * -clones (list) : sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Its usage is as follows: output_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} -disable_force_termination (bool) : sets a special flag to disable the default forced-termination behaviour in WriteGear API when -i FFmpeg parameter is used (For more details, see issue: #149 ) . Its usage is as follows: output_params = { \"-disable_force_termination\" : True } # disable the default forced-termination behaviour","title":"Supported Parameters"},{"location":"gears/writegear/compression/params/#supported-encoders","text":"All the encoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows","title":"Supported Encoders"},{"location":"gears/writegear/compression/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"logging"},{"location":"gears/writegear/compression/usage/","text":"WriteGear API Usage Examples: Compression Mode \u00b6 Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities in Compression Mode. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . DO NOT feed frames with different dimensions or channels to WriteGear, otherwise WriteGear will exit with ValueError . DO NOT provide additional video-source with -i FFmpeg parameter in output_params , otherwise it will interfere with frame you input later, and it will break things! Heavy resolution multimedia files take time to render which can last up to ~.1-to-1 seconds . Kindly wait till the WriteGear API terminates itself, and DO NOT try to kill the process instead. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior. Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with WriteGear API in Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = 'myvideo.avi' ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode in RGB Mode \u00b6 For Compression Mode, WriteGear API contains rgb_mode boolean parameter, which if enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) , thereby also known as RGB Mode . The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # simulating RGB frame for example frame_rgb = frame [:,:,:: - 1 ] # writing RGB frame to writer writer . write ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with controlled FrameRate \u00b6 WriteGear API provides -input_framerate attribute for its options dictionary parameter in Compression Mode, which allow us to control/set the constant framerate of the output video. Advanced Tip for setting constant framerate If -input_framerate attribute doesn't works for you, then define it in conjunction with another -r FFmpeg parameter as attribute: # set output constant framerate to (say 60 fps) output_params = { \"-input_framerate\" : 60 , \"-r\" : 60 } # assign that to WriteGear writer = WriteGear ( output_filename = \"out.mp4\" , logging = True , ** output_params ) But make sure you MUST set value of -r and -input_framerate parameter less than or equal to your input source framerate. In this code we will retrieve framerate from video stream, and set it as -input_framerate attribute for option parameter in WriteGear API: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter output_params = { \"-input_framerate\" : stream . framerate } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with Hardware encoders \u00b6 By default, WriteGear API uses libx264 encoder for encoding its output files in Compression Mode. But you can easily change encoder to your suitable supported encoder by passing -vcodec FFmpeg parameter as an attribute in its output_param dictionary parameter. In addition to this, you can also specify the additional properties/features of your system's GPU easily. User Discretion Advised This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg parameters for your writer output_params = { '-vcodec' : 'h264_vaapi' , '-vaapi_device' : '/dev/dri/renderD128' , '-vf' : 'format=nv12,hwupload' } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with OpenCV \u00b6 You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close () Using Compression Mode with VideoCapture Gears \u00b6 WriteGear API can be used in conjunction with any other Gear effortlessly in Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH \" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS \" : 60 } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open live video stream on webcam at first index(i.e. 0) device and apply source tweak parameters stream = VideoGear ( source = 0 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with Live Audio Input \u00b6 In Compression Mode, WriteGear API allows us to exploit almost all FFmpeg supported parameters that you can think of, in its Compression Mode. Hence, processing, encoding, and combining audio with video is pretty much straightforward. Example Assumptions You're running are Linux machine. You already have appropriate audio & video drivers and softwares installed on your machine. Locate your Sound Card Remember to locate your Sound Card before running this example: Note down the Sound Card value using arecord -L command on the your Linux terminal. It may be similar to this plughw:CARD=CAMERA,DEV=0 Tips The useful audio input options for ALSA input are -ar ( audio sample rate ) and -ac ( audio channels ). Specifying audio sampling rate/frequency will force the audio card to record the audio at that specified rate. Usually the default value is \"44100\" (Hz) but \"48000\" (Hz) works, so chose wisely. Specifying audio channels will force the audio card to record the audio as mono, stereo or even 2.1, and 5.1( if supported by your audio card ). Usually the default value is \"1\" (mono) for Mic input and \"2\" (stereo) for Line-In input. Kindly go through FFmpeg docs for more of such options. In this example code, we will merge the audio from a Audio Source (for e.g. Webcam inbuilt mic) to the frames of a Video Source (for e.g external webcam) , and save this data as a compressed video file, all in real time: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer output_params = { '-thread_queue_size' : '512' , '-f' : 'alsa' , '-ac' : '1' , '-ar' : '48000' , '-i' : 'plughw:CARD=CAMERA,DEV=0' } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = 'Output.mp4' , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/writegear/compression/usage/#writegear-api-usage-examples-compression-mode","text":"Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities in Compression Mode. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . DO NOT feed frames with different dimensions or channels to WriteGear, otherwise WriteGear will exit with ValueError . DO NOT provide additional video-source with -i FFmpeg parameter in output_params , otherwise it will interfere with frame you input later, and it will break things! Heavy resolution multimedia files take time to render which can last up to ~.1-to-1 seconds . Kindly wait till the WriteGear API terminates itself, and DO NOT try to kill the process instead. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior.","title":"WriteGear API Usage Examples: Compression Mode"},{"location":"gears/writegear/compression/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with WriteGear API in Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = 'myvideo.avi' ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Bare-Minimum Usage"},{"location":"gears/writegear/compression/usage/#using-compression-mode-in-rgb-mode","text":"For Compression Mode, WriteGear API contains rgb_mode boolean parameter, which if enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) , thereby also known as RGB Mode . The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # simulating RGB frame for example frame_rgb = frame [:,:,:: - 1 ] # writing RGB frame to writer writer . write ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode in RGB Mode"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-controlled-framerate","text":"WriteGear API provides -input_framerate attribute for its options dictionary parameter in Compression Mode, which allow us to control/set the constant framerate of the output video. Advanced Tip for setting constant framerate If -input_framerate attribute doesn't works for you, then define it in conjunction with another -r FFmpeg parameter as attribute: # set output constant framerate to (say 60 fps) output_params = { \"-input_framerate\" : 60 , \"-r\" : 60 } # assign that to WriteGear writer = WriteGear ( output_filename = \"out.mp4\" , logging = True , ** output_params ) But make sure you MUST set value of -r and -input_framerate parameter less than or equal to your input source framerate. In this code we will retrieve framerate from video stream, and set it as -input_framerate attribute for option parameter in WriteGear API: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter output_params = { \"-input_framerate\" : stream . framerate } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with controlled FrameRate"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-hardware-encoders","text":"By default, WriteGear API uses libx264 encoder for encoding its output files in Compression Mode. But you can easily change encoder to your suitable supported encoder by passing -vcodec FFmpeg parameter as an attribute in its output_param dictionary parameter. In addition to this, you can also specify the additional properties/features of your system's GPU easily. User Discretion Advised This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg parameters for your writer output_params = { '-vcodec' : 'h264_vaapi' , '-vaapi_device' : '/dev/dri/renderD128' , '-vf' : 'format=nv12,hwupload' } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with Hardware encoders"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-opencv","text":"You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Using Compression Mode with OpenCV"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-videocapture-gears","text":"WriteGear API can be used in conjunction with any other Gear effortlessly in Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH \" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS \" : 60 } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open live video stream on webcam at first index(i.e. 0) device and apply source tweak parameters stream = VideoGear ( source = 0 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with VideoCapture Gears"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-live-audio-input","text":"In Compression Mode, WriteGear API allows us to exploit almost all FFmpeg supported parameters that you can think of, in its Compression Mode. Hence, processing, encoding, and combining audio with video is pretty much straightforward. Example Assumptions You're running are Linux machine. You already have appropriate audio & video drivers and softwares installed on your machine. Locate your Sound Card Remember to locate your Sound Card before running this example: Note down the Sound Card value using arecord -L command on the your Linux terminal. It may be similar to this plughw:CARD=CAMERA,DEV=0 Tips The useful audio input options for ALSA input are -ar ( audio sample rate ) and -ac ( audio channels ). Specifying audio sampling rate/frequency will force the audio card to record the audio at that specified rate. Usually the default value is \"44100\" (Hz) but \"48000\" (Hz) works, so chose wisely. Specifying audio channels will force the audio card to record the audio as mono, stereo or even 2.1, and 5.1( if supported by your audio card ). Usually the default value is \"1\" (mono) for Mic input and \"2\" (stereo) for Line-In input. Kindly go through FFmpeg docs for more of such options. In this example code, we will merge the audio from a Audio Source (for e.g. Webcam inbuilt mic) to the frames of a Video Source (for e.g external webcam) , and save this data as a compressed video file, all in real time: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer output_params = { '-thread_queue_size' : '512' , '-f' : 'alsa' , '-ac' : '1' , '-ar' : '48000' , '-i' : 'plughw:CARD=CAMERA,DEV=0' } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = 'Output.mp4' , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with Live Audio Input"},{"location":"gears/writegear/compression/advanced/cciw/","text":"Custom FFmpeg Commands in WriteGear API \u00b6 WriteGear API now provides the execute_ffmpeg_cmd Method in Compression Mode , that enables the user to pass any custom terminal command (that works on the terminal) , as an input to its internal FFmpeg Pipeline by formating it as a list. This opens endless possibilities of exploiting every FFmpeg params within WriteGear without relying on a third-party API to do the same and while doing that it robustly handles all errors/warnings quietly. A user can now pass any custom Terminal command (that works on the terminal) directly to the WriteGear's FFmpeg pipeline by formating it as a list. Important Information This Feature Requires WriteGear's Compression Mode enabled( compression_mode = True ) . Follow these dedicated Installation Instructions \u27b6 for its installation. Only python list is a valid datatype as input value by this function, otherwise it will throw ValueError . Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Features \u00b6 Provides the ability to pass any custom command to WriteGear FFmpeg Pipeline. Compatible with any FFmpeg terminal command. Standalone On-the-fly functioning. Can work without interfering with WriteGear API's Writer pipeline. Minimum hassle and extremely easy to enable and use. Methods \u00b6 execute_ffmpeg_cmd \u00b6 This method allows the users to pass the custom FFmpeg terminal commands as a formatted list directly to WriteGear API's FFmpeg pipeline for processing/execution. Its usage is as follows: #format FFmpeg terminal command `ffmpeg -y -i source_video -acodec copy input_audio.aac` as a list ffmpeg_command = [ '-y' , '-i' , source_video , '-acodec' , 'copy' , 'input_audio.aac' ] #execute this list using this function execute_ffmpeg_cmd ( ffmpeg_command ) Usage Examples \u00b6 User Discretion Advised Following usage examples is just an idea of what can be done with this powerful function. So just Tinker with various FFmpeg parameters/commands yourself and see it working. Also, if you're unable to run any terminal FFmpeg command, then report an issue . Using WriteGear to separate Audio from Video \u00b6 In this example, we will extract and save audio from a URL stream: # import required libraries from vidgear.gears import WriteGear #define a valid url url_to_stream = 'http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4' # Define writer with default parameters writer = WriteGear ( output_filename = 'Output.mp4' , logging = True ) #format command to convert stream audio as 'output_audio.aac' as list ffmpeg_command_to_save_audio = [ '-y' , '-i' , url_to_stream , 'output_audio.aac' ] # `-y` parameter is to overwrite outputfile if exists #execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command_to_save_audio ) # safely close writer writer . close () After running this script, You will get the final 'output_audio.aac' audio file. Using WriteGear to merge Audio with Video \u00b6 In this example, we will merge audio with video: Example Assumptions You already have a separate video(i.e 'input-video.mp4' ) and audio(i.e 'input-audio.aac' ) files. Both these Audio and Video files are of equal duration. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 import time #Open input video stream stream = VideoGear ( source = 'input-video.mp4' ) . start () #set input audio stream path input_audio = \"input-audio.aac\" #define your parameters output_params = { \"-input_framerate\" : stream . framerate } #output framerate must match source framerate # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () #sleep 1 sec as the above video might still be rendering time . sleep ( 1 ) #format FFmpeg command to generate `Output_with_audio.mp4` by merging input_audio in above rendered `Output.mp4` ffmpeg_command = [ '-y' , '-i' , 'Output.mp4' , '-i' , input_audio , '-c:v' , 'copy' , '-c:a' , 'copy' , '-map' , '0:v:0' , '-map' , '1:a:0' , '-shortest' , 'Output_with_audio.mp4' ] # `-y` parameter is to overwrite outputfile if exists #execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) After running this script, You will get the final 'Output_with_audio.mp4' file with both video and audio merged.","title":"Custom FFmpeg Commands"},{"location":"gears/writegear/compression/advanced/cciw/#custom-ffmpeg-commands-in-writegear-api","text":"WriteGear API now provides the execute_ffmpeg_cmd Method in Compression Mode , that enables the user to pass any custom terminal command (that works on the terminal) , as an input to its internal FFmpeg Pipeline by formating it as a list. This opens endless possibilities of exploiting every FFmpeg params within WriteGear without relying on a third-party API to do the same and while doing that it robustly handles all errors/warnings quietly. A user can now pass any custom Terminal command (that works on the terminal) directly to the WriteGear's FFmpeg pipeline by formating it as a list. Important Information This Feature Requires WriteGear's Compression Mode enabled( compression_mode = True ) . Follow these dedicated Installation Instructions \u27b6 for its installation. Only python list is a valid datatype as input value by this function, otherwise it will throw ValueError . Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all.","title":"Custom FFmpeg Commands in WriteGear API"},{"location":"gears/writegear/compression/advanced/cciw/#features","text":"Provides the ability to pass any custom command to WriteGear FFmpeg Pipeline. Compatible with any FFmpeg terminal command. Standalone On-the-fly functioning. Can work without interfering with WriteGear API's Writer pipeline. Minimum hassle and extremely easy to enable and use.","title":"Features"},{"location":"gears/writegear/compression/advanced/cciw/#methods","text":"","title":"Methods"},{"location":"gears/writegear/compression/advanced/cciw/#execute_ffmpeg_cmd","text":"This method allows the users to pass the custom FFmpeg terminal commands as a formatted list directly to WriteGear API's FFmpeg pipeline for processing/execution. Its usage is as follows: #format FFmpeg terminal command `ffmpeg -y -i source_video -acodec copy input_audio.aac` as a list ffmpeg_command = [ '-y' , '-i' , source_video , '-acodec' , 'copy' , 'input_audio.aac' ] #execute this list using this function execute_ffmpeg_cmd ( ffmpeg_command )","title":"execute_ffmpeg_cmd"},{"location":"gears/writegear/compression/advanced/cciw/#usage-examples","text":"User Discretion Advised Following usage examples is just an idea of what can be done with this powerful function. So just Tinker with various FFmpeg parameters/commands yourself and see it working. Also, if you're unable to run any terminal FFmpeg command, then report an issue .","title":"Usage Examples"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-separate-audio-from-video","text":"In this example, we will extract and save audio from a URL stream: # import required libraries from vidgear.gears import WriteGear #define a valid url url_to_stream = 'http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4' # Define writer with default parameters writer = WriteGear ( output_filename = 'Output.mp4' , logging = True ) #format command to convert stream audio as 'output_audio.aac' as list ffmpeg_command_to_save_audio = [ '-y' , '-i' , url_to_stream , 'output_audio.aac' ] # `-y` parameter is to overwrite outputfile if exists #execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command_to_save_audio ) # safely close writer writer . close () After running this script, You will get the final 'output_audio.aac' audio file.","title":"Using WriteGear to separate Audio from Video"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-merge-audio-with-video","text":"In this example, we will merge audio with video: Example Assumptions You already have a separate video(i.e 'input-video.mp4' ) and audio(i.e 'input-audio.aac' ) files. Both these Audio and Video files are of equal duration. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 import time #Open input video stream stream = VideoGear ( source = 'input-video.mp4' ) . start () #set input audio stream path input_audio = \"input-audio.aac\" #define your parameters output_params = { \"-input_framerate\" : stream . framerate } #output framerate must match source framerate # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () #sleep 1 sec as the above video might still be rendering time . sleep ( 1 ) #format FFmpeg command to generate `Output_with_audio.mp4` by merging input_audio in above rendered `Output.mp4` ffmpeg_command = [ '-y' , '-i' , 'Output.mp4' , '-i' , input_audio , '-c:v' , 'copy' , '-c:a' , 'copy' , '-map' , '0:v:0' , '-map' , '1:a:0' , '-shortest' , 'Output_with_audio.mp4' ] # `-y` parameter is to overwrite outputfile if exists #execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) After running this script, You will get the final 'Output_with_audio.mp4' file with both video and audio merged.","title":"Using WriteGear to merge Audio with Video"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/","text":"FFmpeg Installation Instructions \u00b6 WriteGear must requires FFmpeg executables for its Compression capabilities in Compression Mode. You can following machine-specific instructions for its installation: Warning In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . Linux FFmpeg Installation \u00b6 The WriteGear API supports Auto-Detection and Manual Configuration methods on a Linux machine: A. Auto-Detection \u00b6 This is a recommended approach on Linux Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode! Windows FFmpeg Installation \u00b6 The WriteGear API supports Auto-Installation and Manual Configuration methods on Windows systems. A. Auto-Installation \u00b6 This is a recommended approach on Windows Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system WriteGear API auto-generates the required FFmpeg Static Binaries, according to your system specifications, into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, WriteGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then, WriteGear API will auto-disable the Compression Mode and switches to Non-Compression Mode ! B. Manual Configuration \u00b6 Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: http://ffmpeg.zeranoe.com/builds/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode! MacOS FFmpeg Installation \u00b6 The WriteGear API supports Auto-Detection and Manual Configuration methods on a macOS machine. A. Auto-Detection \u00b6 This is a recommended approach on MacOS Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#ffmpeg-installation-instructions","text":"WriteGear must requires FFmpeg executables for its Compression capabilities in Compression Mode. You can following machine-specific instructions for its installation: Warning In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode .","title":"FFmpeg Installation Instructions"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#linux-ffmpeg-installation","text":"The WriteGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:","title":"Linux FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection","text":"This is a recommended approach on Linux Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6","title":"A. Auto-Detection"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration","text":"Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#windows-ffmpeg-installation","text":"The WriteGear API supports Auto-Installation and Manual Configuration methods on Windows systems.","title":"Windows FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-installation","text":"This is a recommended approach on Windows Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system WriteGear API auto-generates the required FFmpeg Static Binaries, according to your system specifications, into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, WriteGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then, WriteGear API will auto-disable the Compression Mode and switches to Non-Compression Mode !","title":"A. Auto-Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_1","text":"Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: http://ffmpeg.zeranoe.com/builds/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#macos-ffmpeg-installation","text":"The WriteGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.","title":"MacOS FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection_1","text":"This is a recommended approach on MacOS Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6","title":"A. Auto-Detection"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_2","text":"Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/non_compression/overview/","text":"WriteGear API: Non-Compression Mode \u00b6 WriteGear API's Non-Compression Mode generalized workflow Overview \u00b6 When compression_mode parameter is disabled (.i.e compression_mode = False ) , WriteGear API uses basic OpenCV's inbuilt VideoWriter API tools for encoding multimedia files but without compression, Thereby, also known as Non-Compression Mode. This mode provides flexible access to OpenCV's VideoWriter API ,and also supports various parameters available within this API, but lacks the ability to control output quality, compression, and other important features like lossless video compression, audio encoding, etc. , which are available in Compression Mode only. Thereby, the resultant output videofile size of this Mode, will be many times larger as compared to Compression Mode. Important Information In case WriteGear API fails to detect valid FFmpeg executables on your system, it will automatically switches to this(Non-Compression) Mode. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/writegear/non_compression/overview/#writegear-api-non-compression-mode","text":"WriteGear API's Non-Compression Mode generalized workflow","title":"WriteGear API: Non-Compression Mode"},{"location":"gears/writegear/non_compression/overview/#overview","text":"When compression_mode parameter is disabled (.i.e compression_mode = False ) , WriteGear API uses basic OpenCV's inbuilt VideoWriter API tools for encoding multimedia files but without compression, Thereby, also known as Non-Compression Mode. This mode provides flexible access to OpenCV's VideoWriter API ,and also supports various parameters available within this API, but lacks the ability to control output quality, compression, and other important features like lossless video compression, audio encoding, etc. , which are available in Compression Mode only. Thereby, the resultant output videofile size of this Mode, will be many times larger as compared to Compression Mode. Important Information In case WriteGear API fails to detect valid FFmpeg executables on your system, it will automatically switches to this(Non-Compression) Mode. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/writegear/non_compression/params/","text":"WriteGear API Parameters: Non-Compression Mode \u00b6 output_filename \u00b6 This parameter sets the valid output Video filename/path for the output video. WriteGear API will throw RuntimeError if output_filename provided is empty or invalid. Data-Type: String Default Value: Its default value is 0 . Usage: Make sure to provide valid filename with valid file-extension based on the encoder in use (default is .mp4 ) . Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer compression_mode \u00b6 This parameter selects the WriteGear's primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = False ) #activates non-compression mode custom_ffmpeg \u00b6 Not supported in Non-Compression Mode! output_params \u00b6 This parameter allows us to exploit almost all OpenCV's VideoWriter API supported parameters effortlessly and flexibly for video-encoding in Non-Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and FOURCC codecs for compression mode discussed below: Info Remember, Non-Compression mode lacks the ability to control output quality and other important features like lossless video compression, audio encoding, etc. , which are available with WriteGear's Compression Mode only. Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u00b6 Non-Compression Mode only gives access to a limited number of parameters, which are as follows: Parameters Description -fourcc 4-character code of codec used to encode frames -fps controls the framerate of output video(Default value: 25) -backend (optional) In case of multiple backends, this parameter allows us to specify VideoWriter API's backends to use. Its valid values are CAP_FFMPEG or CAP_GSTREAMER (if enabled) -color (optional) If it is not zero(0), the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only) -height and -width parameter are no longer supported and are automatically derived from the input data. Usage: To assign desired paramete in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter as follows: # format parameter as dictionary attribute output_params = { \"-fps\" : 30 } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 . Supported FOURCC Codecs \u00b6 FOURCC is a 4-character code of the codec used to encode video in Non-Compression Mode(OpenCV's VideoWriter API) without compression. List of all supported FOURCC codecs can found here \u27b6 Usage: To select desired FOURCC codec in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter. For example, using MJPG as codec, we can: # format codec as dictionary attribute output_params = { \"-fourcc\" : \"MJPG\" } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 . logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"Parameters"},{"location":"gears/writegear/non_compression/params/#writegear-api-parameters-non-compression-mode","text":"","title":"WriteGear API Parameters: Non-Compression Mode"},{"location":"gears/writegear/non_compression/params/#output_filename","text":"This parameter sets the valid output Video filename/path for the output video. WriteGear API will throw RuntimeError if output_filename provided is empty or invalid. Data-Type: String Default Value: Its default value is 0 . Usage: Make sure to provide valid filename with valid file-extension based on the encoder in use (default is .mp4 ) . Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer","title":"output_filename"},{"location":"gears/writegear/non_compression/params/#compression_mode","text":"This parameter selects the WriteGear's primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = False ) #activates non-compression mode","title":"compression_mode"},{"location":"gears/writegear/non_compression/params/#custom_ffmpeg","text":"Not supported in Non-Compression Mode!","title":"custom_ffmpeg"},{"location":"gears/writegear/non_compression/params/#output_params","text":"This parameter allows us to exploit almost all OpenCV's VideoWriter API supported parameters effortlessly and flexibly for video-encoding in Non-Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and FOURCC codecs for compression mode discussed below: Info Remember, Non-Compression mode lacks the ability to control output quality and other important features like lossless video compression, audio encoding, etc. , which are available with WriteGear's Compression Mode only. Data-Type: Dictionary Default Value: Its default value is {} .","title":"output_params"},{"location":"gears/writegear/non_compression/params/#supported-parameters","text":"Non-Compression Mode only gives access to a limited number of parameters, which are as follows: Parameters Description -fourcc 4-character code of codec used to encode frames -fps controls the framerate of output video(Default value: 25) -backend (optional) In case of multiple backends, this parameter allows us to specify VideoWriter API's backends to use. Its valid values are CAP_FFMPEG or CAP_GSTREAMER (if enabled) -color (optional) If it is not zero(0), the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only) -height and -width parameter are no longer supported and are automatically derived from the input data. Usage: To assign desired paramete in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter as follows: # format parameter as dictionary attribute output_params = { \"-fps\" : 30 } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 .","title":"Supported Parameters"},{"location":"gears/writegear/non_compression/params/#supported-fourcc-codecs","text":"FOURCC is a 4-character code of the codec used to encode video in Non-Compression Mode(OpenCV's VideoWriter API) without compression. List of all supported FOURCC codecs can found here \u27b6 Usage: To select desired FOURCC codec in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter. For example, using MJPG as codec, we can: # format codec as dictionary attribute output_params = { \"-fourcc\" : \"MJPG\" } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 .","title":"Supported FOURCC Codecs"},{"location":"gears/writegear/non_compression/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"logging"},{"location":"gears/writegear/non_compression/usage/","text":"WriteGear API Usage Examples: Non-Compression Mode \u00b6 Important Information DO NOT feed frames to WriteGear with different dimensions or channels, or-else WriteGear API will exit with ValueError . In case WriteGear API fails to detect valid FFmpeg executables on your system, it will auto-switches to this(Non-Compression) Mode. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior. Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with WriteGear API in Non-Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = 'myvideo.avi' ) . start () # Define writer with Non-compression mode and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , compression_mode = False ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Non-Compression Mode with VideoCapture Gears \u00b6 In WriteGear API, the Non-Compression mode provides flexible control over OpenCV's VideoWriter API parameters, through its output_param dictionary parameter, by formating them as dictionary attributes. Also, WriteGear API can be used in conjunction with any other Gear effortlessly. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 , logging = True ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Non-Compression Mode with OpenCV \u00b6 You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Non-Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/writegear/non_compression/usage/#writegear-api-usage-examples-non-compression-mode","text":"Important Information DO NOT feed frames to WriteGear with different dimensions or channels, or-else WriteGear API will exit with ValueError . In case WriteGear API fails to detect valid FFmpeg executables on your system, it will auto-switches to this(Non-Compression) Mode. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior.","title":"WriteGear API Usage Examples: Non-Compression Mode"},{"location":"gears/writegear/non_compression/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with WriteGear API in Non-Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = 'myvideo.avi' ) . start () # Define writer with Non-compression mode and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , compression_mode = False ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Bare-Minimum Usage"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-videocapture-gears","text":"In WriteGear API, the Non-Compression mode provides flexible control over OpenCV's VideoWriter API parameters, through its output_param dictionary parameter, by formating them as dictionary attributes. Also, WriteGear API can be used in conjunction with any other Gear effortlessly. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 , logging = True ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Non-Compression Mode with VideoCapture Gears"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-opencv","text":"You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Non-Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Using Non-Compression Mode with OpenCV"},{"location":"help/camgear_faqs/","text":"CamGear FAQs \u00b6 What is CamGear API and what does it do? \u00b6 Answer: CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. For more info. see CamGear doc\u27b6 . I'm only familiar with OpenCV, how to get started with CamGear API? \u00b6 Answer: First see Switching from OpenCV , then go through CamGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. Why CamGear is throwing RuntimeError ? \u00b6 Answer: CamGear API will throw RuntimeError if source provided is Invalid. Recheck the source parameter value!. How to change OpenCV source backend in CamGear API? \u00b6 Answer: See its Parameters \u27b6 . Its, backend (int) parameter sets the backend of the source. Its value can be for e.g. backend = cv2.CAP_DSHOW in case of Direct Show. How to get framerate of the source? \u00b6 Answer: CamGear's framerate global variable can be used to retrieve framerate of the input video stream. See this example \u27b6 . How to open network streams with VidGear? \u00b6 Answer: Just give your stream URL directly to CamGear's source parameter. How to open Gstreamer pipeline in vidgear? \u00b6 Answer: CamGear API supports GStreamer Pipeline. Note that needs your OpenCV to have been built with GStreamer support , you can check this with print(cv2.getBuildInformation()) python command and check output if contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Also finally, be sure videoconvert outputs into BGR format. For example as follows: stream = CamGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) . start () How to set USB camera properties? \u00b6 Answer: See this usage example \u27b6 . How to play YouTube Live Stream or Video with CamGear API? \u00b6 Answer: See this usage example \u27b6 . Can I play 4k video with vidgear? \u00b6 Answer: Yes, you can if your System Hardware supports it. It proven by our playback benchmarking test . How to synchronize between two cameras? \u00b6 Answer: See this issue comment \u27b6 . Can I use GPU to decode the video source? \u00b6 Answer: See this issue comment \u27b6 . Can I perform Deep Learning task with VidGear? \u00b6 Answer: VidGear is a High-performance Video Processing library (similar to OpenCV, FFmpeg etc.) , that can read, write, process, send & receive sequence of Video-frames from/to various devices in real-time. So you have to use a third party library with VidGear to deal with Deep Learning operations. But surely VidGear's high-performance APIs will definitely leverages the overall performance. Why CamGear is throwing warning that Threaded Queue Mode is disabled? \u00b6 Answer: That's a normal behaviour. Please read about Threaded Queue Mode \u27b6","title":"CamGear FAQs"},{"location":"help/camgear_faqs/#camgear-faqs","text":"","title":"CamGear FAQs"},{"location":"help/camgear_faqs/#what-is-camgear-api-and-what-does-it-do","text":"Answer: CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. For more info. see CamGear doc\u27b6 .","title":"What is CamGear API and what does it do?"},{"location":"help/camgear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-camgear-api","text":"Answer: First see Switching from OpenCV , then go through CamGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with CamGear API?"},{"location":"help/camgear_faqs/#why-camgear-is-throwing-runtimeerror","text":"Answer: CamGear API will throw RuntimeError if source provided is Invalid. Recheck the source parameter value!.","title":"Why CamGear is throwing RuntimeError?"},{"location":"help/camgear_faqs/#how-to-change-opencv-source-backend-in-camgear-api","text":"Answer: See its Parameters \u27b6 . Its, backend (int) parameter sets the backend of the source. Its value can be for e.g. backend = cv2.CAP_DSHOW in case of Direct Show.","title":"How to change OpenCV source backend in CamGear API?"},{"location":"help/camgear_faqs/#how-to-get-framerate-of-the-source","text":"Answer: CamGear's framerate global variable can be used to retrieve framerate of the input video stream. See this example \u27b6 .","title":"How to get framerate of the source?"},{"location":"help/camgear_faqs/#how-to-open-network-streams-with-vidgear","text":"Answer: Just give your stream URL directly to CamGear's source parameter.","title":"How to open network streams with VidGear?"},{"location":"help/camgear_faqs/#how-to-open-gstreamer-pipeline-in-vidgear","text":"Answer: CamGear API supports GStreamer Pipeline. Note that needs your OpenCV to have been built with GStreamer support , you can check this with print(cv2.getBuildInformation()) python command and check output if contains something similar as follows: Video I/O: ... GStreamer: base: YES ( ver 1 .8.3 ) video: YES ( ver 1 .8.3 ) app: YES ( ver 1 .8.3 ) ... Also finally, be sure videoconvert outputs into BGR format. For example as follows: stream = CamGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) . start ()","title":"How to open Gstreamer pipeline in vidgear?"},{"location":"help/camgear_faqs/#how-to-set-usb-camera-properties","text":"Answer: See this usage example \u27b6 .","title":"How to set USB camera properties?"},{"location":"help/camgear_faqs/#how-to-play-youtube-live-stream-or-video-with-camgear-api","text":"Answer: See this usage example \u27b6 .","title":"How to play YouTube Live Stream or Video with CamGear API?"},{"location":"help/camgear_faqs/#can-i-play-4k-video-with-vidgear","text":"Answer: Yes, you can if your System Hardware supports it. It proven by our playback benchmarking test .","title":"Can I play 4k video with vidgear?"},{"location":"help/camgear_faqs/#how-to-synchronize-between-two-cameras","text":"Answer: See this issue comment \u27b6 .","title":"How to synchronize between two cameras?"},{"location":"help/camgear_faqs/#can-i-use-gpu-to-decode-the-video-source","text":"Answer: See this issue comment \u27b6 .","title":"Can I use GPU to decode the video source?"},{"location":"help/camgear_faqs/#can-i-perform-deep-learning-task-with-vidgear","text":"Answer: VidGear is a High-performance Video Processing library (similar to OpenCV, FFmpeg etc.) , that can read, write, process, send & receive sequence of Video-frames from/to various devices in real-time. So you have to use a third party library with VidGear to deal with Deep Learning operations. But surely VidGear's high-performance APIs will definitely leverages the overall performance.","title":"Can I perform Deep Learning task with VidGear?"},{"location":"help/camgear_faqs/#why-camgear-is-throwing-warning-that-threaded-queue-mode-is-disabled","text":"Answer: That's a normal behaviour. Please read about Threaded Queue Mode \u27b6","title":"Why CamGear is throwing warning that Threaded Queue Mode is disabled?"},{"location":"help/general_faqs/","text":"General FAQs \u00b6 \"I'm new to Python Programming or its usage in Computer Vision\", How to use vidgear in my projects? \u00b6 Answer: It's recommended to firstly go through following dedicated tutorials/websites thoroughly, and learn how OpenCV-Python actually works( with examples ): PyImageSearch.com \u27b6 is the best resource for learning OpenCV and its Python implementation. Adrian Rosebrock provides many practical OpenCV techniques with tutorials, code examples, blogs and books at PyImageSearch.com. I also learned a lot about computer vision methods, and various useful techniques, when I first started with Computer Vision. Highly recommended! learnopencv.com \u27b6 Maintained by OpenCV CEO Satya Mallick. This blog is for programmers, hackers, engineers, scientists, students and self-starters who are interested in Computer Vision and Machine Learning. There's also the official OpenCV Tutorials \u27b6 , provided by the OpenCV folks themselves. Finally, when you're done, see Switching from OpenCV \u27b6 , and finally go through our Gears \u27b6 to see how VidGear works. If you run into any trouble, or have any questions, then see getting help \u27b6 How to install VidGear python library on my machine? \u00b6 Answer: See Installation Notes \u27b6 . \"VidGear is using Multi-threading, but Python is notorious for its poor performance in multithreading?\" \u00b6 Answer: Most of the VidGear task are I/O bounded, meaning that the thread spends most of its time handling I/O processes such as performing network requests, pooling frames out of Camera devices etc. It is perfectly fine to use multi-threading for these tasks, as the thread is most of the time being blocked and put into blocked queue by the OS automatically. For further reading, see Threaded-Queue-Mode \u27b6 Why VidGear APIs not working for me? \u00b6 Answer: VidGear docs contains a lot of detailed information, please take your time to read it. Please see Getting Help \u27b6 for troubleshooting your problems. How do I report an issue? \u00b6 Answer: See Reporting an Issue \u27b6 Can I ask my question directly without raising an issue? \u00b6 Answer: Yes, please join our Gitter \u27b6 Community channel. How to contribute to VidGear development? \u00b6 Answer: See our Contribution Guidelines \u27b6 What OSes are supported by VidGear? \u00b6 Answer: See Supported Systems \u27b6 What Python versions are supported by VidGear? \u00b6 Answer: See Supported Python legacies \u27b6 Can I include VidGear in my project commercially or not? \u00b6 Answer: Yes, you can, but strictly under the Terms and Conditions given in VidGear License \u27b6 \"I Love using VidGear\", How can I support it? \u00b6 Answer: Thank you! See Helping VidGear \u27b6","title":"General FAQs"},{"location":"help/general_faqs/#general-faqs","text":"","title":"General FAQs"},{"location":"help/general_faqs/#im-new-to-python-programming-or-its-usage-in-computer-vision-how-to-use-vidgear-in-my-projects","text":"Answer: It's recommended to firstly go through following dedicated tutorials/websites thoroughly, and learn how OpenCV-Python actually works( with examples ): PyImageSearch.com \u27b6 is the best resource for learning OpenCV and its Python implementation. Adrian Rosebrock provides many practical OpenCV techniques with tutorials, code examples, blogs and books at PyImageSearch.com. I also learned a lot about computer vision methods, and various useful techniques, when I first started with Computer Vision. Highly recommended! learnopencv.com \u27b6 Maintained by OpenCV CEO Satya Mallick. This blog is for programmers, hackers, engineers, scientists, students and self-starters who are interested in Computer Vision and Machine Learning. There's also the official OpenCV Tutorials \u27b6 , provided by the OpenCV folks themselves. Finally, when you're done, see Switching from OpenCV \u27b6 , and finally go through our Gears \u27b6 to see how VidGear works. If you run into any trouble, or have any questions, then see getting help \u27b6","title":"\"I'm new to Python Programming or its usage in Computer Vision\", How to use vidgear in my projects?"},{"location":"help/general_faqs/#how-to-install-vidgear-python-library-on-my-machine","text":"Answer: See Installation Notes \u27b6 .","title":"How to install VidGear python library on my machine?"},{"location":"help/general_faqs/#vidgear-is-using-multi-threading-but-python-is-notorious-for-its-poor-performance-in-multithreading","text":"Answer: Most of the VidGear task are I/O bounded, meaning that the thread spends most of its time handling I/O processes such as performing network requests, pooling frames out of Camera devices etc. It is perfectly fine to use multi-threading for these tasks, as the thread is most of the time being blocked and put into blocked queue by the OS automatically. For further reading, see Threaded-Queue-Mode \u27b6","title":"\"VidGear is using Multi-threading, but Python is notorious for its poor performance in multithreading?\""},{"location":"help/general_faqs/#why-vidgear-apis-not-working-for-me","text":"Answer: VidGear docs contains a lot of detailed information, please take your time to read it. Please see Getting Help \u27b6 for troubleshooting your problems.","title":"Why VidGear APIs not working for me?"},{"location":"help/general_faqs/#how-do-i-report-an-issue","text":"Answer: See Reporting an Issue \u27b6","title":"How do I report an issue?"},{"location":"help/general_faqs/#can-i-ask-my-question-directly-without-raising-an-issue","text":"Answer: Yes, please join our Gitter \u27b6 Community channel.","title":"Can I ask my question directly without raising an issue?"},{"location":"help/general_faqs/#how-to-contribute-to-vidgear-development","text":"Answer: See our Contribution Guidelines \u27b6","title":"How to contribute to VidGear development?"},{"location":"help/general_faqs/#what-oses-are-supported-by-vidgear","text":"Answer: See Supported Systems \u27b6","title":"What OSes are supported by VidGear?"},{"location":"help/general_faqs/#what-python-versions-are-supported-by-vidgear","text":"Answer: See Supported Python legacies \u27b6","title":"What Python versions are supported by VidGear?"},{"location":"help/general_faqs/#can-i-include-vidgear-in-my-project-commercially-or-not","text":"Answer: Yes, you can, but strictly under the Terms and Conditions given in VidGear License \u27b6","title":"Can I include VidGear in my project commercially or not?"},{"location":"help/general_faqs/#i-love-using-vidgear-how-can-i-support-it","text":"Answer: Thank you! See Helping VidGear \u27b6","title":"\"I Love using VidGear\", How can I support it?"},{"location":"help/get_help/","text":"Getting Help \u00b6 Courtesy - Pinterest Would you like to get help with VidGear? There are several ways to get help with VidGear: \u2009 Frequently Asked Questions \u00b6 Got a question related to VidGear Working? Checkout our Frequently Asked Questions, a curated list of all the questions with answer, that we commonly recieve, for quickly troubleshoot your problems: General FAQs \u27b6 CamGear FAQs \u27b6 PiGear FAQs \u27b6 ScreenGear FAQs \u27b6 StreamGear FAQs \u27b6 WriteGear FAQs \u27b6 NetGear FAQs \u27b6 WebGear FAQs \u27b6 VideoGear FAQs \u27b6 Stabilizer Class FAQs \u27b6 NetGear_Async FAQs \u27b6 \u2009 Join our Gitter Community channel \u00b6 Have you come up with some new idea, or looking for the fastest way troubleshoot your problems Join and chat on our Gitter Community channel: There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas & information, etc. \u2009 This is what you do when... \u00b6 Got a question or problem? Found a typo? Found a bug? Missing a feature/improvement? \u2009 Reporting an issues \u00b6 Want to report a bug? Suggest a new feature? Before you do, please read our guidelines \u27b6 \u2009 Preparing a Pull Request \u00b6 Interested in contributing to VidGear? Before you do, please read our guidelines \u27b6","title":"Getting Help"},{"location":"help/get_help/#getting-help","text":"Courtesy - Pinterest Would you like to get help with VidGear? There are several ways to get help with VidGear:","title":"Getting Help"},{"location":"help/get_help/#frequently-asked-questions","text":"Got a question related to VidGear Working? Checkout our Frequently Asked Questions, a curated list of all the questions with answer, that we commonly recieve, for quickly troubleshoot your problems: General FAQs \u27b6 CamGear FAQs \u27b6 PiGear FAQs \u27b6 ScreenGear FAQs \u27b6 StreamGear FAQs \u27b6 WriteGear FAQs \u27b6 NetGear FAQs \u27b6 WebGear FAQs \u27b6 VideoGear FAQs \u27b6 Stabilizer Class FAQs \u27b6 NetGear_Async FAQs \u27b6","title":"Frequently Asked Questions"},{"location":"help/get_help/#join-our-gitter-community-channel","text":"Have you come up with some new idea, or looking for the fastest way troubleshoot your problems Join and chat on our Gitter Community channel: There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas & information, etc.","title":"Join our Gitter Community channel"},{"location":"help/get_help/#this-is-what-you-do-when","text":"Got a question or problem? Found a typo? Found a bug? Missing a feature/improvement?","title":"This is what you do when..."},{"location":"help/get_help/#reporting-an-issues","text":"Want to report a bug? Suggest a new feature? Before you do, please read our guidelines \u27b6","title":"Reporting an issues"},{"location":"help/get_help/#preparing-a-pull-request","text":"Interested in contributing to VidGear? Before you do, please read our guidelines \u27b6","title":"Preparing a Pull Request"},{"location":"help/motivation/","text":"Project Motivation \u00b6 Why is VidGear a thing? \u00b6 The original motivation and thinking behind creating this project was to build an ultrafast extensible and bugfree python Video Processing library with experimental features like real-time Video-Stabilization, lossless Video-Encoding, flexible parameters manipulation, and Multi-Threading, etc. But also keeping it simple at the same time, thereby it must let programmers and software developers to easily integrate and perform complex Video Processing tasks in their existing or new applications, without going through various underlying python library's documentation and by using just a few lines of code. Chronicle origins \u00b6 This project began as a part of my Pull Request(PR) to another computer vision python library - imutils 's video modules. In this PR I purposed countless bug fixes for the existing implementation by its author. But soon I find out that the author wasn't much interested in merging these fixes and it became apparent it did not belong to the imutils library itself. Therefore, I thought it may benefit others more as a separate project and that allow a wider range of experimental features and targets all available devices and video streams. And that's the chronicle origin of VidGear .","title":"Project Motivation"},{"location":"help/motivation/#project-motivation","text":"","title":"Project Motivation"},{"location":"help/motivation/#why-is-vidgear-a-thing","text":"The original motivation and thinking behind creating this project was to build an ultrafast extensible and bugfree python Video Processing library with experimental features like real-time Video-Stabilization, lossless Video-Encoding, flexible parameters manipulation, and Multi-Threading, etc. But also keeping it simple at the same time, thereby it must let programmers and software developers to easily integrate and perform complex Video Processing tasks in their existing or new applications, without going through various underlying python library's documentation and by using just a few lines of code.","title":"Why is VidGear a thing?"},{"location":"help/motivation/#chronicle-origins","text":"This project began as a part of my Pull Request(PR) to another computer vision python library - imutils 's video modules. In this PR I purposed countless bug fixes for the existing implementation by its author. But soon I find out that the author wasn't much interested in merging these fixes and it became apparent it did not belong to the imutils library itself. Therefore, I thought it may benefit others more as a separate project and that allow a wider range of experimental features and targets all available devices and video streams. And that's the chronicle origin of VidGear .","title":"Chronicle origins"},{"location":"help/netgear_async_faqs/","text":"NetGear_Async FAQs \u00b6 What is NetGear_Async API and what does it do? \u00b6 Answer: NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. For more info. see NetGear_Async doc \u27b6 How to get started with NetGear_Async API? \u00b6 Answer: See NetGear_Async doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \"NetGear_Async is throwing ModuleNotFoundError on importing\", Why? \u00b6 Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 . What is the key difference between NetGear_Async and NetGear APIs? \u00b6 Answer: NetGear: implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear_Async: is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Key Difference: NetGear_Async is way memory efficient and little faster, but has less features as compared to NetGear API. On the other hand, NetGear API provides many powerful Exclusive Modes , but is way less memory efficient and a bit slower than NetGear_Async API. Can I use Multi-Server, Bi-Directional like modes in NetGear_Async? \u00b6 Answer: No, NetGear_Async does NOT provide support for any NetGear's Exclusive modes yet. How to use NetGear_Async with custom Server Source from OpenCV? \u00b6 Answer: See this usage example \u27b6 . Why NetGear_Async is running slow? \u00b6 Answer: Checkout tips suggested in this answer \u27b6","title":"NetGear_Async FAQs"},{"location":"help/netgear_async_faqs/#netgear_async-faqs","text":"","title":"NetGear_Async FAQs"},{"location":"help/netgear_async_faqs/#what-is-netgear_async-api-and-what-does-it-do","text":"Answer: NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. For more info. see NetGear_Async doc \u27b6","title":"What is NetGear_Async API and what does it do?"},{"location":"help/netgear_async_faqs/#how-to-get-started-with-netgear_async-api","text":"Answer: See NetGear_Async doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with NetGear_Async API?"},{"location":"help/netgear_async_faqs/#netgear_async-is-throwing-modulenotfounderror-on-importing-why","text":"Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 .","title":"\"NetGear_Async is throwing ModuleNotFoundError on importing\", Why?"},{"location":"help/netgear_async_faqs/#what-is-the-key-difference-between-netgear_async-and-netgear-apis","text":"Answer: NetGear: implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear_Async: is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Key Difference: NetGear_Async is way memory efficient and little faster, but has less features as compared to NetGear API. On the other hand, NetGear API provides many powerful Exclusive Modes , but is way less memory efficient and a bit slower than NetGear_Async API.","title":"What is the key difference between NetGear_Async and NetGear APIs?"},{"location":"help/netgear_async_faqs/#can-i-use-multi-server-bi-directional-like-modes-in-netgear_async","text":"Answer: No, NetGear_Async does NOT provide support for any NetGear's Exclusive modes yet.","title":"Can I use Multi-Server, Bi-Directional like modes in NetGear_Async?"},{"location":"help/netgear_async_faqs/#how-to-use-netgear_async-with-custom-server-source-from-opencv","text":"Answer: See this usage example \u27b6 .","title":"How to use NetGear_Async with custom Server Source from OpenCV?"},{"location":"help/netgear_async_faqs/#why-netgear_async-is-running-slow","text":"Answer: Checkout tips suggested in this answer \u27b6","title":"Why NetGear_Async is running slow?"},{"location":"help/netgear_faqs/","text":"NetGear FAQs \u00b6 What is NetGear API and what does it do? \u00b6 Answer: NetGear is exclusively designed to transfer video frames & data synchronously (Pair & Request/Reply) as well as asynchronously (Publish/Subscribe) between various interconnecting systems over the network in real-time. For more info. see NetGear doc \u27b6 How to get started with NetGear API? \u00b6 Answer: See NetGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. What Exclusive Modes are compatible with each other in NetGear API? \u00b6 Here's the compatibility chart for NetGear's Exclusive Modes : Exclusive Modes Multi-Servers Multi-Clients Secure Bidirectional Multi-Servers - No (throws error) Yes No (disables it) Multi-Clients No (throws error) - Yes No (disables it) Secure Yes Yes - Yes Bidirectional No (disabled) No (disabled) Yes - How to receive frames from multiple Servers and multiple Clients through NetGear API? \u00b6 Answer: See Multi-Servers Mode doc \u27b6 and Multi-Clients Mode doc \u27b6 How to send data along with frames in Multi-Servers and Multi-Clients Modes? \u00b6 Answer: See Multi-Servers usage example \u27b6 and Multi-Clients usage example \u27b6 How to use enable Encryption and Authentication in NetGear API? \u00b6 Answer: See its Secure Mode doc \u27b6 . How to send custom data along with frames bidirectionally in NetGear API? \u00b6 Answer: See its Bidirectional Mode doc \u27b6 . Are there any side-effect of sending data with frames? \u00b6 Answer: Yes, it may lead to additional LATENCY depending upon the size/amount of the data being transferred. User discretion is advised. How can I compress frames before sending them to Client(s) in NetGear API? \u00b6 Answer: See Frame Compression doc \u27b6 Which compression format is the fastest for NetGear API? \u00b6 Answer: According to an answer : The time varies differently for different encoding/decoding format as follows: Encoding format Time taken (in milliseconds) bmp 20-40 jpg 50-70 png 200-250 Despite bmp being the fasted, using jpg is more suitable for encoding, since highly-optimized libjpeg-turbo library is now a part of OpenCV binaries. But you can choose whatever suits you. Why NetGear API not working correctly? \u00b6 Answer: First, carefully go through NetGear doc \u27b6 that contains detailed information. Also, checkout PyZmq Docs \u27b6 for its various settings/parameters. If still it doesn't work for you, then let us know on Gitter \u27b6 Why NetGear is running slow? \u00b6 Answer: Here are few tips to troubleshoot performance on your machine: Update ZMQ to latest: Update your pyzmq lib as follows: sudo pip3 install -U pyzmq Install testing branch: The testing branch may contain many latest performance updates, which are not yet merged into master branch. Therefore, you can try them earlier, by installing testing branch directly \u27b6 . Use PUB/SUB pattern if you're live streaming : Try different pattern values, as each of them suits different settings. For example, you can use its Publisher/Subscriber pattern (i.e. pattern=2 ) for asynchronous high-speed transmission over real-time streams, and it works faster than other synchronous patterns for this scenario. Use Wired connection instead of Wireless connection : Remember typical 802.11g Wireless has a theoretical maximum of 54Mbps. Typical wired 10/100/1000 Ethernet has a theoretical maximum of 100 Gbps. So in theory wired is faster. However, these speeds are only on your local network. So chose your network configuration wisely. Compress your image/frame before transmission: Try Frame Encoding/Decoding Compression capabilities for NetGear API \u27b6 . Reduce Frame Size: Use VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance (see this usage example \u27b6 ) . Remember, sending large HQ video-frames may required more network bandwidth and packet size, which can lead to additional latency! Systematically, check for Hardware/Network Issues \u27b6 Finally, if nothing works, then, checkout NetGear_Async API \u27b6","title":"NetGear FAQs"},{"location":"help/netgear_faqs/#netgear-faqs","text":"","title":"NetGear FAQs"},{"location":"help/netgear_faqs/#what-is-netgear-api-and-what-does-it-do","text":"Answer: NetGear is exclusively designed to transfer video frames & data synchronously (Pair & Request/Reply) as well as asynchronously (Publish/Subscribe) between various interconnecting systems over the network in real-time. For more info. see NetGear doc \u27b6","title":"What is NetGear API and what does it do?"},{"location":"help/netgear_faqs/#how-to-get-started-with-netgear-api","text":"Answer: See NetGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with NetGear API?"},{"location":"help/netgear_faqs/#what-exclusive-modes-are-compatible-with-each-other-in-netgear-api","text":"Here's the compatibility chart for NetGear's Exclusive Modes : Exclusive Modes Multi-Servers Multi-Clients Secure Bidirectional Multi-Servers - No (throws error) Yes No (disables it) Multi-Clients No (throws error) - Yes No (disables it) Secure Yes Yes - Yes Bidirectional No (disabled) No (disabled) Yes -","title":"What Exclusive Modes are compatible with each other in NetGear API?"},{"location":"help/netgear_faqs/#how-to-receive-frames-from-multiple-servers-and-multiple-clients-through-netgear-api","text":"Answer: See Multi-Servers Mode doc \u27b6 and Multi-Clients Mode doc \u27b6","title":"How to receive frames from multiple Servers and multiple Clients through NetGear API?"},{"location":"help/netgear_faqs/#how-to-send-data-along-with-frames-in-multi-servers-and-multi-clients-modes","text":"Answer: See Multi-Servers usage example \u27b6 and Multi-Clients usage example \u27b6","title":"How to send data along with frames in Multi-Servers and Multi-Clients Modes?"},{"location":"help/netgear_faqs/#how-to-use-enable-encryption-and-authentication-in-netgear-api","text":"Answer: See its Secure Mode doc \u27b6 .","title":"How to use enable Encryption and Authentication in NetGear API?"},{"location":"help/netgear_faqs/#how-to-send-custom-data-along-with-frames-bidirectionally-in-netgear-api","text":"Answer: See its Bidirectional Mode doc \u27b6 .","title":"How to send custom data along with frames bidirectionally in NetGear API?"},{"location":"help/netgear_faqs/#are-there-any-side-effect-of-sending-data-with-frames","text":"Answer: Yes, it may lead to additional LATENCY depending upon the size/amount of the data being transferred. User discretion is advised.","title":"Are there any side-effect of sending data with frames?"},{"location":"help/netgear_faqs/#how-can-i-compress-frames-before-sending-them-to-clients-in-netgear-api","text":"Answer: See Frame Compression doc \u27b6","title":"How can I compress frames before sending them to Client(s) in NetGear API?"},{"location":"help/netgear_faqs/#which-compression-format-is-the-fastest-for-netgear-api","text":"Answer: According to an answer : The time varies differently for different encoding/decoding format as follows: Encoding format Time taken (in milliseconds) bmp 20-40 jpg 50-70 png 200-250 Despite bmp being the fasted, using jpg is more suitable for encoding, since highly-optimized libjpeg-turbo library is now a part of OpenCV binaries. But you can choose whatever suits you.","title":"Which compression format is the fastest for NetGear API?"},{"location":"help/netgear_faqs/#why-netgear-api-not-working-correctly","text":"Answer: First, carefully go through NetGear doc \u27b6 that contains detailed information. Also, checkout PyZmq Docs \u27b6 for its various settings/parameters. If still it doesn't work for you, then let us know on Gitter \u27b6","title":"Why NetGear API not working correctly?"},{"location":"help/netgear_faqs/#why-netgear-is-running-slow","text":"Answer: Here are few tips to troubleshoot performance on your machine: Update ZMQ to latest: Update your pyzmq lib as follows: sudo pip3 install -U pyzmq Install testing branch: The testing branch may contain many latest performance updates, which are not yet merged into master branch. Therefore, you can try them earlier, by installing testing branch directly \u27b6 . Use PUB/SUB pattern if you're live streaming : Try different pattern values, as each of them suits different settings. For example, you can use its Publisher/Subscriber pattern (i.e. pattern=2 ) for asynchronous high-speed transmission over real-time streams, and it works faster than other synchronous patterns for this scenario. Use Wired connection instead of Wireless connection : Remember typical 802.11g Wireless has a theoretical maximum of 54Mbps. Typical wired 10/100/1000 Ethernet has a theoretical maximum of 100 Gbps. So in theory wired is faster. However, these speeds are only on your local network. So chose your network configuration wisely. Compress your image/frame before transmission: Try Frame Encoding/Decoding Compression capabilities for NetGear API \u27b6 . Reduce Frame Size: Use VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance (see this usage example \u27b6 ) . Remember, sending large HQ video-frames may required more network bandwidth and packet size, which can lead to additional latency! Systematically, check for Hardware/Network Issues \u27b6 Finally, if nothing works, then, checkout NetGear_Async API \u27b6","title":"Why NetGear is running slow?"},{"location":"help/pigear_faqs/","text":"PiGear FAQs \u00b6 What is PiGear API and what does it do? \u00b6 Answer: PiGear is similar to CamGear but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module ). For more info. see PiGear doc \u27b6 I'm only familiar with OpenCV, how to get started with PiGear API? \u00b6 Answer: First see Switching from OpenCV , then go through PiGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. Why my camera module is not detected by PiGear? \u00b6 Answer: Make sure to enable Raspberry Pi hardware-specific settings \u27b6 prior using this API. Also recheck/change your Camera Module's ribbon-cable, if it damaged or broken somehow. Why PiGear is throwing SystemError ? \u00b6 Answer: This means your Raspberry Pi CSI ribbon-cable is not connected properly to your Camera Module, or damaged, or even both. How to assign picamera settings for Camera Module with PiGear? \u00b6 Answer: See this usage example \u27b6 \"Video output is too dark with PiGear\", Why? \u00b6 Answer: Seems like incorrect settings. Kindly see picamera docs for available parameters, and look for parameters are sensor_mode , shutter_speed and exposure_mode , try changing those values. Also, maybe your framerate value is too high, try lowering it. How to select camera index on Pi Compute IO board with two Cameras attached? \u00b6 Answer: See PiGear's camera_num parameter \u27b6","title":"PiGear FAQs"},{"location":"help/pigear_faqs/#pigear-faqs","text":"","title":"PiGear FAQs"},{"location":"help/pigear_faqs/#what-is-pigear-api-and-what-does-it-do","text":"Answer: PiGear is similar to CamGear but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module ). For more info. see PiGear doc \u27b6","title":"What is PiGear API and what does it do?"},{"location":"help/pigear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-pigear-api","text":"Answer: First see Switching from OpenCV , then go through PiGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with PiGear API?"},{"location":"help/pigear_faqs/#why-my-camera-module-is-not-detected-by-pigear","text":"Answer: Make sure to enable Raspberry Pi hardware-specific settings \u27b6 prior using this API. Also recheck/change your Camera Module's ribbon-cable, if it damaged or broken somehow.","title":"Why my camera module is not detected by PiGear?"},{"location":"help/pigear_faqs/#why-pigear-is-throwing-systemerror","text":"Answer: This means your Raspberry Pi CSI ribbon-cable is not connected properly to your Camera Module, or damaged, or even both.","title":"Why PiGear is throwing SystemError?"},{"location":"help/pigear_faqs/#how-to-assign-picamera-settings-for-camera-module-with-pigear","text":"Answer: See this usage example \u27b6","title":"How to assign picamera settings for Camera Module with PiGear?"},{"location":"help/pigear_faqs/#video-output-is-too-dark-with-pigear-why","text":"Answer: Seems like incorrect settings. Kindly see picamera docs for available parameters, and look for parameters are sensor_mode , shutter_speed and exposure_mode , try changing those values. Also, maybe your framerate value is too high, try lowering it.","title":"\"Video output is too dark with PiGear\", Why?"},{"location":"help/pigear_faqs/#how-to-select-camera-index-on-pi-compute-io-board-with-two-cameras-attached","text":"Answer: See PiGear's camera_num parameter \u27b6","title":"How to select camera index on Pi Compute IO board with two Cameras attached?"},{"location":"help/screengear_faqs/","text":"ScreenGear FAQs \u00b6 What is ScreenGear API and what does it do? \u00b6 Answer: ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors. For more info. see ScreenGear doc \u27b6 I'm only familiar with OpenCV, how to get started with ScreenGear API? \u00b6 Answer: First see Switching from OpenCV , then go through ScreenGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. How to define area on screen to record with ScreenGear? \u00b6 Answer: See this usage example \u27b6 How to record video from all connected screens? \u00b6 Answer: See ScreenGear's monitor parameter , that sets the index of the monitor where to grab a frame from. If its value is 0 , it will record from all monitors. More information can be found here \u27b6","title":"ScreenGear FAQs"},{"location":"help/screengear_faqs/#screengear-faqs","text":"","title":"ScreenGear FAQs"},{"location":"help/screengear_faqs/#what-is-screengear-api-and-what-does-it-do","text":"Answer: ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors. For more info. see ScreenGear doc \u27b6","title":"What is ScreenGear API and what does it do?"},{"location":"help/screengear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-screengear-api","text":"Answer: First see Switching from OpenCV , then go through ScreenGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with ScreenGear API?"},{"location":"help/screengear_faqs/#how-to-define-area-on-screen-to-record-with-screengear","text":"Answer: See this usage example \u27b6","title":"How to define area on screen to record with ScreenGear?"},{"location":"help/screengear_faqs/#how-to-record-video-from-all-connected-screens","text":"Answer: See ScreenGear's monitor parameter , that sets the index of the monitor where to grab a frame from. If its value is 0 , it will record from all monitors. More information can be found here \u27b6","title":"How to record video from all connected screens?"},{"location":"help/stabilizer_faqs/","text":"Stabilizer Class FAQs \u00b6 What is Stabilizer Class and what does it do? \u00b6 Answer: Stabilizer Class is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. For more info. see Stabilizer Class doc \u27b6 How much latency you would typically expect with Stabilizer Class? \u00b6 Answer: The stabilizer might be slower for High-Quality videos-frames, try reducing frames size before feeding them for reducing latency. Also, see smoothing_radius parameter of Stabilizer class that handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. How to remove black borders in output video after stabilizing it? \u00b6 Answer: See crop_n_zoom parameter of Stabilizer class, that enables the feature, where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the feature available in Adobe AfterEffects) . It works in conjunction with the border_size parameter, i.e. when this parameter is enabled border_size will be used for cropping border instead of making them. Its default value is False. Can I use Stabilizer directly with OpenCV? \u00b6 Answer: Yes, see this usage example \u27b6 . Why stabilization is not working for my video? \u00b6 Answer: The Stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! Also, check if increasing smoothing_radius parameter value helps, but it will add latency too.","title":"Stabilizer Class FAQs"},{"location":"help/stabilizer_faqs/#stabilizer-class-faqs","text":"","title":"Stabilizer Class FAQs"},{"location":"help/stabilizer_faqs/#what-is-stabilizer-class-and-what-does-it-do","text":"Answer: Stabilizer Class is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. For more info. see Stabilizer Class doc \u27b6","title":"What is Stabilizer Class and what does it do?"},{"location":"help/stabilizer_faqs/#how-much-latency-you-would-typically-expect-with-stabilizer-class","text":"Answer: The stabilizer might be slower for High-Quality videos-frames, try reducing frames size before feeding them for reducing latency. Also, see smoothing_radius parameter of Stabilizer class that handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa.","title":"How much latency you would typically expect with Stabilizer Class?"},{"location":"help/stabilizer_faqs/#how-to-remove-black-borders-in-output-video-after-stabilizing-it","text":"Answer: See crop_n_zoom parameter of Stabilizer class, that enables the feature, where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the feature available in Adobe AfterEffects) . It works in conjunction with the border_size parameter, i.e. when this parameter is enabled border_size will be used for cropping border instead of making them. Its default value is False.","title":"How to remove black borders in output video after stabilizing it?"},{"location":"help/stabilizer_faqs/#can-i-use-stabilizer-directly-with-opencv","text":"Answer: Yes, see this usage example \u27b6 .","title":"Can I use Stabilizer directly with OpenCV?"},{"location":"help/stabilizer_faqs/#why-stabilization-is-not-working-for-my-video","text":"Answer: The Stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! Also, check if increasing smoothing_radius parameter value helps, but it will add latency too.","title":"Why stabilization is not working for my video?"},{"location":"help/streamgear_faqs/","text":"StreamGear FAQs \u00b6 \u2009 What is StreamGear API and what does it do? \u00b6 Answer: SteamGear API automatically transcodes source videos/audio files & real-time frames, and breaks them into a sequence of multiple smaller chunks/segments (typically 2-4 seconds in length) at different quality levels (i.e. different bitrates or spatial resolutions) . It also creates a Manifest file (MPD in-case of DASH) that describes these segment information (timing, URL, media characteristics like video resolution and bit rates) , and is provided to the client prior to the streaming session. Thereby, segments are served on a web server and can be downloaded through HTTP standard compliant GET requests. This makes it possible to stream videos at different quality levels, and to switch in the middle of a video from one quality level to another one \u2013 if bandwidth permits \u2013 on a per segment basis. For more info. see StreamGear doc \u27b6 \u2009 How to get started with StreamGear API? \u00b6 Answer: See StreamGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \u2009 What is MPD file created with StreamGear? \u00b6 Answer: The MPD (Media Presentation Description) is an XML file that represents the different qualities of the media content and the individual segments of each quality with HTTP Uniform Resource Locators (URLs). Each MPD could contain one or more Periods. Each of those Periods contains media components such as video components e.g., different view angles or with different codecs, audio components for different languages , subtitle or caption components, etc. Those components have certain characteristics like the bitrate, frame rate, audio-channels, etc. which do not change during one Period. The client is able to adapt according to the available bitrates, resolutions, codecs, etc. that are available in a given Period. \u2009 How to play Streaming Assets created with StreamGear API? \u00b6 Answer: You can easily feed Manifest file( .mpd ) to DASH Supported Players Input. See this list of recommended players \u27b6 \u2009 What Adaptive Streaming Formats are supported yet? \u00b6 Answer: SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. \u2009 Is DRM Encryption supported in StreamGear API? \u00b6 Answer: No, DRM Encryption is not supported yet. \u2009 How to create additional streams in StreamGear API? \u00b6 Answer: See this example \u27b6 \u2009 How to use StreamGear API with real-time frames? \u00b6 Answer: See Real-time Frames Mode \u27b6 \u2009 How to use StreamGear API with OpenCV? \u00b6 Answer: See this example \u27b6 \u2009 How to use Hardware/GPU encoder for StreamGear trancoding? \u00b6 Answer: See this example \u27b6","title":"StreamGear FAQs"},{"location":"help/streamgear_faqs/#streamgear-faqs","text":"","title":"StreamGear FAQs"},{"location":"help/streamgear_faqs/#what-is-streamgear-api-and-what-does-it-do","text":"Answer: SteamGear API automatically transcodes source videos/audio files & real-time frames, and breaks them into a sequence of multiple smaller chunks/segments (typically 2-4 seconds in length) at different quality levels (i.e. different bitrates or spatial resolutions) . It also creates a Manifest file (MPD in-case of DASH) that describes these segment information (timing, URL, media characteristics like video resolution and bit rates) , and is provided to the client prior to the streaming session. Thereby, segments are served on a web server and can be downloaded through HTTP standard compliant GET requests. This makes it possible to stream videos at different quality levels, and to switch in the middle of a video from one quality level to another one \u2013 if bandwidth permits \u2013 on a per segment basis. For more info. see StreamGear doc \u27b6","title":"What is StreamGear API and what does it do?"},{"location":"help/streamgear_faqs/#how-to-get-started-with-streamgear-api","text":"Answer: See StreamGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with StreamGear API?"},{"location":"help/streamgear_faqs/#what-is-mpd-file-created-with-streamgear","text":"Answer: The MPD (Media Presentation Description) is an XML file that represents the different qualities of the media content and the individual segments of each quality with HTTP Uniform Resource Locators (URLs). Each MPD could contain one or more Periods. Each of those Periods contains media components such as video components e.g., different view angles or with different codecs, audio components for different languages , subtitle or caption components, etc. Those components have certain characteristics like the bitrate, frame rate, audio-channels, etc. which do not change during one Period. The client is able to adapt according to the available bitrates, resolutions, codecs, etc. that are available in a given Period.","title":"What is MPD file created with StreamGear?"},{"location":"help/streamgear_faqs/#how-to-play-streaming-assets-created-with-streamgear-api","text":"Answer: You can easily feed Manifest file( .mpd ) to DASH Supported Players Input. See this list of recommended players \u27b6","title":"How to play Streaming Assets created with StreamGear API?"},{"location":"help/streamgear_faqs/#what-adaptive-streaming-formats-are-supported-yet","text":"Answer: SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon.","title":"What Adaptive Streaming Formats are supported yet?"},{"location":"help/streamgear_faqs/#is-drm-encryption-supported-in-streamgear-api","text":"Answer: No, DRM Encryption is not supported yet.","title":"Is DRM Encryption supported in StreamGear API?"},{"location":"help/streamgear_faqs/#how-to-create-additional-streams-in-streamgear-api","text":"Answer: See this example \u27b6","title":"How to create additional streams in StreamGear API?"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-real-time-frames","text":"Answer: See Real-time Frames Mode \u27b6","title":"How to use StreamGear API with real-time frames?"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-opencv","text":"Answer: See this example \u27b6","title":"How to use StreamGear API with OpenCV?"},{"location":"help/streamgear_faqs/#how-to-use-hardwaregpu-encoder-for-streamgear-trancoding","text":"Answer: See this example \u27b6","title":"How to use Hardware/GPU encoder for StreamGear trancoding?"},{"location":"help/videogear_faqs/","text":"VideoGear FAQs \u00b6 What is VideoGear API and what does it do? \u00b6 Answer: VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. It also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. For more info. see VideoGear doc \u27b6 What's the need of VideoGear API? \u00b6 Answer: VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using way fewer lines of code. It also serve as backend for other powerful APIs, such WebGear and NetGear_Async . Which APIs are accessible with VideoGear API? \u00b6 Answer: VideoGear provided an internal access to both CamGear and PiGear APIs and their parameters, also it contains wrapper around Video Stabilizer class. Can we access WriteGear API too with VideoGear? \u00b6 Answer: No, only selected VideoCapture gears (anwsered above) are accessible. Does using VideoGear instead of CamGear API directly, affects performance? \u00b6 Answer: No, there's no difference, as VideoGear just a high-level wrapper around CamGear API, and that is without any modifications inbetween.","title":"VideoGear FAQs"},{"location":"help/videogear_faqs/#videogear-faqs","text":"","title":"VideoGear FAQs"},{"location":"help/videogear_faqs/#what-is-videogear-api-and-what-does-it-do","text":"Answer: VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. It also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. For more info. see VideoGear doc \u27b6","title":"What is VideoGear API and what does it do?"},{"location":"help/videogear_faqs/#whats-the-need-of-videogear-api","text":"Answer: VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using way fewer lines of code. It also serve as backend for other powerful APIs, such WebGear and NetGear_Async .","title":"What's the need of VideoGear API?"},{"location":"help/videogear_faqs/#which-apis-are-accessible-with-videogear-api","text":"Answer: VideoGear provided an internal access to both CamGear and PiGear APIs and their parameters, also it contains wrapper around Video Stabilizer class.","title":"Which APIs are accessible with VideoGear API?"},{"location":"help/videogear_faqs/#can-we-access-writegear-api-too-with-videogear","text":"Answer: No, only selected VideoCapture gears (anwsered above) are accessible.","title":"Can we access WriteGear API too with VideoGear?"},{"location":"help/videogear_faqs/#does-using-videogear-instead-of-camgear-api-directly-affects-performance","text":"Answer: No, there's no difference, as VideoGear just a high-level wrapper around CamGear API, and that is without any modifications inbetween.","title":"Does using VideoGear instead of CamGear API directly, affects performance?"},{"location":"help/webgear_faqs/","text":"WebGear FAQs \u00b6 What is WebGear API and what does it do? \u00b6 Answer: WebGear is as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. For more info. see WebGear doc \u27b6 How to get started with WebGear API? \u00b6 Answer: See WebGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \"WebGear is throwing ModuleNotFoundError on importing\", Why? \u00b6 Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 . Can WebGear always need Active Internet Connection? \u00b6 Answer: No, it just need Internet only once, during its Auto-Generation Process \u27b6 to download default data-files, and it takes few seconds. For more information see Data-Files Auto-Generation WorkFlow \u27b6 Can I manually place default files for WebGear? \u00b6 Answer: Yes, you can either download default files from Github Server , and manually place at default location , OR, you can yourself create the require three critical files (i.e index.html , 404.html & 500.html ) inside templates folder at the default location , thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6 Can I run WebGear from terminal? \u00b6 Answer: Yes, see this usage example \u27b6 . How can I add my custom WebPage to WebGear? \u00b6 Answer: See this usage example \u27b6 . Can I re-download default data in WebGear? \u00b6 Answer: Yes, either you can delete default data-files manually, OR, you can force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files attribute of option parameter in WebGear API. Remember only downloaded default data-files will be overwritten in this process, and any other file/folder will NOT be affected. Can I change the default location? \u00b6 Answer: Yes, you can use WebGear's custom_data_location attribute of option parameter in WebGear API, to change default location to somewhere else. Can I delete/rename the WebGear default data? \u00b6 Answer: Yes, WebGear gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to follow these rules \u27b6 How to send OpenCV frames directly to Webgear Server? \u00b6 Answer: Here's the trick to do it: Step-1: Trigger Auto-Generation Process: Firstly, run any WebGear usage example to trigger the Auto-generation process . Thereby, the default generated files will be saved at default location of your machine. Step-2: Change Webpage address in your own HTML file: then, Go inside templates directory at default location of your machine, and change the line -> 25 on index.html file : From: < p class = \"lead\" >< img src = \"/video\" class = \"img-fluid\" alt = \"Feed\" ></ p > To: < p class = \"lead\" >< img src = \"/my_frames\" class = \"img-fluid\" alt = \"Feed\" ></ p > Step-3: Build your own Frame Producer and add it to route: Now, create a python script code with OpenCV source, as follows: # import necessary libs import uvicorn , asyncio , cv2 from starlette.routing import Route from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer from starlette.responses import StreamingResponse # !!! define your own video source here !!! stream = cv2 . VideoCapture ( \"/home/foo/foo.avi\" ) # initialize WebGear app with same source web = WebGear ( source = \"/home/foo/foo.avi\" , logging = True ) # also enable `logging` for debugging # create your own frame producer async def my_frame_producer (): # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with frame here #reducer frames size if you want more performance otherwise comment this line frame = reducer ( frame , percentage = 50 ) #reduce frame by 50% #handle JPEG encoding encodedImage = cv2 . imencode ( '.jpg' , frame )[ 1 ] . tobytes () #yield frame in byte format yield ( b '--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n ' + encodedImage + b ' \\r\\n ' ) await asyncio . sleep ( 0.01 ) # now create your own streaming response server async def video_server ( scope ): assert scope [ 'type' ] == 'http' return StreamingResponse ( my_frame_producer (), media_type = 'multipart/x-mixed-replace; boundary=frame' ) # add your frame producer # append new route to point your own streaming response server created above web . routes . append ( Route ( '/my_frames' , endpoint = video_server )) #new route for your frames producer will be `{address}/my_frames` # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) # close app safely web . shutdown () Final Step: Finally, you can run the above python script, and see the desire output at address http://localhost:8000/ on your browser. Can I also manipulate frames before sending it to Webgear Server? \u00b6 Answer: Yes, see previous answer and this comment \u27b6 . \"WebGear is too slow on my browser\", How can I make it run faster? \u00b6 Answer: See Performance Tweaks doc \u27b6 . What Web browser are supported by WebGear API? \u00b6 Answer: All modern browser with Javascript support are supported by WebGear. If not, then tell us on Gitter \u27b6 Community channel.","title":"WebGear FAQs"},{"location":"help/webgear_faqs/#webgear-faqs","text":"","title":"WebGear FAQs"},{"location":"help/webgear_faqs/#what-is-webgear-api-and-what-does-it-do","text":"Answer: WebGear is as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. For more info. see WebGear doc \u27b6","title":"What is WebGear API and what does it do?"},{"location":"help/webgear_faqs/#how-to-get-started-with-webgear-api","text":"Answer: See WebGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with WebGear API?"},{"location":"help/webgear_faqs/#webgear-is-throwing-modulenotfounderror-on-importing-why","text":"Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 .","title":"\"WebGear is throwing ModuleNotFoundError on importing\", Why?"},{"location":"help/webgear_faqs/#can-webgear-always-need-active-internet-connection","text":"Answer: No, it just need Internet only once, during its Auto-Generation Process \u27b6 to download default data-files, and it takes few seconds. For more information see Data-Files Auto-Generation WorkFlow \u27b6","title":"Can WebGear always need Active Internet Connection?"},{"location":"help/webgear_faqs/#can-i-manually-place-default-files-for-webgear","text":"Answer: Yes, you can either download default files from Github Server , and manually place at default location , OR, you can yourself create the require three critical files (i.e index.html , 404.html & 500.html ) inside templates folder at the default location , thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6","title":"Can I manually place default files for WebGear?"},{"location":"help/webgear_faqs/#can-i-run-webgear-from-terminal","text":"Answer: Yes, see this usage example \u27b6 .","title":"Can I run WebGear from terminal?"},{"location":"help/webgear_faqs/#how-can-i-add-my-custom-webpage-to-webgear","text":"Answer: See this usage example \u27b6 .","title":"How can I add my custom WebPage to WebGear?"},{"location":"help/webgear_faqs/#can-i-re-download-default-data-in-webgear","text":"Answer: Yes, either you can delete default data-files manually, OR, you can force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files attribute of option parameter in WebGear API. Remember only downloaded default data-files will be overwritten in this process, and any other file/folder will NOT be affected.","title":"Can I re-download default data in WebGear?"},{"location":"help/webgear_faqs/#can-i-change-the-default-location","text":"Answer: Yes, you can use WebGear's custom_data_location attribute of option parameter in WebGear API, to change default location to somewhere else.","title":"Can I change the default location?"},{"location":"help/webgear_faqs/#can-i-deleterename-the-webgear-default-data","text":"Answer: Yes, WebGear gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to follow these rules \u27b6","title":"Can I delete/rename the WebGear default data?"},{"location":"help/webgear_faqs/#how-to-send-opencv-frames-directly-to-webgear-server","text":"Answer: Here's the trick to do it: Step-1: Trigger Auto-Generation Process: Firstly, run any WebGear usage example to trigger the Auto-generation process . Thereby, the default generated files will be saved at default location of your machine. Step-2: Change Webpage address in your own HTML file: then, Go inside templates directory at default location of your machine, and change the line -> 25 on index.html file : From: < p class = \"lead\" >< img src = \"/video\" class = \"img-fluid\" alt = \"Feed\" ></ p > To: < p class = \"lead\" >< img src = \"/my_frames\" class = \"img-fluid\" alt = \"Feed\" ></ p > Step-3: Build your own Frame Producer and add it to route: Now, create a python script code with OpenCV source, as follows: # import necessary libs import uvicorn , asyncio , cv2 from starlette.routing import Route from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer from starlette.responses import StreamingResponse # !!! define your own video source here !!! stream = cv2 . VideoCapture ( \"/home/foo/foo.avi\" ) # initialize WebGear app with same source web = WebGear ( source = \"/home/foo/foo.avi\" , logging = True ) # also enable `logging` for debugging # create your own frame producer async def my_frame_producer (): # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with frame here #reducer frames size if you want more performance otherwise comment this line frame = reducer ( frame , percentage = 50 ) #reduce frame by 50% #handle JPEG encoding encodedImage = cv2 . imencode ( '.jpg' , frame )[ 1 ] . tobytes () #yield frame in byte format yield ( b '--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n ' + encodedImage + b ' \\r\\n ' ) await asyncio . sleep ( 0.01 ) # now create your own streaming response server async def video_server ( scope ): assert scope [ 'type' ] == 'http' return StreamingResponse ( my_frame_producer (), media_type = 'multipart/x-mixed-replace; boundary=frame' ) # add your frame producer # append new route to point your own streaming response server created above web . routes . append ( Route ( '/my_frames' , endpoint = video_server )) #new route for your frames producer will be `{address}/my_frames` # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) # close app safely web . shutdown () Final Step: Finally, you can run the above python script, and see the desire output at address http://localhost:8000/ on your browser.","title":"How to send OpenCV frames directly to Webgear Server?"},{"location":"help/webgear_faqs/#can-i-also-manipulate-frames-before-sending-it-to-webgear-server","text":"Answer: Yes, see previous answer and this comment \u27b6 .","title":"Can I also manipulate frames before sending it to Webgear Server?"},{"location":"help/webgear_faqs/#webgear-is-too-slow-on-my-browser-how-can-i-make-it-run-faster","text":"Answer: See Performance Tweaks doc \u27b6 .","title":"\"WebGear is too slow on my browser\", How can I make it run faster?"},{"location":"help/webgear_faqs/#what-web-browser-are-supported-by-webgear-api","text":"Answer: All modern browser with Javascript support are supported by WebGear. If not, then tell us on Gitter \u27b6 Community channel.","title":"What Web browser are supported by WebGear API?"},{"location":"help/writegear_faqs/","text":"WriteGear FAQs \u00b6 What is WriteGear API and what does it do? \u00b6 Answer: WriteGear handles various powerful Writer Tools that provide us the freedom to do almost anything imagine with multimedia files. For more info. see WriteGear doc \u27b6 I'm only familiar with OpenCV, how to get started with WriteGear API? \u00b6 Answer: First see Switching from OpenCV , then go through WriteGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. Why WriteGear is throwing ValueError ? \u00b6 Answer: DO NOT feed frames to WriteGear with different dimensions or channels!, otherwise WriteGear will exit with ValueError . Why WriteGear is switching to Non-compression Mode, even if it is not enable? \u00b6 Answer: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it will automatically fallback to Non-Compression Mode. Follow these Installation Instructions \u27b6 for its installation.. How to install and configure FFmpeg correctly for WriteGear? \u00b6 Answer: Follow these Installation Instructions \u27b6 for its installation. Can I use WriteGear directly with OpenCV? \u00b6 Answer: Yes, For Compression Mode: See this usage example \u27b6 . For Non-Compression Mode: See this usage example \u27b6 What FFmpeg's encoders and parameters are supported by WriteGear in compression mode? \u00b6 Answer: See Supported Parameters \u27b6 and Supported encoders \u27b6 What OpenCV's FOURCC and parameters are supported by WriteGear in non-compression mode? \u00b6 Answer: See Supported Parameters \u27b6 and Supported FOURCC \u27b6 . Why this FOURCC is not working for me? \u00b6 Answer: Remember not all the FOURCC and Video extensions are compatible and supported by OpenCV VideoWriter Class. You\u2019ll need to try different combinations of FourCC and file extensions. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . Can I pass my custom FFmpeg commands directly in WriteGear API? \u00b6 Answer: Yes, See Custom FFmpeg Commands in WriteGear API \u27b6 . How to use specific Hardware Encoder in WriteGear? \u00b6 Answer: See this usage example \u27b6 How to add live audio to WriteGear? \u00b6 Answer: See this doc \u27b6 How to separate and merge audio from/to video? \u00b6 Answer: See these usage examples \u27b6 Can I write frames to the network with WriteGear? \u00b6 Answer: No, not yet. Seek Network gears \u27b6 instead. What FFmpeg parameters is not working for me in compression mode? \u00b6 Answer: WriteGear allows us to exploit almost all available parameters( framerate, bitrate, codecs, format, and size, etc. ) supported by FFmpeg, effortlessly and flexibly with its output_param dictionary parameter. See its usage example here \u27b6 Best of all, WriteGear grants the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc ) , without relying on any Third-party library. Therefore, if some FFmpeg parameter doesn't work for you, then tell us on Gitter \u27b6 , and if that doesn't help, then finally report an issue \u27b6","title":"WriteGear FAQs"},{"location":"help/writegear_faqs/#writegear-faqs","text":"","title":"WriteGear FAQs"},{"location":"help/writegear_faqs/#what-is-writegear-api-and-what-does-it-do","text":"Answer: WriteGear handles various powerful Writer Tools that provide us the freedom to do almost anything imagine with multimedia files. For more info. see WriteGear doc \u27b6","title":"What is WriteGear API and what does it do?"},{"location":"help/writegear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-writegear-api","text":"Answer: First see Switching from OpenCV , then go through WriteGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with WriteGear API?"},{"location":"help/writegear_faqs/#why-writegear-is-throwing-valueerror","text":"Answer: DO NOT feed frames to WriteGear with different dimensions or channels!, otherwise WriteGear will exit with ValueError .","title":"Why WriteGear is throwing ValueError?"},{"location":"help/writegear_faqs/#why-writegear-is-switching-to-non-compression-mode-even-if-it-is-not-enable","text":"Answer: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it will automatically fallback to Non-Compression Mode. Follow these Installation Instructions \u27b6 for its installation..","title":"Why WriteGear is switching to Non-compression Mode, even if it is not enable?"},{"location":"help/writegear_faqs/#how-to-install-and-configure-ffmpeg-correctly-for-writegear","text":"Answer: Follow these Installation Instructions \u27b6 for its installation.","title":"How to install and configure FFmpeg correctly for WriteGear?"},{"location":"help/writegear_faqs/#can-i-use-writegear-directly-with-opencv","text":"Answer: Yes, For Compression Mode: See this usage example \u27b6 . For Non-Compression Mode: See this usage example \u27b6","title":"Can I use WriteGear directly with OpenCV?"},{"location":"help/writegear_faqs/#what-ffmpegs-encoders-and-parameters-are-supported-by-writegear-in-compression-mode","text":"Answer: See Supported Parameters \u27b6 and Supported encoders \u27b6","title":"What FFmpeg's encoders and parameters are supported by WriteGear in compression mode?"},{"location":"help/writegear_faqs/#what-opencvs-fourcc-and-parameters-are-supported-by-writegear-in-non-compression-mode","text":"Answer: See Supported Parameters \u27b6 and Supported FOURCC \u27b6 .","title":"What OpenCV's FOURCC and parameters are supported by WriteGear in non-compression mode?"},{"location":"help/writegear_faqs/#why-this-fourcc-is-not-working-for-me","text":"Answer: Remember not all the FOURCC and Video extensions are compatible and supported by OpenCV VideoWriter Class. You\u2019ll need to try different combinations of FourCC and file extensions. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error .","title":"Why this FOURCC is not working for me?"},{"location":"help/writegear_faqs/#can-i-pass-my-custom-ffmpeg-commands-directly-in-writegear-api","text":"Answer: Yes, See Custom FFmpeg Commands in WriteGear API \u27b6 .","title":"Can I pass my custom FFmpeg commands directly in WriteGear API?"},{"location":"help/writegear_faqs/#how-to-use-specific-hardware-encoder-in-writegear","text":"Answer: See this usage example \u27b6","title":"How to use specific Hardware Encoder in WriteGear?"},{"location":"help/writegear_faqs/#how-to-add-live-audio-to-writegear","text":"Answer: See this doc \u27b6","title":"How to add live audio to WriteGear?"},{"location":"help/writegear_faqs/#how-to-separate-and-merge-audio-fromto-video","text":"Answer: See these usage examples \u27b6","title":"How to separate and merge audio from/to video?"},{"location":"help/writegear_faqs/#can-i-write-frames-to-the-network-with-writegear","text":"Answer: No, not yet. Seek Network gears \u27b6 instead.","title":"Can I write frames to the network with WriteGear?"},{"location":"help/writegear_faqs/#what-ffmpeg-parameters-is-not-working-for-me-in-compression-mode","text":"Answer: WriteGear allows us to exploit almost all available parameters( framerate, bitrate, codecs, format, and size, etc. ) supported by FFmpeg, effortlessly and flexibly with its output_param dictionary parameter. See its usage example here \u27b6 Best of all, WriteGear grants the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc ) , without relying on any Third-party library. Therefore, if some FFmpeg parameter doesn't work for you, then tell us on Gitter \u27b6 , and if that doesn't help, then finally report an issue \u27b6","title":"What FFmpeg parameters is not working for me in compression mode?"},{"location":"installation/pip_install/","text":"Install using pip \u00b6 Best option for quickly getting stable VidGear installed. Prerequisites \u00b6 When installing VidGear with pip, you need to check manually if following dependencies are installed: OpenCV \u00b6 Must require OpenCV(3.0+) python binaries installed for its core functions. You install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux and Raspberry Pi machines manually from its source. pip install -U opencv-python FFmpeg \u00b6 Must require for the video compression and encoding compatibilities within Compression Mode in WriteGear API. FFmpeg Installation Follow this dedicated FFmpeg Installation doc for its installation. Picamera \u00b6 Must Required if you're using Raspberry Pi Camera Modules with its PiGear API. You can easily install it via pip: Make sure to enable Raspberry Pi hardware-specific settings prior to using this library, otherwise it won't work. pip install picamera Uvloop \u00b6 Must required if you're using the NetGear_Async API on a UNIX machine for maximum performance. You can easily install it via pip: uvloop is NOT yet supported on Windows Machines . pip install uvloop Installation \u00b6 Installation is as simple as: Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: python -m pip install vidgear # or with asyncio support python -m pip install vidgear [ asyncio ] If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: python -m pip install --user vidgear # or with asyncio support python -m pip install --user vidgear [ asyncio ] # Install stable release pip install vidgear # Or Install stable release with Asyncio support pip install vidgear [ asyncio ] And if you prefer to install VidGear directly from the repository: pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear # or with asyncio support pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear [ asyncio ] Or you can also download its wheel ( .whl ) package from our releases , and thereby can be installed as follows: pip install vidgear-0.1.7-py3-none-any.whl # or with asyncio support pip install vidgear-0.1.7-py3-none-any.whl [ asyncio ]","title":"Install using pip"},{"location":"installation/pip_install/#install-using-pip","text":"Best option for quickly getting stable VidGear installed.","title":"Install using pip"},{"location":"installation/pip_install/#prerequisites","text":"When installing VidGear with pip, you need to check manually if following dependencies are installed:","title":"Prerequisites"},{"location":"installation/pip_install/#opencv","text":"Must require OpenCV(3.0+) python binaries installed for its core functions. You install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux and Raspberry Pi machines manually from its source. pip install -U opencv-python","title":"OpenCV"},{"location":"installation/pip_install/#ffmpeg","text":"Must require for the video compression and encoding compatibilities within Compression Mode in WriteGear API. FFmpeg Installation Follow this dedicated FFmpeg Installation doc for its installation.","title":"FFmpeg"},{"location":"installation/pip_install/#picamera","text":"Must Required if you're using Raspberry Pi Camera Modules with its PiGear API. You can easily install it via pip: Make sure to enable Raspberry Pi hardware-specific settings prior to using this library, otherwise it won't work. pip install picamera","title":"Picamera"},{"location":"installation/pip_install/#uvloop","text":"Must required if you're using the NetGear_Async API on a UNIX machine for maximum performance. You can easily install it via pip: uvloop is NOT yet supported on Windows Machines . pip install uvloop","title":"Uvloop"},{"location":"installation/pip_install/#installation","text":"Installation is as simple as: Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: python -m pip install vidgear # or with asyncio support python -m pip install vidgear [ asyncio ] If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: python -m pip install --user vidgear # or with asyncio support python -m pip install --user vidgear [ asyncio ] # Install stable release pip install vidgear # Or Install stable release with Asyncio support pip install vidgear [ asyncio ] And if you prefer to install VidGear directly from the repository: pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear # or with asyncio support pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear [ asyncio ] Or you can also download its wheel ( .whl ) package from our releases , and thereby can be installed as follows: pip install vidgear-0.1.7-py3-none-any.whl # or with asyncio support pip install vidgear-0.1.7-py3-none-any.whl [ asyncio ]","title":"Installation"},{"location":"installation/source_install/","text":"Install from source \u00b6 Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all dependencies(except FFmpeg). Prerequisites \u00b6 When installing VidGear from source, FFmpeg is the only dependency you need to install manually: What about rest of the dependencies? Any other python dependencies will be automatically installed based on your OS specifications. FFmpeg \u00b6 Must require for the video compression and encoding compatibilities within Compression Mode in WriteGear API. FFmpeg Installation Follow this dedicated FFmpeg Installation doc for its installation. Installation \u00b6 If you want to just install and try out the checkout the latest beta testing branch , you can do so with the following command. This can be useful if you want to provide feedback for a new feature or want to confirm if a bug you have encountered is fixed in the testing branch. DO NOT clone or install development branch, as it is not tested with CI environments and is possibly very unstable or unusable. Windows Installation Install git for windows . Use following commands to clone and install VidGear: # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # install normally python -m pip install . # OR install with asyncio support python - m pip install . [ asyncio ] # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # install normally pip install . # OR install with asyncio support pip install . [ asyncio ] Or just install directly without cloning: pip install git+git://github.com/abhiTronix/vidgear@testing#egg = vidgear # or with asyncio support pip install git+git://github.com/abhiTronix/vidgear@testing#egg = vidgear [ asyncio ]","title":"Install from source"},{"location":"installation/source_install/#install-from-source","text":"Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all dependencies(except FFmpeg).","title":"Install from source"},{"location":"installation/source_install/#prerequisites","text":"When installing VidGear from source, FFmpeg is the only dependency you need to install manually: What about rest of the dependencies? Any other python dependencies will be automatically installed based on your OS specifications.","title":"Prerequisites"},{"location":"installation/source_install/#ffmpeg","text":"Must require for the video compression and encoding compatibilities within Compression Mode in WriteGear API. FFmpeg Installation Follow this dedicated FFmpeg Installation doc for its installation.","title":"FFmpeg"},{"location":"installation/source_install/#installation","text":"If you want to just install and try out the checkout the latest beta testing branch , you can do so with the following command. This can be useful if you want to provide feedback for a new feature or want to confirm if a bug you have encountered is fixed in the testing branch. DO NOT clone or install development branch, as it is not tested with CI environments and is possibly very unstable or unusable. Windows Installation Install git for windows . Use following commands to clone and install VidGear: # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # install normally python -m pip install . # OR install with asyncio support python - m pip install . [ asyncio ] # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # install normally pip install . # OR install with asyncio support pip install . [ asyncio ] Or just install directly without cloning: pip install git+git://github.com/abhiTronix/vidgear@testing#egg = vidgear # or with asyncio support pip install git+git://github.com/abhiTronix/vidgear@testing#egg = vidgear [ asyncio ]","title":"Installation"},{"location":"overrides/assets/","text":"VidGear Docs Assets \u00b6 The files under this folder contains VidGear Docs assets, which contains primary design elements, that brings standard and quality to its visual design experience. All these files are not covered under VidGear's Apache License , and are provided separately under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License . Warning: In javascripts folder, clappr.min.js , clappr-level-selector.min.js like third-party javascripts are made avaliable under BSD-3-Clause License , whereas dash-shaka-playback.js is also available under Apache License 2.0 seperately. License \u00b6 This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License .","title":"VidGear Docs Assets"},{"location":"overrides/assets/#vidgear-docs-assets","text":"The files under this folder contains VidGear Docs assets, which contains primary design elements, that brings standard and quality to its visual design experience. All these files are not covered under VidGear's Apache License , and are provided separately under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License . Warning: In javascripts folder, clappr.min.js , clappr-level-selector.min.js like third-party javascripts are made avaliable under BSD-3-Clause License , whereas dash-shaka-playback.js is also available under Apache License 2.0 seperately.","title":"VidGear Docs Assets"},{"location":"overrides/assets/#license","text":"This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License .","title":"License"}]}