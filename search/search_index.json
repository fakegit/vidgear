{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 \u2009 VidGear is a High-Performance Video-Processing Framework for building complex real-time media applications in python VidGear provides an easy-to-use, highly extensible, Multi-Threaded + Asyncio Framework on top of many state-of-the-art specialized libraries like OpenCV , FFmpeg , ZeroMQ , picamera , starlette , streamlink , pafy , pyscreenshot and python-mss at its backend, and enable us to flexibly exploit their internal parameters and methods, while silently delivering robust error-handling and unparalleled real-time performance. \"Write Less and Accomplish More\" \u2014 VidGear's Motto VidGear focuses on simplicity, and thereby lets programmers and software developers to easily integrate and perform Complex Video Processing Tasks, in just a few lines of code. \u2009 Getting Started \u00b6 If this is your first time using VidGear, head straight to the Installation \u27b6 to install VidGear. Once you have VidGear installed, Checkout its Function-Specific Gears \u27b6 Also, if you're already familar with OpenCV library, then see Switching from OpenCV Library \u27b6 Or, if you're just getting started with OpenCV with Python, then see here \u27b6 \u2009 Gears \u00b6 VidGear is built with multiple APIs a.k.a Gears , each with some unique functionality. Each Gear is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. These Gears can be classified as follows: VideoCapture Gears \u00b6 CamGear : Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs. PiGear : Multi-Threaded API targeting various Raspberry-Pi Camera Modules. ScreenGear : Multi-Threaded API targeting ultra-fast Screencasting. VideoGear : Common Video-Capture API with internal Video Stabilizer wrapper. VideoWriter Gears \u00b6 WriteGear : Handles Lossless Video-Writer for file/stream/frames Encoding and Compression. Streaming Gears \u00b6 StreamGear : Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats. Asynchronous I/O Streaming Gear: WebGear : ASGI Video-Server that broadcasts Live Video-Frames to any web-browser on the network. Network Gears \u00b6 NetGear : Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network. Asynchronous I/O Network Gear: NetGear_Async : Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework. \u2009 Contributions \u00b6 Contributions are welcome, and greatly appreciated! Please see our Contribution Guidelines \u27b6 for more details. \u2009 Community Channel \u00b6 If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6 \u2009 Become a Stargazer \u00b6 You can be a Stargazer by starring us on Github, it helps us a lot and you're making it easier for others to find & trust this library. Thanks! \u2009 Support Us \u00b6 VidGear relies on your support Donations help keep VidGear's Development alive. Giving a little means a lot, even the smallest contribution can make a huge difference. kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); \u2009 Citation \u00b6 Here is a Bibtex entry you can use to cite this project in a publication: @misc { vidgear , author = {Abhishek Thakur} , title = {vidgear} , howpublished = {\\url{https://github.com/abhiTronix/vidgear}} , year = {2019-2020} }","title":"Overview"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#getting-started","text":"If this is your first time using VidGear, head straight to the Installation \u27b6 to install VidGear. Once you have VidGear installed, Checkout its Function-Specific Gears \u27b6 Also, if you're already familar with OpenCV library, then see Switching from OpenCV Library \u27b6 Or, if you're just getting started with OpenCV with Python, then see here \u27b6","title":"Getting Started"},{"location":"#gears","text":"VidGear is built with multiple APIs a.k.a Gears , each with some unique functionality. Each Gear is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. These Gears can be classified as follows:","title":"Gears"},{"location":"#videocapture-gears","text":"CamGear : Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs. PiGear : Multi-Threaded API targeting various Raspberry-Pi Camera Modules. ScreenGear : Multi-Threaded API targeting ultra-fast Screencasting. VideoGear : Common Video-Capture API with internal Video Stabilizer wrapper.","title":"VideoCapture Gears"},{"location":"#videowriter-gears","text":"WriteGear : Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.","title":"VideoWriter Gears"},{"location":"#streaming-gears","text":"StreamGear : Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats. Asynchronous I/O Streaming Gear: WebGear : ASGI Video-Server that broadcasts Live Video-Frames to any web-browser on the network.","title":"Streaming Gears"},{"location":"#network-gears","text":"NetGear : Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network. Asynchronous I/O Network Gear: NetGear_Async : Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.","title":"Network Gears"},{"location":"#contributions","text":"Contributions are welcome, and greatly appreciated! Please see our Contribution Guidelines \u27b6 for more details.","title":"Contributions"},{"location":"#community-channel","text":"If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6","title":"Community Channel"},{"location":"#become-a-stargazer","text":"You can be a Stargazer by starring us on Github, it helps us a lot and you're making it easier for others to find & trust this library. Thanks!","title":"Become a Stargazer"},{"location":"#support-us","text":"VidGear relies on your support Donations help keep VidGear's Development alive. Giving a little means a lot, even the smallest contribution can make a huge difference. kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw();","title":"Support Us"},{"location":"#citation","text":"Here is a Bibtex entry you can use to cite this project in a publication: @misc { vidgear , author = {Abhishek Thakur} , title = {vidgear} , howpublished = {\\url{https://github.com/abhiTronix/vidgear}} , year = {2019-2020} }","title":"Citation"},{"location":"changelog/","text":"Release Notes \u00b6 v0.2.0 (In Progress) \u00b6 New Features \u00b6 CamGear API: Support for various Live-Video-Streaming services: Added seamless support for live video streaming sites like Twitch, LiveStream, Dailymotion etc. Implemented flexible framework around streamlink python library with easy control over parameters and quality. Stream Mode can now automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Re-implemented YouTube URLs Handler: Re-implemented CamGear's YouTube URLs Handler completely from scratch. New Robust Logic to flexibly handing video and video-audio streams. Intelligent stream selector for selecting best possible stream compatible with OpenCV. Added support for selecting stream qualities and parameters. Implemented new get_supported_quality helper method for handling specified qualities Fixed Live-Stream URLs not supported by OpenCV's Videocapture and its FFmpeg. Added additional STREAM_QUALITY and STREAM_PARAMS attributes. ScreenGear API: Multiple Backends Support: Added new multiple backend support with new pyscreenshot python library. Made pyscreenshot the default API for ScreenGear, replaces mss . Added new backend parameter for this feature while retaining previous behavior. Added native automated RGB to BGR conversion for default PIL backend. Kept support for old mss for old compatibility and multi-screen support. Added native dimensional support for multi-screen. Added support all input from all multiple screens. Updated ScreenGear Docs. Updated ScreenGear CI tests. StreamGear API: Changed default behaviour to support complete video transcoding. Added -livestream attribute to support live-streaming. Added additional parameters for -livestream attribute functionality. Updated StreamGear Tests. Updated StreamGear docs. Stabilizer Class: New Robust Error Handling with Blank Frames: Elegantly handles all crashes due to Empty/Blank/Dark frames. Stabilizer throws Warning with this new behavior instead of crashing. Updated CI test for this feature. Docs: Automated Docs Versioning: Implemented Docs versioning through mike API. Separate new workflow steps to handle different versions. Updated docs deploy worflow to support release and dev builds. Added automatic version extraction from github events. Added version-select.js and version-select.css files. Toggleable Dark-White Docs Support: Toggle-button to easily switch dark, white and preferred theme. New Updated Assets for dark backgrounds New css, js files/content to implement this behavior. New material icons for button. Updated scheme to slate in mkdocs.yml . New Theme and assets: New purple theme with dark-purple accent color. New images assets with updated transparent background. Support for both dark and white theme. Increased rebufferingGoal for dash videos. New updated custom 404 page for docs. Issue and PR automated-bots changes New need_info.yml YAML Workflow. New needs-more-info.yml Request-Info template. Replaced Request-Info templates. Improved PR and Issue welcome formatting. Added custom HTML pages. Added show_root_heading flag to disable headings in References. Added new inserAfter function to version-select.js. Adjusted hue for dark-theme for better contrast. New usage examples and FAQs. Added gitmoji for commits. Continuous Integration: Maintenance Updates: Added support for new VIDGEAR_LOGFILE environment variable in Travis CI. Added missing CI tests. Added logging for helper functions. Azure-Pipeline workflow for MacOS envs Added Azure-Pipeline Workflow for testing MacOS environment. Added codecov support. GitHub Actions workflow for Linux envs Added GitHub Action work-flow for testing Linux environment. New YAML to implement GitHub Action workflow for python 3.6, 3.7, 3,8 & 3.9 matrices. Added Upload coverage to Codecov GitHub Action workflow. New codecov-bash uploader for Azure Pipelines. Logging: Added file support Added VIDGEAR_LOGFILE environment variable to manually add file/dir path. Reworked logger_handler() Helper methods (in asyncio too). Added new formatter and Filehandler for handling logger files. Added restore_levelnames auxiliary method for restoring logging levelnames. Added auto version extraction from package version.py in setup.py. Updates/Improvements \u00b6 Added missing Lazy-pirate auto-reconnection support for Multi-Servers and Multi-Clients Mode in NetGear API. Added new FFmpeg test path to Bash-Script and updated README broken links. Asset Cleanup: Removed all third-party javascripts from projects. Linked all third-party javascript directly. Cleaned up necessary code from CSS and JS files. Removed any copyrighted material or links. Rewritten Docs from scratch: Improved complete docs formatting. Simplified language for easier understanding. Fixed mkdocstrings showing root headings. Included all APIs methods to mkdocstrings docs. Removed unnecessary information from docs. Corrected Spelling and typos. Fixed context and grammar. Removed motivation.md . Renamed many terms. Fixed hyper-links. Reformatted missing or improper information. Fixed context and spellings in Docs files. Simplified language for easy understanding. Updated image sizes for better visibility. Bash Script: Updated to Latest OpenCV Binaries version and related changes Docs: Moved version-selector to header and changed default to alias. Docs: Updated deploy_docs.yml for releasing dev, stable, and release versions. Re-implemented overridden material theme. Updated docs with all new additions and examples. CamGear: CI Stream Mode test updated. Updated ReadMe.md badges. Updated CI tests. Updated setup.py with new features. Updated contributing.md and ReadMe.md . Updated OpenCV version to 4.5.1-dev in bash scripts Updated changelog.md . Moved WebGear API to Streaming Gears. Bumped Codecov. UI changes to version-select.js Docs: Retitle the versions and mkdocs.yml formatting updated. Docs: Version Selector UI reworked and other minor changes. Breaking Updates/Changes \u00b6 y_tube parameter renamed as stream_mode in CamGear API! Removed Travis support and travis.yml deleted. Bug-fixes \u00b6 Fixed StreamGear API Limited Segments Bug Fixed Missing links in docs and bump up version. CI: Fixed Appveyor need newer VM image to support Python 3.9.x matrix. ScreenGear BugFix: Fixed Error Handling and updated CI Tests. Fixed improper mkdocs.yml variables. Fixed GStreamer plugin support in bash scripts. Fixed typos in YAMLs and docs. Docs: Fixed Docs Deployer YAML bug for CI envs. Fixed wrong import in YAML. Fixed visible hyperlink on hover in dark-toggle button. Docs: Deployer YAML bug fixed. Docs YAML: issue jimporter/mike#33 patched and fixed fetch-depth=0 . Docs: version-select.js bug fixed. Docs: UI Bugs Fixed. CI: Codecov bugfixes. Azure-Pipelines Codecov BugFixes. Fixed version.json not detecting properly in version-select.js . Fixed images not centered inside tag. Fixed Asset Colors. Fixed failing CI tests. Fixed Several logging bugs. Pull Requests \u00b6 PR #164 PR #170 PR #173 PR #181 PR #183 PR #184 v0.1.9 (2020-08-31) \u00b6 New Features \u00b6 StreamGear API: New API that automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. Implemented multi-platform , standalone, highly extensible and flexible wrapper around FFmpeg for generating chunked-encoded media segments of the media, and easily accessing almost all of its parameters. API automatically transcodes videos/audio files & real-time frames into a sequence of multiple smaller chunks/segments and also creates a Manifest file. Added initial support for MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) . Constructed default behavior in StreamGear, for auto-creating a Primary Stream of same resolution and framerate as source. Added TQDM progress bar in non-debugged output for visual representation of internal processes. Implemented several internal methods for preprocessing FFmpeg and internal parameters for producing streams. Several standalone internal checks to ensure robust performance. New terminate() function to terminate StremGear Safely. New StreamGear Dual Modes of Operation: Implemented Single-Source and Real-time Frames like independent Transcoding Modes. Linked -video_source attribute for activating these modes Single-Source Mode , transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller segments for streaming Real-time Frames Mode , directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller segments for streaming Added separate functions, stream() for Real-time Frame Mode and transcode_source() for Single-Source Mode for easy transcoding. Included auto-colorspace detection and RGB Mode like features (extracted from WriteGear) , into StreamGear. New StreamGear Parameters: Developed several new parameters such as: output : handles assets directory formats : handles adaptive HTTP streaming format. custom_ffmpeg : handles custom FFmpeg location. stream_params : handles internal and FFmpeg parameter seamlessly. logging : turns logging on or off. New stream_params parameter allows us to exploit almost all FFmpeg parameters and flexibly change its internal settings, and seamlessly generating high-quality streams with its attributes: -streams (list of dictionaries) for building additional streams with -resolution , -video_bitrate & -framerate like sub-attributes. -audio for specifying external audio. -video_source for specifying Single-Source Mode source. -input_framerate for handling input framerate in Real-time Frames Mode. -bpp attribute for handling bits-per-pixels used to auto-calculate video-bitrate. -gop to manually specify GOP length. -ffmpeg_download_path to handle custom FFmpeg download path on windows. -clear_prev_assets to remove any previous copies of SteamGear Assets. New StreamGear docs, MPEG-DASH demo, and recommended DASH players list: Added new StreamGear docs, usage examples, parameters, references, new FAQs. Added Several StreamGear usage examples w.r.t Mode of Operation. Implemented Clappr based on Shaka-Player , as Demo Player. Added Adaptive-dimensional behavior for Demo-player, purely in css. Hosted StreamGear generated DASH chunks on GitHub and served with raw.githack.com . Introduced variable quality level-selector plugin for Clapper Player. Provide various required javascripts and implemented additional functionality for player in extra.js . Recommended tested Online, Command-line and GUI Adaptive Stream players. Implemented separate FFmpeg installation doc for StreamGear API. Reduced rebufferingGoal for faster response. New StreamGear CI tests: Added IO and API initialization CI tests for its Modes. Added various mode Streaming check CI tests. NetGear_Async API: Added new send_terminate_signal internal method. Added WindowsSelectorEventLoopPolicy() for windows 3.8+ envs. Moved Client auto-termination to separate method. Implemented graceful termination with signal API on UNIX machines. Added new timeout attribute for controlling Timeout in Connections. Added missing termination optimizer ( linger=0 ) flag. Several ZMQ Optimizer Flags added to boost performance. WriteGear API: Added support for adding duplicate FFmpeg parameters to output_params : Added new -clones attribute in output_params parameter for handing this behavior.. Support to pass FFmpeg parameters as list, while maintaining the exact order it was specified. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Added new CI tests debugging this behavior. Updated docs accordingly. Added support for Networks URLs in Compression Mode: output_filename parameter supports Networks URLs in compression modes only Added automated handling of non path/file Networks URLs as input. Implemented new is_valid_url helper method to easily validate assigned URLs value. Validates whether the given URL value has scheme/protocol supported by assigned/installed ffmpeg or not. WriteGear will throw ValueError if -output_filename is not supported. Added related CI tests and docs. Added disable_force_termination attribute in WriteGear to disable force-termination. NetGear API: Added option to completely disable Native Frame-Compression: Checks if any Incorrect/Invalid value is assigned on compression_format attribute. Completely disables Native Frame-Compression. Updated docs accordingly. CamGear API: Added new and robust regex for identifying YouTube URLs. Moved youtube_url_validator to Helper. New helper.py methods: Added validate_video function to validate video_source. Added extract_time Extract time from give string value. Added get_video_bitrate to calculate video birate from resolution, framerate, bits-per-pixels values. Added delete_safe to safely delete files of given extension. Added validate_audio to validate audio source. Added new Helper CI tests. Added new check_valid_mpd function to test MPD files validity. Added mpegdash library to CI requirements. Deployed New Docs Upgrades: Added new assets like images, gifs, custom scripts, javascripts fonts etc. for achieving better visual graphics in docs. Added clappr.min.js , dash-shaka-playback.js , clappr-level-selector.min.js third-party javascripts locally. Extended Overview docs Hyperlinks to include all major sub-pages (such as Usage Examples, Reference, FAQs etc.) . Replaced GIF with interactive MPEG-DASH Video Example in Stabilizer Docs. Added new pymdownx.keys to replace [Ctrl+C]/[\u2318+C] formats. Added new custom.css stylescripts variables for fluid animations in docs. Overridden announce bar and added donation button. Lossless WEBP compressed all PNG assets for faster loading. Enabled lazy-loading for GIFS and Images for performance. Reimplemented Admonitions contexts and added new ones. Added StreamGear and its different modes Docs Assets. Added patch for images & unicodes for PiP flavored markdown in setup.py . Added Request Info and Welcome GitHub Apps to automate PR and issue workflow Added new config.yml for customizations. Added various suitable configurations. Added new -clones attribute to handle FFmpeg parameter clones in StreamGear and WriteGear API. Added new Video-only and Audio-Only sources in bash script. Added new paths in bash script for storing StreamGear & WriteGear assets temporarily. Updates/Improvements \u00b6 Added patch for NotImplementedError in NetGear_Async API on Windows 3.8+ envs. Check for valid output file extension according to format selected in StreamGear. Completed migration to travis.com . Created new temp_write temp directory for WriteGear Assets in bash script. Deleted old Redundant assets and added new ones. Employed isort library to sort and group imports in Vidgear APIs. Enabled exception for list, tuple, int, float in WriteGear API's output_params dict. Enabled missing support for frame-compression in its primary Receive Mode. Enforced pixel formats for streams. Improved check for valid system path detection in WriteGear API. Overrided pytest-asyncio fixture in NetGear_Async API. Quoted Gear Headline for understanding each gear easily. Re-Positioned Gear's banner images in overview for better readability. Reduced redundant try-except blocks in NetGear Async. Reformatted and Simplified Docs context. Reimplemented return_testvideo_path CI function with variable streams. Reimplemented skip_loop in NetGear_Async to fix asyncio.CancelledError . Reimplemented buggy audio handler in StreamGear. Reimplemented images with <figure> and <figurecaption> like tags. Removed Python < 3.8 condition from all CI tests. Removed or Grouped redundant code for increasing codecov. Removed redundant code and simplified algorithmic complexities in Gears. Replaced ;nbsp with ;thinsp and ;emsp . Replaced IOError with more reliable RuntimeError in StreamGear Pipelines. Replaced del with pop in dicts. Replaced all Netgear CI tests with more reliable try-except-final blocks. Replaced simple lists with pymdownx.tasklist . Replaced subprocess call() with run() for better error handling in execute_ffmpeg_cmd function. Resized over-sized docs images. Simplified delete_safe Helper function. Simplified default audio-bitrate logic in StreamGear Updated CI tests and cleared redundant code from NetGear_Async API. Updated CI with new tests and Bumped Codecov. Updated Issue and PR templates. Updated Licenses for new files and shrink images dimensions. Updated Missing Helpful tips and increased logging. Updated PR guidelines for more clarity. Updated WebGear examples addresses from 0.0.0.0 to localhost . Updated WriteGear and StreamGear CI tests for not supporting temp directory. Updated README.md and changelog.md with new changes. Updated check_output and added force_retrieve_stderr support to **kwargs to extract stderr output even on FFmpeg error. Updated dicts2args to support internal repeated coreX FFmpeg parameters for StreamGear. Updated mkdocs.yml , changelog.md and README.md with latest changes. Updated validate_audio Helper function will now retrieve audio-bitrate for validation. Updated buggy mpegdash dependency with custom dev fork for Windows machines. Updated core parameters for audio handling. Updated logging for debugging selected eventloops in NetGear_Async API. Updated termination linger to zero at Server's end. Breaking Updates/Changes \u00b6 Changed Webgear API default address to localhost for cross-compatibility between different platforms. In Netgear_Async API, source value can now be NoneType for a custom frame-generator at Server-end only. Temp (such as /tmp in linux) is now not a valid directory for WriteGear & StreamGear API outputs. Moved vidgear docs assets (i.e images, gifs, javascripts and stylescripts) to override directory. Bug-fixes \u00b6 Added workaround for system path not handle correctly. Fixed Bug: URL Audio format not being handled properly. Fixed Critical Bug in NetGear_Async throwing ValueError with None-type Source. Fixed Critical StreamGear Bug: FFmpeg pipeline terminating prematurely in Single-Source Mode. Fixed Critical external audio handler bug: moved audio-input to input_parameters. Fixed Frozen-threads bug in CI tests. Fixed Mkdocs only accepting Relative paths. Fixed OSError in WriteGear's compression mode. Fixed StreamGear CI bugs for Windows and CI envs. Fixed Typos and Indentation bugs in NetGear API. Fixed ZMQ throwing error on termination if all max-tries exhausted. Fixed NameError bug in NetGear API and CI tests. Fixed TimeoutError bug in NetGear_Async CI tests. Fixed get_valid_ffmpeg_path throwing TypeError with non-string values. Fixed broken links in docs. Fixed critical duplicate logging bug. Fixed default gop value not handle correctly. Fixed handling of incorrect paths detection. Fixed incorrect definitions in NetGear_Async. Fixed left-over attribute bug in WriteGear. Fixed logic and indentation bugs in CI tests. Fixed logic for handling output parameters in WriteGear API. Fixed missing definitions and logic bug in StreamGear. Fixed missing import and incorrect CI definitions. Fixed missing source dimensions from extract_resolutions output in StreamGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed round off error in FPS. Fixed several CI bugs and updated extract_resolutions method. Fixed several bugs from CI Bidirectional Mode tests. Fixed several typos in docs usage examples. Fixed various AttributeError with wrong attribute names and definition in CI Helper functions. Fixed wrong and missing definitions in docs. Fixed wrong logic for extracting OpenCV frames. Fixed wrong type bug in StreamGear API. Fixed wrong type error bug in WriteGear API. Fixed wrong variable assignments bug in WriteGear API. Fixes to CLI tests and missing docs imports. Many minor typos and wrong definitions. Pull Requests \u00b6 PR #129 PR #130 PR #155 v0.1.8 (2020-06-12) \u00b6 New Features \u00b6 Multiple Clients support in NetGear API: Implemented support for handling any number of Clients simultaneously with a single Server in this mode. Added new multiclient_mode attribute for enabling this mode easily. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Implemented ability to receive data from all Client(s) along with frames with zmq.REQ/zmq.REP pattern only. Updated related CI tests Support for robust Lazy Pirate pattern(auto-reconnection) in NetGear API for both server and client ends: Implemented a algorithm where NetGear rather than doing a blocking receive, will now: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Implemented its default support for REQ/REP and PAIR messaging patterns internally. Added new max_retries and request_timeout (in seconds) for handling polling. Added DONTWAIT flag for interruption-free data receiving. Both Server and Client can now reconnect even after a premature termination. Performance Updates for NetGear API: Added default Frame Compression support for Bidirectional frame transmission in Bidirectional mode. Added support for Reducer() function in Helper.py to aid reducing frame-size on-the-go for more performance. Added small delay in recv() function at client's end to reduce system load. Reworked and Optimized NetGear termination, and also removed/changed redundant definitions and flags. Docs Migration to Mkdocs: Implemented a beautiful, static documentation site based on MkDocs which will then be hosted on GitHub Pages. Crafted base mkdocs with third-party elegant & simplistic mkdocs-material theme. Implemented new mkdocs.yml for Mkdocs with relevant data. Added new docs folder to handle markdown pages and its assets. Added new Markdown pages( .md ) to docs folder, which are carefully crafted documents - [x] based on previous Wiki's docs, and some completely new additions. Added navigation under tabs for easily accessing each document. New Assets: Added new assets like gifs, images, custom scripts, favicons, site.webmanifest etc. for bringing standard and quality to docs visual design. Designed brand new logo and banner for VidGear Documents. Deployed all assets under separate Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License . Added Required Plugins and Extensions: Added support for all pymarkdown-extensions . Added support for some important admonition , attr_list , codehilite , def_list , footnotes , meta , and toc like Mkdocs extensions. Enabled search , minify and git-revision-date-localized plugins support. Added various VidGear's social links to yaml. Added support for en (English) language. Auto-Build API Reference with mkdocstrings: Added support for mkdocstrings plugin for auto-building each VidGear's API references. Added python handler for parsing python source-code to mkdocstrings . Auto-Deploy Docs with Github Actions: Implemented Automated Docs Deployment on gh-pages through GitHub Actions workflow. Added new workflow yaml with minimal configuration for automated docs deployment. Added all required python dependencies and environment for this workflow. Added master branch on Ubuntu machine to build matrix. Updates/Improvements \u00b6 Added in-built support for bidirectional frames( NDarray ) transfer in Bidirectional mode. Added support for User-Defined compression params in Bidirectional frames transfer. Added workaround for address already in use bug at client's end. Unified Bidirectional and Multi-Clients mode for client's return data transmission. Replaced ValueError with more suitable RuntimeError . Updated logging for better readability. Added CI test for Multi-Clients mode. Reformatted and grouped imports in VidGear. Added Reducer Helper function CI test. Added Reliability tests for both Server and Client end. Disabled reliable reconnection for Multi-Clients mode. Replaced os.devnull with suprocess's inbuilt function. Updated README.md, Issue and PR templates with new information and updates. Moved changelog.md to /docs and updated contribution guidelines. Improved source-code docs for compatibility with mkdocstrings . Added additional dependency mkdocs-exclude , for excluding files from Mkdocs builds. Updated license and compressed images/diagrams. Added new CI tests and Bumped Codecov. Changed YouTube video URL for CI tests to Creative Commons(CC) video. Removed redundant code. Breaking Updates/Changes \u00b6 VidGear Docs moved to GitHub Pages, Now Available at https://abhitronix.github.io/vidgear . Removed filter attribute from options parameter in NetGear API. Removed force_terminate parameter support from NetGear API. Disabled additional data of datatype numpy.ndarray for Server end in Bidirectional Mode. Bug-fixes \u00b6 Fixed 'NoneType' object is not subscriptable bug. Fixed bugs related to delayed termination in NetGear API. Reduced default request_timeout value to 4 and also lowered cut-off limit for the same. Removed redundant ZMQ context termination and similar variables. Added missing VidGear installation in workflow. Excluded conflicting assets README.md from Mkdocs builds. Fixed pattern value check bypassed if wrong value is assigned. Fixed incorrect handling of additional data transferred in synchronous mode at both Server and Client end. Replaced Netgear CI test with more reliable try-except-final blocks. Updated termination linger to zero at Server's end. Fixed NameError bug in NetGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed ZMQ throwing error on termination if all max-tries exhausted. Enabled missing support for frame compression in its primary receive mode. Fixed several bugs from CI Bidirectional Mode tests. Removed or Grouped redundant code for increasing codecov. Fixed Mkdocs only accepting Relative paths. Fixed broken links in docs. Fixed round off error in FPS. Many small typos and bugs fixes. Pull Requests \u00b6 PR #129 PR #130 v0.1.7 (2020-04-29) \u00b6 New Features \u00b6 WebGear API: Added a robust Live Video Server API that can transfer live video frames to any web browser on the network in real-time. Implemented a flexible asyncio wrapper around starlette ASGI Application Server. Added seamless access to various starlette's Response classes, Routing tables, Static Files, Template engine(with Jinja2), etc. Added a special internal access to VideoGear API and all its parameters. Implemented a new Auto-Generation Work-flow to generate/download & thereby validate WebGear API data files from its GitHub server automatically. Added on-the-go dictionary parameter in WebGear to tweak performance, Route Tables and other internal properties easily. Added new simple & elegant default Bootstrap Cover Template for WebGear Server. Added __main__.py to directly run WebGear Server through the terminal. Added new gif and related docs for WebGear API. Added and Updated various CI tests for this API. NetGear_Async API: Designed NetGear_Async asynchronous network API built upon ZeroMQ's asyncio API. Implemented support for state-of-the-art asyncio event loop uvloop at its backend. Achieved Unmatchable high-speed and lag-free video streaming over the network with minimal resource constraint. Added exclusive internal wrapper around VideoGear API for this API. Implemented complete server-client handling and options to use variable protocols/patterns for this API. Implemented support for all four ZeroMQ messaging patterns: i.e zmq.PAIR , zmq.REQ/zmq.REP , zmq.PUB/zmq.SUB , and zmq.PUSH/zmq.PULL . Implemented initial support for tcp and ipc protocols. Added new Coverage CI tests for NetGear_Async Network Gear. Added new Benchmark tests for benchmarking NetGear_Async against NetGear. Asynchronous Enhancements: Added asyncio package to for handling asynchronous APIs. Moved WebGear API(webgear.py) to asyncio and created separate asyncio helper.py for it. Various Performance tweaks for Asyncio APIs with concurrency within a single thread. Moved __main__.py to asyncio for easier access to WebGear API through the terminal. Updated setup.py with new dependencies and separated asyncio dependencies. General Enhancements: Added new highly-precise Threaded FPS class for accurate benchmarking with time.perf_counter python module. Added a new Gitter community channel. Added a new Reducer function to reduce the frame size on-the-go. Add Flake8 tests to Travis CI to find undefined names. (PR by @cclauss ) Added a new unified logging handler helper function for vidgear. Updates/Improvements \u00b6 Re-implemented and simplified logic for NetGear Async server-end. Added new dependencies for upcoming asyncio updates to setup.py . Added retry function and replaced wget with curl for Linux test envs. Bumped OpenCV to latest 4.2.0-dev for Linux test envs. Updated YAML files to reflect new changes to different CI envs. Separated each API logger with a common helper method to avoid multiple copies. Limited Importing OpenCV API version check's scope to helper.py only. Implemented case for incorrect color_space value in ScreenGear API. Removed old conflicting logging formatter with a common method and expanded logging. Improved and added shutdown function for safely stopping frame producer threads in WebGear API. Re-implemented and simplified all CI tests with maximum code-coverage in mind. Replaced old mkdir function with new mkdir_safe helper function for creating directories safely. Updated ReadMe.md with updated diagrams, gifs and information. Improve, structured and Simplified the Contribution Guidelines. Bundled CI requirements in a single command.(Suggested by @cclauss ) Replaced line endings CRLF with LF endings. Added dos2unix for Travis OSX envs. Bumped Codecov to maximum. Breaking Updates/Changes \u00b6 Dropped support for Python 3.5 and below legacies. (See issue #99 ) Dropped and replaced Python 3.5 matrices with new Python 3.8 matrices in all CI environments. Implemented PEP-8 Styled Black formatting throughout the source-code. Limited protocols support to tcp and ipc only, in NetGear API. Bug-fixes \u00b6 Fixed Major NetGear_Async bug where __address and __port are not set in async mode.(PR by @otter-in-a-suit ) Fixed Major PiGear Color-space Conversion logic bug. Workaround for CAP_IMAGES error in YouTube Mode. Replaced incorrect terminate() with join() in PiGear. Removed uvloop for windows as still NOT yet supported . Refactored Asynchronous Package name async to asyncio , since it is used as Keyword in python>=3.7 (raises SyntaxError) . Fixed unfinished close of event loops bug in WebGear API. Fixed NameError in helper.py. Added fix for OpenCV installer failure on Linux test envs. Fixed undefined NameError in helper.py context. ( @cclauss ) Fixed incorrect logic while pulling frames from ScreenGear API. Fixed missing functions in __main__.py . Fixed Typos and definitions in docs. Added missing camera_num parameter to VideoGear. Added OpenSSL's [SSL: CERTIFICATE_VERIFY_FAILED] bug workaround for macOS envs. Removed download_url meta from setup.py. Removed PiGear from CI completely due to hardware emulation limitation. Removed VideoCapture benchmark tests for macOS envs. Removed trivial __main__.py from codecov. Removed several redundant try-catch loops. Renamed youtube_url_validation as youtube_url_validator . Several minor wrong/duplicate variable definitions and various bugs fixed. Fixed, Improved & removed many Redundant CI tests for various APIs. Pull Requests \u00b6 PR #88 PR #91 PR #93 PR #95 PR #98 PR #101 PR #114 PR #118 PR #124 v0.1.6 (2020-01-01) \u00b6 New Features \u00b6 NetGear API: Added powerful ZMQ Authentication & Data Encryption features for NetGear API: Added exclusive secure_mode param for enabling it. Added support for two most powerful Stonehouse & Ironhouse ZMQ security mechanisms. Added smart auth-certificates/key generation and validation features. Implemented Robust Multi-Servers support for NetGear API: Enables Multiple Servers messaging support with a single client. Added exclusive multiserver_mode param for enabling it. Added support for REQ/REP & PUB/SUB patterns for this mode. Added ability to send additional data of any datatype along with the frame in realtime in this mode. Introducing exclusive Bidirectional Mode for bidirectional data transmission: Added new return_data parameter to recv() function. Added new bidirectional_mode attribute for enabling this mode. Added support for PAIR & REQ/REP patterns for this mode Added support for sending data of any python datatype. Added support for message parameter for non-exclusive primary modes for this mode. Implemented compression support with on-the-fly flexible frame encoding for the Server-end: Added initial support for JPEG , PNG & BMP encoding formats . Added exclusive options attribute compression_format & compression_param to tweak this feature. Client-end will now decode frame automatically based on the encoding as well as support decoding flags. Added force_terminate attribute flag for handling force socket termination at the Server-end if there's latency in the network. Implemented new Publish/Subscribe( zmq.PUB/zmq.SUB ) pattern for seamless Live Streaming in NetGear API. PiGear API: Added new threaded internal timing function for PiGear to handle any hardware failures/frozen threads. PiGear will not exit safely with SystemError if Picamera ribbon cable is pulled out to save resources. Added support for new user-defined HWFAILURE_TIMEOUT options attribute to alter timeout. VideoGear API: Added framerate global variable and removed redundant function. Added CROP_N_ZOOM attribute in Videogear API for supporting Crop and Zoom stabilizer feature. WriteGear API: Added new execute_ffmpeg_cmd function to pass a custom command to its FFmpeg pipeline. Stabilizer class: Added new Crop and Zoom feature. Added crop_n_zoom param for enabling this feature. Updated docs. CI & Tests updates: Replaced python 3.5 matrices with latest python 3.8 matrices in Linux environment. Added full support for Codecov in all CI environments. Updated OpenCV to v4.2.0-pre(master branch). Added various Netgear API tests. Added initial Screengear API test. More test RTSP feeds added with better error handling in CamGear network test. Added tests for ZMQ authentication certificate generation. Added badge and Minor doc updates. Added VidGear's official native support for MacOS environments. Updates/Improvements \u00b6 Replace print logging commands with python's logging module completely. Implemented encapsulation for class functions and variables on all gears. Updated support for screen casting from multiple/all monitors in ScreenGear API. Updated ScreenGear API to use Threaded Queue Mode by default, thereby removed redundant THREADED_QUEUE_MODE param. Updated bash script path to download test dataset in $TMPDIR rather than $HOME directory for downloading testdata. Implemented better error handling of colorspace in various videocapture APIs. Updated bash scripts, Moved FFmpeg static binaries to github.com . Updated bash scripts, Added additional flag to support un-secure apt sources. CamGear API will now throw RuntimeError if source provided is invalid. Updated threaded Queue mode in CamGear API for more robust performance. Added new camera_num to support multiple Picameras. Moved thread exceptions to the main thread and then re-raised. Added alternate github mirror for FFmpeg static binaries auto-installation on windows oses. Added colorlog python module for presentable colored logging. Replaced traceback with sys.exc_info . Overall APIs Code and Docs optimizations. Updated Code Readability and Wiki Docs. Updated ReadMe & Changelog with the latest changes. Updated Travis CI Tests with support for macOS environment. Reformatted & implemented necessary MacOS related changes and dependencies in travis.yml . Breaking Updates/Changes \u00b6 Warning Python 2.7 legacy support dropped completely. Source-code Relicensed to Apache 2.0 License. Python 3+ are only supported legacies for installing v0.1.6 and above. Python 2.7 and 3.4 legacies support dropped from CI tests. Bug-fixes \u00b6 Reimplemented Pub/Sub pattern for smoother performance on various networks. Fixed Assertion error in CamGear API during colorspace manipulation. Fixed random freezing in Secure Mode and several related performance updates Fixed multiserver_mode not working properly over some networks. Fixed assigned Port address ignored bug (commit 073bca1). Fixed several wrong definition bugs from NetGear API(commit 8f7153c). Fixed unreliable dataset video URL(rehosted file on github.com ). Disabled overwrite_cert for client-end in NetGear API. Disabled Universal Python wheel builds in setup.cfg file. Removed duplicate code to import MSS( @BoboTiG ) from ScreenGear API. Eliminated unused redundant code blocks from library. Fixed Code indentation in setup.py and updated new release information. Fixed code definitions & Typos. Fixed several bugs related to secure_mode & multiserver_mode Modes. Fixed various macOS environment bugs. Pull Requests \u00b6 PR #39 PR #42 PR #44 PR #52 PR #55 PR #62 PR #67 PR #72 PR #77 PR #78 PR #82 PR #84 v0.1.5 (2019-07-24) \u00b6 New Features \u00b6 Added new ScreenGear API, supports Live ScreenCasting. Added new NetGear API, aids real-time frame transfer through messaging(ZmQ) over network. Added new new Stabilizer Class, for minimum latency Video Stabilization with OpenCV. Added Option to use API's standalone. Added Option to use VideoGear API as internal wrapper around Stabilizer Class. Added new parameter stabilize to API, to enable or disable Video Stabilization. Added support for **option dict attributes to update VidGear's video stabilizer parameters directly. Added brand new logo and functional block diagram ( .svg ) in readme.md Added new pictures and GIFs for improving readme.md readability Added new contributing.md and changelog.md for reference. Added collections.deque import in Threaded Queue Mode for performance consideration Added new install_opencv.sh bash scripts for Travis cli, to handle OpenCV installation. Added new Project Issue & PR Templates Added new Sponsor Button( FUNDING.yml ) Updates/Improvements \u00b6 Updated New dependencies: mss , pyzmq and rejected redundant ones. Revamped and refreshed look for readme.md and added new badges. Updated Releases Documentation completely. Updated CI tests for new changes Updated Code Documentation. Updated bash scripts and removed redundant information Updated Youtube video URL in tests Completely Reformatted and Updated Wiki Docs with new changes. Breaking Updates/Changes \u00b6 Implemented experimental Threaded Queue Mode( a.k.a Blocking Mode ) for fast, synchronized, error-free multi-threading. Renamed bash script pre-install.sh to prepare_dataset.sh - [x] downloads opensourced test datasets and static FFmpeg binaries for debugging. Changed script folder location to bash/script . Python 3.4 removed from Travis CI tests. Bug-fixes \u00b6 Temporarily fixed Travis CI bug: Replaced opencv-contrib-python with OpenCV built from scratch as dependency. Fixed CI Timeout Bug: Disable Threaded Queue Mode for CI Tests Fixes** sys.stderr.close() throws ValueError bug: Replaced sys.close() with DEVNULL.close() Fixed Youtube Live Stream bug that return NonType frames in CamGear API. Fixed NoneType frames bug in PiGear class on initialization. Fixed Wrong function definitions Removed /xe2 unicode bug from Stabilizer class. Fixed **output_params KeyError bug in WriteGear API Fixed subprocess not closing properly on exit in WriteGear API. Fixed bugs in ScreenGear: Non-negative monitor values Fixed missing import, typos, wrong variable definitions Removed redundant hack from setup.py Fixed Minor YouTube playback Test CI Bug Fixed new Twitter Intent Fixed bug in bash script that not working properly due to changes at server end. Pull Requests \u00b6 PR #17 PR #21 PR #22 PR #27 PR #31 PR #32 PR #33 PR #34 v0.1.4 (2019-05-11) \u00b6 New Features \u00b6 Added new WriteGear API: for enabling lossless video encoding and compression(built around FFmpeg and OpenCV Video Writer) Added YouTube Mode for direct Video Pipelining from YouTube in CamGear API Added new y_tube to access YouTube Mode in CamGear API. Added flexible Output file Compression control capabilities in compression-mode(WriteGear). Added -output_dimensions special parameter to WriteGear API. Added new helper.py to handle special helper functions. Added feature to auto-download and configure FFmpeg Static binaries(if not found) on Windows platforms. Added -input_framerate special parameter to WriteGear class to change/control output constant framerate in compression mode(WriteGear). Added new Direct Video colorspace Conversion capabilities in CamGear and PiGear API. Added new framerate class variable for CamGear API, to retrieve input framerate. Added new parameter backend - [x] changes the backend of CamGear's API Added automatic required prerequisites installation ability, when installation from source. Added Travis CI Complete Integration for Linux-based Testing for VidGear. Added and configured travis.yml Added Appveyor CI Complete Integration for Windows-based Testing in VidGear. Added and configured new appveyor.yml Added new bash script pre-install.sh to download opensourced test datasets and static FFmpeg binaries for debugging. Added several new Tests(including Benchmarking Tests) for each API for testing with pytest . Added license to code docs. Added Say Thank you! badge to readme. Updates/Improvements \u00b6 Removed redundant dependencies Updated youtube-dl as a dependency, as required by pafy 's backend. Updated common VideoGear API with new parameter. Update robust algorithm to auto-detect FFmpeg executables and test them, if failed, auto fallback to OpenCV's VideoWriter API. Improved system previously installed OpenCV detection in setup.py. Updated setup.py with hack to remove bullets from pypi description. Updated Code Documentation Reformatted & Modernized readme.md with new badges. Reformatted and Updated Wiki Docs. Breaking Updates/Changes \u00b6 Bugs Patched: Removed unnecessary -height and -width parameter from CamGear API. Replaced dependency opencv-python with opencv-contrib-python completely Bug-fixes \u00b6 Windows Cross-Platform fix: replaced dependency os with platform in setup.py. Fixed Bug: Arises due to spaces in input **options / **output_param dictionary keys. Fixed several wrong/missing variable & function definitions. Fixed code uneven indentation. Fixed several typos in docs. Pull Requests \u00b6 PR #7 PR #8 PR #10 PR #12 v0.1.3 (2019-04-07) \u00b6 Bug-fixes \u00b6 Patched Major PiGear Bug: Incorrect import of PiRGBArray function in PiGear Class Several Fixes** for backend picamera API handling during frame capture(PiGear) Fixed missing frame variable initialization. Fixed minor typos Pull Requests \u00b6 PR #6 PR #5 v0.1.2 (2019-03-27) \u00b6 New Features \u00b6 Added easy Source manipulation feature in CamGear API, to control features like resolution, brightness, framerate etc. Added new **option parameter to CamGear API, provides the flexibility to manipulate input stream directly. Added new parameters for Camgear API for time delay and logging. Added new Logo to readme.md Added new Wiki Documentation. Updates/Improvements \u00b6 Reformatted readme.md. Updated Wiki Docs with new changes. Bug-fixes \u00b6 Improved Error Handling in CamGear & PiGear API. Fixed minor typos in docs. Pull Requests \u00b6 PR #4 v0.1.1 (2019-03-24) \u00b6 New Features \u00b6 Release ViGear binaries on the Python Package Index (PyPI) Added new and configured setup.py & setup.cfg Bug-fixes \u00b6 Fixed PEP bugs: added and configured properly __init__.py in each folder Fixed PEP bugs: improved code Indentation Fixed wrong imports: replaced distutils.core with setuptools Fixed readme.md v0.1.0 (2019-03-17) \u00b6 New Features \u00b6 Initial Release Converted my imutils PR into Python Project. Renamed conventions and reformatted complete source-code from scratch. Added support for both python 2.7 and 3 legacies Added new multi-threaded CamGear, PiGear, and VideoGear APIs Added multi-platform compatibility Added robust & flexible control over the source in PiGear API.","title":"Release Notes"},{"location":"changelog/#release-notes","text":"","title":"Release Notes"},{"location":"changelog/#v020-in-progress","text":"","title":"v0.2.0 (In Progress)"},{"location":"changelog/#new-features","text":"CamGear API: Support for various Live-Video-Streaming services: Added seamless support for live video streaming sites like Twitch, LiveStream, Dailymotion etc. Implemented flexible framework around streamlink python library with easy control over parameters and quality. Stream Mode can now automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Re-implemented YouTube URLs Handler: Re-implemented CamGear's YouTube URLs Handler completely from scratch. New Robust Logic to flexibly handing video and video-audio streams. Intelligent stream selector for selecting best possible stream compatible with OpenCV. Added support for selecting stream qualities and parameters. Implemented new get_supported_quality helper method for handling specified qualities Fixed Live-Stream URLs not supported by OpenCV's Videocapture and its FFmpeg. Added additional STREAM_QUALITY and STREAM_PARAMS attributes. ScreenGear API: Multiple Backends Support: Added new multiple backend support with new pyscreenshot python library. Made pyscreenshot the default API for ScreenGear, replaces mss . Added new backend parameter for this feature while retaining previous behavior. Added native automated RGB to BGR conversion for default PIL backend. Kept support for old mss for old compatibility and multi-screen support. Added native dimensional support for multi-screen. Added support all input from all multiple screens. Updated ScreenGear Docs. Updated ScreenGear CI tests. StreamGear API: Changed default behaviour to support complete video transcoding. Added -livestream attribute to support live-streaming. Added additional parameters for -livestream attribute functionality. Updated StreamGear Tests. Updated StreamGear docs. Stabilizer Class: New Robust Error Handling with Blank Frames: Elegantly handles all crashes due to Empty/Blank/Dark frames. Stabilizer throws Warning with this new behavior instead of crashing. Updated CI test for this feature. Docs: Automated Docs Versioning: Implemented Docs versioning through mike API. Separate new workflow steps to handle different versions. Updated docs deploy worflow to support release and dev builds. Added automatic version extraction from github events. Added version-select.js and version-select.css files. Toggleable Dark-White Docs Support: Toggle-button to easily switch dark, white and preferred theme. New Updated Assets for dark backgrounds New css, js files/content to implement this behavior. New material icons for button. Updated scheme to slate in mkdocs.yml . New Theme and assets: New purple theme with dark-purple accent color. New images assets with updated transparent background. Support for both dark and white theme. Increased rebufferingGoal for dash videos. New updated custom 404 page for docs. Issue and PR automated-bots changes New need_info.yml YAML Workflow. New needs-more-info.yml Request-Info template. Replaced Request-Info templates. Improved PR and Issue welcome formatting. Added custom HTML pages. Added show_root_heading flag to disable headings in References. Added new inserAfter function to version-select.js. Adjusted hue for dark-theme for better contrast. New usage examples and FAQs. Added gitmoji for commits. Continuous Integration: Maintenance Updates: Added support for new VIDGEAR_LOGFILE environment variable in Travis CI. Added missing CI tests. Added logging for helper functions. Azure-Pipeline workflow for MacOS envs Added Azure-Pipeline Workflow for testing MacOS environment. Added codecov support. GitHub Actions workflow for Linux envs Added GitHub Action work-flow for testing Linux environment. New YAML to implement GitHub Action workflow for python 3.6, 3.7, 3,8 & 3.9 matrices. Added Upload coverage to Codecov GitHub Action workflow. New codecov-bash uploader for Azure Pipelines. Logging: Added file support Added VIDGEAR_LOGFILE environment variable to manually add file/dir path. Reworked logger_handler() Helper methods (in asyncio too). Added new formatter and Filehandler for handling logger files. Added restore_levelnames auxiliary method for restoring logging levelnames. Added auto version extraction from package version.py in setup.py.","title":"New Features"},{"location":"changelog/#updatesimprovements","text":"Added missing Lazy-pirate auto-reconnection support for Multi-Servers and Multi-Clients Mode in NetGear API. Added new FFmpeg test path to Bash-Script and updated README broken links. Asset Cleanup: Removed all third-party javascripts from projects. Linked all third-party javascript directly. Cleaned up necessary code from CSS and JS files. Removed any copyrighted material or links. Rewritten Docs from scratch: Improved complete docs formatting. Simplified language for easier understanding. Fixed mkdocstrings showing root headings. Included all APIs methods to mkdocstrings docs. Removed unnecessary information from docs. Corrected Spelling and typos. Fixed context and grammar. Removed motivation.md . Renamed many terms. Fixed hyper-links. Reformatted missing or improper information. Fixed context and spellings in Docs files. Simplified language for easy understanding. Updated image sizes for better visibility. Bash Script: Updated to Latest OpenCV Binaries version and related changes Docs: Moved version-selector to header and changed default to alias. Docs: Updated deploy_docs.yml for releasing dev, stable, and release versions. Re-implemented overridden material theme. Updated docs with all new additions and examples. CamGear: CI Stream Mode test updated. Updated ReadMe.md badges. Updated CI tests. Updated setup.py with new features. Updated contributing.md and ReadMe.md . Updated OpenCV version to 4.5.1-dev in bash scripts Updated changelog.md . Moved WebGear API to Streaming Gears. Bumped Codecov. UI changes to version-select.js Docs: Retitle the versions and mkdocs.yml formatting updated. Docs: Version Selector UI reworked and other minor changes.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges","text":"y_tube parameter renamed as stream_mode in CamGear API! Removed Travis support and travis.yml deleted.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes","text":"Fixed StreamGear API Limited Segments Bug Fixed Missing links in docs and bump up version. CI: Fixed Appveyor need newer VM image to support Python 3.9.x matrix. ScreenGear BugFix: Fixed Error Handling and updated CI Tests. Fixed improper mkdocs.yml variables. Fixed GStreamer plugin support in bash scripts. Fixed typos in YAMLs and docs. Docs: Fixed Docs Deployer YAML bug for CI envs. Fixed wrong import in YAML. Fixed visible hyperlink on hover in dark-toggle button. Docs: Deployer YAML bug fixed. Docs YAML: issue jimporter/mike#33 patched and fixed fetch-depth=0 . Docs: version-select.js bug fixed. Docs: UI Bugs Fixed. CI: Codecov bugfixes. Azure-Pipelines Codecov BugFixes. Fixed version.json not detecting properly in version-select.js . Fixed images not centered inside tag. Fixed Asset Colors. Fixed failing CI tests. Fixed Several logging bugs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests","text":"PR #164 PR #170 PR #173 PR #181 PR #183 PR #184","title":"Pull Requests"},{"location":"changelog/#v019-2020-08-31","text":"","title":"v0.1.9 (2020-08-31)"},{"location":"changelog/#new-features_1","text":"StreamGear API: New API that automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats. Implemented multi-platform , standalone, highly extensible and flexible wrapper around FFmpeg for generating chunked-encoded media segments of the media, and easily accessing almost all of its parameters. API automatically transcodes videos/audio files & real-time frames into a sequence of multiple smaller chunks/segments and also creates a Manifest file. Added initial support for MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) . Constructed default behavior in StreamGear, for auto-creating a Primary Stream of same resolution and framerate as source. Added TQDM progress bar in non-debugged output for visual representation of internal processes. Implemented several internal methods for preprocessing FFmpeg and internal parameters for producing streams. Several standalone internal checks to ensure robust performance. New terminate() function to terminate StremGear Safely. New StreamGear Dual Modes of Operation: Implemented Single-Source and Real-time Frames like independent Transcoding Modes. Linked -video_source attribute for activating these modes Single-Source Mode , transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller segments for streaming Real-time Frames Mode , directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller segments for streaming Added separate functions, stream() for Real-time Frame Mode and transcode_source() for Single-Source Mode for easy transcoding. Included auto-colorspace detection and RGB Mode like features (extracted from WriteGear) , into StreamGear. New StreamGear Parameters: Developed several new parameters such as: output : handles assets directory formats : handles adaptive HTTP streaming format. custom_ffmpeg : handles custom FFmpeg location. stream_params : handles internal and FFmpeg parameter seamlessly. logging : turns logging on or off. New stream_params parameter allows us to exploit almost all FFmpeg parameters and flexibly change its internal settings, and seamlessly generating high-quality streams with its attributes: -streams (list of dictionaries) for building additional streams with -resolution , -video_bitrate & -framerate like sub-attributes. -audio for specifying external audio. -video_source for specifying Single-Source Mode source. -input_framerate for handling input framerate in Real-time Frames Mode. -bpp attribute for handling bits-per-pixels used to auto-calculate video-bitrate. -gop to manually specify GOP length. -ffmpeg_download_path to handle custom FFmpeg download path on windows. -clear_prev_assets to remove any previous copies of SteamGear Assets. New StreamGear docs, MPEG-DASH demo, and recommended DASH players list: Added new StreamGear docs, usage examples, parameters, references, new FAQs. Added Several StreamGear usage examples w.r.t Mode of Operation. Implemented Clappr based on Shaka-Player , as Demo Player. Added Adaptive-dimensional behavior for Demo-player, purely in css. Hosted StreamGear generated DASH chunks on GitHub and served with raw.githack.com . Introduced variable quality level-selector plugin for Clapper Player. Provide various required javascripts and implemented additional functionality for player in extra.js . Recommended tested Online, Command-line and GUI Adaptive Stream players. Implemented separate FFmpeg installation doc for StreamGear API. Reduced rebufferingGoal for faster response. New StreamGear CI tests: Added IO and API initialization CI tests for its Modes. Added various mode Streaming check CI tests. NetGear_Async API: Added new send_terminate_signal internal method. Added WindowsSelectorEventLoopPolicy() for windows 3.8+ envs. Moved Client auto-termination to separate method. Implemented graceful termination with signal API on UNIX machines. Added new timeout attribute for controlling Timeout in Connections. Added missing termination optimizer ( linger=0 ) flag. Several ZMQ Optimizer Flags added to boost performance. WriteGear API: Added support for adding duplicate FFmpeg parameters to output_params : Added new -clones attribute in output_params parameter for handing this behavior.. Support to pass FFmpeg parameters as list, while maintaining the exact order it was specified. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Added new CI tests debugging this behavior. Updated docs accordingly. Added support for Networks URLs in Compression Mode: output_filename parameter supports Networks URLs in compression modes only Added automated handling of non path/file Networks URLs as input. Implemented new is_valid_url helper method to easily validate assigned URLs value. Validates whether the given URL value has scheme/protocol supported by assigned/installed ffmpeg or not. WriteGear will throw ValueError if -output_filename is not supported. Added related CI tests and docs. Added disable_force_termination attribute in WriteGear to disable force-termination. NetGear API: Added option to completely disable Native Frame-Compression: Checks if any Incorrect/Invalid value is assigned on compression_format attribute. Completely disables Native Frame-Compression. Updated docs accordingly. CamGear API: Added new and robust regex for identifying YouTube URLs. Moved youtube_url_validator to Helper. New helper.py methods: Added validate_video function to validate video_source. Added extract_time Extract time from give string value. Added get_video_bitrate to calculate video birate from resolution, framerate, bits-per-pixels values. Added delete_safe to safely delete files of given extension. Added validate_audio to validate audio source. Added new Helper CI tests. Added new check_valid_mpd function to test MPD files validity. Added mpegdash library to CI requirements. Deployed New Docs Upgrades: Added new assets like images, gifs, custom scripts, javascripts fonts etc. for achieving better visual graphics in docs. Added clappr.min.js , dash-shaka-playback.js , clappr-level-selector.min.js third-party javascripts locally. Extended Overview docs Hyperlinks to include all major sub-pages (such as Usage Examples, Reference, FAQs etc.) . Replaced GIF with interactive MPEG-DASH Video Example in Stabilizer Docs. Added new pymdownx.keys to replace [Ctrl+C]/[\u2318+C] formats. Added new custom.css stylescripts variables for fluid animations in docs. Overridden announce bar and added donation button. Lossless WEBP compressed all PNG assets for faster loading. Enabled lazy-loading for GIFS and Images for performance. Reimplemented Admonitions contexts and added new ones. Added StreamGear and its different modes Docs Assets. Added patch for images & unicodes for PiP flavored markdown in setup.py . Added Request Info and Welcome GitHub Apps to automate PR and issue workflow Added new config.yml for customizations. Added various suitable configurations. Added new -clones attribute to handle FFmpeg parameter clones in StreamGear and WriteGear API. Added new Video-only and Audio-Only sources in bash script. Added new paths in bash script for storing StreamGear & WriteGear assets temporarily.","title":"New Features"},{"location":"changelog/#updatesimprovements_1","text":"Added patch for NotImplementedError in NetGear_Async API on Windows 3.8+ envs. Check for valid output file extension according to format selected in StreamGear. Completed migration to travis.com . Created new temp_write temp directory for WriteGear Assets in bash script. Deleted old Redundant assets and added new ones. Employed isort library to sort and group imports in Vidgear APIs. Enabled exception for list, tuple, int, float in WriteGear API's output_params dict. Enabled missing support for frame-compression in its primary Receive Mode. Enforced pixel formats for streams. Improved check for valid system path detection in WriteGear API. Overrided pytest-asyncio fixture in NetGear_Async API. Quoted Gear Headline for understanding each gear easily. Re-Positioned Gear's banner images in overview for better readability. Reduced redundant try-except blocks in NetGear Async. Reformatted and Simplified Docs context. Reimplemented return_testvideo_path CI function with variable streams. Reimplemented skip_loop in NetGear_Async to fix asyncio.CancelledError . Reimplemented buggy audio handler in StreamGear. Reimplemented images with <figure> and <figurecaption> like tags. Removed Python < 3.8 condition from all CI tests. Removed or Grouped redundant code for increasing codecov. Removed redundant code and simplified algorithmic complexities in Gears. Replaced ;nbsp with ;thinsp and ;emsp . Replaced IOError with more reliable RuntimeError in StreamGear Pipelines. Replaced del with pop in dicts. Replaced all Netgear CI tests with more reliable try-except-final blocks. Replaced simple lists with pymdownx.tasklist . Replaced subprocess call() with run() for better error handling in execute_ffmpeg_cmd function. Resized over-sized docs images. Simplified delete_safe Helper function. Simplified default audio-bitrate logic in StreamGear Updated CI tests and cleared redundant code from NetGear_Async API. Updated CI with new tests and Bumped Codecov. Updated Issue and PR templates. Updated Licenses for new files and shrink images dimensions. Updated Missing Helpful tips and increased logging. Updated PR guidelines for more clarity. Updated WebGear examples addresses from 0.0.0.0 to localhost . Updated WriteGear and StreamGear CI tests for not supporting temp directory. Updated README.md and changelog.md with new changes. Updated check_output and added force_retrieve_stderr support to **kwargs to extract stderr output even on FFmpeg error. Updated dicts2args to support internal repeated coreX FFmpeg parameters for StreamGear. Updated mkdocs.yml , changelog.md and README.md with latest changes. Updated validate_audio Helper function will now retrieve audio-bitrate for validation. Updated buggy mpegdash dependency with custom dev fork for Windows machines. Updated core parameters for audio handling. Updated logging for debugging selected eventloops in NetGear_Async API. Updated termination linger to zero at Server's end.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_1","text":"Changed Webgear API default address to localhost for cross-compatibility between different platforms. In Netgear_Async API, source value can now be NoneType for a custom frame-generator at Server-end only. Temp (such as /tmp in linux) is now not a valid directory for WriteGear & StreamGear API outputs. Moved vidgear docs assets (i.e images, gifs, javascripts and stylescripts) to override directory.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_1","text":"Added workaround for system path not handle correctly. Fixed Bug: URL Audio format not being handled properly. Fixed Critical Bug in NetGear_Async throwing ValueError with None-type Source. Fixed Critical StreamGear Bug: FFmpeg pipeline terminating prematurely in Single-Source Mode. Fixed Critical external audio handler bug: moved audio-input to input_parameters. Fixed Frozen-threads bug in CI tests. Fixed Mkdocs only accepting Relative paths. Fixed OSError in WriteGear's compression mode. Fixed StreamGear CI bugs for Windows and CI envs. Fixed Typos and Indentation bugs in NetGear API. Fixed ZMQ throwing error on termination if all max-tries exhausted. Fixed NameError bug in NetGear API and CI tests. Fixed TimeoutError bug in NetGear_Async CI tests. Fixed get_valid_ffmpeg_path throwing TypeError with non-string values. Fixed broken links in docs. Fixed critical duplicate logging bug. Fixed default gop value not handle correctly. Fixed handling of incorrect paths detection. Fixed incorrect definitions in NetGear_Async. Fixed left-over attribute bug in WriteGear. Fixed logic and indentation bugs in CI tests. Fixed logic for handling output parameters in WriteGear API. Fixed missing definitions and logic bug in StreamGear. Fixed missing import and incorrect CI definitions. Fixed missing source dimensions from extract_resolutions output in StreamGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed round off error in FPS. Fixed several CI bugs and updated extract_resolutions method. Fixed several bugs from CI Bidirectional Mode tests. Fixed several typos in docs usage examples. Fixed various AttributeError with wrong attribute names and definition in CI Helper functions. Fixed wrong and missing definitions in docs. Fixed wrong logic for extracting OpenCV frames. Fixed wrong type bug in StreamGear API. Fixed wrong type error bug in WriteGear API. Fixed wrong variable assignments bug in WriteGear API. Fixes to CLI tests and missing docs imports. Many minor typos and wrong definitions.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_1","text":"PR #129 PR #130 PR #155","title":"Pull Requests"},{"location":"changelog/#v018-2020-06-12","text":"","title":"v0.1.8 (2020-06-12)"},{"location":"changelog/#new-features_2","text":"Multiple Clients support in NetGear API: Implemented support for handling any number of Clients simultaneously with a single Server in this mode. Added new multiclient_mode attribute for enabling this mode easily. Built support for zmq.REQ/zmq.REP and zmq.PUB/zmq.SUB patterns in this mode. Implemented ability to receive data from all Client(s) along with frames with zmq.REQ/zmq.REP pattern only. Updated related CI tests Support for robust Lazy Pirate pattern(auto-reconnection) in NetGear API for both server and client ends: Implemented a algorithm where NetGear rather than doing a blocking receive, will now: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Implemented its default support for REQ/REP and PAIR messaging patterns internally. Added new max_retries and request_timeout (in seconds) for handling polling. Added DONTWAIT flag for interruption-free data receiving. Both Server and Client can now reconnect even after a premature termination. Performance Updates for NetGear API: Added default Frame Compression support for Bidirectional frame transmission in Bidirectional mode. Added support for Reducer() function in Helper.py to aid reducing frame-size on-the-go for more performance. Added small delay in recv() function at client's end to reduce system load. Reworked and Optimized NetGear termination, and also removed/changed redundant definitions and flags. Docs Migration to Mkdocs: Implemented a beautiful, static documentation site based on MkDocs which will then be hosted on GitHub Pages. Crafted base mkdocs with third-party elegant & simplistic mkdocs-material theme. Implemented new mkdocs.yml for Mkdocs with relevant data. Added new docs folder to handle markdown pages and its assets. Added new Markdown pages( .md ) to docs folder, which are carefully crafted documents - [x] based on previous Wiki's docs, and some completely new additions. Added navigation under tabs for easily accessing each document. New Assets: Added new assets like gifs, images, custom scripts, favicons, site.webmanifest etc. for bringing standard and quality to docs visual design. Designed brand new logo and banner for VidGear Documents. Deployed all assets under separate Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License . Added Required Plugins and Extensions: Added support for all pymarkdown-extensions . Added support for some important admonition , attr_list , codehilite , def_list , footnotes , meta , and toc like Mkdocs extensions. Enabled search , minify and git-revision-date-localized plugins support. Added various VidGear's social links to yaml. Added support for en (English) language. Auto-Build API Reference with mkdocstrings: Added support for mkdocstrings plugin for auto-building each VidGear's API references. Added python handler for parsing python source-code to mkdocstrings . Auto-Deploy Docs with Github Actions: Implemented Automated Docs Deployment on gh-pages through GitHub Actions workflow. Added new workflow yaml with minimal configuration for automated docs deployment. Added all required python dependencies and environment for this workflow. Added master branch on Ubuntu machine to build matrix.","title":"New Features"},{"location":"changelog/#updatesimprovements_2","text":"Added in-built support for bidirectional frames( NDarray ) transfer in Bidirectional mode. Added support for User-Defined compression params in Bidirectional frames transfer. Added workaround for address already in use bug at client's end. Unified Bidirectional and Multi-Clients mode for client's return data transmission. Replaced ValueError with more suitable RuntimeError . Updated logging for better readability. Added CI test for Multi-Clients mode. Reformatted and grouped imports in VidGear. Added Reducer Helper function CI test. Added Reliability tests for both Server and Client end. Disabled reliable reconnection for Multi-Clients mode. Replaced os.devnull with suprocess's inbuilt function. Updated README.md, Issue and PR templates with new information and updates. Moved changelog.md to /docs and updated contribution guidelines. Improved source-code docs for compatibility with mkdocstrings . Added additional dependency mkdocs-exclude , for excluding files from Mkdocs builds. Updated license and compressed images/diagrams. Added new CI tests and Bumped Codecov. Changed YouTube video URL for CI tests to Creative Commons(CC) video. Removed redundant code.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_2","text":"VidGear Docs moved to GitHub Pages, Now Available at https://abhitronix.github.io/vidgear . Removed filter attribute from options parameter in NetGear API. Removed force_terminate parameter support from NetGear API. Disabled additional data of datatype numpy.ndarray for Server end in Bidirectional Mode.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_2","text":"Fixed 'NoneType' object is not subscriptable bug. Fixed bugs related to delayed termination in NetGear API. Reduced default request_timeout value to 4 and also lowered cut-off limit for the same. Removed redundant ZMQ context termination and similar variables. Added missing VidGear installation in workflow. Excluded conflicting assets README.md from Mkdocs builds. Fixed pattern value check bypassed if wrong value is assigned. Fixed incorrect handling of additional data transferred in synchronous mode at both Server and Client end. Replaced Netgear CI test with more reliable try-except-final blocks. Updated termination linger to zero at Server's end. Fixed NameError bug in NetGear API. Fixed missing support for compression parameters in Multi-Clients Mode. Fixed ZMQ throwing error on termination if all max-tries exhausted. Enabled missing support for frame compression in its primary receive mode. Fixed several bugs from CI Bidirectional Mode tests. Removed or Grouped redundant code for increasing codecov. Fixed Mkdocs only accepting Relative paths. Fixed broken links in docs. Fixed round off error in FPS. Many small typos and bugs fixes.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_2","text":"PR #129 PR #130","title":"Pull Requests"},{"location":"changelog/#v017-2020-04-29","text":"","title":"v0.1.7 (2020-04-29)"},{"location":"changelog/#new-features_3","text":"WebGear API: Added a robust Live Video Server API that can transfer live video frames to any web browser on the network in real-time. Implemented a flexible asyncio wrapper around starlette ASGI Application Server. Added seamless access to various starlette's Response classes, Routing tables, Static Files, Template engine(with Jinja2), etc. Added a special internal access to VideoGear API and all its parameters. Implemented a new Auto-Generation Work-flow to generate/download & thereby validate WebGear API data files from its GitHub server automatically. Added on-the-go dictionary parameter in WebGear to tweak performance, Route Tables and other internal properties easily. Added new simple & elegant default Bootstrap Cover Template for WebGear Server. Added __main__.py to directly run WebGear Server through the terminal. Added new gif and related docs for WebGear API. Added and Updated various CI tests for this API. NetGear_Async API: Designed NetGear_Async asynchronous network API built upon ZeroMQ's asyncio API. Implemented support for state-of-the-art asyncio event loop uvloop at its backend. Achieved Unmatchable high-speed and lag-free video streaming over the network with minimal resource constraint. Added exclusive internal wrapper around VideoGear API for this API. Implemented complete server-client handling and options to use variable protocols/patterns for this API. Implemented support for all four ZeroMQ messaging patterns: i.e zmq.PAIR , zmq.REQ/zmq.REP , zmq.PUB/zmq.SUB , and zmq.PUSH/zmq.PULL . Implemented initial support for tcp and ipc protocols. Added new Coverage CI tests for NetGear_Async Network Gear. Added new Benchmark tests for benchmarking NetGear_Async against NetGear. Asynchronous Enhancements: Added asyncio package to for handling asynchronous APIs. Moved WebGear API(webgear.py) to asyncio and created separate asyncio helper.py for it. Various Performance tweaks for Asyncio APIs with concurrency within a single thread. Moved __main__.py to asyncio for easier access to WebGear API through the terminal. Updated setup.py with new dependencies and separated asyncio dependencies. General Enhancements: Added new highly-precise Threaded FPS class for accurate benchmarking with time.perf_counter python module. Added a new Gitter community channel. Added a new Reducer function to reduce the frame size on-the-go. Add Flake8 tests to Travis CI to find undefined names. (PR by @cclauss ) Added a new unified logging handler helper function for vidgear.","title":"New Features"},{"location":"changelog/#updatesimprovements_3","text":"Re-implemented and simplified logic for NetGear Async server-end. Added new dependencies for upcoming asyncio updates to setup.py . Added retry function and replaced wget with curl for Linux test envs. Bumped OpenCV to latest 4.2.0-dev for Linux test envs. Updated YAML files to reflect new changes to different CI envs. Separated each API logger with a common helper method to avoid multiple copies. Limited Importing OpenCV API version check's scope to helper.py only. Implemented case for incorrect color_space value in ScreenGear API. Removed old conflicting logging formatter with a common method and expanded logging. Improved and added shutdown function for safely stopping frame producer threads in WebGear API. Re-implemented and simplified all CI tests with maximum code-coverage in mind. Replaced old mkdir function with new mkdir_safe helper function for creating directories safely. Updated ReadMe.md with updated diagrams, gifs and information. Improve, structured and Simplified the Contribution Guidelines. Bundled CI requirements in a single command.(Suggested by @cclauss ) Replaced line endings CRLF with LF endings. Added dos2unix for Travis OSX envs. Bumped Codecov to maximum.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_3","text":"Dropped support for Python 3.5 and below legacies. (See issue #99 ) Dropped and replaced Python 3.5 matrices with new Python 3.8 matrices in all CI environments. Implemented PEP-8 Styled Black formatting throughout the source-code. Limited protocols support to tcp and ipc only, in NetGear API.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_3","text":"Fixed Major NetGear_Async bug where __address and __port are not set in async mode.(PR by @otter-in-a-suit ) Fixed Major PiGear Color-space Conversion logic bug. Workaround for CAP_IMAGES error in YouTube Mode. Replaced incorrect terminate() with join() in PiGear. Removed uvloop for windows as still NOT yet supported . Refactored Asynchronous Package name async to asyncio , since it is used as Keyword in python>=3.7 (raises SyntaxError) . Fixed unfinished close of event loops bug in WebGear API. Fixed NameError in helper.py. Added fix for OpenCV installer failure on Linux test envs. Fixed undefined NameError in helper.py context. ( @cclauss ) Fixed incorrect logic while pulling frames from ScreenGear API. Fixed missing functions in __main__.py . Fixed Typos and definitions in docs. Added missing camera_num parameter to VideoGear. Added OpenSSL's [SSL: CERTIFICATE_VERIFY_FAILED] bug workaround for macOS envs. Removed download_url meta from setup.py. Removed PiGear from CI completely due to hardware emulation limitation. Removed VideoCapture benchmark tests for macOS envs. Removed trivial __main__.py from codecov. Removed several redundant try-catch loops. Renamed youtube_url_validation as youtube_url_validator . Several minor wrong/duplicate variable definitions and various bugs fixed. Fixed, Improved & removed many Redundant CI tests for various APIs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_3","text":"PR #88 PR #91 PR #93 PR #95 PR #98 PR #101 PR #114 PR #118 PR #124","title":"Pull Requests"},{"location":"changelog/#v016-2020-01-01","text":"","title":"v0.1.6 (2020-01-01)"},{"location":"changelog/#new-features_4","text":"NetGear API: Added powerful ZMQ Authentication & Data Encryption features for NetGear API: Added exclusive secure_mode param for enabling it. Added support for two most powerful Stonehouse & Ironhouse ZMQ security mechanisms. Added smart auth-certificates/key generation and validation features. Implemented Robust Multi-Servers support for NetGear API: Enables Multiple Servers messaging support with a single client. Added exclusive multiserver_mode param for enabling it. Added support for REQ/REP & PUB/SUB patterns for this mode. Added ability to send additional data of any datatype along with the frame in realtime in this mode. Introducing exclusive Bidirectional Mode for bidirectional data transmission: Added new return_data parameter to recv() function. Added new bidirectional_mode attribute for enabling this mode. Added support for PAIR & REQ/REP patterns for this mode Added support for sending data of any python datatype. Added support for message parameter for non-exclusive primary modes for this mode. Implemented compression support with on-the-fly flexible frame encoding for the Server-end: Added initial support for JPEG , PNG & BMP encoding formats . Added exclusive options attribute compression_format & compression_param to tweak this feature. Client-end will now decode frame automatically based on the encoding as well as support decoding flags. Added force_terminate attribute flag for handling force socket termination at the Server-end if there's latency in the network. Implemented new Publish/Subscribe( zmq.PUB/zmq.SUB ) pattern for seamless Live Streaming in NetGear API. PiGear API: Added new threaded internal timing function for PiGear to handle any hardware failures/frozen threads. PiGear will not exit safely with SystemError if Picamera ribbon cable is pulled out to save resources. Added support for new user-defined HWFAILURE_TIMEOUT options attribute to alter timeout. VideoGear API: Added framerate global variable and removed redundant function. Added CROP_N_ZOOM attribute in Videogear API for supporting Crop and Zoom stabilizer feature. WriteGear API: Added new execute_ffmpeg_cmd function to pass a custom command to its FFmpeg pipeline. Stabilizer class: Added new Crop and Zoom feature. Added crop_n_zoom param for enabling this feature. Updated docs. CI & Tests updates: Replaced python 3.5 matrices with latest python 3.8 matrices in Linux environment. Added full support for Codecov in all CI environments. Updated OpenCV to v4.2.0-pre(master branch). Added various Netgear API tests. Added initial Screengear API test. More test RTSP feeds added with better error handling in CamGear network test. Added tests for ZMQ authentication certificate generation. Added badge and Minor doc updates. Added VidGear's official native support for MacOS environments.","title":"New Features"},{"location":"changelog/#updatesimprovements_4","text":"Replace print logging commands with python's logging module completely. Implemented encapsulation for class functions and variables on all gears. Updated support for screen casting from multiple/all monitors in ScreenGear API. Updated ScreenGear API to use Threaded Queue Mode by default, thereby removed redundant THREADED_QUEUE_MODE param. Updated bash script path to download test dataset in $TMPDIR rather than $HOME directory for downloading testdata. Implemented better error handling of colorspace in various videocapture APIs. Updated bash scripts, Moved FFmpeg static binaries to github.com . Updated bash scripts, Added additional flag to support un-secure apt sources. CamGear API will now throw RuntimeError if source provided is invalid. Updated threaded Queue mode in CamGear API for more robust performance. Added new camera_num to support multiple Picameras. Moved thread exceptions to the main thread and then re-raised. Added alternate github mirror for FFmpeg static binaries auto-installation on windows oses. Added colorlog python module for presentable colored logging. Replaced traceback with sys.exc_info . Overall APIs Code and Docs optimizations. Updated Code Readability and Wiki Docs. Updated ReadMe & Changelog with the latest changes. Updated Travis CI Tests with support for macOS environment. Reformatted & implemented necessary MacOS related changes and dependencies in travis.yml .","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_4","text":"Warning Python 2.7 legacy support dropped completely. Source-code Relicensed to Apache 2.0 License. Python 3+ are only supported legacies for installing v0.1.6 and above. Python 2.7 and 3.4 legacies support dropped from CI tests.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_4","text":"Reimplemented Pub/Sub pattern for smoother performance on various networks. Fixed Assertion error in CamGear API during colorspace manipulation. Fixed random freezing in Secure Mode and several related performance updates Fixed multiserver_mode not working properly over some networks. Fixed assigned Port address ignored bug (commit 073bca1). Fixed several wrong definition bugs from NetGear API(commit 8f7153c). Fixed unreliable dataset video URL(rehosted file on github.com ). Disabled overwrite_cert for client-end in NetGear API. Disabled Universal Python wheel builds in setup.cfg file. Removed duplicate code to import MSS( @BoboTiG ) from ScreenGear API. Eliminated unused redundant code blocks from library. Fixed Code indentation in setup.py and updated new release information. Fixed code definitions & Typos. Fixed several bugs related to secure_mode & multiserver_mode Modes. Fixed various macOS environment bugs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_4","text":"PR #39 PR #42 PR #44 PR #52 PR #55 PR #62 PR #67 PR #72 PR #77 PR #78 PR #82 PR #84","title":"Pull Requests"},{"location":"changelog/#v015-2019-07-24","text":"","title":"v0.1.5 (2019-07-24)"},{"location":"changelog/#new-features_5","text":"Added new ScreenGear API, supports Live ScreenCasting. Added new NetGear API, aids real-time frame transfer through messaging(ZmQ) over network. Added new new Stabilizer Class, for minimum latency Video Stabilization with OpenCV. Added Option to use API's standalone. Added Option to use VideoGear API as internal wrapper around Stabilizer Class. Added new parameter stabilize to API, to enable or disable Video Stabilization. Added support for **option dict attributes to update VidGear's video stabilizer parameters directly. Added brand new logo and functional block diagram ( .svg ) in readme.md Added new pictures and GIFs for improving readme.md readability Added new contributing.md and changelog.md for reference. Added collections.deque import in Threaded Queue Mode for performance consideration Added new install_opencv.sh bash scripts for Travis cli, to handle OpenCV installation. Added new Project Issue & PR Templates Added new Sponsor Button( FUNDING.yml )","title":"New Features"},{"location":"changelog/#updatesimprovements_5","text":"Updated New dependencies: mss , pyzmq and rejected redundant ones. Revamped and refreshed look for readme.md and added new badges. Updated Releases Documentation completely. Updated CI tests for new changes Updated Code Documentation. Updated bash scripts and removed redundant information Updated Youtube video URL in tests Completely Reformatted and Updated Wiki Docs with new changes.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_5","text":"Implemented experimental Threaded Queue Mode( a.k.a Blocking Mode ) for fast, synchronized, error-free multi-threading. Renamed bash script pre-install.sh to prepare_dataset.sh - [x] downloads opensourced test datasets and static FFmpeg binaries for debugging. Changed script folder location to bash/script . Python 3.4 removed from Travis CI tests.","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_5","text":"Temporarily fixed Travis CI bug: Replaced opencv-contrib-python with OpenCV built from scratch as dependency. Fixed CI Timeout Bug: Disable Threaded Queue Mode for CI Tests Fixes** sys.stderr.close() throws ValueError bug: Replaced sys.close() with DEVNULL.close() Fixed Youtube Live Stream bug that return NonType frames in CamGear API. Fixed NoneType frames bug in PiGear class on initialization. Fixed Wrong function definitions Removed /xe2 unicode bug from Stabilizer class. Fixed **output_params KeyError bug in WriteGear API Fixed subprocess not closing properly on exit in WriteGear API. Fixed bugs in ScreenGear: Non-negative monitor values Fixed missing import, typos, wrong variable definitions Removed redundant hack from setup.py Fixed Minor YouTube playback Test CI Bug Fixed new Twitter Intent Fixed bug in bash script that not working properly due to changes at server end.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_5","text":"PR #17 PR #21 PR #22 PR #27 PR #31 PR #32 PR #33 PR #34","title":"Pull Requests"},{"location":"changelog/#v014-2019-05-11","text":"","title":"v0.1.4 (2019-05-11)"},{"location":"changelog/#new-features_6","text":"Added new WriteGear API: for enabling lossless video encoding and compression(built around FFmpeg and OpenCV Video Writer) Added YouTube Mode for direct Video Pipelining from YouTube in CamGear API Added new y_tube to access YouTube Mode in CamGear API. Added flexible Output file Compression control capabilities in compression-mode(WriteGear). Added -output_dimensions special parameter to WriteGear API. Added new helper.py to handle special helper functions. Added feature to auto-download and configure FFmpeg Static binaries(if not found) on Windows platforms. Added -input_framerate special parameter to WriteGear class to change/control output constant framerate in compression mode(WriteGear). Added new Direct Video colorspace Conversion capabilities in CamGear and PiGear API. Added new framerate class variable for CamGear API, to retrieve input framerate. Added new parameter backend - [x] changes the backend of CamGear's API Added automatic required prerequisites installation ability, when installation from source. Added Travis CI Complete Integration for Linux-based Testing for VidGear. Added and configured travis.yml Added Appveyor CI Complete Integration for Windows-based Testing in VidGear. Added and configured new appveyor.yml Added new bash script pre-install.sh to download opensourced test datasets and static FFmpeg binaries for debugging. Added several new Tests(including Benchmarking Tests) for each API for testing with pytest . Added license to code docs. Added Say Thank you! badge to readme.","title":"New Features"},{"location":"changelog/#updatesimprovements_6","text":"Removed redundant dependencies Updated youtube-dl as a dependency, as required by pafy 's backend. Updated common VideoGear API with new parameter. Update robust algorithm to auto-detect FFmpeg executables and test them, if failed, auto fallback to OpenCV's VideoWriter API. Improved system previously installed OpenCV detection in setup.py. Updated setup.py with hack to remove bullets from pypi description. Updated Code Documentation Reformatted & Modernized readme.md with new badges. Reformatted and Updated Wiki Docs.","title":"Updates/Improvements"},{"location":"changelog/#breaking-updateschanges_6","text":"Bugs Patched: Removed unnecessary -height and -width parameter from CamGear API. Replaced dependency opencv-python with opencv-contrib-python completely","title":"Breaking Updates/Changes"},{"location":"changelog/#bug-fixes_6","text":"Windows Cross-Platform fix: replaced dependency os with platform in setup.py. Fixed Bug: Arises due to spaces in input **options / **output_param dictionary keys. Fixed several wrong/missing variable & function definitions. Fixed code uneven indentation. Fixed several typos in docs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_6","text":"PR #7 PR #8 PR #10 PR #12","title":"Pull Requests"},{"location":"changelog/#v013-2019-04-07","text":"","title":"v0.1.3 (2019-04-07)"},{"location":"changelog/#bug-fixes_7","text":"Patched Major PiGear Bug: Incorrect import of PiRGBArray function in PiGear Class Several Fixes** for backend picamera API handling during frame capture(PiGear) Fixed missing frame variable initialization. Fixed minor typos","title":"Bug-fixes"},{"location":"changelog/#pull-requests_7","text":"PR #6 PR #5","title":"Pull Requests"},{"location":"changelog/#v012-2019-03-27","text":"","title":"v0.1.2 (2019-03-27)"},{"location":"changelog/#new-features_7","text":"Added easy Source manipulation feature in CamGear API, to control features like resolution, brightness, framerate etc. Added new **option parameter to CamGear API, provides the flexibility to manipulate input stream directly. Added new parameters for Camgear API for time delay and logging. Added new Logo to readme.md Added new Wiki Documentation.","title":"New Features"},{"location":"changelog/#updatesimprovements_7","text":"Reformatted readme.md. Updated Wiki Docs with new changes.","title":"Updates/Improvements"},{"location":"changelog/#bug-fixes_8","text":"Improved Error Handling in CamGear & PiGear API. Fixed minor typos in docs.","title":"Bug-fixes"},{"location":"changelog/#pull-requests_8","text":"PR #4","title":"Pull Requests"},{"location":"changelog/#v011-2019-03-24","text":"","title":"v0.1.1 (2019-03-24)"},{"location":"changelog/#new-features_8","text":"Release ViGear binaries on the Python Package Index (PyPI) Added new and configured setup.py & setup.cfg","title":"New Features"},{"location":"changelog/#bug-fixes_9","text":"Fixed PEP bugs: added and configured properly __init__.py in each folder Fixed PEP bugs: improved code Indentation Fixed wrong imports: replaced distutils.core with setuptools Fixed readme.md","title":"Bug-fixes"},{"location":"changelog/#v010-2019-03-17","text":"","title":"v0.1.0 (2019-03-17)"},{"location":"changelog/#new-features_9","text":"Initial Release Converted my imutils PR into Python Project. Renamed conventions and reformatted complete source-code from scratch. Added support for both python 2.7 and 3 legacies Added new multi-threaded CamGear, PiGear, and VideoGear APIs Added multi-platform compatibility Added robust & flexible control over the source in PiGear API.","title":"New Features"},{"location":"contribution/","text":"Contribution Overview \u00b6 Contributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features! Contribution Opportunities If you're looking for something to work on, check for the PR WELCOMED labeled issues on our GitHub Repository. \u2009 Submission Guidelines \u00b6 Submitting an Issue Guidelines \u27b6 Submitting Pull Request(PR) Guidelines \u27b6 \u2009 Submission Contexts \u00b6 Got a question or problem? \u00b6 For quick questions, please refrain from opening an issue, instead read our FAQ & Troubleshooting section or you can reach us on Gitter community channel. Found a typo? \u00b6 There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time. Found a bug? \u00b6 If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6 . Request for a feature/improvement? \u00b6 Subscribe to Github Repository You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in VidGear. Learn more about it here \u27b6 You can request our GitHub Repository for a new feature/improvement based on the type of request: Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community. Major Feature Requests: If you require a major feature for VidGear, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! Minor Feature Requests: Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.","title":"Contribution Overview"},{"location":"contribution/#contribution-overview","text":"Contributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features! Contribution Opportunities If you're looking for something to work on, check for the PR WELCOMED labeled issues on our GitHub Repository.","title":"Contribution Overview"},{"location":"contribution/#submission-guidelines","text":"Submitting an Issue Guidelines \u27b6 Submitting Pull Request(PR) Guidelines \u27b6","title":"Submission Guidelines"},{"location":"contribution/#submission-contexts","text":"","title":"Submission Contexts"},{"location":"contribution/#got-a-question-or-problem","text":"For quick questions, please refrain from opening an issue, instead read our FAQ & Troubleshooting section or you can reach us on Gitter community channel.","title":"Got a question or problem?"},{"location":"contribution/#found-a-typo","text":"There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time.","title":"Found a typo?"},{"location":"contribution/#found-a-bug","text":"If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6 .","title":"Found a bug?"},{"location":"contribution/#request-for-a-featureimprovement","text":"Subscribe to Github Repository You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in VidGear. Learn more about it here \u27b6 You can request our GitHub Repository for a new feature/improvement based on the type of request: Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community. Major Feature Requests: If you require a major feature for VidGear, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! Minor Feature Requests: Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.","title":"Request for a feature/improvement?"},{"location":"gears/","text":"Introduction \u00b6 Gears: generalized workflow diagram Gears, What are these? \u00b6 VidGear is built on Standalone APIs - also known as Gears , each with some unique functionality. Each Gears is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. These Gears provides the user an easy-to-use, dynamic, extensible, and exposed Multi-Threaded + Asyncio optimized internal layer above state-of-the-art libraries to work with, while silently delivering robust error-handling. Gears Classification \u00b6 These Gears can be classified as follows: A. VideoCapture Gears \u00b6 Basic Function: Retrieves numpy.ndarray frames from various sources. CamGear : Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs. PiGear : Multi-Threaded API targeting various Raspberry-Pi Camera Modules. ScreenGear : Multi-Threaded API targeting ultra-fast Screencasting. VideoGear : Common Video-Capture API with internal Video Stabilizer wrapper. B. VideoWriter Gears \u00b6 Basic Function: Writes numpy.ndarray frames to a video file or stream. WriteGear : Handles Lossless Video-Writer for file/stream/frames Encoding and Compression. C. Streaming Gears \u00b6 Basic Function: Transcodes/Broadcasts files & numpy.ndarray frames for streaming. StreamGear : Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats. Asynchronous I/O Streaming Gear: WebGear : ASGI Video-Server that broadcasts Live Video-Frames to any web-browser on the network. D. Network Gears \u00b6 Basic Function: Sends/Receives numpy.ndarray frames over the network. NetGear : Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network. Asynchronous I/O Network Gear: NetGear_Async : Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.","title":"Introduction"},{"location":"gears/#introduction","text":"Gears: generalized workflow diagram","title":"Introduction"},{"location":"gears/#gears-what-are-these","text":"VidGear is built on Standalone APIs - also known as Gears , each with some unique functionality. Each Gears is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. These Gears provides the user an easy-to-use, dynamic, extensible, and exposed Multi-Threaded + Asyncio optimized internal layer above state-of-the-art libraries to work with, while silently delivering robust error-handling.","title":"Gears, What are these?"},{"location":"gears/#gears-classification","text":"These Gears can be classified as follows:","title":"Gears Classification"},{"location":"gears/#a-videocapture-gears","text":"Basic Function: Retrieves numpy.ndarray frames from various sources. CamGear : Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs. PiGear : Multi-Threaded API targeting various Raspberry-Pi Camera Modules. ScreenGear : Multi-Threaded API targeting ultra-fast Screencasting. VideoGear : Common Video-Capture API with internal Video Stabilizer wrapper.","title":"A. VideoCapture Gears"},{"location":"gears/#b-videowriter-gears","text":"Basic Function: Writes numpy.ndarray frames to a video file or stream. WriteGear : Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.","title":"B. VideoWriter Gears"},{"location":"gears/#c-streaming-gears","text":"Basic Function: Transcodes/Broadcasts files & numpy.ndarray frames for streaming. StreamGear : Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats. Asynchronous I/O Streaming Gear: WebGear : ASGI Video-Server that broadcasts Live Video-Frames to any web-browser on the network.","title":"C. Streaming Gears"},{"location":"gears/#d-network-gears","text":"Basic Function: Sends/Receives numpy.ndarray frames over the network. NetGear : Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network. Asynchronous I/O Network Gear: NetGear_Async : Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.","title":"D. Network Gears"},{"location":"help/","text":"Helping VidGear \u00b6 Liked VidGear? Would you like to help VidGear, other users, and the author? There are very simple ways to help us: Star VidGear on GitHub \u00b6 You can star VidGear on GitHub: It helps us a lot by making it easier for others to find & trust this library. Thanks! Help others with issues on GitHub \u00b6 You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: Watch the GitHub repository \u00b6 You can watch \ud83d\udc40 VidGear Activities on GitHub: When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request. You can try helping solving those issues, or give valuable feedback/review on new Pull Requests. Tweet about VidGear \u00b6 Tweet about VidGear and Spread the word \ud83d\udde3: Tweet #vidgear Let others know how you are using VidGear and why you like it! Help Author \u00b6 Donations help keep VidGear's Development alive and motivate me (author) . Giving a little means a lot, even the smallest contribution can make a huge difference. You can financially support through ko-fi \ud83e\udd1d: kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Thanks a million! Connect with Author \u00b6 You can connect with me, the author \ud83d\udc4b: Follow author on GitHub: Follow author on Twitter: Follow @abhi_una12 Get in touch with author on Linkedin:","title":"Helping VidGear"},{"location":"help/#helping-vidgear","text":"Liked VidGear? Would you like to help VidGear, other users, and the author? There are very simple ways to help us:","title":"Helping VidGear"},{"location":"help/#star-vidgear-on-github","text":"You can star VidGear on GitHub: It helps us a lot by making it easier for others to find & trust this library. Thanks!","title":"Star VidGear on GitHub"},{"location":"help/#help-others-with-issues-on-github","text":"You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible:","title":"Help others with issues on GitHub"},{"location":"help/#watch-the-github-repository","text":"You can watch \ud83d\udc40 VidGear Activities on GitHub: When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request. You can try helping solving those issues, or give valuable feedback/review on new Pull Requests.","title":"Watch the GitHub repository"},{"location":"help/#tweet-about-vidgear","text":"Tweet about VidGear and Spread the word \ud83d\udde3: Tweet #vidgear Let others know how you are using VidGear and why you like it!","title":"Tweet about VidGear"},{"location":"help/#help-author","text":"Donations help keep VidGear's Development alive and motivate me (author) . Giving a little means a lot, even the smallest contribution can make a huge difference. You can financially support through ko-fi \ud83e\udd1d: kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Thanks a million!","title":"Help Author"},{"location":"help/#connect-with-author","text":"You can connect with me, the author \ud83d\udc4b: Follow author on GitHub: Follow author on Twitter: Follow @abhi_una12 Get in touch with author on Linkedin:","title":"Connect with Author"},{"location":"installation/","text":"Installation Overview \u00b6 Supported Systems \u00b6 VidGear is well-tested and supported on the following systems, with python 3.6+ and pip installed: Any Linux distro released in 2016 or later Windows 7 or later macOS 10.12.6 (Sierra) or later \u2009 Supported Python legacies \u00b6 Python 3.6+ are only supported legacies for installing Vidgear v0.1.7 and above. \u2009 Installation methods \u00b6 Install using pip (recommended) Install from source","title":"Installation Overview"},{"location":"installation/#installation-overview","text":"","title":"Installation Overview"},{"location":"installation/#supported-systems","text":"VidGear is well-tested and supported on the following systems, with python 3.6+ and pip installed: Any Linux distro released in 2016 or later Windows 7 or later macOS 10.12.6 (Sierra) or later","title":"Supported Systems"},{"location":"installation/#supported-python-legacies","text":"Python 3.6+ are only supported legacies for installing Vidgear v0.1.7 and above.","title":"Supported Python legacies"},{"location":"installation/#installation-methods","text":"Install using pip (recommended) Install from source","title":"Installation methods"},{"location":"license/","text":"License \u00b6 This library is released under the Apache 2.0 License . Copyright Notice \u00b6 Copyright (c) 2019-2020 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"license/#license","text":"This library is released under the Apache 2.0 License .","title":"License"},{"location":"license/#copyright-notice","text":"Copyright (c) 2019-2020 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Copyright Notice"},{"location":"switch_from_cv/","text":"Switching from OpenCV Library \u00b6 Switching OpenCV with VidGear APIs is usually a fairly painless process, and will just require changing a few lines in your python script. This document is intended to software developers who want to migrate their python code from OpenCV Library to VidGear APIs. Prior knowledge of Python and OpenCV won't be covered in this guide. Proficiency with OpenCV is a must in order understand this document. Why VidGear is better than OpenCV? \u00b6 If you're just getting started with OpenCV, then see here \u27b6 VidGear employs OpenCV at its backend and enhances its existing capabilities even further by introducing many new state-of-the-art features on top of it, like real-time Stabilization, and inherit support for screen-casting, live network-streaming, multiple devices, multi-threading, etc., plus way much more \u27b6 . While VidGear maintains the same standard OpenCV-Python (Python API for OpenCV) coding syntax for all of its APIs. Making it even easier to implement Complex OpenCV applications in fewer lines of python code. Switching the VideoCapture APIs \u00b6 Let's compare a bare-minimum python code for extracting frames out of any Webcam/USB-camera (connected at index 0) , between OpenCV's VideoCapture Class and VidGear's CamGear VideoCapture API side-by-side: CamGear API share the same syntax as other VideoCapture APIs , thereby you can easily switch to any of those APIs in a similar manner. OpenCV VideoCapture Class # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () VidGear's CamGear API # import required libraries from vidgear.gears import CamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () and both syntax almost looks the same, easy, isn't it? \u2009 Differences \u00b6 Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoCapture Class VidGear's CamGear API Initiating stream = cv2 . VideoCapture ( 0 ) stream = CamGear ( source = 0 ) . start () Reading frames ( grabbed , frame ) = stream . read () frame = stream . read () Checking empty frame if not grabbed : if frame is None : Terminating stream . release () stream . stop () Now, checkout other VideoCapture Gears \u27b6 Switching the VideoWriter API \u00b6 Let's extend previous bare-minimum python code and save those extracted frames to disk as a valid file, with OpenCV's VideoWriter Class and VidGear's WriteGear (with FFmpeg backend) , compared side-to-side: WriteGear API also provides backend for OpenCV's VideoWriter Class. More information here \u27b6 OpenCV VideoWriter Class # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define the codec and create VideoWriter object with suitable output filename for e.g. `Output.avi` fourcc = cv2 . VideoWriter_fourcc ( * 'XVID' ) writer = cv2 . VideoWriter ( 'output.avi' , fourcc , 20.0 , ( 640 , 480 )) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . release () VidGear's WriteGear API # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # Define WriteGear Object with suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Noticed WriteGear's coding syntax looks similar but less complex? \u2009 Differences \u00b6 Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoWriter Class VidGear's WriteGear API Initiating writer = cv2 . VideoWriter ( 'output.avi' , cv2 . VideoWriter_fourcc ( * 'XVID' ), 20.0 , ( 640 , 480 )) writer = WriteGear ( output_filename = 'Output.mp4' ) Writing frames writer . write ( frame ) writer . write ( frame ) Terminating writer . release () writer . close () Now, checkout more examples of WriteGear API (with FFmpeg backend) here \u27b6","title":"Switching from OpenCV"},{"location":"switch_from_cv/#switching-from-opencv-library","text":"Switching OpenCV with VidGear APIs is usually a fairly painless process, and will just require changing a few lines in your python script. This document is intended to software developers who want to migrate their python code from OpenCV Library to VidGear APIs. Prior knowledge of Python and OpenCV won't be covered in this guide. Proficiency with OpenCV is a must in order understand this document.","title":"Switching from OpenCV Library"},{"location":"switch_from_cv/#why-vidgear-is-better-than-opencv","text":"If you're just getting started with OpenCV, then see here \u27b6 VidGear employs OpenCV at its backend and enhances its existing capabilities even further by introducing many new state-of-the-art features on top of it, like real-time Stabilization, and inherit support for screen-casting, live network-streaming, multiple devices, multi-threading, etc., plus way much more \u27b6 . While VidGear maintains the same standard OpenCV-Python (Python API for OpenCV) coding syntax for all of its APIs. Making it even easier to implement Complex OpenCV applications in fewer lines of python code.","title":"Why VidGear is better than OpenCV?"},{"location":"switch_from_cv/#switching-the-videocapture-apis","text":"Let's compare a bare-minimum python code for extracting frames out of any Webcam/USB-camera (connected at index 0) , between OpenCV's VideoCapture Class and VidGear's CamGear VideoCapture API side-by-side: CamGear API share the same syntax as other VideoCapture APIs , thereby you can easily switch to any of those APIs in a similar manner. OpenCV VideoCapture Class # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () VidGear's CamGear API # import required libraries from vidgear.gears import CamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () and both syntax almost looks the same, easy, isn't it?","title":"Switching the VideoCapture APIs"},{"location":"switch_from_cv/#differences","text":"Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoCapture Class VidGear's CamGear API Initiating stream = cv2 . VideoCapture ( 0 ) stream = CamGear ( source = 0 ) . start () Reading frames ( grabbed , frame ) = stream . read () frame = stream . read () Checking empty frame if not grabbed : if frame is None : Terminating stream . release () stream . stop () Now, checkout other VideoCapture Gears \u27b6","title":"Differences"},{"location":"switch_from_cv/#switching-the-videowriter-api","text":"Let's extend previous bare-minimum python code and save those extracted frames to disk as a valid file, with OpenCV's VideoWriter Class and VidGear's WriteGear (with FFmpeg backend) , compared side-to-side: WriteGear API also provides backend for OpenCV's VideoWriter Class. More information here \u27b6 OpenCV VideoWriter Class # import required libraries import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define the codec and create VideoWriter object with suitable output filename for e.g. `Output.avi` fourcc = cv2 . VideoWriter_fourcc ( * 'XVID' ) writer = cv2 . VideoWriter ( 'output.avi' , fourcc , 20.0 , ( 640 , 480 )) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . release () VidGear's WriteGear API # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # Define WriteGear Object with suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = 'Output.mp4' ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Noticed WriteGear's coding syntax looks similar but less complex?","title":"Switching the VideoWriter API"},{"location":"switch_from_cv/#differences_1","text":"Let's breakdown a few noteworthy difference in both syntaxes: Task OpenCV VideoWriter Class VidGear's WriteGear API Initiating writer = cv2 . VideoWriter ( 'output.avi' , cv2 . VideoWriter_fourcc ( * 'XVID' ), 20.0 , ( 640 , 480 )) writer = WriteGear ( output_filename = 'Output.mp4' ) Writing frames writer . write ( frame ) writer . write ( frame ) Terminating writer . release () writer . close () Now, checkout more examples of WriteGear API (with FFmpeg backend) here \u27b6","title":"Differences"},{"location":"bonus/TQM/","text":"Threaded Queue Mode \u00b6 Overview \u00b6 Threaded-Queue-Mode: generalized timing diagram Threaded Queue Mode is designed exclusively for VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and few Network Gears (such as NetGear(Client's end)) for achieving high-performance, synchronized, and error-free video-frames handling with their Internal Multi-Threaded Frame Extractor Daemons . Threaded-Queue-Mode is enabled by default, but a user can disable it , if extremely necessary. What does Threaded-Queue-Mode exactly do? \u00b6 Threaded-Queue-Mode helps VidGear do the Threaded Video-Processing tasks in a well-organized, and most competent way possible: A. Enables Multi-Threading \u00b6 In case you don't already know, OpenCV's' read() is a blocking method for reading/decoding the next video-frame and consumes much of the I/O bound memory depending upon our Source-properties & System-hardware. This means, it blocks the function from returning until the next frame. As a result, this behavior halts our python script's main thread completely for that moment. Threaded-Queue-Mode employs Multi-Threading to separate frame-decoding like tasks to multiple independent threads in layman's word. Multiple-Threads helps it execute different Video Processing I/O-bound operations all at the same time by overlapping the waiting times. In this way, Threaded-Queue-Mode keeps on processing frames faster in the background(daemon) without waiting for blocked I/O operations and doesn't get affected by how sluggish our main python thread is. B. Monitors Fix-Sized Deques \u00b6 Although Multi-threading is fast & easy, it may lead to undesired effects like frame-skipping, deadlocks, and race conditions, etc. Threaded-Queue-Mode utilizes Monitored, Thread-Safe, Memory-Efficient, and Fixed-Sized Deques (with approximately the same O(1) performance in either direction) , that always maintains a fixed-length of frames buffer in the memory. It blocks the thread if the queue is full or otherwise pops out the frames synchronously and efficiently without any obstructions. Its fixed-length Deques stops multiple threads from accessing the same source simultaneously and thus preventing Global Interpreter Lock (a.k.a GIL) . What are the advantages of Threaded-Queue-Mode? \u00b6 Enables Blocking, Sequential and Threaded LIFO Frame Handling. Sequentially adds and releases frames to/from deque and handles the overflow of this queue. Utilizes thread-safe, memory efficient deques that appends and pops frames with same O(1) performance from either side. Requires less RAM at due to buffered frames in the deque . Manually disabling Threaded-Queue-Mode \u00b6 To manually disable Threaded-Queue-Mode, VidGear provides THREADED_QUEUE_MODE boolean attribute for options dictionary parameter in respective VideoCapture APIs : Important Warning This THREADED_QUEUE_MODE attribute does NOT work with Live feed, such as Camera Devices/Modules. This THREADED_QUEUE_MODE attribute is NOT supported by ScreenGear & NetGear APIs, as Threaded Queue Mode is essential for their core operations. Disabling Threaded-Queue-Mode will NOT disable Multi-Threading. Disabling Threaded-Queue-Mode may lead to Random Intermittent Bugs that can be quite difficult to discover. More insight can be found here \u27b6 THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode to manually disable it: options = { 'THREADED_QUEUE_MODE' : False } # to disable Threaded Queue Mode. and you can pass it to options dictionary parameter of the respective API.","title":"Threaded Queue Mode"},{"location":"bonus/TQM/#threaded-queue-mode","text":"","title":"Threaded Queue Mode"},{"location":"bonus/TQM/#overview","text":"Threaded-Queue-Mode: generalized timing diagram Threaded Queue Mode is designed exclusively for VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and few Network Gears (such as NetGear(Client's end)) for achieving high-performance, synchronized, and error-free video-frames handling with their Internal Multi-Threaded Frame Extractor Daemons . Threaded-Queue-Mode is enabled by default, but a user can disable it , if extremely necessary.","title":"Overview"},{"location":"bonus/TQM/#what-does-threaded-queue-mode-exactly-do","text":"Threaded-Queue-Mode helps VidGear do the Threaded Video-Processing tasks in a well-organized, and most competent way possible:","title":"What does Threaded-Queue-Mode exactly do?"},{"location":"bonus/TQM/#a-enables-multi-threading","text":"In case you don't already know, OpenCV's' read() is a blocking method for reading/decoding the next video-frame and consumes much of the I/O bound memory depending upon our Source-properties & System-hardware. This means, it blocks the function from returning until the next frame. As a result, this behavior halts our python script's main thread completely for that moment. Threaded-Queue-Mode employs Multi-Threading to separate frame-decoding like tasks to multiple independent threads in layman's word. Multiple-Threads helps it execute different Video Processing I/O-bound operations all at the same time by overlapping the waiting times. In this way, Threaded-Queue-Mode keeps on processing frames faster in the background(daemon) without waiting for blocked I/O operations and doesn't get affected by how sluggish our main python thread is.","title":"A. Enables Multi-Threading"},{"location":"bonus/TQM/#b-monitors-fix-sized-deques","text":"Although Multi-threading is fast & easy, it may lead to undesired effects like frame-skipping, deadlocks, and race conditions, etc. Threaded-Queue-Mode utilizes Monitored, Thread-Safe, Memory-Efficient, and Fixed-Sized Deques (with approximately the same O(1) performance in either direction) , that always maintains a fixed-length of frames buffer in the memory. It blocks the thread if the queue is full or otherwise pops out the frames synchronously and efficiently without any obstructions. Its fixed-length Deques stops multiple threads from accessing the same source simultaneously and thus preventing Global Interpreter Lock (a.k.a GIL) .","title":"B. Monitors Fix-Sized Deques"},{"location":"bonus/TQM/#what-are-the-advantages-of-threaded-queue-mode","text":"Enables Blocking, Sequential and Threaded LIFO Frame Handling. Sequentially adds and releases frames to/from deque and handles the overflow of this queue. Utilizes thread-safe, memory efficient deques that appends and pops frames with same O(1) performance from either side. Requires less RAM at due to buffered frames in the deque .","title":"What are the advantages of Threaded-Queue-Mode?"},{"location":"bonus/TQM/#manually-disabling-threaded-queue-mode","text":"To manually disable Threaded-Queue-Mode, VidGear provides THREADED_QUEUE_MODE boolean attribute for options dictionary parameter in respective VideoCapture APIs : Important Warning This THREADED_QUEUE_MODE attribute does NOT work with Live feed, such as Camera Devices/Modules. This THREADED_QUEUE_MODE attribute is NOT supported by ScreenGear & NetGear APIs, as Threaded Queue Mode is essential for their core operations. Disabling Threaded-Queue-Mode will NOT disable Multi-Threading. Disabling Threaded-Queue-Mode may lead to Random Intermittent Bugs that can be quite difficult to discover. More insight can be found here \u27b6 THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode to manually disable it: options = { 'THREADED_QUEUE_MODE' : False } # to disable Threaded Queue Mode. and you can pass it to options dictionary parameter of the respective API.","title":"Manually disabling Threaded-Queue-Mode"},{"location":"bonus/colorspace_manipulation/","text":"Colorspace Manipulation for VideoCapture Gears \u00b6 Source ColorSpace manipulation \u00b6 All VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and some Streaming Gears (WebGear) and Network Gears (Client's end) - provides exclusive internal support for Source Color Space manipulation . There are two ways to alter source colorspace: Using colorspace parameter \u00b6 Primarily, the safest way is by colorspace (string) parameter of the respective VideoCapture API, that can be used to easily alter the colorspace of the input source, during initialization. But on the downside, colorspace parameter value CANNOT be changed/altered at runtime. All possible values for this parameter are discussed below \u27b6 Using color_space global variable \u00b6 Alternatively, a more direct approach is by using color_space (integer) global variable the respective VideoCapture API, can be used for directly changing the source colorspace at runtime. It can be used in conjunction with colorspace parameter easily. Supported Colorspace Conversions Any conversion from default Source colorspace (i.e. BGR in case of OpenCV) , to any other colorspace and vice-versa (use None to revert) , is supported. Important Information Using color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . Any incorrect or None-type value, will immediately revert the colorspace to default (i.e. BGR ) . Using color_space global variable with Threaded Queue Mode may have minor lag, User discretion is advised. Tip It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Supported colorspace parameter values \u00b6 All supported string values for colorspace parameter are as follows: You can check all OpenCV Colorspace Conversion Codes here \u27b6 . Supported Conversion Values Description COLOR_BGR2BGRA BGR to BGRA COLOR_BGR2RGBA BGR to RGBA COLOR_BGR2RGB BGR to RGB backward conversions to RGB/BGR COLOR_BGR2GRAY BGR to GRAY COLOR_BGR2BGR565 BGR to BGR565 COLOR_BGR2BGR555 BGR to BGR555 COLOR_BGR2XYZ BGR to CIE XYZ COLOR_BGR2YCrCb BGR to luma-chroma (aka YCC) COLOR_BGR2HSV BGR to HSV (hue saturation value) COLOR_BGR2Lab BGR to CIE Lab COLOR_BGR2Luv BGR to CIE Luv COLOR_BGR2HLS BGR to HLS (hue lightness saturation) COLOR_BGR2HSV_FULL BGR to HSV_FULL COLOR_BGR2HLS_FULL BGR to HLS_FULL COLOR_BGR2YUV BGR to YUV COLOR_BGR2YUV_I420 BGR to YUV 4:2:0 family COLOR_BGR2YUV_IYUV BGR to IYUV COLOR_BGR2YUV_YV12 BGR to YUV_YV12 None Back to default colorspace (i.e. BGR) Usage examples \u00b6 Using CamGear with Direct Colorspace Manipulation \u00b6 The complete usage example can be found here \u27b6 Using PiGear with Direct Colorspace Manipulation \u00b6 The complete usage example can be found here \u27b6 Using VideoGear with Colorspace Manipulation \u00b6 The complete usage example can be found here \u27b6 Using ScreenGear with Direct Colorspace Manipulation \u00b6 The complete usage example can be found here \u27b6","title":"Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#colorspace-manipulation-for-videocapture-gears","text":"","title":"Colorspace Manipulation for VideoCapture Gears"},{"location":"bonus/colorspace_manipulation/#source-colorspace-manipulation","text":"All VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and some Streaming Gears (WebGear) and Network Gears (Client's end) - provides exclusive internal support for Source Color Space manipulation . There are two ways to alter source colorspace:","title":"Source ColorSpace manipulation"},{"location":"bonus/colorspace_manipulation/#using-colorspace-parameter","text":"Primarily, the safest way is by colorspace (string) parameter of the respective VideoCapture API, that can be used to easily alter the colorspace of the input source, during initialization. But on the downside, colorspace parameter value CANNOT be changed/altered at runtime. All possible values for this parameter are discussed below \u27b6","title":"Using colorspace parameter"},{"location":"bonus/colorspace_manipulation/#using-color_space-global-variable","text":"Alternatively, a more direct approach is by using color_space (integer) global variable the respective VideoCapture API, can be used for directly changing the source colorspace at runtime. It can be used in conjunction with colorspace parameter easily. Supported Colorspace Conversions Any conversion from default Source colorspace (i.e. BGR in case of OpenCV) , to any other colorspace and vice-versa (use None to revert) , is supported. Important Information Using color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . Any incorrect or None-type value, will immediately revert the colorspace to default (i.e. BGR ) . Using color_space global variable with Threaded Queue Mode may have minor lag, User discretion is advised. Tip It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Using color_space global variable"},{"location":"bonus/colorspace_manipulation/#supported-colorspace-parameter-values","text":"All supported string values for colorspace parameter are as follows: You can check all OpenCV Colorspace Conversion Codes here \u27b6 . Supported Conversion Values Description COLOR_BGR2BGRA BGR to BGRA COLOR_BGR2RGBA BGR to RGBA COLOR_BGR2RGB BGR to RGB backward conversions to RGB/BGR COLOR_BGR2GRAY BGR to GRAY COLOR_BGR2BGR565 BGR to BGR565 COLOR_BGR2BGR555 BGR to BGR555 COLOR_BGR2XYZ BGR to CIE XYZ COLOR_BGR2YCrCb BGR to luma-chroma (aka YCC) COLOR_BGR2HSV BGR to HSV (hue saturation value) COLOR_BGR2Lab BGR to CIE Lab COLOR_BGR2Luv BGR to CIE Luv COLOR_BGR2HLS BGR to HLS (hue lightness saturation) COLOR_BGR2HSV_FULL BGR to HSV_FULL COLOR_BGR2HLS_FULL BGR to HLS_FULL COLOR_BGR2YUV BGR to YUV COLOR_BGR2YUV_I420 BGR to YUV 4:2:0 family COLOR_BGR2YUV_IYUV BGR to IYUV COLOR_BGR2YUV_YV12 BGR to YUV_YV12 None Back to default colorspace (i.e. BGR)","title":"Supported colorspace parameter values"},{"location":"bonus/colorspace_manipulation/#usage-examples","text":"","title":"Usage examples"},{"location":"bonus/colorspace_manipulation/#using-camgear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using CamGear with Direct Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-pigear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using PiGear with Direct Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-videogear-with-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using VideoGear with Colorspace Manipulation"},{"location":"bonus/colorspace_manipulation/#using-screengear-with-direct-colorspace-manipulation","text":"The complete usage example can be found here \u27b6","title":"Using ScreenGear with Direct Colorspace Manipulation"},{"location":"bonus/reference/camgear/","text":"All CamGear API parameters are explained here \u27b6 CamGear API supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture Class with direct access to almost all of its available parameters, and also internally employs pafy with youtube-dl backend for enabling seamless live YouTube streaming . CamGear relies exclusively on Threaded Queue mode for threaded, error-free and synchronized frame handling. __init__ ( self , source = 0 , stream_mode = False , backend = 0 , colorspace = None , logging = False , time_delay = 0 , ** options ) special \u00b6 This constructor method initializes the object state and attributes of the CamGear class. Parameters: Name Type Description Default source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive Stream Mode for handling streaming URLs. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Source Tweak Parameters. {} Source code in vidgear/gears/camgear.py def __init__ ( self , source = 0 , stream_mode = False , backend = 0 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the CamGear class. Parameters: source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" # enable logging if specified self . __logging = False if logging : self . __logging = logging # check if Stream-Mode is ON (True) if stream_mode : # check GStreamer backend support gst_support = check_gstreamer_support ( logging = logging ) # handle special Stream Mode parameters stream_resolution = get_supported_resolution ( options . pop ( \"STREAM_RESOLUTION\" , \"best\" ), logging = logging ) stream_params = options . pop ( \"STREAM_PARAMS\" , {}) if isinstance ( stream_params , dict ): stream_params = { str ( k ) . strip (): v for k , v in stream_params . items ()} else : stream_params = {} # handle Stream-Mode try : # detect whether a YouTube URL video_url = youtube_url_validator ( source ) if video_url : # import backend library import pafy logger . info ( \"Using Youtube-dl Backend\" ) # create new pafy object source_object = pafy . new ( video_url , ydl_opts = stream_params ) # extract all valid video-streams valid_streams = [ v_streams for v_streams in source_object . videostreams if v_streams . notes != \"HLS\" and v_streams . extension == \"webm\" ] + [ va_streams for va_streams in source_object . streams ] # extract available stream resolutions available_streams = [ qs . notes for qs in valid_streams ] # check whether YouTube-stream is live or not? is_live = ( all ( x == \"HLS\" or x == \"\" for x in available_streams ) if available_streams else False ) # validate streams if valid_streams and ( not is_live or gst_support ): # handle live-streams if is_live : # Enforce GStreamer backend for YouTube-livestreams if logging : logger . critical ( \"YouTube livestream URL detected. Enforcing GStreamer backend.\" ) backend = cv2 . CAP_GSTREAMER # convert stream dimensions to streams resolutions available_streams = dimensions_to_resolutions ( [ qs . resolution for qs in valid_streams ] ) # check whether stream-resolution was specified and available if stream_resolution in [ \"best\" , \"worst\" ] or not ( stream_resolution in available_streams ): # not specified and unavailable if not stream_resolution in [ \"best\" , \"worst\" ]: logger . warning ( \"Specified stream-resolution ` {} ` is not available. Reverting to `best`!\" . format ( stream_resolution ) ) # revert to best stream_resolution = \"best\" # parse and select best or worst streams valid_streams . sort ( key = lambda x : x . dimensions , reverse = True if stream_resolution == \"best\" else False , ) parsed_stream = valid_streams [ 0 ] else : # apply specfied valid stream-resolution matched_stream = [ i for i , s in enumerate ( available_streams ) if stream_resolution in s ] parsed_stream = valid_streams [ matched_stream [ 0 ]] # extract stream URL as source source = parsed_stream . url # log progress if self . __logging : logger . debug ( \"YouTube source ID: ` {} `, Title: ` {} `, Quality: ` {} `\" . format ( video_url , source_object . title , stream_resolution ) ) else : # raise error if Gstreamer backend unavailable for YouTube live-streams # see issue: https://github.com/abhiTronix/vidgear/issues/133 raise RuntimeError ( \"[CamGear:ERROR] :: Unable to find any OpenCV supported streams in ` {} ` YouTube URL. Kindly compile OpenCV with GSstreamer(>=v1.0.0) support or Use another URL!\" . format ( source ) ) else : # import backend library from streamlink import Streamlink restore_levelnames () logger . info ( \"Using Streamlink Backend\" ) # check session session = Streamlink () # extract streams streams = session . streams ( source ) # set parameters for key , value in stream_params . items (): session . set_option ( key , value ) # select streams are available assert ( streams ), \"[CamGear:ERROR] :: Invalid ` {} ` URL cannot be processed!\" . format ( source ) # check whether stream-resolution was specified and available if not stream_resolution in streams . keys (): # if unavailable logger . warning ( \"Specified stream-resolution ` {} ` is not available. Reverting to `best`!\" . format ( stream_resolution ) ) # revert to best stream_resolution = \"best\" # extract url source = streams [ stream_resolution ] . url except Exception as e : # raise error if something went wrong raise ValueError ( \"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\" ) # youtube mode variable initialization self . __youtube_mode = stream_mode # assigns special parameter to global variable and clear self . __threaded_queue_mode = options . pop ( \"THREADED_QUEUE_MODE\" , True ) if not isinstance ( self . __threaded_queue_mode , bool ): # reset improper values self . __threaded_queue_mode = True self . __queue = None # initialize deque for video files only if self . __threaded_queue_mode and isinstance ( source , str ): # import deque from collections import deque # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # log it if self . __logging : logger . debug ( \"Enabling Threaded Queue Mode for the current video source!\" ) else : # otherwise disable it self . __threaded_queue_mode = False # log it if self . __logging : logger . warning ( \"Threaded Queue Mode is disabled for the current video source!\" ) # stream variable initialization self . stream = None if backend and isinstance ( backend , int ): # add backend if specified and initialize the camera stream if check_CV_version () == 3 : # Different OpenCV 3.4.x statement self . stream = cv2 . VideoCapture ( source + backend ) else : # Two parameters are available since OpenCV 4+ (master branch) self . stream = cv2 . VideoCapture ( source , backend ) logger . debug ( \"Setting backend ` {} ` for this source.\" . format ( backend )) else : # initialize the camera stream self . stream = cv2 . VideoCapture ( source ) # initializing colorspace variable self . color_space = None # apply attributes to source if specified options = { str ( k ) . strip (): v for k , v in options . items ()} for key , value in options . items (): property = capPropId ( key ) if not ( property is None ): self . stream . set ( property , value ) # handle colorspace value if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # initialize and assign frame-rate variable self . framerate = 0.0 _fps = self . stream . get ( cv2 . CAP_PROP_FPS ) if _fps > 1.0 : self . framerate = _fps # applying time delay to warm-up webcam only if specified if time_delay : time . sleep ( time_delay ) # frame variable initialization ( grabbed , self . frame ) = self . stream . read () # check if valid stream if grabbed : # render colorspace if defined if not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) if self . __threaded_queue_mode : # initialize and append to queue self . __queue . append ( self . frame ) else : raise RuntimeError ( \"[CamGear:ERROR] :: Source is invalid, CamGear failed to intitialize stream on this source!\" ) # thread initialization self . __thread = None # initialize termination flag self . __terminate = False read ( self ) \u00b6 Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/camgear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __threaded_queue_mode : if len ( self . __queue ) > 0 : return self . __queue . popleft () return self . frame start ( self ) \u00b6 Launches the internal Threaded Frames Extractor daemon. Returns: A reference to the CamGear class object. Source code in vidgear/gears/camgear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon. **Returns:** A reference to the CamGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"CamGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self stop ( self ) \u00b6 Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/camgear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" if self . __logging : logger . debug ( \"Terminating processes.\" ) # terminate Threaded queue mode separately if self . __threaded_queue_mode and not ( self . __queue is None ): if len ( self . __queue ) > 0 : self . __queue . clear () self . __threaded_queue_mode = False self . frame = None # indicate that the thread should be terminate self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : self . __thread . join ()","title":"CamGear API"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.__init__","text":"This constructor method initializes the object state and attributes of the CamGear class. Parameters: Name Type Description Default source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive Stream Mode for handling streaming URLs. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Source Tweak Parameters. {} Source code in vidgear/gears/camgear.py def __init__ ( self , source = 0 , stream_mode = False , backend = 0 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the CamGear class. Parameters: source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" # enable logging if specified self . __logging = False if logging : self . __logging = logging # check if Stream-Mode is ON (True) if stream_mode : # check GStreamer backend support gst_support = check_gstreamer_support ( logging = logging ) # handle special Stream Mode parameters stream_resolution = get_supported_resolution ( options . pop ( \"STREAM_RESOLUTION\" , \"best\" ), logging = logging ) stream_params = options . pop ( \"STREAM_PARAMS\" , {}) if isinstance ( stream_params , dict ): stream_params = { str ( k ) . strip (): v for k , v in stream_params . items ()} else : stream_params = {} # handle Stream-Mode try : # detect whether a YouTube URL video_url = youtube_url_validator ( source ) if video_url : # import backend library import pafy logger . info ( \"Using Youtube-dl Backend\" ) # create new pafy object source_object = pafy . new ( video_url , ydl_opts = stream_params ) # extract all valid video-streams valid_streams = [ v_streams for v_streams in source_object . videostreams if v_streams . notes != \"HLS\" and v_streams . extension == \"webm\" ] + [ va_streams for va_streams in source_object . streams ] # extract available stream resolutions available_streams = [ qs . notes for qs in valid_streams ] # check whether YouTube-stream is live or not? is_live = ( all ( x == \"HLS\" or x == \"\" for x in available_streams ) if available_streams else False ) # validate streams if valid_streams and ( not is_live or gst_support ): # handle live-streams if is_live : # Enforce GStreamer backend for YouTube-livestreams if logging : logger . critical ( \"YouTube livestream URL detected. Enforcing GStreamer backend.\" ) backend = cv2 . CAP_GSTREAMER # convert stream dimensions to streams resolutions available_streams = dimensions_to_resolutions ( [ qs . resolution for qs in valid_streams ] ) # check whether stream-resolution was specified and available if stream_resolution in [ \"best\" , \"worst\" ] or not ( stream_resolution in available_streams ): # not specified and unavailable if not stream_resolution in [ \"best\" , \"worst\" ]: logger . warning ( \"Specified stream-resolution ` {} ` is not available. Reverting to `best`!\" . format ( stream_resolution ) ) # revert to best stream_resolution = \"best\" # parse and select best or worst streams valid_streams . sort ( key = lambda x : x . dimensions , reverse = True if stream_resolution == \"best\" else False , ) parsed_stream = valid_streams [ 0 ] else : # apply specfied valid stream-resolution matched_stream = [ i for i , s in enumerate ( available_streams ) if stream_resolution in s ] parsed_stream = valid_streams [ matched_stream [ 0 ]] # extract stream URL as source source = parsed_stream . url # log progress if self . __logging : logger . debug ( \"YouTube source ID: ` {} `, Title: ` {} `, Quality: ` {} `\" . format ( video_url , source_object . title , stream_resolution ) ) else : # raise error if Gstreamer backend unavailable for YouTube live-streams # see issue: https://github.com/abhiTronix/vidgear/issues/133 raise RuntimeError ( \"[CamGear:ERROR] :: Unable to find any OpenCV supported streams in ` {} ` YouTube URL. Kindly compile OpenCV with GSstreamer(>=v1.0.0) support or Use another URL!\" . format ( source ) ) else : # import backend library from streamlink import Streamlink restore_levelnames () logger . info ( \"Using Streamlink Backend\" ) # check session session = Streamlink () # extract streams streams = session . streams ( source ) # set parameters for key , value in stream_params . items (): session . set_option ( key , value ) # select streams are available assert ( streams ), \"[CamGear:ERROR] :: Invalid ` {} ` URL cannot be processed!\" . format ( source ) # check whether stream-resolution was specified and available if not stream_resolution in streams . keys (): # if unavailable logger . warning ( \"Specified stream-resolution ` {} ` is not available. Reverting to `best`!\" . format ( stream_resolution ) ) # revert to best stream_resolution = \"best\" # extract url source = streams [ stream_resolution ] . url except Exception as e : # raise error if something went wrong raise ValueError ( \"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\" ) # youtube mode variable initialization self . __youtube_mode = stream_mode # assigns special parameter to global variable and clear self . __threaded_queue_mode = options . pop ( \"THREADED_QUEUE_MODE\" , True ) if not isinstance ( self . __threaded_queue_mode , bool ): # reset improper values self . __threaded_queue_mode = True self . __queue = None # initialize deque for video files only if self . __threaded_queue_mode and isinstance ( source , str ): # import deque from collections import deque # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # log it if self . __logging : logger . debug ( \"Enabling Threaded Queue Mode for the current video source!\" ) else : # otherwise disable it self . __threaded_queue_mode = False # log it if self . __logging : logger . warning ( \"Threaded Queue Mode is disabled for the current video source!\" ) # stream variable initialization self . stream = None if backend and isinstance ( backend , int ): # add backend if specified and initialize the camera stream if check_CV_version () == 3 : # Different OpenCV 3.4.x statement self . stream = cv2 . VideoCapture ( source + backend ) else : # Two parameters are available since OpenCV 4+ (master branch) self . stream = cv2 . VideoCapture ( source , backend ) logger . debug ( \"Setting backend ` {} ` for this source.\" . format ( backend )) else : # initialize the camera stream self . stream = cv2 . VideoCapture ( source ) # initializing colorspace variable self . color_space = None # apply attributes to source if specified options = { str ( k ) . strip (): v for k , v in options . items ()} for key , value in options . items (): property = capPropId ( key ) if not ( property is None ): self . stream . set ( property , value ) # handle colorspace value if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # initialize and assign frame-rate variable self . framerate = 0.0 _fps = self . stream . get ( cv2 . CAP_PROP_FPS ) if _fps > 1.0 : self . framerate = _fps # applying time delay to warm-up webcam only if specified if time_delay : time . sleep ( time_delay ) # frame variable initialization ( grabbed , self . frame ) = self . stream . read () # check if valid stream if grabbed : # render colorspace if defined if not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) if self . __threaded_queue_mode : # initialize and append to queue self . __queue . append ( self . frame ) else : raise RuntimeError ( \"[CamGear:ERROR] :: Source is invalid, CamGear failed to intitialize stream on this source!\" ) # thread initialization self . __thread = None # initialize termination flag self . __terminate = False","title":"__init__()"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.read","text":"Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/camgear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __threaded_queue_mode : if len ( self . __queue ) > 0 : return self . __queue . popleft () return self . frame","title":"read()"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.start","text":"Launches the internal Threaded Frames Extractor daemon. Returns: A reference to the CamGear class object. Source code in vidgear/gears/camgear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon. **Returns:** A reference to the CamGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"CamGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self","title":"start()"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.stop","text":"Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/camgear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" if self . __logging : logger . debug ( \"Terminating processes.\" ) # terminate Threaded queue mode separately if self . __threaded_queue_mode and not ( self . __queue is None ): if len ( self . __queue ) > 0 : self . __queue . clear () self . __threaded_queue_mode = False self . frame = None # indicate that the thread should be terminate self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : self . __thread . join ()","title":"stop()"},{"location":"bonus/reference/helper/","text":"logger_handler \u00b6 Returns the logger handler Returns: A logger handler Source code in vidgear/gears/helper.py def logger_handler (): \"\"\" ### logger_handler Returns the logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" %(bold_cyan)s%(asctime)s :: %(bold_blue)s%(name)s%(reset)s :: %(log_color)s%(levelname)s%(reset)s :: %(message)s \" , datefmt = \"%H:%M:%S\" , reset = True , log_colors = { \"INFO\" : \"bold_green\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_purple\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, ) # check if VIDGEAR_LOGFILE defined file_mode = os . environ . get ( \"VIDGEAR_LOGFILE\" , False ) # define handler handler = log . StreamHandler () if file_mode and isinstance ( file_mode , str ): file_path = os . path . abspath ( file_mode ) if ( os . name == \"nt\" or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( file_path ), os . W_OK ): file_path = ( os . path . join ( file_path , \"vidgear.log\" ) if os . path . isdir ( file_path ) else file_path ) handler = log . FileHandler ( file_path , mode = \"a\" ) formatter = log . Formatter ( \" %(asctime)s :: %(name)s :: %(levelname)s :: %(message)s \" , datefmt = \"%H:%M:%S\" , ) handler . setFormatter ( formatter ) return handler check_CV_version \u00b6 Returns: OpenCV's version first bit Source code in vidgear/gears/helper.py def check_CV_version (): \"\"\" ### check_CV_version **Returns:** OpenCV's version first bit \"\"\" if parse_version ( cv2 . __version__ ) >= parse_version ( \"4\" ): return 4 else : return 3 check_gstreamer_support \u00b6 Checks whether OpenCV is compiled with Gstreamer( >=1.0.0 ) support. Parameters: Name Type Description Default logging bool enables logging for its operations False Returns: A Boolean value Source code in vidgear/gears/helper.py def check_gstreamer_support ( logging = False ): \"\"\" ### check_gstreamer_support Checks whether OpenCV is compiled with Gstreamer(`>=1.0.0`) support. Parameters: logging (bool): enables logging for its operations **Returns:** A Boolean value \"\"\" raw = cv2 . getBuildInformation () gst = [ x . strip () for x in raw . split ( \" \\n \" ) if x and re . search ( r \"GStreamer[,-:]+\\s*(?:YES|NO)\" , x ) ] if gst and \"YES\" in gst [ 0 ]: version = re . search ( r \"(\\d+\\.)?(\\d+\\.)?(\\*|\\d+)\" , gst [ 0 ]) if logging : logger . debug ( \"Found GStreamer version: {} \" . format ( version [ 0 ])) return version [ 0 ] >= \"1.0.0\" else : logger . warning ( \"GStreamer not found!\" ) return False get_supported_resolution \u00b6 Parameters: Name Type Description Default value string value to be validated required logging bool enables logging for its operations False Returns: Valid stream resolution Source code in vidgear/gears/helper.py def get_supported_resolution ( value , logging = False ): \"\"\" ### get_supported_resolution Parameters: value (string): value to be validated logging (bool): enables logging for its operations **Returns:** Valid stream resolution \"\"\" # default to best stream_resolution = \"best\" supported_stream_qualities = [ \"144p\" , \"240p\" , \"360p\" , \"480p\" , \"720p\" , \"1080p\" , \"1440p\" , \"2160p\" , \"worst\" , \"best\" , ] if isinstance ( value , str ): if value . strip () . lower () in supported_stream_qualities : stream_resolution = value . strip () . lower () if logging : logger . debug ( \"Selecting ` {} ` resolution for streams.\" . format ( stream_resolution ) ) else : logger . warning ( \"Specified stream-resolution ` {} ` is not supported. Reverting to `best`!\" . format ( value ) ) else : logger . warning ( \"Specified stream-resolution ` {} ` is Invalid. Reverting to `best`!\" . format ( value ) ) return stream_resolution dimensions_to_resolutions \u00b6 Parameters: Name Type Description Default value list list of dimensions (e.g. 640x360 ) required Returns: list of resolutions (e.g. 360p ) Source code in vidgear/gears/helper.py def dimensions_to_resolutions ( value ): \"\"\" ### dimensions_to_resolutions Parameters: value (list): list of dimensions (e.g. `640x360`) **Returns:** list of resolutions (e.g. `360p`) \"\"\" supported_resolutions = { \"256x144\" : \"144p\" , \"426x240\" : \"240p\" , \"640x360\" : \"360p\" , \"854x480\" : \"480p\" , \"1280x720\" : \"720p\" , \"1920x1080\" : \"1080p\" , \"2560x1440\" : \"1440p\" , \"3840x2160\" : \"2160p\" , } return ( list ( map ( supported_resolutions . get , value , value )) if isinstance ( value , list ) else [] ) mkdir_safe \u00b6 Safely creates directory at given path. Parameters: Name Type Description Default dir_path string path to the directory required logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def mkdir_safe ( dir_path , logging = False ): \"\"\" ### mkdir_safe Safely creates directory at given path. Parameters: dir_path (string): path to the directory logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir_path ) if logging : logger . debug ( \"Created directory at ` {} `\" . format ( dir_path )) except OSError as e : if e . errno != errno . EEXIST : raise if logging : logger . debug ( \"Directory already exists at ` {} `\" . format ( dir_path )) delete_safe \u00b6 Safely deletes files with given extensions at given path. Parameters: Name Type Description Default dir_path string path to the directory required extensions list list of extensions to be deleted [] logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def delete_safe ( dir_path , extensions = [], logging = False ): \"\"\" ### delete_safe Safely deletes files with given extensions at given path. Parameters: dir_path (string): path to the directory extensions (list): list of extensions to be deleted logging (bool): enables logging for its operations \"\"\" if not extensions or not os . path . exists ( dir_path ): logger . warning ( \"Invalid input provided for deleting!\" ) return if logging : logger . debug ( \"Clearing Assets at ` {} `!\" . format ( dir_path )) for ext in extensions : files_ext = [ os . path . join ( dir_path , f ) for f in os . listdir ( dir_path ) if f . endswith ( ext ) ] for file in files_ext : os . remove ( file ) if logging : logger . debug ( \"Deleted file: ` {} `\" . format ( file )) capPropId \u00b6 Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: Name Type Description Default property string inputs OpenCV property as string. required Returns: Resultant integer value. Source code in vidgear/gears/helper.py def capPropId ( property ): \"\"\" ### capPropId Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: property (string): inputs OpenCV property as string. **Returns:** Resultant integer value. \"\"\" integer_value = 0 try : integer_value = getattr ( cv2 , property ) except Exception as e : logger . exception ( str ( e )) logger . critical ( \"` {} ` is not a valid OpenCV property!\" . format ( property )) return None return integer_value reducer \u00b6 Reduces frame size by given percentage Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/helper.py def reducer ( frame = None , percentage = 0 ): \"\"\" ### reducer Reduces frame size by given percentage Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = cv2 . INTER_LANCZOS4 ) dict2Args \u00b6 Converts dictionary attributes to list(args) Parameters: Name Type Description Default param_dict dict Parameters dictionary required Returns: Arguments list Source code in vidgear/gears/helper.py def dict2Args ( param_dict ): \"\"\" ### dict2Args Converts dictionary attributes to list(args) Parameters: param_dict (dict): Parameters dictionary **Returns:** Arguments list \"\"\" args = [] for key in param_dict . keys (): if key in [ \"-clones\" ] or key . startswith ( \"-core\" ): if isinstance ( param_dict [ key ], list ): args . extend ( param_dict [ key ]) else : logger . warning ( \" {} with invalid datatype:` {} `, Skipped!\" . format ( \"Core parameter\" if key . startswith ( \"-core\" ) else \"Clone\" , param_dict [ key ], ) ) else : args . append ( key ) args . append ( str ( param_dict [ key ])) return args get_valid_ffmpeg_path \u00b6 Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' logging bool enables logging for its operations False Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , logging = False ): \"\"\" ### get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ logging (bool): enables logging for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () if logging : logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred if logging : logger . exception ( str ( e )) logger . debug ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False if logging : logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False if logging : logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" if logging : logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , logging = logging ) else False download_ffmpeg_binaries \u00b6 Generates FFmpeg Static Binaries for windows(if not available) Parameters: Name Type Description Default path string path for downloading custom FFmpeg executables required os_windows boolean is running on Windows OS? False os_bit string 32-bit or 64-bit OS? '' Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def download_ffmpeg_binaries ( path , os_windows = False , os_bit = \"\" ): \"\"\" ### download_ffmpeg_binaries Generates FFmpeg Static Binaries for windows(if not available) Parameters: path (string): path for downloading custom FFmpeg executables os_windows (boolean): is running on Windows OS? os_bit (string): 32-bit or 64-bit OS? **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if os_windows and os_bit : # initialize variables file_url = \"https://ffmpeg.zeranoe.com/builds/ {} /static/ffmpeg-latest- {} -static.zip\" . format ( os_bit , os_bit ) file_name = os . path . join ( os . path . abspath ( path ), \"ffmpeg-latest- {} -static.zip\" . format ( os_bit ) ) file_path = os . path . join ( os . path . abspath ( path ), \"ffmpeg-latest- {} -static/bin/ffmpeg.exe\" . format ( os_bit ), ) base_path , _ = os . path . split ( file_name ) # extract file base path # check if file already exists if os . path . isfile ( file_path ): final_path += file_path # skip download if does else : # import libs import zipfile # check if given path has write access assert os . access ( path , os . W_OK ), ( \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \" + path ) # remove leftovers if exists if os . path . isfile ( file_name ): os . remove ( file_name ) # download and write file to the given path with open ( file_name , \"wb\" ) as f : logger . debug ( \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries now. Please wait...\" ) try : response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () except Exception as e : logger . exception ( str ( e )) logger . warning ( \"Downloading Failed. Trying GitHub mirror now!\" ) file_url = \"https://raw.githubusercontent.com/abhiTronix/ffmpeg-static-builds/master/windows/ffmpeg-latest- {} -static.zip\" . format ( os_bit , os_bit ) response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 4096 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () logger . debug ( \"Extracting executables.\" ) with zipfile . ZipFile ( file_name , \"r\" ) as zip_ref : zip_ref . extractall ( base_path ) # perform cleaning os . remove ( file_name ) logger . debug ( \"FFmpeg binaries for Windows configured successfully!\" ) final_path += file_path # return final path return final_path validate_ffmpeg \u00b6 Validate FFmeg Binaries. returns True if tests are passed. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def validate_ffmpeg ( path , logging = False ): \"\"\" ### validate_ffmpeg Validate FFmeg Binaries. returns `True` if tests are passed. Parameters: path (string): absolute path of FFmpeg binaries logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" try : # get the FFmpeg version version = check_output ([ path , \"-version\" ]) firstline = version . split ( b \" \\n \" )[ 0 ] version = firstline . split ( b \" \" )[ 2 ] . strip () if logging : # log if test are passed logger . debug ( \"FFmpeg validity Test Passed!\" ) logger . debug ( \"Found valid FFmpeg Version: ` {} ` installed on this system\" . format ( version ) ) except Exception as e : # log if test are failed if logging : logger . exception ( str ( e )) logger . warning ( \"FFmpeg validity Test Failed!\" ) return False return True check_output \u00b6 Returns stdin output from subprocess module Source code in vidgear/gears/helper.py def check_output ( * args , ** kwargs ): \"\"\" ### check_output Returns stdin output from subprocess module \"\"\" # import libs import subprocess as sp # handle additional params retrieve_stderr = kwargs . pop ( \"force_retrieve_stderr\" , False ) # execute command in subprocess process = sp . Popen ( stdout = sp . PIPE , stderr = sp . DEVNULL if not ( retrieve_stderr ) else sp . PIPE , * args , ** kwargs ) output , stderr = process . communicate () retcode = process . poll () # handle return code if retcode and not ( retrieve_stderr ): cmd = kwargs . get ( \"args\" ) if cmd is None : cmd = args [ 0 ] error = sp . CalledProcessError ( retcode , cmd ) error . output = output raise error return output if not ( retrieve_stderr ) else stderr generate_auth_certificates \u00b6 Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: Name Type Description Default path string path for generating CURVE key-pairs required overwrite boolean overwrite existing key-pairs or not? False logging bool enables logging for its operations False Returns: A valid CURVE key-pairs path as string. Source code in vidgear/gears/helper.py def generate_auth_certificates ( path , overwrite = False , logging = False ): \"\"\" ### generate_auth_certificates Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: path (string): path for generating CURVE key-pairs overwrite (boolean): overwrite existing key-pairs or not? logging (bool): enables logging for its operations **Returns:** A valid CURVE key-pairs path as string. \"\"\" # import necessary libs import shutil import zmq.auth # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # generate keys dir keys_dir = os . path . join ( path , \"keys\" ) mkdir_safe ( keys_dir , logging = logging ) # generate separate public and private key dirs public_keys_dir = os . path . join ( keys_dir , \"public_keys\" ) secret_keys_dir = os . path . join ( keys_dir , \"private_keys\" ) # check if overwriting is allowed if overwrite : # delete previous certificates for dirs in [ public_keys_dir , secret_keys_dir ]: if os . path . exists ( dirs ): shutil . rmtree ( dirs ) mkdir_safe ( dirs , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ): shutil . move ( os . path . join ( keys_dir , key_file ), public_keys_dir ) elif key_file . endswith ( \".key_secret\" ): shutil . move ( os . path . join ( keys_dir , key_file ), secret_keys_dir ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): os . remove ( redundant_key ) else : # otherwise validate available keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # check if all valid keys are found if status_private_keys and status_public_keys : return ( keys_dir , secret_keys_dir , public_keys_dir ) # check if valid public keys are found if not ( status_public_keys ): mkdir_safe ( public_keys_dir , logging = logging ) # check if valid private keys are found if not ( status_private_keys ): mkdir_safe ( secret_keys_dir , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ) and not ( status_public_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( public_keys_dir , \".\" ) ) elif key_file . endswith ( \".key_secret\" ) and not ( status_private_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( secret_keys_dir , \".\" ) ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): os . remove ( redundant_key ) # validate newly generated keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # raise error is validation test fails if not ( status_private_keys ) or not ( status_public_keys ): raise RuntimeError ( \"[Helper:ERROR] :: Unable to generate valid ZMQ authentication certificates at ` {} `!\" . format ( keys_dir ) ) # finally return valid key paths return ( keys_dir , secret_keys_dir , public_keys_dir ) validate_audio \u00b6 Validates audio by retrieving audio-bitrate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required file_path string absolute path to file to be validated. None Returns: A string value, confirming whether audio is present, or not?. Source code in vidgear/gears/helper.py def validate_audio ( path , file_path = None ): \"\"\" ### validate_audio Validates audio by retrieving audio-bitrate from file. Parameters: path (string): absolute path of FFmpeg binaries file_path (string): absolute path to file to be validated. **Returns:** A string value, confirming whether audio is present, or not?. \"\"\" if file_path is None or not ( file_path ): logger . warning ( \"File path is empty!\" ) return \"\" # extract audio sample-rate from metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , file_path ], force_retrieve_stderr = True ) audio_bitrate = re . findall ( r \"fltp,\\s[0-9]+\\s\\w\\w[/]s\" , metadata . decode ( \"utf-8\" )) if audio_bitrate : filtered = audio_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] final_bitrate = \" {}{} \" . format ( int ( filtered [ 0 ] . strip ()), \"k\" if ( filtered [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) return final_bitrate else : return \"\" extract_time \u00b6 Extract time from give string value. Parameters: Name Type Description Default value string string value. required Returns: Time (in seconds) as integer. Source code in vidgear/gears/helper.py def extract_time ( value ): \"\"\" ### extract_time Extract time from give string value. Parameters: value (string): string value. **Returns:** Time _(in seconds)_ as integer. \"\"\" if not ( value ): logger . warning ( \"Value is empty!\" ) return 0 else : stripped_data = value . strip () t_duration = re . findall ( r \"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d)\" , stripped_data ) return ( sum ( int ( x ) * 60 ** i for i , x in enumerate ( reversed ( t_duration [ 0 ] . split ( \":\" ))) ) if t_duration else 0 ) validate_video \u00b6 Validates video by retrieving resolution/size and framerate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required video_path string absolute path to Video. None Returns: A dictionary of retieved Video resolution (as tuple(width, height)) and framerate (as float) . Source code in vidgear/gears/helper.py def validate_video ( path , video_path = None ): \"\"\" ### validate_video Validates video by retrieving resolution/size and framerate from file. Parameters: path (string): absolute path of FFmpeg binaries video_path (string): absolute path to Video. **Returns:** A dictionary of retieved Video resolution _(as tuple(width, height))_ and framerate _(as float)_. \"\"\" if video_path is None or not ( video_path ): logger . warning ( \"Video path is empty!\" ) return None # extract metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , video_path ], force_retrieve_stderr = True ) # clean and search stripped_data = [ x . decode ( \"utf-8\" ) . strip () for x in metadata . split ( b \" \\n \" )] result = {} for data in stripped_data : output_a = re . findall ( r \"(\\d+)x(\\d+)\" , data ) output_b = re . findall ( r \"\\d+(?:\\.\\d+)?\\sfps\" , data ) if len ( result ) == 2 : break if output_b and not \"framerate\" in result : result [ \"framerate\" ] = re . findall ( r \"[\\d\\.\\d]+\" , output_b [ 0 ])[ 0 ] if output_a and not \"resolution\" in result : result [ \"resolution\" ] = output_a [ - 1 ] # return values return result if ( len ( result ) == 2 ) else None is_valid_url \u00b6 Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required url string URL to be validated None logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def is_valid_url ( path , url = None , logging = False ): \"\"\" ### is_valid_url Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: path (string): absolute path of FFmpeg binaries url (string): URL to be validated logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if url is None or not ( url ): logger . warning ( \"URL is empty!\" ) return False # extract URL scheme extracted_scheme_url = url . split ( \"://\" , 1 )[ 0 ] # extract all FFmpeg supported protocols protocols = check_output ([ path , \"-hide_banner\" , \"-protocols\" ]) splitted = protocols . split ( b \" \\n \" ) supported_protocols = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ 2 : len ( splitted ) - 1 ] ] # Test and return result whether scheme is supported if extracted_scheme_url and extracted_scheme_url in supported_protocols : if logging : logger . debug ( \"URL scheme ` {} ` is supported by FFmpeg.\" . format ( extracted_scheme_url ) ) return True else : logger . warning ( \"URL scheme ` {} ` is not supported by FFmpeg!\" . format ( extracted_scheme_url ) ) return False get_video_bitrate \u00b6 Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: Name Type Description Default width int video-width required height int video-height required fps float video-framerate required bpp float bit-per-pixels value required Returns: Video bitrate (in Kbps) as integer. Source code in vidgear/gears/helper.py def get_video_bitrate ( width , height , fps , bpp ): \"\"\" ### get_video_bitrate Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: width (int): video-width height (int): video-height fps (float): video-framerate bpp (float): bit-per-pixels value **Returns:** Video bitrate _(in Kbps)_ as integer. \"\"\" return round (( width * height * bpp * fps ) / 1000 )","title":"Helper Methods"},{"location":"bonus/reference/helper/#logger_handler","text":"Returns the logger handler Returns: A logger handler Source code in vidgear/gears/helper.py def logger_handler (): \"\"\" ### logger_handler Returns the logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" %(bold_cyan)s%(asctime)s :: %(bold_blue)s%(name)s%(reset)s :: %(log_color)s%(levelname)s%(reset)s :: %(message)s \" , datefmt = \"%H:%M:%S\" , reset = True , log_colors = { \"INFO\" : \"bold_green\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_purple\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, ) # check if VIDGEAR_LOGFILE defined file_mode = os . environ . get ( \"VIDGEAR_LOGFILE\" , False ) # define handler handler = log . StreamHandler () if file_mode and isinstance ( file_mode , str ): file_path = os . path . abspath ( file_mode ) if ( os . name == \"nt\" or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( file_path ), os . W_OK ): file_path = ( os . path . join ( file_path , \"vidgear.log\" ) if os . path . isdir ( file_path ) else file_path ) handler = log . FileHandler ( file_path , mode = \"a\" ) formatter = log . Formatter ( \" %(asctime)s :: %(name)s :: %(levelname)s :: %(message)s \" , datefmt = \"%H:%M:%S\" , ) handler . setFormatter ( formatter ) return handler","title":"logger_handler"},{"location":"bonus/reference/helper/#check_cv_version","text":"Returns: OpenCV's version first bit Source code in vidgear/gears/helper.py def check_CV_version (): \"\"\" ### check_CV_version **Returns:** OpenCV's version first bit \"\"\" if parse_version ( cv2 . __version__ ) >= parse_version ( \"4\" ): return 4 else : return 3","title":"check_CV_version"},{"location":"bonus/reference/helper/#check_gstreamer_support","text":"Checks whether OpenCV is compiled with Gstreamer( >=1.0.0 ) support. Parameters: Name Type Description Default logging bool enables logging for its operations False Returns: A Boolean value Source code in vidgear/gears/helper.py def check_gstreamer_support ( logging = False ): \"\"\" ### check_gstreamer_support Checks whether OpenCV is compiled with Gstreamer(`>=1.0.0`) support. Parameters: logging (bool): enables logging for its operations **Returns:** A Boolean value \"\"\" raw = cv2 . getBuildInformation () gst = [ x . strip () for x in raw . split ( \" \\n \" ) if x and re . search ( r \"GStreamer[,-:]+\\s*(?:YES|NO)\" , x ) ] if gst and \"YES\" in gst [ 0 ]: version = re . search ( r \"(\\d+\\.)?(\\d+\\.)?(\\*|\\d+)\" , gst [ 0 ]) if logging : logger . debug ( \"Found GStreamer version: {} \" . format ( version [ 0 ])) return version [ 0 ] >= \"1.0.0\" else : logger . warning ( \"GStreamer not found!\" ) return False","title":"check_gstreamer_support"},{"location":"bonus/reference/helper/#get_supported_resolution","text":"Parameters: Name Type Description Default value string value to be validated required logging bool enables logging for its operations False Returns: Valid stream resolution Source code in vidgear/gears/helper.py def get_supported_resolution ( value , logging = False ): \"\"\" ### get_supported_resolution Parameters: value (string): value to be validated logging (bool): enables logging for its operations **Returns:** Valid stream resolution \"\"\" # default to best stream_resolution = \"best\" supported_stream_qualities = [ \"144p\" , \"240p\" , \"360p\" , \"480p\" , \"720p\" , \"1080p\" , \"1440p\" , \"2160p\" , \"worst\" , \"best\" , ] if isinstance ( value , str ): if value . strip () . lower () in supported_stream_qualities : stream_resolution = value . strip () . lower () if logging : logger . debug ( \"Selecting ` {} ` resolution for streams.\" . format ( stream_resolution ) ) else : logger . warning ( \"Specified stream-resolution ` {} ` is not supported. Reverting to `best`!\" . format ( value ) ) else : logger . warning ( \"Specified stream-resolution ` {} ` is Invalid. Reverting to `best`!\" . format ( value ) ) return stream_resolution","title":"get_supported_resolution"},{"location":"bonus/reference/helper/#dimensions_to_resolutions","text":"Parameters: Name Type Description Default value list list of dimensions (e.g. 640x360 ) required Returns: list of resolutions (e.g. 360p ) Source code in vidgear/gears/helper.py def dimensions_to_resolutions ( value ): \"\"\" ### dimensions_to_resolutions Parameters: value (list): list of dimensions (e.g. `640x360`) **Returns:** list of resolutions (e.g. `360p`) \"\"\" supported_resolutions = { \"256x144\" : \"144p\" , \"426x240\" : \"240p\" , \"640x360\" : \"360p\" , \"854x480\" : \"480p\" , \"1280x720\" : \"720p\" , \"1920x1080\" : \"1080p\" , \"2560x1440\" : \"1440p\" , \"3840x2160\" : \"2160p\" , } return ( list ( map ( supported_resolutions . get , value , value )) if isinstance ( value , list ) else [] )","title":"dimensions_to_resolutions"},{"location":"bonus/reference/helper/#mkdir_safe","text":"Safely creates directory at given path. Parameters: Name Type Description Default dir_path string path to the directory required logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def mkdir_safe ( dir_path , logging = False ): \"\"\" ### mkdir_safe Safely creates directory at given path. Parameters: dir_path (string): path to the directory logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir_path ) if logging : logger . debug ( \"Created directory at ` {} `\" . format ( dir_path )) except OSError as e : if e . errno != errno . EEXIST : raise if logging : logger . debug ( \"Directory already exists at ` {} `\" . format ( dir_path ))","title":"mkdir_safe"},{"location":"bonus/reference/helper/#delete_safe","text":"Safely deletes files with given extensions at given path. Parameters: Name Type Description Default dir_path string path to the directory required extensions list list of extensions to be deleted [] logging bool enables logging for its operations False Source code in vidgear/gears/helper.py def delete_safe ( dir_path , extensions = [], logging = False ): \"\"\" ### delete_safe Safely deletes files with given extensions at given path. Parameters: dir_path (string): path to the directory extensions (list): list of extensions to be deleted logging (bool): enables logging for its operations \"\"\" if not extensions or not os . path . exists ( dir_path ): logger . warning ( \"Invalid input provided for deleting!\" ) return if logging : logger . debug ( \"Clearing Assets at ` {} `!\" . format ( dir_path )) for ext in extensions : files_ext = [ os . path . join ( dir_path , f ) for f in os . listdir ( dir_path ) if f . endswith ( ext ) ] for file in files_ext : os . remove ( file ) if logging : logger . debug ( \"Deleted file: ` {} `\" . format ( file ))","title":"delete_safe"},{"location":"bonus/reference/helper/#cappropid","text":"Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: Name Type Description Default property string inputs OpenCV property as string. required Returns: Resultant integer value. Source code in vidgear/gears/helper.py def capPropId ( property ): \"\"\" ### capPropId Retrieves the OpenCV property's Integer(Actual) value from string. Parameters: property (string): inputs OpenCV property as string. **Returns:** Resultant integer value. \"\"\" integer_value = 0 try : integer_value = getattr ( cv2 , property ) except Exception as e : logger . exception ( str ( e )) logger . critical ( \"` {} ` is not a valid OpenCV property!\" . format ( property )) return None return integer_value","title":"capPropId"},{"location":"bonus/reference/helper/#reducer","text":"Reduces frame size by given percentage Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/helper.py def reducer ( frame = None , percentage = 0 ): \"\"\" ### reducer Reduces frame size by given percentage Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = cv2 . INTER_LANCZOS4 )","title":"reducer"},{"location":"bonus/reference/helper/#dict2args","text":"Converts dictionary attributes to list(args) Parameters: Name Type Description Default param_dict dict Parameters dictionary required Returns: Arguments list Source code in vidgear/gears/helper.py def dict2Args ( param_dict ): \"\"\" ### dict2Args Converts dictionary attributes to list(args) Parameters: param_dict (dict): Parameters dictionary **Returns:** Arguments list \"\"\" args = [] for key in param_dict . keys (): if key in [ \"-clones\" ] or key . startswith ( \"-core\" ): if isinstance ( param_dict [ key ], list ): args . extend ( param_dict [ key ]) else : logger . warning ( \" {} with invalid datatype:` {} `, Skipped!\" . format ( \"Core parameter\" if key . startswith ( \"-core\" ) else \"Clone\" , param_dict [ key ], ) ) else : args . append ( key ) args . append ( str ( param_dict [ key ])) return args","title":"dict2Args"},{"location":"bonus/reference/helper/#get_valid_ffmpeg_path","text":"Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' logging bool enables logging for its operations False Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , logging = False ): \"\"\" ### get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ logging (bool): enables logging for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () if logging : logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred if logging : logger . exception ( str ( e )) logger . debug ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False if logging : logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False if logging : logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" if logging : logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , logging = logging ) else False","title":"get_valid_ffmpeg_path"},{"location":"bonus/reference/helper/#download_ffmpeg_binaries","text":"Generates FFmpeg Static Binaries for windows(if not available) Parameters: Name Type Description Default path string path for downloading custom FFmpeg executables required os_windows boolean is running on Windows OS? False os_bit string 32-bit or 64-bit OS? '' Returns: A valid FFmpeg executable path string. Source code in vidgear/gears/helper.py def download_ffmpeg_binaries ( path , os_windows = False , os_bit = \"\" ): \"\"\" ### download_ffmpeg_binaries Generates FFmpeg Static Binaries for windows(if not available) Parameters: path (string): path for downloading custom FFmpeg executables os_windows (boolean): is running on Windows OS? os_bit (string): 32-bit or 64-bit OS? **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if os_windows and os_bit : # initialize variables file_url = \"https://ffmpeg.zeranoe.com/builds/ {} /static/ffmpeg-latest- {} -static.zip\" . format ( os_bit , os_bit ) file_name = os . path . join ( os . path . abspath ( path ), \"ffmpeg-latest- {} -static.zip\" . format ( os_bit ) ) file_path = os . path . join ( os . path . abspath ( path ), \"ffmpeg-latest- {} -static/bin/ffmpeg.exe\" . format ( os_bit ), ) base_path , _ = os . path . split ( file_name ) # extract file base path # check if file already exists if os . path . isfile ( file_path ): final_path += file_path # skip download if does else : # import libs import zipfile # check if given path has write access assert os . access ( path , os . W_OK ), ( \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \" + path ) # remove leftovers if exists if os . path . isfile ( file_name ): os . remove ( file_name ) # download and write file to the given path with open ( file_name , \"wb\" ) as f : logger . debug ( \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries now. Please wait...\" ) try : response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () except Exception as e : logger . exception ( str ( e )) logger . warning ( \"Downloading Failed. Trying GitHub mirror now!\" ) file_url = \"https://raw.githubusercontent.com/abhiTronix/ffmpeg-static-builds/master/windows/ffmpeg-latest- {} -static.zip\" . format ( os_bit , os_bit ) response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 4096 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () logger . debug ( \"Extracting executables.\" ) with zipfile . ZipFile ( file_name , \"r\" ) as zip_ref : zip_ref . extractall ( base_path ) # perform cleaning os . remove ( file_name ) logger . debug ( \"FFmpeg binaries for Windows configured successfully!\" ) final_path += file_path # return final path return final_path","title":"download_ffmpeg_binaries"},{"location":"bonus/reference/helper/#validate_ffmpeg","text":"Validate FFmeg Binaries. returns True if tests are passed. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def validate_ffmpeg ( path , logging = False ): \"\"\" ### validate_ffmpeg Validate FFmeg Binaries. returns `True` if tests are passed. Parameters: path (string): absolute path of FFmpeg binaries logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" try : # get the FFmpeg version version = check_output ([ path , \"-version\" ]) firstline = version . split ( b \" \\n \" )[ 0 ] version = firstline . split ( b \" \" )[ 2 ] . strip () if logging : # log if test are passed logger . debug ( \"FFmpeg validity Test Passed!\" ) logger . debug ( \"Found valid FFmpeg Version: ` {} ` installed on this system\" . format ( version ) ) except Exception as e : # log if test are failed if logging : logger . exception ( str ( e )) logger . warning ( \"FFmpeg validity Test Failed!\" ) return False return True","title":"validate_ffmpeg"},{"location":"bonus/reference/helper/#check_output","text":"Returns stdin output from subprocess module Source code in vidgear/gears/helper.py def check_output ( * args , ** kwargs ): \"\"\" ### check_output Returns stdin output from subprocess module \"\"\" # import libs import subprocess as sp # handle additional params retrieve_stderr = kwargs . pop ( \"force_retrieve_stderr\" , False ) # execute command in subprocess process = sp . Popen ( stdout = sp . PIPE , stderr = sp . DEVNULL if not ( retrieve_stderr ) else sp . PIPE , * args , ** kwargs ) output , stderr = process . communicate () retcode = process . poll () # handle return code if retcode and not ( retrieve_stderr ): cmd = kwargs . get ( \"args\" ) if cmd is None : cmd = args [ 0 ] error = sp . CalledProcessError ( retcode , cmd ) error . output = output raise error return output if not ( retrieve_stderr ) else stderr","title":"check_output"},{"location":"bonus/reference/helper/#generate_auth_certificates","text":"Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: Name Type Description Default path string path for generating CURVE key-pairs required overwrite boolean overwrite existing key-pairs or not? False logging bool enables logging for its operations False Returns: A valid CURVE key-pairs path as string. Source code in vidgear/gears/helper.py def generate_auth_certificates ( path , overwrite = False , logging = False ): \"\"\" ### generate_auth_certificates Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode. Parameters: path (string): path for generating CURVE key-pairs overwrite (boolean): overwrite existing key-pairs or not? logging (bool): enables logging for its operations **Returns:** A valid CURVE key-pairs path as string. \"\"\" # import necessary libs import shutil import zmq.auth # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # generate keys dir keys_dir = os . path . join ( path , \"keys\" ) mkdir_safe ( keys_dir , logging = logging ) # generate separate public and private key dirs public_keys_dir = os . path . join ( keys_dir , \"public_keys\" ) secret_keys_dir = os . path . join ( keys_dir , \"private_keys\" ) # check if overwriting is allowed if overwrite : # delete previous certificates for dirs in [ public_keys_dir , secret_keys_dir ]: if os . path . exists ( dirs ): shutil . rmtree ( dirs ) mkdir_safe ( dirs , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ): shutil . move ( os . path . join ( keys_dir , key_file ), public_keys_dir ) elif key_file . endswith ( \".key_secret\" ): shutil . move ( os . path . join ( keys_dir , key_file ), secret_keys_dir ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): os . remove ( redundant_key ) else : # otherwise validate available keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # check if all valid keys are found if status_private_keys and status_public_keys : return ( keys_dir , secret_keys_dir , public_keys_dir ) # check if valid public keys are found if not ( status_public_keys ): mkdir_safe ( public_keys_dir , logging = logging ) # check if valid private keys are found if not ( status_private_keys ): mkdir_safe ( secret_keys_dir , logging = logging ) # generate new keys server_public_file , server_secret_file = zmq . auth . create_certificates ( keys_dir , \"server\" ) client_public_file , client_secret_file = zmq . auth . create_certificates ( keys_dir , \"client\" ) # move keys to their appropriate directory respectively for key_file in os . listdir ( keys_dir ): if key_file . endswith ( \".key\" ) and not ( status_public_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( public_keys_dir , \".\" ) ) elif key_file . endswith ( \".key_secret\" ) and not ( status_private_keys ): shutil . move ( os . path . join ( keys_dir , key_file ), os . path . join ( secret_keys_dir , \".\" ) ) else : # clean redundant keys if present redundant_key = os . path . join ( keys_dir , key_file ) if os . path . isfile ( redundant_key ): os . remove ( redundant_key ) # validate newly generated keys status_public_keys = validate_auth_keys ( public_keys_dir , \".key\" ) status_private_keys = validate_auth_keys ( secret_keys_dir , \".key_secret\" ) # raise error is validation test fails if not ( status_private_keys ) or not ( status_public_keys ): raise RuntimeError ( \"[Helper:ERROR] :: Unable to generate valid ZMQ authentication certificates at ` {} `!\" . format ( keys_dir ) ) # finally return valid key paths return ( keys_dir , secret_keys_dir , public_keys_dir )","title":"generate_auth_certificates"},{"location":"bonus/reference/helper/#validate_audio","text":"Validates audio by retrieving audio-bitrate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required file_path string absolute path to file to be validated. None Returns: A string value, confirming whether audio is present, or not?. Source code in vidgear/gears/helper.py def validate_audio ( path , file_path = None ): \"\"\" ### validate_audio Validates audio by retrieving audio-bitrate from file. Parameters: path (string): absolute path of FFmpeg binaries file_path (string): absolute path to file to be validated. **Returns:** A string value, confirming whether audio is present, or not?. \"\"\" if file_path is None or not ( file_path ): logger . warning ( \"File path is empty!\" ) return \"\" # extract audio sample-rate from metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , file_path ], force_retrieve_stderr = True ) audio_bitrate = re . findall ( r \"fltp,\\s[0-9]+\\s\\w\\w[/]s\" , metadata . decode ( \"utf-8\" )) if audio_bitrate : filtered = audio_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] final_bitrate = \" {}{} \" . format ( int ( filtered [ 0 ] . strip ()), \"k\" if ( filtered [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) return final_bitrate else : return \"\"","title":"validate_audio"},{"location":"bonus/reference/helper/#extract_time","text":"Extract time from give string value. Parameters: Name Type Description Default value string string value. required Returns: Time (in seconds) as integer. Source code in vidgear/gears/helper.py def extract_time ( value ): \"\"\" ### extract_time Extract time from give string value. Parameters: value (string): string value. **Returns:** Time _(in seconds)_ as integer. \"\"\" if not ( value ): logger . warning ( \"Value is empty!\" ) return 0 else : stripped_data = value . strip () t_duration = re . findall ( r \"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d)\" , stripped_data ) return ( sum ( int ( x ) * 60 ** i for i , x in enumerate ( reversed ( t_duration [ 0 ] . split ( \":\" ))) ) if t_duration else 0 )","title":"extract_time"},{"location":"bonus/reference/helper/#validate_video","text":"Validates video by retrieving resolution/size and framerate from file. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required video_path string absolute path to Video. None Returns: A dictionary of retieved Video resolution (as tuple(width, height)) and framerate (as float) . Source code in vidgear/gears/helper.py def validate_video ( path , video_path = None ): \"\"\" ### validate_video Validates video by retrieving resolution/size and framerate from file. Parameters: path (string): absolute path of FFmpeg binaries video_path (string): absolute path to Video. **Returns:** A dictionary of retieved Video resolution _(as tuple(width, height))_ and framerate _(as float)_. \"\"\" if video_path is None or not ( video_path ): logger . warning ( \"Video path is empty!\" ) return None # extract metadata metadata = check_output ( [ path , \"-hide_banner\" , \"-i\" , video_path ], force_retrieve_stderr = True ) # clean and search stripped_data = [ x . decode ( \"utf-8\" ) . strip () for x in metadata . split ( b \" \\n \" )] result = {} for data in stripped_data : output_a = re . findall ( r \"(\\d+)x(\\d+)\" , data ) output_b = re . findall ( r \"\\d+(?:\\.\\d+)?\\sfps\" , data ) if len ( result ) == 2 : break if output_b and not \"framerate\" in result : result [ \"framerate\" ] = re . findall ( r \"[\\d\\.\\d]+\" , output_b [ 0 ])[ 0 ] if output_a and not \"resolution\" in result : result [ \"resolution\" ] = output_a [ - 1 ] # return values return result if ( len ( result ) == 2 ) else None","title":"validate_video"},{"location":"bonus/reference/helper/#is_valid_url","text":"Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required url string URL to be validated None logging bool enables logging for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in vidgear/gears/helper.py def is_valid_url ( path , url = None , logging = False ): \"\"\" ### is_valid_url Checks URL validity by testing its scheme against FFmpeg's supported protocols Parameters: path (string): absolute path of FFmpeg binaries url (string): URL to be validated logging (bool): enables logging for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if url is None or not ( url ): logger . warning ( \"URL is empty!\" ) return False # extract URL scheme extracted_scheme_url = url . split ( \"://\" , 1 )[ 0 ] # extract all FFmpeg supported protocols protocols = check_output ([ path , \"-hide_banner\" , \"-protocols\" ]) splitted = protocols . split ( b \" \\n \" ) supported_protocols = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ 2 : len ( splitted ) - 1 ] ] # Test and return result whether scheme is supported if extracted_scheme_url and extracted_scheme_url in supported_protocols : if logging : logger . debug ( \"URL scheme ` {} ` is supported by FFmpeg.\" . format ( extracted_scheme_url ) ) return True else : logger . warning ( \"URL scheme ` {} ` is not supported by FFmpeg!\" . format ( extracted_scheme_url ) ) return False","title":"is_valid_url"},{"location":"bonus/reference/helper/#get_video_bitrate","text":"Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: Name Type Description Default width int video-width required height int video-height required fps float video-framerate required bpp float bit-per-pixels value required Returns: Video bitrate (in Kbps) as integer. Source code in vidgear/gears/helper.py def get_video_bitrate ( width , height , fps , bpp ): \"\"\" ### get_video_bitrate Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values Parameters: width (int): video-width height (int): video-height fps (float): video-framerate bpp (float): bit-per-pixels value **Returns:** Video bitrate _(in Kbps)_ as integer. \"\"\" return round (( width * height * bpp * fps ) / 1000 )","title":"get_video_bitrate"},{"location":"bonus/reference/helper_async/","text":"logger_handler \u00b6 Returns the logger handler Returns: A logger handler Source code in vidgear/gears/asyncio/helper.py def logger_handler (): \"\"\" ### logger_handler Returns the logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" %(bold_cyan)s%(asctime)s :: %(bold_blue)s%(name)s%(reset)s :: %(log_color)s%(levelname)s%(reset)s :: %(message)s \" , datefmt = \"%H:%M:%S\" , reset = False , log_colors = { \"INFO\" : \"bold_green\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_purple\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, ) # check if VIDGEAR_LOGFILE defined file_mode = os . environ . get ( \"VIDGEAR_LOGFILE\" , False ) # define handler handler = log . StreamHandler () if file_mode and isinstance ( file_mode , str ): file_path = os . path . abspath ( file_mode ) if ( os . name == \"nt\" or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( file_path ), os . W_OK ): file_path = ( os . path . join ( file_path , \"vidgear.log\" ) if os . path . isdir ( file_path ) else file_path ) handler = log . FileHandler ( file_path , mode = \"a\" ) formatter = log . Formatter ( \" %(asctime)s :: %(name)s :: %(levelname)s :: %(message)s \" , datefmt = \"%H:%M:%S\" , ) handler . setFormatter ( formatter ) return handler mkdir_safe \u00b6 Safely creates directory at given path. Parameters: Name Type Description Default logging bool enables logging for its operations False Source code in vidgear/gears/asyncio/helper.py def mkdir_safe ( dir , logging = False ): \"\"\" ### mkdir_safe Safely creates directory at given path. Parameters: logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir ) if logging : logger . debug ( \"Created directory at ` {} `\" . format ( dir )) except OSError as e : if e . errno != errno . EEXIST : raise if logging : logger . debug ( \"Directory already exists at ` {} `\" . format ( dir )) reducer \u00b6 Asynchronous method that reduces frame size by given percentage. Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/asyncio/helper.py async def reducer ( frame = None , percentage = 0 ): \"\"\" ### reducer Asynchronous method that reduces frame size by given percentage. Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = cv2 . INTER_LANCZOS4 ) generate_webdata \u00b6 Auto-Generates, and Auto-validates default data for WebGear API. Parameters: Name Type Description Default path string path for generating data required overwrite_default boolean overwrite existing data or not? False logging bool enables logging for its operations False Returns: A valid data path as string. Source code in vidgear/gears/asyncio/helper.py def generate_webdata ( path , overwrite_default = False , logging = False ): \"\"\" ### generate_webdata Auto-Generates, and Auto-validates default data for WebGear API. Parameters: path (string): path for generating data overwrite_default (boolean): overwrite existing data or not? logging (bool): enables logging for its operations **Returns:** A valid data path as string. \"\"\" # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # self-generate dirs template_dir = os . path . join ( path , \"templates\" ) # generates HTML templates dir static_dir = os . path . join ( path , \"static\" ) # generates static dir # generate js & css static and favicon img subdirs js_static_dir = os . path . join ( static_dir , \"js\" ) css_static_dir = os . path . join ( static_dir , \"css\" ) favicon_dir = os . path . join ( static_dir , \"img\" ) mkdir_safe ( static_dir , logging = logging ) mkdir_safe ( template_dir , logging = logging ) mkdir_safe ( js_static_dir , logging = logging ) mkdir_safe ( css_static_dir , logging = logging ) mkdir_safe ( favicon_dir , logging = logging ) # check if overwriting is enabled if overwrite_default : logger . critical ( \"Overwriting existing WebGear data-files with default data-files from the server!\" ) download_webdata ( template_dir , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , files = [ \"bootstrap.min.css\" , \"cover.css\" ], logging = logging ) download_webdata ( js_static_dir , files = [ \"bootstrap.min.js\" , \"jquery-3.4.1.slim.min.js\" , \"popper.min.js\" ], logging = logging , ) download_webdata ( favicon_dir , files = [ \"favicon-32x32.png\" ], logging = logging ) else : # validate important data-files if validate_webdata ( template_dir , [ \"index.html\" , \"404.html\" , \"500.html\" ]): if logging : logger . debug ( \"Found valid WebGear data-files successfully.\" ) else : # otherwise download default files logger . critical ( \"Failed to detect critical WebGear data-files: index.html, 404.html & 500.html!\" ) logger . warning ( \"Re-downloading default data-files from the server.\" ) download_webdata ( template_dir , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , files = [ \"bootstrap.min.css\" , \"cover.css\" ], logging = logging , ) download_webdata ( js_static_dir , files = [ \"bootstrap.min.js\" , \"jquery-3.4.1.slim.min.js\" , \"popper.min.js\" ], logging = logging , ) download_webdata ( favicon_dir , files = [ \"favicon-32x32.png\" ], logging = logging ) return path download_webdata \u00b6 Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: Name Type Description Default path string path for downloading data required files list list of files to be downloaded [] logging bool enables logging for its operations False Returns: A valid path as string. Source code in vidgear/gears/asyncio/helper.py def download_webdata ( path , files = [], logging = False ): \"\"\" ### download_webdata Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: path (string): path for downloading data files (list): list of files to be downloaded logging (bool): enables logging for its operations **Returns:** A valid path as string. \"\"\" basename = os . path . basename ( path ) if logging : logger . debug ( \"Downloading {} data-files at ` {} `\" . format ( basename , path )) for file in files : # get filename file_name = os . path . join ( path , file ) # get URL if basename == \"templates\" : file_url = \"https://raw.githubusercontent.com/abhiTronix/webgear_data/master/ {} / {} \" . format ( basename , file ) else : file_url = \"https://raw.githubusercontent.com/abhiTronix/webgear_data/master/static/ {} / {} \" . format ( basename , file ) # download and write file to the given path if logging : logger . debug ( \"Downloading {} data-file: {} .\" . format ( basename , file )) response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) with open ( file_name , \"wb\" ) as f : for data in response . iter_content ( chunk_size = 256 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () if logging : logger . debug ( \"Verifying downloaded data:\" ) if validate_webdata ( path , files = files , logging = logging ): if logging : logger . info ( \"Successful!\" ) return path else : raise RuntimeError ( \"[Helper:ERROR] :: Failed to download required {} data-files at: {} , Check your Internet connectivity!\" . format ( basename , path ) )","title":"Helper Methods"},{"location":"bonus/reference/helper_async/#logger_handler","text":"Returns the logger handler Returns: A logger handler Source code in vidgear/gears/asyncio/helper.py def logger_handler (): \"\"\" ### logger_handler Returns the logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" %(bold_cyan)s%(asctime)s :: %(bold_blue)s%(name)s%(reset)s :: %(log_color)s%(levelname)s%(reset)s :: %(message)s \" , datefmt = \"%H:%M:%S\" , reset = False , log_colors = { \"INFO\" : \"bold_green\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_purple\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, ) # check if VIDGEAR_LOGFILE defined file_mode = os . environ . get ( \"VIDGEAR_LOGFILE\" , False ) # define handler handler = log . StreamHandler () if file_mode and isinstance ( file_mode , str ): file_path = os . path . abspath ( file_mode ) if ( os . name == \"nt\" or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( file_path ), os . W_OK ): file_path = ( os . path . join ( file_path , \"vidgear.log\" ) if os . path . isdir ( file_path ) else file_path ) handler = log . FileHandler ( file_path , mode = \"a\" ) formatter = log . Formatter ( \" %(asctime)s :: %(name)s :: %(levelname)s :: %(message)s \" , datefmt = \"%H:%M:%S\" , ) handler . setFormatter ( formatter ) return handler","title":"logger_handler"},{"location":"bonus/reference/helper_async/#mkdir_safe","text":"Safely creates directory at given path. Parameters: Name Type Description Default logging bool enables logging for its operations False Source code in vidgear/gears/asyncio/helper.py def mkdir_safe ( dir , logging = False ): \"\"\" ### mkdir_safe Safely creates directory at given path. Parameters: logging (bool): enables logging for its operations \"\"\" try : os . makedirs ( dir ) if logging : logger . debug ( \"Created directory at ` {} `\" . format ( dir )) except OSError as e : if e . errno != errno . EEXIST : raise if logging : logger . debug ( \"Directory already exists at ` {} `\" . format ( dir ))","title":"mkdir_safe"},{"location":"bonus/reference/helper_async/#reducer","text":"Asynchronous method that reduces frame size by given percentage. Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). None percentage int/float inputs size-reduction percentage. 0 Returns: A reduced numpy ndarray array. Source code in vidgear/gears/asyncio/helper.py async def reducer ( frame = None , percentage = 0 ): \"\"\" ### reducer Asynchronous method that reduces frame size by given percentage. Parameters: frame (numpy.ndarray): inputs numpy array(frame). percentage (int/float): inputs size-reduction percentage. **Returns:** A reduced numpy ndarray array. \"\"\" # check if frame is valid if frame is None : raise ValueError ( \"[Helper:ERROR] :: Input frame cannot be NoneType!\" ) # check if valid reduction percentage is given if not ( percentage > 0 and percentage < 90 ): raise ValueError ( \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\" ) # grab the frame size ( height , width ) = frame . shape [: 2 ] # calculate the ratio of the width from percentage reduction = (( 100 - percentage ) / 100 ) * width ratio = reduction / float ( width ) # construct the dimensions dimensions = ( int ( reduction ), int ( height * ratio )) # return the resized frame return cv2 . resize ( frame , dimensions , interpolation = cv2 . INTER_LANCZOS4 )","title":"reducer"},{"location":"bonus/reference/helper_async/#generate_webdata","text":"Auto-Generates, and Auto-validates default data for WebGear API. Parameters: Name Type Description Default path string path for generating data required overwrite_default boolean overwrite existing data or not? False logging bool enables logging for its operations False Returns: A valid data path as string. Source code in vidgear/gears/asyncio/helper.py def generate_webdata ( path , overwrite_default = False , logging = False ): \"\"\" ### generate_webdata Auto-Generates, and Auto-validates default data for WebGear API. Parameters: path (string): path for generating data overwrite_default (boolean): overwrite existing data or not? logging (bool): enables logging for its operations **Returns:** A valid data path as string. \"\"\" # check if path corresponds to vidgear only if os . path . basename ( path ) != \".vidgear\" : path = os . path . join ( path , \".vidgear\" ) # self-generate dirs template_dir = os . path . join ( path , \"templates\" ) # generates HTML templates dir static_dir = os . path . join ( path , \"static\" ) # generates static dir # generate js & css static and favicon img subdirs js_static_dir = os . path . join ( static_dir , \"js\" ) css_static_dir = os . path . join ( static_dir , \"css\" ) favicon_dir = os . path . join ( static_dir , \"img\" ) mkdir_safe ( static_dir , logging = logging ) mkdir_safe ( template_dir , logging = logging ) mkdir_safe ( js_static_dir , logging = logging ) mkdir_safe ( css_static_dir , logging = logging ) mkdir_safe ( favicon_dir , logging = logging ) # check if overwriting is enabled if overwrite_default : logger . critical ( \"Overwriting existing WebGear data-files with default data-files from the server!\" ) download_webdata ( template_dir , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , files = [ \"bootstrap.min.css\" , \"cover.css\" ], logging = logging ) download_webdata ( js_static_dir , files = [ \"bootstrap.min.js\" , \"jquery-3.4.1.slim.min.js\" , \"popper.min.js\" ], logging = logging , ) download_webdata ( favicon_dir , files = [ \"favicon-32x32.png\" ], logging = logging ) else : # validate important data-files if validate_webdata ( template_dir , [ \"index.html\" , \"404.html\" , \"500.html\" ]): if logging : logger . debug ( \"Found valid WebGear data-files successfully.\" ) else : # otherwise download default files logger . critical ( \"Failed to detect critical WebGear data-files: index.html, 404.html & 500.html!\" ) logger . warning ( \"Re-downloading default data-files from the server.\" ) download_webdata ( template_dir , files = [ \"index.html\" , \"404.html\" , \"500.html\" , \"base.html\" ], logging = logging , ) download_webdata ( css_static_dir , files = [ \"bootstrap.min.css\" , \"cover.css\" ], logging = logging , ) download_webdata ( js_static_dir , files = [ \"bootstrap.min.js\" , \"jquery-3.4.1.slim.min.js\" , \"popper.min.js\" ], logging = logging , ) download_webdata ( favicon_dir , files = [ \"favicon-32x32.png\" ], logging = logging ) return path","title":"generate_webdata"},{"location":"bonus/reference/helper_async/#download_webdata","text":"Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: Name Type Description Default path string path for downloading data required files list list of files to be downloaded [] logging bool enables logging for its operations False Returns: A valid path as string. Source code in vidgear/gears/asyncio/helper.py def download_webdata ( path , files = [], logging = False ): \"\"\" ### download_webdata Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them. Parameters: path (string): path for downloading data files (list): list of files to be downloaded logging (bool): enables logging for its operations **Returns:** A valid path as string. \"\"\" basename = os . path . basename ( path ) if logging : logger . debug ( \"Downloading {} data-files at ` {} `\" . format ( basename , path )) for file in files : # get filename file_name = os . path . join ( path , file ) # get URL if basename == \"templates\" : file_url = \"https://raw.githubusercontent.com/abhiTronix/webgear_data/master/ {} / {} \" . format ( basename , file ) else : file_url = \"https://raw.githubusercontent.com/abhiTronix/webgear_data/master/static/ {} / {} \" . format ( basename , file ) # download and write file to the given path if logging : logger . debug ( \"Downloading {} data-file: {} .\" . format ( basename , file )) response = requests . get ( file_url , stream = True , timeout = 2 ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) with open ( file_name , \"wb\" ) as f : for data in response . iter_content ( chunk_size = 256 ): f . write ( data ) if len ( data ) > 0 : bar . update ( len ( data )) bar . close () if logging : logger . debug ( \"Verifying downloaded data:\" ) if validate_webdata ( path , files = files , logging = logging ): if logging : logger . info ( \"Successful!\" ) return path else : raise RuntimeError ( \"[Helper:ERROR] :: Failed to download required {} data-files at: {} , Check your Internet connectivity!\" . format ( basename , path ) )","title":"download_webdata"},{"location":"bonus/reference/netgear/","text":"All NetGear API parameters are explained here \u27b6 NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middle-ware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. Info NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns (i.e. zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc . Modes of Operation Primary Modes NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. The mode sends back confirmation when the frame is received successfully in few patterns. Exclusive Modes In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes: Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames . Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. __init__ ( self , address = None , port = None , protocol = None , pattern = 0 , receive_mode = False , logging = False , ** options ) special \u00b6 This constructor method initializes the object state and attributes of the NetGear class. Parameters: Name Type Description Default address str sets the valid network address of the Server/Client. None port str sets the valid Network Port of the Server/Client. None protocol str sets the valid messaging protocol between Server/Client. None pattern int sets the supported messaging pattern(flow of communication) between Server/Client 0 receive_mode bool select the Netgear's Mode of operation. False logging bool enables/disables logging. False options dict provides the flexibility to alter various NetGear internal properties. {} Source code in vidgear/gears/netgear.py def __init__ ( self , address = None , port = None , protocol = None , pattern = 0 , receive_mode = False , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the Netgear's Mode of operation. logging (bool): enables/disables logging. options (dict): provides the flexibility to alter various NetGear internal properties. \"\"\" try : # import PyZMQ library import zmq from zmq.error import ZMQError # assign values to global variable for further use self . __zmq = zmq self . __ZMQError = ZMQError except ImportError as error : # raise error raise ImportError ( \"[NetGear:ERROR] :: pyzmq python library not installed. Kindly install it with `pip install pyzmq` command.\" ) # enable logging if specified self . __logging = True if logging else False # define valid messaging patterns => `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), } # Handle messaging pattern msg_pattern = None # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns . keys (): # assign value msg_pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` pattern = 0 msg_pattern = valid_messaging_patterns [ pattern ] if self . __logging : logger . warning ( \"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\" ) # assign pattern to global parameter for further use self . __pattern = pattern # Handle messaging protocol if protocol is None or not ( protocol in [ \"tcp\" , \"ipc\" ]): # else default to `tcp` protocol protocol = \"tcp\" # log it if self . __logging : logger . warning ( \"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\" ) # Handle connection params self . __msg_flag = 0 # handles connection flags self . __msg_copy = False # handles whether to copy data self . __msg_track = False # handles whether to track packets # Handle NetGear's internal exclusive modes and params # define Multi-Server mode self . __multiserver_mode = False # handles multi-server_mode state # define Multi-Client mode self . __multiclient_mode = False # handles multi-client_mode state # define Bi-directional mode self . __bi_mode = False # handles bi-directional mode state # define Secure mode valid_security_mech = { 0 : \"Grasslands\" , 1 : \"StoneHouse\" , 2 : \"IronHouse\" } self . __secure_mode = 0 # handles ZMQ security layer status auth_cert_dir = \"\" # handles valid ZMQ certificates dir self . __auth_publickeys_dir = \"\" # handles valid ZMQ public certificates dir self . __auth_secretkeys_dir = \"\" # handles valid ZMQ private certificates dir overwrite_cert = False # checks if certificates overwriting allowed custom_cert_location = \"\" # handles custom ZMQ certificates path # define frame-compression handler self . __compression = ( \".jpg\" if not ( address is None ) else None ) # disabled by default for local connections self . __compression_params = ( cv2 . IMREAD_COLOR if receive_mode else [ cv2 . IMWRITE_JPEG_QUALITY , 85 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ] ) # defines frame compression on return data self . __ex_compression_params = None # define receiver return data handler self . __return_data = None # generate random system id self . __id = \"\" . join ( random . choice ( \"0123456789ABCDEF\" ) for i in range ( 5 )) # define termination flag self . __terminate = False # additional settings for reliability if pattern < 2 : # define zmq poller for reliable transmission self . __poll = zmq . Poller () # define max retries self . __max_retries = 3 # request timeout self . __request_timeout = 4000 # 4 secs # Handle user-defined options dictionary values # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # loop over dictionary key & values and assign to global variables if valid for key , value in options . items (): if key == \"multiserver_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-server mode self . __multiserver_mode = value else : # otherwise disable it and raise error self . __multiserver_mode = False logger . critical ( \"Multi-Server Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) if key == \"multiclient_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-client mode self . __multiclient_mode = value else : # otherwise disable it and raise error self . __multiclient_mode = False logger . critical ( \"Multi-Client Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) elif ( key == \"secure_mode\" and isinstance ( value , int ) and ( value in valid_security_mech ) ): # check if installed libzmq version is valid assert zmq . zmq_version_info () >= ( 4 , 0 , ), \"[NetGear:ERROR] :: ZMQ Security feature is not supported in libzmq version < 4.0.\" # assign valid mode self . __secure_mode = value elif key == \"custom_cert_location\" and isinstance ( value , str ): # verify custom auth certificates path for secure mode assert os . access ( value , os . W_OK ), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\" custom_cert_location = os . path . abspath ( value ) elif key == \"overwrite_cert\" and isinstance ( value , bool ): # enable/disable auth certificate overwriting in secure mode overwrite_cert = value elif key == \"bidirectional_mode\" and isinstance ( value , bool ): # check if pattern is valid if pattern < 2 : # activate bi-directional mode if specified self . __bi_mode = value else : # otherwise disable it and raise error self . __bi_mode = False logger . critical ( \"Bi-Directional data transmission is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Bi-Directional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) elif key == \"compression_format\" : if isinstance ( value , str ) and value . lower () . strip () in [ \".jpg\" , \".jpeg\" , \".bmp\" , \".png\" , ]: # assign frame-compression encoding value self . __compression = value . lower () . strip () else : logger . warning ( \"Incorrect encoding format: ` {} ` skipped. Disabling Frame-Compression!\" . format ( value ) ) self . __compression = None elif key == \"compression_param\" : # assign encoding/decoding params/flags for frame-compression if valid if receive_mode and isinstance ( value , int ): self . __compression_params = value elif not ( receive_mode ) and isinstance ( value , list ): self . __compression_params = value elif isinstance ( value , tuple ) and len ( value ) == 2 : if receive_mode : self . __compression_params = [ x for x in value if isinstance ( x , int ) ][ 0 ] self . __ex_compression_params = [ x for x in value if ( value and isinstance ( x , list )) ][ 0 ] else : self . __compression_params = [ x for x in value if ( value and isinstance ( x , list )) ][ 0 ] self . __ex_compression_params = [ x for x in value if isinstance ( x , int ) ][ 0 ] else : logger . warning ( \"Invalid compression parameters: {} skipped.\" . format ( value ) ) # assign maximum retries in synchronous patterns elif key == \"max_retries\" and isinstance ( value , int ) and pattern < 2 : if value >= 0 : self . __max_retries = value else : logger . warning ( \"Invalid `max_retries` value skipped!\" ) # assign request timeout in synchronous patterns elif key == \"request_timeout\" and isinstance ( value , int ) and pattern < 2 : if value >= 4 : self . __request_timeout = value * 1000 # covert to milliseconds else : logger . warning ( \"Invalid `request_timeout` value skipped!\" ) # assign ZMQ flags elif key == \"flag\" and isinstance ( value , int ): self . __msg_flag = value elif key == \"copy\" and isinstance ( value , bool ): self . __msg_copy = value elif key == \"track\" and isinstance ( value , bool ): self . __msg_track = value else : pass # Handle Secure mode if self . __secure_mode : # import required libs import zmq.auth from zmq.auth.thread import ThreadAuthenticator # activate and log if overwriting is enabled if overwrite_cert : if not receive_mode : if self . __logging : logger . warning ( \"Overwriting ZMQ Authentication certificates over previous ones!\" ) else : overwrite_cert = False if self . __logging : logger . critical ( \"Overwriting ZMQ Authentication certificates is disabled for Client's end!\" ) # Validate certificate generation paths try : # check if custom certificates path is specified if custom_cert_location : ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( custom_cert_location , overwrite = overwrite_cert , logging = logging ) else : # otherwise auto-generate suitable path from os.path import expanduser ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), overwrite = overwrite_cert , logging = logging , ) # log it if self . __logging : logger . debug ( \"` {} ` is the default location for storing ZMQ authentication certificates/keys.\" . format ( auth_cert_dir ) ) except Exception as e : # catch if any error occurred and disable Secure mode logger . exception ( str ( e )) self . __secure_mode = 0 logger . critical ( \"ZMQ Security Mechanism is disabled for this connection due to errors!\" ) # Handle multiple exclusive modes if enabled if self . __multiclient_mode and self . __multiserver_mode : raise ValueError ( \"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\" ) elif self . __multiserver_mode or self . __multiclient_mode : # check if Bi-directional Mode also enabled if self . __bi_mode : # disable bi_mode if enabled self . __bi_mode = False logger . warning ( \"Bi-Directional Data Transmission is disabled when {} Mode is Enabled due to incompatibility!\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" ) ) elif self . __bi_mode : # log Bi-directional mode activation if self . __logging : logger . debug ( \"Bi-Directional Data Transmission is enabled for this connection!\" ) # handle frame compression on return data if ( ( self . __bi_mode or self . __multiclient_mode ) and not ( self . __compression is None ) and self . __ex_compression_params is None ): # define exclusive compression params self . __ex_compression_params = ( [ cv2 . IMWRITE_JPEG_QUALITY , 85 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ] if receive_mode else cv2 . IMREAD_COLOR ) # define messaging context instance self . __msg_context = zmq . Context . instance () # initialize and assign receive mode to global variable self . __receive_mode = receive_mode # check whether `receive_mode` is enabled if self . __receive_mode : # define connection address if address is None : address = \"*\" # define address # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address list/tuple is assigned or not in multiserver_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client's port(s) self . __port_buffer = [] # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique server port address is assigned or not in multiclient_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Client-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context auth = ThreadAuthenticator ( self . __msg_context ) auth . start () auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated auth . configure_curve ( domain = \"*\" , location = zmq . auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 1 ]) # define pub-sub flag if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load server key server_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"server.key_secret\" ) server_public , server_secret = zmq . auth . load_certificate ( server_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = server_secret self . __msg_socket . curve_publickey = server_public # enable CURVE connection for this socket self . __msg_socket . curve_server = True # define exclusive socket options for patterns if self . __pattern == 2 : self . __msg_socket . setsockopt_string ( zmq . SUBSCRIBE , \"\" ) # if multiserver_mode is enabled, then assign port addresses to zmq socket if self . __multiserver_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # bind socket to given protocol, address and port normally self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiserver_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 1 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) if self . __logging : logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bi-Directional Mode for this connection!\" ) raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) # Handle threaded queue mode if self . __logging : logger . debug ( \"Threaded Queue Mode is enabled by default for this connection.\" ) # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # initialize and start threaded recv_handler self . __thread = Thread ( target = self . __recv_handler , name = \"NetGear\" , args = ()) self . __thread . daemon = True self . __thread . start () if self . __logging : # finally log progress logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if not ( self . __compression is None ): logger . debug ( \"Optimized ` {} ` Frame-Compression is enabled with decoding flag:` {} ` for this connection.\" . format ( self . __compression , self . __compression_params ) ) if self . __secure_mode : logger . debug ( \"Successfully enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Multi-threaded Receive Mode is successfully enabled.\" ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Receive Mode is now activated.\" ) else : # otherwise default to `Send Mode` # define connection address if address is None : address = \"localhost\" # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address is assigned or not in multiserver_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Server-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique client port address list/tuple is assigned or not in multiclient_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client ports self . __port_buffer = [] else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context auth = ThreadAuthenticator ( self . __msg_context ) auth . start () auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated auth . configure_curve ( domain = \"*\" , location = zmq . auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 0 ]) # if req/rep pattern, define additional flags if self . __pattern == 1 : self . __msg_socket . REQ_RELAXED = True self . __msg_socket . REQ_CORRELATE = True # if pub/sub pattern, define additional optimizer if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load client key client_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"client.key_secret\" ) client_public , client_secret = zmq . auth . load_certificate ( client_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = client_secret self . __msg_socket . curve_publickey = client_public # load server key server_public_file = os . path . join ( self . __auth_publickeys_dir , \"server.key\" ) server_public , _ = zmq . auth . load_certificate ( server_public_file ) # inject public key to make a CURVE connection. self . __msg_socket . curve_serverkey = server_public # check if multi-client_mode is enabled if self . __multiclient_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # connect socket to given protocol, address and port self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiclient_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 0 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) if self . __logging : logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bi-Directional Mode for this connection!\" ) raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __logging : # finally log progress logger . debug ( \"Successfully connected to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if not ( self . __compression is None ): logger . debug ( \"Optimized ` {} ` Frame-Compression is enabled with encoding params:` {} ` for this connection.\" . format ( self . __compression , self . __compression_params ) ) if self . __secure_mode : logger . debug ( \"Enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Send Mode is successfully activated and ready to send data.\" ) close ( self ) \u00b6 Safely terminates the threads, and NetGear resources. Source code in vidgear/gears/netgear.py def close ( self ): \"\"\" Safely terminates the threads, and NetGear resources. \"\"\" if self . __logging : # log it logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # check whether queue mode is empty if not ( self . __queue is None ) and self . __queue : self . __queue . clear () # call immediate termination self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : # properly handle thread exit self . __thread . join () self . __thread = None if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) # properly close the socket self . __msg_socket . close ( linger = 0 ) if self . __logging : logger . debug ( \"Terminated Successfully!\" ) else : # indicate that process should be terminated self . __terminate = True # check if all attempts of reconnecting failed, then skip to closure if ( self . __pattern < 2 and not self . __max_retries ) or ( self . __multiclient_mode and not self . __port_buffer ): try : # properly close the socket self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () except self . __ZMQError : pass finally : return if self . __multiserver_mode : # check if multiserver_mode # send termination flag to client with its unique port term_dict = dict ( terminate_flag = True , port = self . __port ) else : # otherwise send termination flag to client term_dict = dict ( terminate_flag = True ) try : if self . __multiclient_mode : if self . __port_buffer : for _ in self . __port_buffer : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within half timeout if self . __pattern < 2 : if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , self . __zmq . POLLIN ): self . __msg_socket . recv () else : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within half timeout if self . __pattern < 2 : if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , self . __zmq . POLLIN ): self . __msg_socket . recv () except Exception as e : if not isinstance ( e , self . __ZMQError ): logger . exception ( str ( e )) finally : # properly close the socket self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () if self . __logging : logger . debug ( \"Terminated Successfully!\" ) recv ( self , return_data = None ) \u00b6 A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: Name Type Description Default return_data any inputs return data (of any datatype) , for sending back to Server. None Returns: A n-dimensional numpy array. Source code in vidgear/gears/netgear.py def recv ( self , return_data = None ): \"\"\" A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: return_data (any): inputs return data _(of any datatype)_, for sending back to Server. **Returns:** A n-dimensional numpy array. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\" ) # handle bi-directional return data if ( self . __bi_mode or self . __multiclient_mode ) and not ( return_data is None ): self . __return_data = return_data # check whether or not termination flag is enabled while not self . __terminate : try : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : time . sleep ( 0.00001 ) continue except KeyboardInterrupt : self . __terminate = True break # otherwise return NoneType return None send ( self , frame , message = None ) \u00b6 A Server end method, that sends the data and frames over the network to Client(s). Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). required message any input for sending additional data (of any datatype except numpy.ndarray ) to Client(s). None Returns: Data (of any datatype) in selected exclusive modes, otherwise None-type. Source code in vidgear/gears/netgear.py def send ( self , frame , message = None ): \"\"\" A Server end method, that sends the data and frames over the network to Client(s). Parameters: frame (numpy.ndarray): inputs numpy array(frame). message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s). **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type. \"\"\" # check whether `receive_mode` is disabled if self . __receive_mode : # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\" ) if not ( message is None ) and isinstance ( message , np . ndarray ): logger . warning ( \"Skipped unsupported `message` of datatype: {} !\" . format ( type ( message ) . __name__ ) ) message = None # define exit_flag and assign value exit_flag = True if ( frame is None or self . __terminate ) else False # check whether exit_flag is False if not ( exit_flag ) and not ( frame . flags [ \"C_CONTIGUOUS\" ]): # check whether the incoming frame is contiguous frame = np . ascontiguousarray ( frame , dtype = frame . dtype ) # handle encoding if not ( self . __compression is None ): retval , frame = cv2 . imencode ( self . __compression , frame , self . __compression_params ) # check if it works if not ( retval ): # otherwise raise error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: Frame compression failed with encoding: {} and parameters: {} .\" . format ( self . __compression , self . __compression_params ) ) # check if multiserver_mode is activated if self . __multiserver_mode : # prepare the exclusive json dict and assign values with unique port msg_dict = dict ( terminate_flag = exit_flag , compression = str ( self . __compression ) if not ( self . __compression is None ) else \"\" , port = self . __port , pattern = str ( self . __pattern ), message = message , dtype = str ( frame . dtype ), shape = frame . shape , ) else : # otherwise prepare normal json dict and assign values msg_dict = dict ( terminate_flag = exit_flag , compression = str ( self . __compression ) if not ( self . __compression is None ) else \"\" , message = message , pattern = str ( self . __pattern ), dtype = str ( frame . dtype ), shape = frame . shape , ) # send the json dict self . __msg_socket . send_json ( msg_dict , self . __msg_flag | self . __zmq . SNDMORE ) # send the frame array with correct flags self . __msg_socket . send ( frame , flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track ) # check if synchronous patterns, then wait for confirmation if self . __pattern < 2 : # check if bi-directional data transmission is enabled if self . __bi_mode or self . __multiclient_mode : # handles return data recvd_data = None socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == self . __zmq . POLLIN : # handle return data recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): if self . __multiclient_mode : logger . error ( \"All Clients failed to respond on multiple attempts.\" ) else : logger . error ( \"Client failed to respond on multiple attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) if isinstance ( self . __connection_address , list ): for _connection in self . __connection_address : self . __msg_socket . connect ( _connection ) else : self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , self . __zmq . POLLIN ) return None # save the unique port addresses if ( self . __multiclient_mode and not recv_json [ \"port\" ] in self . __port_buffer ): self . __port_buffer . append ( recv_json [ \"port\" ]) if recv_json [ \"return_type\" ] == \"ndarray\" : recv_array = self . __msg_socket . recv ( flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track , ) recvd_data = np . frombuffer ( recv_array , dtype = recv_json [ \"array_dtype\" ] ) . reshape ( recv_json [ \"array_shape\" ]) # check if encoding was enabled if recv_json [ \"compression\" ]: recvd_data = cv2 . imdecode ( recvd_data , self . __ex_compression_params ) # check if valid frame returned if recvd_data is None : self . __terminate = True # otherwise raise error and exit raise RuntimeError ( \"[NetGear:ERROR] :: Received compressed frame ` {} ` decoding failed with flag: {} .\" . format ( recv_json [ \"compression\" ], self . __ex_compression_params , ) ) else : recvd_data = recv_json [ \"data\" ] return ( ( recv_json [ \"port\" ], recvd_data ) if self . __multiclient_mode else recvd_data ) else : # otherwise log normally socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == self . __zmq . POLLIN : recv_confirmation = self . __msg_socket . recv () else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): logger . error ( \"Client failed to respond on repeated attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , self . __zmq . POLLIN ) return None # log confirmation if self . __logging : logger . debug ( recv_confirmation )","title":"NetGear API"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.__init__","text":"This constructor method initializes the object state and attributes of the NetGear class. Parameters: Name Type Description Default address str sets the valid network address of the Server/Client. None port str sets the valid Network Port of the Server/Client. None protocol str sets the valid messaging protocol between Server/Client. None pattern int sets the supported messaging pattern(flow of communication) between Server/Client 0 receive_mode bool select the Netgear's Mode of operation. False logging bool enables/disables logging. False options dict provides the flexibility to alter various NetGear internal properties. {} Source code in vidgear/gears/netgear.py def __init__ ( self , address = None , port = None , protocol = None , pattern = 0 , receive_mode = False , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the Netgear's Mode of operation. logging (bool): enables/disables logging. options (dict): provides the flexibility to alter various NetGear internal properties. \"\"\" try : # import PyZMQ library import zmq from zmq.error import ZMQError # assign values to global variable for further use self . __zmq = zmq self . __ZMQError = ZMQError except ImportError as error : # raise error raise ImportError ( \"[NetGear:ERROR] :: pyzmq python library not installed. Kindly install it with `pip install pyzmq` command.\" ) # enable logging if specified self . __logging = True if logging else False # define valid messaging patterns => `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), } # Handle messaging pattern msg_pattern = None # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns . keys (): # assign value msg_pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` pattern = 0 msg_pattern = valid_messaging_patterns [ pattern ] if self . __logging : logger . warning ( \"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\" ) # assign pattern to global parameter for further use self . __pattern = pattern # Handle messaging protocol if protocol is None or not ( protocol in [ \"tcp\" , \"ipc\" ]): # else default to `tcp` protocol protocol = \"tcp\" # log it if self . __logging : logger . warning ( \"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\" ) # Handle connection params self . __msg_flag = 0 # handles connection flags self . __msg_copy = False # handles whether to copy data self . __msg_track = False # handles whether to track packets # Handle NetGear's internal exclusive modes and params # define Multi-Server mode self . __multiserver_mode = False # handles multi-server_mode state # define Multi-Client mode self . __multiclient_mode = False # handles multi-client_mode state # define Bi-directional mode self . __bi_mode = False # handles bi-directional mode state # define Secure mode valid_security_mech = { 0 : \"Grasslands\" , 1 : \"StoneHouse\" , 2 : \"IronHouse\" } self . __secure_mode = 0 # handles ZMQ security layer status auth_cert_dir = \"\" # handles valid ZMQ certificates dir self . __auth_publickeys_dir = \"\" # handles valid ZMQ public certificates dir self . __auth_secretkeys_dir = \"\" # handles valid ZMQ private certificates dir overwrite_cert = False # checks if certificates overwriting allowed custom_cert_location = \"\" # handles custom ZMQ certificates path # define frame-compression handler self . __compression = ( \".jpg\" if not ( address is None ) else None ) # disabled by default for local connections self . __compression_params = ( cv2 . IMREAD_COLOR if receive_mode else [ cv2 . IMWRITE_JPEG_QUALITY , 85 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ] ) # defines frame compression on return data self . __ex_compression_params = None # define receiver return data handler self . __return_data = None # generate random system id self . __id = \"\" . join ( random . choice ( \"0123456789ABCDEF\" ) for i in range ( 5 )) # define termination flag self . __terminate = False # additional settings for reliability if pattern < 2 : # define zmq poller for reliable transmission self . __poll = zmq . Poller () # define max retries self . __max_retries = 3 # request timeout self . __request_timeout = 4000 # 4 secs # Handle user-defined options dictionary values # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # loop over dictionary key & values and assign to global variables if valid for key , value in options . items (): if key == \"multiserver_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-server mode self . __multiserver_mode = value else : # otherwise disable it and raise error self . __multiserver_mode = False logger . critical ( \"Multi-Server Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) if key == \"multiclient_mode\" and isinstance ( value , bool ): # check if valid pattern assigned if pattern > 0 : # activate Multi-client mode self . __multiclient_mode = value else : # otherwise disable it and raise error self . __multiclient_mode = False logger . critical ( \"Multi-Client Mode is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\" . format ( pattern ) ) elif ( key == \"secure_mode\" and isinstance ( value , int ) and ( value in valid_security_mech ) ): # check if installed libzmq version is valid assert zmq . zmq_version_info () >= ( 4 , 0 , ), \"[NetGear:ERROR] :: ZMQ Security feature is not supported in libzmq version < 4.0.\" # assign valid mode self . __secure_mode = value elif key == \"custom_cert_location\" and isinstance ( value , str ): # verify custom auth certificates path for secure mode assert os . access ( value , os . W_OK ), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\" custom_cert_location = os . path . abspath ( value ) elif key == \"overwrite_cert\" and isinstance ( value , bool ): # enable/disable auth certificate overwriting in secure mode overwrite_cert = value elif key == \"bidirectional_mode\" and isinstance ( value , bool ): # check if pattern is valid if pattern < 2 : # activate bi-directional mode if specified self . __bi_mode = value else : # otherwise disable it and raise error self . __bi_mode = False logger . critical ( \"Bi-Directional data transmission is disabled!\" ) raise ValueError ( \"[NetGear:ERROR] :: ` {} ` pattern is not valid when Bi-Directional Mode is enabled. Kindly refer Docs for more Information!\" . format ( pattern ) ) elif key == \"compression_format\" : if isinstance ( value , str ) and value . lower () . strip () in [ \".jpg\" , \".jpeg\" , \".bmp\" , \".png\" , ]: # assign frame-compression encoding value self . __compression = value . lower () . strip () else : logger . warning ( \"Incorrect encoding format: ` {} ` skipped. Disabling Frame-Compression!\" . format ( value ) ) self . __compression = None elif key == \"compression_param\" : # assign encoding/decoding params/flags for frame-compression if valid if receive_mode and isinstance ( value , int ): self . __compression_params = value elif not ( receive_mode ) and isinstance ( value , list ): self . __compression_params = value elif isinstance ( value , tuple ) and len ( value ) == 2 : if receive_mode : self . __compression_params = [ x for x in value if isinstance ( x , int ) ][ 0 ] self . __ex_compression_params = [ x for x in value if ( value and isinstance ( x , list )) ][ 0 ] else : self . __compression_params = [ x for x in value if ( value and isinstance ( x , list )) ][ 0 ] self . __ex_compression_params = [ x for x in value if isinstance ( x , int ) ][ 0 ] else : logger . warning ( \"Invalid compression parameters: {} skipped.\" . format ( value ) ) # assign maximum retries in synchronous patterns elif key == \"max_retries\" and isinstance ( value , int ) and pattern < 2 : if value >= 0 : self . __max_retries = value else : logger . warning ( \"Invalid `max_retries` value skipped!\" ) # assign request timeout in synchronous patterns elif key == \"request_timeout\" and isinstance ( value , int ) and pattern < 2 : if value >= 4 : self . __request_timeout = value * 1000 # covert to milliseconds else : logger . warning ( \"Invalid `request_timeout` value skipped!\" ) # assign ZMQ flags elif key == \"flag\" and isinstance ( value , int ): self . __msg_flag = value elif key == \"copy\" and isinstance ( value , bool ): self . __msg_copy = value elif key == \"track\" and isinstance ( value , bool ): self . __msg_track = value else : pass # Handle Secure mode if self . __secure_mode : # import required libs import zmq.auth from zmq.auth.thread import ThreadAuthenticator # activate and log if overwriting is enabled if overwrite_cert : if not receive_mode : if self . __logging : logger . warning ( \"Overwriting ZMQ Authentication certificates over previous ones!\" ) else : overwrite_cert = False if self . __logging : logger . critical ( \"Overwriting ZMQ Authentication certificates is disabled for Client's end!\" ) # Validate certificate generation paths try : # check if custom certificates path is specified if custom_cert_location : ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( custom_cert_location , overwrite = overwrite_cert , logging = logging ) else : # otherwise auto-generate suitable path from os.path import expanduser ( auth_cert_dir , self . __auth_secretkeys_dir , self . __auth_publickeys_dir , ) = generate_auth_certificates ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), overwrite = overwrite_cert , logging = logging , ) # log it if self . __logging : logger . debug ( \"` {} ` is the default location for storing ZMQ authentication certificates/keys.\" . format ( auth_cert_dir ) ) except Exception as e : # catch if any error occurred and disable Secure mode logger . exception ( str ( e )) self . __secure_mode = 0 logger . critical ( \"ZMQ Security Mechanism is disabled for this connection due to errors!\" ) # Handle multiple exclusive modes if enabled if self . __multiclient_mode and self . __multiserver_mode : raise ValueError ( \"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\" ) elif self . __multiserver_mode or self . __multiclient_mode : # check if Bi-directional Mode also enabled if self . __bi_mode : # disable bi_mode if enabled self . __bi_mode = False logger . warning ( \"Bi-Directional Data Transmission is disabled when {} Mode is Enabled due to incompatibility!\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" ) ) elif self . __bi_mode : # log Bi-directional mode activation if self . __logging : logger . debug ( \"Bi-Directional Data Transmission is enabled for this connection!\" ) # handle frame compression on return data if ( ( self . __bi_mode or self . __multiclient_mode ) and not ( self . __compression is None ) and self . __ex_compression_params is None ): # define exclusive compression params self . __ex_compression_params = ( [ cv2 . IMWRITE_JPEG_QUALITY , 85 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ] if receive_mode else cv2 . IMREAD_COLOR ) # define messaging context instance self . __msg_context = zmq . Context . instance () # initialize and assign receive mode to global variable self . __receive_mode = receive_mode # check whether `receive_mode` is enabled if self . __receive_mode : # define connection address if address is None : address = \"*\" # define address # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address list/tuple is assigned or not in multiserver_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client's port(s) self . __port_buffer = [] # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique server port address is assigned or not in multiclient_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Client-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context auth = ThreadAuthenticator ( self . __msg_context ) auth . start () auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated auth . configure_curve ( domain = \"*\" , location = zmq . auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 1 ]) # define pub-sub flag if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load server key server_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"server.key_secret\" ) server_public , server_secret = zmq . auth . load_certificate ( server_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = server_secret self . __msg_socket . curve_publickey = server_public # enable CURVE connection for this socket self . __msg_socket . curve_server = True # define exclusive socket options for patterns if self . __pattern == 2 : self . __msg_socket . setsockopt_string ( zmq . SUBSCRIBE , \"\" ) # if multiserver_mode is enabled, then assign port addresses to zmq socket if self . __multiserver_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # bind socket to given protocol, address and port normally self . __msg_socket . bind ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiserver_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 1 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) if self . __logging : logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bi-Directional Mode for this connection!\" ) raise RuntimeError ( \"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) # Handle threaded queue mode if self . __logging : logger . debug ( \"Threaded Queue Mode is enabled by default for this connection.\" ) # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # initialize and start threaded recv_handler self . __thread = Thread ( target = self . __recv_handler , name = \"NetGear\" , args = ()) self . __thread . daemon = True self . __thread . start () if self . __logging : # finally log progress logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if not ( self . __compression is None ): logger . debug ( \"Optimized ` {} ` Frame-Compression is enabled with decoding flag:` {} ` for this connection.\" . format ( self . __compression , self . __compression_params ) ) if self . __secure_mode : logger . debug ( \"Successfully enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Multi-threaded Receive Mode is successfully enabled.\" ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Receive Mode is now activated.\" ) else : # otherwise default to `Send Mode` # define connection address if address is None : address = \"localhost\" # check if multiserver_mode is enabled if self . __multiserver_mode : # check if unique server port address is assigned or not in multiserver_mode if port is None : # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Kindly provide a unique & valid port value at Server-end. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Server Mode at PORT: {} on this device!\" . format ( port ) ) # assign value to global variable self . __port = port # check if multiclient_mode is enabled elif self . __multiclient_mode : # check if unique client port address list/tuple is assigned or not in multiclient_mode if port is None or not isinstance ( port , ( tuple , list )): # raise error if not raise ValueError ( \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\" ) else : # otherwise log it logger . debug ( \"Enabling Multi-Client Mode at PORTS: {} !\" . format ( port ) ) # create port address buffer for keeping track of connected client ports self . __port_buffer = [] else : # otherwise assign local port address if None if port is None : port = \"5555\" try : # activate secure_mode threaded authenticator if self . __secure_mode > 0 : # start an authenticator for this context auth = ThreadAuthenticator ( self . __msg_context ) auth . start () auth . allow ( str ( address )) # allow current address # check if `IronHouse` is activated if self . __secure_mode == 2 : # tell authenticator to use the certificate from given valid dir auth . configure_curve ( domain = \"*\" , location = self . __auth_publickeys_dir ) else : # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated auth . configure_curve ( domain = \"*\" , location = zmq . auth . CURVE_ALLOW_ANY ) # define thread-safe messaging socket self . __msg_socket = self . __msg_context . socket ( msg_pattern [ 0 ]) # if req/rep pattern, define additional flags if self . __pattern == 1 : self . __msg_socket . REQ_RELAXED = True self . __msg_socket . REQ_CORRELATE = True # if pub/sub pattern, define additional optimizer if self . __pattern == 2 : self . __msg_socket . set_hwm ( 1 ) # enable specified secure mode for the socket if self . __secure_mode > 0 : # load client key client_secret_file = os . path . join ( self . __auth_secretkeys_dir , \"client.key_secret\" ) client_public , client_secret = zmq . auth . load_certificate ( client_secret_file ) # load all CURVE keys self . __msg_socket . curve_secretkey = client_secret self . __msg_socket . curve_publickey = client_public # load server key server_public_file = os . path . join ( self . __auth_publickeys_dir , \"server.key\" ) server_public , _ = zmq . auth . load_certificate ( server_public_file ) # inject public key to make a CURVE connection. self . __msg_socket . curve_serverkey = server_public # check if multi-client_mode is enabled if self . __multiclient_mode : # bind socket to given server protocol, address and ports for pt in port : self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : # connect socket to given protocol, address and port self . __msg_socket . connect ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) # additional settings if pattern < 2 : if self . __multiclient_mode : self . __connection_address = [] for pt in port : self . __connection_address . append ( protocol + \"://\" + str ( address ) + \":\" + str ( pt ) ) else : self . __connection_address = ( protocol + \"://\" + str ( address ) + \":\" + str ( port ) ) self . __msg_pattern = msg_pattern [ 0 ] self . __poll . register ( self . __msg_socket , zmq . POLLIN ) if self . __logging : logger . debug ( \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\" . format ( self . __max_retries , self . __request_timeout / 1000 ) ) except Exception as e : # otherwise log and raise error logger . exception ( str ( e )) if self . __secure_mode : logger . critical ( \"Failed to activate Secure Mode: ` {} ` for this connection!\" . format ( valid_security_mech [ self . __secure_mode ] ) ) if self . __multiserver_mode or self . __multiclient_mode : raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {} ! Kindly recheck all parameters.\" . format ( \"Multi-Server\" if self . __multiserver_mode else \"Multi-Client\" , ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern , ) ) else : if self . __bi_mode : logger . critical ( \"Failed to activate Bi-Directional Mode for this connection!\" ) raise RuntimeError ( \"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {} ! Kindly recheck all parameters.\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if self . __logging : # finally log progress logger . debug ( \"Successfully connected to address: {} with pattern: {} .\" . format ( ( protocol + \"://\" + str ( address ) + \":\" + str ( port )), pattern ) ) if not ( self . __compression is None ): logger . debug ( \"Optimized ` {} ` Frame-Compression is enabled with encoding params:` {} ` for this connection.\" . format ( self . __compression , self . __compression_params ) ) if self . __secure_mode : logger . debug ( \"Enabled ZMQ Security Mechanism: ` {} ` for this connection.\" . format ( valid_security_mech [ self . __secure_mode ] ) ) logger . debug ( \"Unique System ID is {} .\" . format ( self . __id )) logger . debug ( \"Send Mode is successfully activated and ready to send data.\" )","title":"__init__()"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.close","text":"Safely terminates the threads, and NetGear resources. Source code in vidgear/gears/netgear.py def close ( self ): \"\"\" Safely terminates the threads, and NetGear resources. \"\"\" if self . __logging : # log it logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # check whether queue mode is empty if not ( self . __queue is None ) and self . __queue : self . __queue . clear () # call immediate termination self . __terminate = True # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : # properly handle thread exit self . __thread . join () self . __thread = None if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) # properly close the socket self . __msg_socket . close ( linger = 0 ) if self . __logging : logger . debug ( \"Terminated Successfully!\" ) else : # indicate that process should be terminated self . __terminate = True # check if all attempts of reconnecting failed, then skip to closure if ( self . __pattern < 2 and not self . __max_retries ) or ( self . __multiclient_mode and not self . __port_buffer ): try : # properly close the socket self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () except self . __ZMQError : pass finally : return if self . __multiserver_mode : # check if multiserver_mode # send termination flag to client with its unique port term_dict = dict ( terminate_flag = True , port = self . __port ) else : # otherwise send termination flag to client term_dict = dict ( terminate_flag = True ) try : if self . __multiclient_mode : if self . __port_buffer : for _ in self . __port_buffer : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within half timeout if self . __pattern < 2 : if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , self . __zmq . POLLIN ): self . __msg_socket . recv () else : self . __msg_socket . send_json ( term_dict ) # check for confirmation if available within half timeout if self . __pattern < 2 : if self . __logging : logger . debug ( \"Terminating. Please wait...\" ) if self . __msg_socket . poll ( self . __request_timeout // 5 , self . __zmq . POLLIN ): self . __msg_socket . recv () except Exception as e : if not isinstance ( e , self . __ZMQError ): logger . exception ( str ( e )) finally : # properly close the socket self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () if self . __logging : logger . debug ( \"Terminated Successfully!\" )","title":"close()"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.recv","text":"A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: Name Type Description Default return_data any inputs return data (of any datatype) , for sending back to Server. None Returns: A n-dimensional numpy array. Source code in vidgear/gears/netgear.py def recv ( self , return_data = None ): \"\"\" A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Parameters: return_data (any): inputs return data _(of any datatype)_, for sending back to Server. **Returns:** A n-dimensional numpy array. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\" ) # handle bi-directional return data if ( self . __bi_mode or self . __multiclient_mode ) and not ( return_data is None ): self . __return_data = return_data # check whether or not termination flag is enabled while not self . __terminate : try : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : time . sleep ( 0.00001 ) continue except KeyboardInterrupt : self . __terminate = True break # otherwise return NoneType return None","title":"recv()"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.send","text":"A Server end method, that sends the data and frames over the network to Client(s). Parameters: Name Type Description Default frame numpy.ndarray inputs numpy array(frame). required message any input for sending additional data (of any datatype except numpy.ndarray ) to Client(s). None Returns: Data (of any datatype) in selected exclusive modes, otherwise None-type. Source code in vidgear/gears/netgear.py def send ( self , frame , message = None ): \"\"\" A Server end method, that sends the data and frames over the network to Client(s). Parameters: frame (numpy.ndarray): inputs numpy array(frame). message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s). **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type. \"\"\" # check whether `receive_mode` is disabled if self . __receive_mode : # raise value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\" ) if not ( message is None ) and isinstance ( message , np . ndarray ): logger . warning ( \"Skipped unsupported `message` of datatype: {} !\" . format ( type ( message ) . __name__ ) ) message = None # define exit_flag and assign value exit_flag = True if ( frame is None or self . __terminate ) else False # check whether exit_flag is False if not ( exit_flag ) and not ( frame . flags [ \"C_CONTIGUOUS\" ]): # check whether the incoming frame is contiguous frame = np . ascontiguousarray ( frame , dtype = frame . dtype ) # handle encoding if not ( self . __compression is None ): retval , frame = cv2 . imencode ( self . __compression , frame , self . __compression_params ) # check if it works if not ( retval ): # otherwise raise error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: Frame compression failed with encoding: {} and parameters: {} .\" . format ( self . __compression , self . __compression_params ) ) # check if multiserver_mode is activated if self . __multiserver_mode : # prepare the exclusive json dict and assign values with unique port msg_dict = dict ( terminate_flag = exit_flag , compression = str ( self . __compression ) if not ( self . __compression is None ) else \"\" , port = self . __port , pattern = str ( self . __pattern ), message = message , dtype = str ( frame . dtype ), shape = frame . shape , ) else : # otherwise prepare normal json dict and assign values msg_dict = dict ( terminate_flag = exit_flag , compression = str ( self . __compression ) if not ( self . __compression is None ) else \"\" , message = message , pattern = str ( self . __pattern ), dtype = str ( frame . dtype ), shape = frame . shape , ) # send the json dict self . __msg_socket . send_json ( msg_dict , self . __msg_flag | self . __zmq . SNDMORE ) # send the frame array with correct flags self . __msg_socket . send ( frame , flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track ) # check if synchronous patterns, then wait for confirmation if self . __pattern < 2 : # check if bi-directional data transmission is enabled if self . __bi_mode or self . __multiclient_mode : # handles return data recvd_data = None socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == self . __zmq . POLLIN : # handle return data recv_json = self . __msg_socket . recv_json ( flags = self . __msg_flag ) else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): if self . __multiclient_mode : logger . error ( \"All Clients failed to respond on multiple attempts.\" ) else : logger . error ( \"Client failed to respond on multiple attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) if isinstance ( self . __connection_address , list ): for _connection in self . __connection_address : self . __msg_socket . connect ( _connection ) else : self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , self . __zmq . POLLIN ) return None # save the unique port addresses if ( self . __multiclient_mode and not recv_json [ \"port\" ] in self . __port_buffer ): self . __port_buffer . append ( recv_json [ \"port\" ]) if recv_json [ \"return_type\" ] == \"ndarray\" : recv_array = self . __msg_socket . recv ( flags = self . __msg_flag , copy = self . __msg_copy , track = self . __msg_track , ) recvd_data = np . frombuffer ( recv_array , dtype = recv_json [ \"array_dtype\" ] ) . reshape ( recv_json [ \"array_shape\" ]) # check if encoding was enabled if recv_json [ \"compression\" ]: recvd_data = cv2 . imdecode ( recvd_data , self . __ex_compression_params ) # check if valid frame returned if recvd_data is None : self . __terminate = True # otherwise raise error and exit raise RuntimeError ( \"[NetGear:ERROR] :: Received compressed frame ` {} ` decoding failed with flag: {} .\" . format ( recv_json [ \"compression\" ], self . __ex_compression_params , ) ) else : recvd_data = recv_json [ \"data\" ] return ( ( recv_json [ \"port\" ], recvd_data ) if self . __multiclient_mode else recvd_data ) else : # otherwise log normally socks = dict ( self . __poll . poll ( self . __request_timeout )) if socks . get ( self . __msg_socket ) == self . __zmq . POLLIN : recv_confirmation = self . __msg_socket . recv () else : logger . critical ( \"No response from Client, Reconnecting again...\" ) # Socket is confused. Close and remove it. self . __msg_socket . setsockopt ( self . __zmq . LINGER , 0 ) self . __msg_socket . close () self . __poll . unregister ( self . __msg_socket ) self . __max_retries -= 1 if not ( self . __max_retries ): logger . error ( \"Client failed to respond on repeated attempts.\" ) self . __terminate = True raise RuntimeError ( \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\" ) # Create new connection self . __msg_socket = self . __msg_context . socket ( self . __msg_pattern ) self . __msg_socket . connect ( self . __connection_address ) self . __poll . register ( self . __msg_socket , self . __zmq . POLLIN ) return None # log confirmation if self . __logging : logger . debug ( recv_confirmation )","title":"send()"},{"location":"bonus/reference/netgear_async/","text":"All NetGear_Async API parameters are explained here \u27b6 NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async can generate double performance as compared to NetGear API at about \u2153rd of memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but it doesn't support any NetGear's Exclusive Modes yet. Furthermore, NetGear_Async allows us to define our own custom Server Source to manipulate frames easily before sending them across the network. In addition to all this, NetGear_Async also provides a special internal wrapper around VideoGear API] , which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any connected device/source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . __init__ ( self , address = None , port = None , protocol = 'tcp' , pattern = 0 , receive_mode = False , timeout = 0.0 , enablePiCamera = False , stabilize = False , source = 0 , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , time_delay = 0 , logging = False , ** options ) special \u00b6 This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: Name Type Description Default address str sets the valid network address of the Server/Client. None port str sets the valid Network Port of the Server/Client. None protocol str sets the valid messaging protocol between Server/Client. 'tcp' pattern int sets the supported messaging pattern(flow of communication) between Server/Client 0 receive_mode bool select the Netgear's Mode of operation. False timeout int/float controls the maximum waiting time(in sec) after which Client throws TimeoutError . 0.0 enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of NetGear, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/netgear_async.py def __init__ ( self , # NetGear_Async parameters address = None , port = None , protocol = \"tcp\" , pattern = 0 , receive_mode = False , timeout = 0.0 , # Videogear parameters enablePiCamera = False , stabilize = False , source = 0 , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , time_delay = 0 , # common parameters logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the Netgear's Mode of operation. timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`. enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of NetGear, CamGear, PiGear & Stabilizer. \"\"\" # enable logging if specified self . __logging = logging # define valid messaging patterns => `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), 3 : ( zmq . PUSH , zmq . PULL ), } # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns : # assign value self . __msg_pattern = pattern self . __pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` self . __msg_pattern = 0 self . __pattern = valid_messaging_patterns [ self . __msg_pattern ] if self . __logging : logger . warning ( \"Invalid pattern {pattern} . Defaulting to `zmq.PAIR`!\" . format ( pattern = pattern ) ) # check whether user-defined messaging protocol is valid if isinstance ( protocol , str ) and protocol in [ \"tcp\" , \"ipc\" ]: # assign value self . __protocol = protocol else : # else default to `tcp` protocol self . __protocol = \"tcp\" if self . __logging : logger . warning ( \"Invalid protocol. Defaulting to `tcp`!\" ) # initialize Termination flag self . __terminate = False # initialize and assign `Receive Mode` self . __receive_mode = receive_mode # initialize stream handler self . __stream = None # initialize Messaging Socket self . __msg_socket = None # initialize NetGear's configuration dictionary self . config = {} # assign timeout for Receiver end if timeout > 0 and isinstance ( timeout , ( int , float )): self . __timeout = float ( timeout ) else : self . __timeout = 15.0 # define messaging asynchronous Context self . __msg_context = zmq . asyncio . Context () # check whether `Receive Mode` is enabled if receive_mode : # assign local ip address if None if address is None : self . __address = \"*\" # define address else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port else : # Handle video source if not None if source is None : self . config = { \"generator\" : None } if self . __logging : logger . warning ( \"Given source is of NoneType!\" ) else : # define stream with necessary params self . __stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # define default frame generator in configuration self . config = { \"generator\" : self . __frame_generator ()} # assign local ip address if None if address is None : self . __address = \"localhost\" else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port # add server task handler self . task = None # Setup and assign event loop policy if platform . system () == \"Windows\" : # On Windows, VidGear requires the ``WindowsSelectorEventLoop``, and this is # the default in Python 3.7 and older, but new Python 3.8, defaults to an # event loop that is not compatible with it. Thereby, we had to set it manually. if sys . version_info [: 2 ] >= ( 3 , 8 ): asyncio . set_event_loop_policy ( asyncio . WindowsSelectorEventLoopPolicy ()) else : # import library import uvloop # uvloop eventloop is only available for UNIX machines. asyncio . set_event_loop_policy ( uvloop . EventLoopPolicy ()) # Retrieve event loop and assign it self . loop = asyncio . get_event_loop () # debugging logger . info ( \"Using ` {} ` event loop for this process.\" . format ( self . loop . __class__ . __name__ ) ) close ( self , skip_loop = False ) \u00b6 Terminates all NetGear Asynchronous processes gracefully. Parameters: Name Type Description Default skip_loop Boolean (optional)used only if closing executor loop throws an error. False Source code in vidgear/gears/asyncio/netgear_async.py def close ( self , skip_loop = False ): \"\"\" Terminates all NetGear Asynchronous processes gracefully. Parameters: skip_loop (Boolean): (optional)used only if closing executor loop throws an error. \"\"\" # log termination if self . __logging : logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # indicate that process should be terminated self . __terminate = True else : # indicate that process should be terminated self . __terminate = True # terminate stream if not ( self . __stream is None ): self . __stream . stop () # close event loop if specified if not ( skip_loop ): self . loop . close () launch ( self ) \u00b6 Launches an asynchronous generators and loop executors for respective task. Source code in vidgear/gears/asyncio/netgear_async.py def launch ( self ): \"\"\" Launches an asynchronous generators and loop executors for respective task. \"\"\" # check if receive mode enabled if self . __receive_mode : if self . __logging : logger . debug ( \"Launching NetGear asynchronous generator!\" ) # run loop executor for Receiver asynchronous generator self . loop . run_in_executor ( None , self . recv_generator ) # return instance return self else : # Otherwise launch Server handler if self . __logging : logger . debug ( \"Creating NetGear asynchronous server handler!\" ) # create task for Server Handler self . task = asyncio . ensure_future ( self . __server_handler (), loop = self . loop ) # return instance return self recv_generator ( self ) \u00b6 A default Asynchronous Frame Generator for NetGear's Receiver-end. Source code in vidgear/gears/asyncio/netgear_async.py async def recv_generator ( self ): \"\"\" A default Asynchronous Frame Generator for NetGear's Receiver-end. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise Value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\" ) # initialize and define messaging socket self . __msg_socket = self . __msg_context . socket ( self . __pattern [ 1 ]) # define exclusive socket options for patterns if self . __msg_pattern == 2 : self . __msg_socket . set_hwm ( 1 ) self . __msg_socket . setsockopt ( zmq . SUBSCRIBE , b \"\" ) try : # bind socket to the assigned protocol, address and port self . __msg_socket . bind ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ) # finally log progress if self . __logging : logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) logger . debug ( \"Receive Mode is activated successfully!\" ) except Exception as e : logger . exception ( str ( e )) raise ValueError ( \"[NetGear:ERROR] :: Failed to bind address: {} and pattern: {} !\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) # loop until terminated while not self . __terminate : # get message withing timeout limit recvd_msg = await asyncio . wait_for ( self . __msg_socket . recv_multipart (), timeout = self . __timeout ) # check if bidirectional patterns if self . __msg_pattern < 2 : # send confirmation await self . __msg_socket . send_multipart ([ b \"Message Received!\" ]) # terminate if exit` flag received if recvd_msg [ 0 ] == b \"exit\" : break # retrieve frame from message frame = msgpack . unpackb ( recvd_msg [ 0 ], object_hook = m . decode ) # yield received frame yield frame # sleep for sometime await asyncio . sleep ( 0.00001 )","title":"NetGear_Async API"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.__init__","text":"This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: Name Type Description Default address str sets the valid network address of the Server/Client. None port str sets the valid Network Port of the Server/Client. None protocol str sets the valid messaging protocol between Server/Client. 'tcp' pattern int sets the supported messaging pattern(flow of communication) between Server/Client 0 receive_mode bool select the Netgear's Mode of operation. False timeout int/float controls the maximum waiting time(in sec) after which Client throws TimeoutError . 0.0 enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of NetGear, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/netgear_async.py def __init__ ( self , # NetGear_Async parameters address = None , port = None , protocol = \"tcp\" , pattern = 0 , receive_mode = False , timeout = 0.0 , # Videogear parameters enablePiCamera = False , stabilize = False , source = 0 , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , time_delay = 0 , # common parameters logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the NetGear_Async class. Parameters: address (str): sets the valid network address of the Server/Client. port (str): sets the valid Network Port of the Server/Client. protocol (str): sets the valid messaging protocol between Server/Client. pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client receive_mode (bool): select the Netgear's Mode of operation. timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`. enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of NetGear, CamGear, PiGear & Stabilizer. \"\"\" # enable logging if specified self . __logging = logging # define valid messaging patterns => `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL) valid_messaging_patterns = { 0 : ( zmq . PAIR , zmq . PAIR ), 1 : ( zmq . REQ , zmq . REP ), 2 : ( zmq . PUB , zmq . SUB ), 3 : ( zmq . PUSH , zmq . PULL ), } # check whether user-defined messaging pattern is valid if isinstance ( pattern , int ) and pattern in valid_messaging_patterns : # assign value self . __msg_pattern = pattern self . __pattern = valid_messaging_patterns [ pattern ] else : # otherwise default to 0:`zmq.PAIR` self . __msg_pattern = 0 self . __pattern = valid_messaging_patterns [ self . __msg_pattern ] if self . __logging : logger . warning ( \"Invalid pattern {pattern} . Defaulting to `zmq.PAIR`!\" . format ( pattern = pattern ) ) # check whether user-defined messaging protocol is valid if isinstance ( protocol , str ) and protocol in [ \"tcp\" , \"ipc\" ]: # assign value self . __protocol = protocol else : # else default to `tcp` protocol self . __protocol = \"tcp\" if self . __logging : logger . warning ( \"Invalid protocol. Defaulting to `tcp`!\" ) # initialize Termination flag self . __terminate = False # initialize and assign `Receive Mode` self . __receive_mode = receive_mode # initialize stream handler self . __stream = None # initialize Messaging Socket self . __msg_socket = None # initialize NetGear's configuration dictionary self . config = {} # assign timeout for Receiver end if timeout > 0 and isinstance ( timeout , ( int , float )): self . __timeout = float ( timeout ) else : self . __timeout = 15.0 # define messaging asynchronous Context self . __msg_context = zmq . asyncio . Context () # check whether `Receive Mode` is enabled if receive_mode : # assign local ip address if None if address is None : self . __address = \"*\" # define address else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port else : # Handle video source if not None if source is None : self . config = { \"generator\" : None } if self . __logging : logger . warning ( \"Given source is of NoneType!\" ) else : # define stream with necessary params self . __stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # define default frame generator in configuration self . config = { \"generator\" : self . __frame_generator ()} # assign local ip address if None if address is None : self . __address = \"localhost\" else : self . __address = address # assign default port address if None if port is None : self . __port = \"5555\" else : self . __port = port # add server task handler self . task = None # Setup and assign event loop policy if platform . system () == \"Windows\" : # On Windows, VidGear requires the ``WindowsSelectorEventLoop``, and this is # the default in Python 3.7 and older, but new Python 3.8, defaults to an # event loop that is not compatible with it. Thereby, we had to set it manually. if sys . version_info [: 2 ] >= ( 3 , 8 ): asyncio . set_event_loop_policy ( asyncio . WindowsSelectorEventLoopPolicy ()) else : # import library import uvloop # uvloop eventloop is only available for UNIX machines. asyncio . set_event_loop_policy ( uvloop . EventLoopPolicy ()) # Retrieve event loop and assign it self . loop = asyncio . get_event_loop () # debugging logger . info ( \"Using ` {} ` event loop for this process.\" . format ( self . loop . __class__ . __name__ ) )","title":"__init__()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.close","text":"Terminates all NetGear Asynchronous processes gracefully. Parameters: Name Type Description Default skip_loop Boolean (optional)used only if closing executor loop throws an error. False Source code in vidgear/gears/asyncio/netgear_async.py def close ( self , skip_loop = False ): \"\"\" Terminates all NetGear Asynchronous processes gracefully. Parameters: skip_loop (Boolean): (optional)used only if closing executor loop throws an error. \"\"\" # log termination if self . __logging : logger . debug ( \"Terminating various {} Processes.\" . format ( \"Receive Mode\" if self . __receive_mode else \"Send Mode\" ) ) # whether `receive_mode` is enabled or not if self . __receive_mode : # indicate that process should be terminated self . __terminate = True else : # indicate that process should be terminated self . __terminate = True # terminate stream if not ( self . __stream is None ): self . __stream . stop () # close event loop if specified if not ( skip_loop ): self . loop . close ()","title":"close()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.launch","text":"Launches an asynchronous generators and loop executors for respective task. Source code in vidgear/gears/asyncio/netgear_async.py def launch ( self ): \"\"\" Launches an asynchronous generators and loop executors for respective task. \"\"\" # check if receive mode enabled if self . __receive_mode : if self . __logging : logger . debug ( \"Launching NetGear asynchronous generator!\" ) # run loop executor for Receiver asynchronous generator self . loop . run_in_executor ( None , self . recv_generator ) # return instance return self else : # Otherwise launch Server handler if self . __logging : logger . debug ( \"Creating NetGear asynchronous server handler!\" ) # create task for Server Handler self . task = asyncio . ensure_future ( self . __server_handler (), loop = self . loop ) # return instance return self","title":"launch()"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.recv_generator","text":"A default Asynchronous Frame Generator for NetGear's Receiver-end. Source code in vidgear/gears/asyncio/netgear_async.py async def recv_generator ( self ): \"\"\" A default Asynchronous Frame Generator for NetGear's Receiver-end. \"\"\" # check whether `receive mode` is activated if not ( self . __receive_mode ): # raise Value error and exit self . __terminate = True raise ValueError ( \"[NetGear:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\" ) # initialize and define messaging socket self . __msg_socket = self . __msg_context . socket ( self . __pattern [ 1 ]) # define exclusive socket options for patterns if self . __msg_pattern == 2 : self . __msg_socket . set_hwm ( 1 ) self . __msg_socket . setsockopt ( zmq . SUBSCRIBE , b \"\" ) try : # bind socket to the assigned protocol, address and port self . __msg_socket . bind ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ) # finally log progress if self . __logging : logger . debug ( \"Successfully Binded to address: {} with pattern: {} .\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) logger . debug ( \"Receive Mode is activated successfully!\" ) except Exception as e : logger . exception ( str ( e )) raise ValueError ( \"[NetGear:ERROR] :: Failed to bind address: {} and pattern: {} !\" . format ( ( self . __protocol + \"://\" + str ( self . __address ) + \":\" + str ( self . __port ) ), self . __msg_pattern , ) ) # loop until terminated while not self . __terminate : # get message withing timeout limit recvd_msg = await asyncio . wait_for ( self . __msg_socket . recv_multipart (), timeout = self . __timeout ) # check if bidirectional patterns if self . __msg_pattern < 2 : # send confirmation await self . __msg_socket . send_multipart ([ b \"Message Received!\" ]) # terminate if exit` flag received if recvd_msg [ 0 ] == b \"exit\" : break # retrieve frame from message frame = msgpack . unpackb ( recvd_msg [ 0 ], object_hook = m . decode ) # yield received frame yield frame # sleep for sometime await asyncio . sleep ( 0.00001 )","title":"recv_generator()"},{"location":"bonus/reference/pigear/","text":"All PiGear API parameters are explained here \u27b6 PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded wrapper around complete picamera python library, and also provides us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear supports multiple camera modules, such as in case of Raspberry Pi Compute module IO boards. Best of all, PiGear provides excellent error-handling with features like a Threaded Internal Timer - that keeps active track of any frozen-threads/hardware-failures robustly, and exit safely if it does occurs, i.e. If you're running PiGear API in your script, and someone accidentally pulls Camera module cable out, instead of going into possible kernel panic, PiGear will exit safely to save resources. __init__ ( self , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , colorspace = None , logging = False , time_delay = 0 , ** options ) special \u00b6 This constructor method initializes the object state and attributes of the PiGear class. Parameters: Name Type Description Default camera_num int selects the camera module index which will be used as source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the source.. (640, 480) framerate int/float sets the framerate of the source. 30 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Source Tweak Parameters. {} Source code in vidgear/gears/pigear.py def __init__ ( self , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the PiGear class. Parameters: camera_num (int): selects the camera module index which will be used as source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source.. framerate (int/float): sets the framerate of the source. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" try : import picamera from picamera import PiCamera from picamera.array import PiRGBArray except Exception as error : if isinstance ( error , ImportError ): # Output expected ImportErrors. raise ImportError ( '[PiGear:ERROR] :: Failed to detect Picamera executables, install it with \"pip3 install picamera\" command.' ) else : # Handle any API errors raise RuntimeError ( \"[PiGear:ERROR] :: Picamera API failure: {} \" . format ( error ) ) # enable logging if specified self . __logging = False if logging : self . __logging = logging assert ( isinstance ( framerate , ( int , float )) and framerate > 5.0 ), \"[PiGear:ERROR] :: Input framerate value ` {} ` is a Invalid! Kindly read docs.\" . format ( framerate ) assert ( isinstance ( resolution , ( tuple , list )) and len ( resolution ) == 2 ), \"[PiGear:ERROR] :: Input resolution value ` {} ` is a Invalid! Kindly read docs.\" . format ( resolution ) if not ( isinstance ( camera_num , int ) and camera_num >= 0 ): camera_num = 0 logger . warning ( \"Input camera_num value ` {} ` is invalid, Defaulting to index 0!\" ) # initialize the picamera stream at given index self . __camera = PiCamera ( camera_num = camera_num ) self . __camera . resolution = tuple ( resolution ) self . __camera . framerate = framerate if self . __logging : logger . debug ( \"Activating Pi camera at index: {} with resolution: {} & framerate: {} \" . format ( camera_num , resolution , framerate ) ) # initialize framerate variable self . framerate = framerate # initializing colorspace variable self . color_space = None # reformat dict options = { str ( k ) . strip (): v for k , v in options . items ()} # define timeout variable default value(handles hardware failures) self . __failure_timeout = options . pop ( \"HWFAILURE_TIMEOUT\" , 2.0 ) if isinstance ( self . __failure_timeout , ( int , float )): if not ( 10.0 > self . __failure_timeout > 1.0 ): raise ValueError ( \"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\" ) if self . __logging : logger . debug ( \"Setting HW Failure Timeout: {} seconds\" . format ( self . __failure_timeout ) ) else : # reset improper values self . __failure_timeout = 2.0 try : # apply attributes to source if specified for key , value in options . items (): setattr ( self . __camera , key , value ) except Exception as e : # Catch if any error occurred if self . __logging : logger . exception ( str ( e )) # separately handle colorspace value to int conversion if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # enable rgb capture array thread and capture stream self . __rawCapture = PiRGBArray ( self . __camera , size = resolution ) self . stream = self . __camera . capture_continuous ( self . __rawCapture , format = \"bgr\" , use_video_port = True ) # frame variable initialization self . frame = None try : stream = next ( self . stream ) self . frame = stream . array self . __rawCapture . seek ( 0 ) self . __rawCapture . truncate () # render colorspace if defined if not ( self . frame is None ) and not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) except Exception as e : logger . exception ( str ( e )) raise RuntimeError ( \"[PiGear:ERROR] :: Camera Module failed to initialize!\" ) # applying time delay to warm-up picamera only if specified if time_delay : time . sleep ( time_delay ) # thread initialization self . __thread = None # timer thread initialization(Keeps check on frozen thread) self . __timer = None self . __t_elasped = 0.0 # records time taken by thread # catching thread exceptions self . __exceptions = None # initialize termination flag self . __terminate = False read ( self ) \u00b6 Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/pigear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check if there are any thread exceptions if not ( self . __exceptions is None ): if isinstance ( self . __exceptions , bool ): # clear frame self . frame = None # notify user about hardware failure raise SystemError ( \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\" ) else : # clear frame self . frame = None # re-raise error for debugging error_msg = ( \"[PiGear:ERROR] :: Camera Module API failure occured: {} \" . format ( self . __exceptions [ 1 ] ) ) raise RuntimeError ( error_msg ) . with_traceback ( self . __exceptions [ 2 ]) # return the frame return self . frame start ( self ) \u00b6 Launches the internal Threaded Frames Extractor daemon Returns: A reference to the CamGear class object. Source code in vidgear/gears/pigear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" # Start frame producer thread self . __thread = Thread ( target = self . __update , name = \"PiGear\" , args = ()) self . __thread . daemon = True self . __thread . start () # Start internal timer thread self . __timer = Thread ( target = self . __timeit , name = \"PiTimer\" , args = ()) self . __timer . daemon = True self . __timer . start () return self stop ( self ) \u00b6 Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/pigear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" if self . __logging : logger . debug ( \"Terminating PiGear Processes.\" ) # make sure that the threads should be terminated self . __terminate = True # stop timer thread if not ( self . __timer is None ): self . __timer . join () # handle camera thread if not ( self . __thread is None ): # check if hardware failure occured if not ( self . __exceptions is None ) and isinstance ( self . __exceptions , bool ): # force release picamera resources self . stream . close () self . __rawCapture . close () self . __camera . close () # properly handle thread exit self . __thread . join () self . __thread . wait () # wait if still process is still processing some information self . __thread = None else : # properly handle thread exit self . __thread . join ()","title":"PiGear API"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.__init__","text":"This constructor method initializes the object state and attributes of the PiGear class. Parameters: Name Type Description Default camera_num int selects the camera module index which will be used as source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the source.. (640, 480) framerate int/float sets the framerate of the source. 30 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Source Tweak Parameters. {} Source code in vidgear/gears/pigear.py def __init__ ( self , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , colorspace = None , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the PiGear class. Parameters: camera_num (int): selects the camera module index which will be used as source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source.. framerate (int/float): sets the framerate of the source. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Source Tweak Parameters. \"\"\" try : import picamera from picamera import PiCamera from picamera.array import PiRGBArray except Exception as error : if isinstance ( error , ImportError ): # Output expected ImportErrors. raise ImportError ( '[PiGear:ERROR] :: Failed to detect Picamera executables, install it with \"pip3 install picamera\" command.' ) else : # Handle any API errors raise RuntimeError ( \"[PiGear:ERROR] :: Picamera API failure: {} \" . format ( error ) ) # enable logging if specified self . __logging = False if logging : self . __logging = logging assert ( isinstance ( framerate , ( int , float )) and framerate > 5.0 ), \"[PiGear:ERROR] :: Input framerate value ` {} ` is a Invalid! Kindly read docs.\" . format ( framerate ) assert ( isinstance ( resolution , ( tuple , list )) and len ( resolution ) == 2 ), \"[PiGear:ERROR] :: Input resolution value ` {} ` is a Invalid! Kindly read docs.\" . format ( resolution ) if not ( isinstance ( camera_num , int ) and camera_num >= 0 ): camera_num = 0 logger . warning ( \"Input camera_num value ` {} ` is invalid, Defaulting to index 0!\" ) # initialize the picamera stream at given index self . __camera = PiCamera ( camera_num = camera_num ) self . __camera . resolution = tuple ( resolution ) self . __camera . framerate = framerate if self . __logging : logger . debug ( \"Activating Pi camera at index: {} with resolution: {} & framerate: {} \" . format ( camera_num , resolution , framerate ) ) # initialize framerate variable self . framerate = framerate # initializing colorspace variable self . color_space = None # reformat dict options = { str ( k ) . strip (): v for k , v in options . items ()} # define timeout variable default value(handles hardware failures) self . __failure_timeout = options . pop ( \"HWFAILURE_TIMEOUT\" , 2.0 ) if isinstance ( self . __failure_timeout , ( int , float )): if not ( 10.0 > self . __failure_timeout > 1.0 ): raise ValueError ( \"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\" ) if self . __logging : logger . debug ( \"Setting HW Failure Timeout: {} seconds\" . format ( self . __failure_timeout ) ) else : # reset improper values self . __failure_timeout = 2.0 try : # apply attributes to source if specified for key , value in options . items (): setattr ( self . __camera , key , value ) except Exception as e : # Catch if any error occurred if self . __logging : logger . exception ( str ( e )) # separately handle colorspace value to int conversion if not ( colorspace is None ): self . color_space = capPropId ( colorspace . strip ()) if self . __logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) # enable rgb capture array thread and capture stream self . __rawCapture = PiRGBArray ( self . __camera , size = resolution ) self . stream = self . __camera . capture_continuous ( self . __rawCapture , format = \"bgr\" , use_video_port = True ) # frame variable initialization self . frame = None try : stream = next ( self . stream ) self . frame = stream . array self . __rawCapture . seek ( 0 ) self . __rawCapture . truncate () # render colorspace if defined if not ( self . frame is None ) and not ( self . color_space is None ): self . frame = cv2 . cvtColor ( self . frame , self . color_space ) except Exception as e : logger . exception ( str ( e )) raise RuntimeError ( \"[PiGear:ERROR] :: Camera Module failed to initialize!\" ) # applying time delay to warm-up picamera only if specified if time_delay : time . sleep ( time_delay ) # thread initialization self . __thread = None # timer thread initialization(Keeps check on frozen thread) self . __timer = None self . __t_elasped = 0.0 # records time taken by thread # catching thread exceptions self . __exceptions = None # initialize termination flag self . __terminate = False","title":"__init__()"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.read","text":"Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/pigear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check if there are any thread exceptions if not ( self . __exceptions is None ): if isinstance ( self . __exceptions , bool ): # clear frame self . frame = None # notify user about hardware failure raise SystemError ( \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\" ) else : # clear frame self . frame = None # re-raise error for debugging error_msg = ( \"[PiGear:ERROR] :: Camera Module API failure occured: {} \" . format ( self . __exceptions [ 1 ] ) ) raise RuntimeError ( error_msg ) . with_traceback ( self . __exceptions [ 2 ]) # return the frame return self . frame","title":"read()"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.start","text":"Launches the internal Threaded Frames Extractor daemon Returns: A reference to the CamGear class object. Source code in vidgear/gears/pigear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the CamGear class object. \"\"\" # Start frame producer thread self . __thread = Thread ( target = self . __update , name = \"PiGear\" , args = ()) self . __thread . daemon = True self . __thread . start () # Start internal timer thread self . __timer = Thread ( target = self . __timeit , name = \"PiTimer\" , args = ()) self . __timer . daemon = True self . __timer . start () return self","title":"start()"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.stop","text":"Safely terminates the thread, and release the VideoStream resources. Source code in vidgear/gears/pigear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the VideoStream resources. \"\"\" if self . __logging : logger . debug ( \"Terminating PiGear Processes.\" ) # make sure that the threads should be terminated self . __terminate = True # stop timer thread if not ( self . __timer is None ): self . __timer . join () # handle camera thread if not ( self . __thread is None ): # check if hardware failure occured if not ( self . __exceptions is None ) and isinstance ( self . __exceptions , bool ): # force release picamera resources self . stream . close () self . __rawCapture . close () self . __camera . close () # properly handle thread exit self . __thread . join () self . __thread . wait () # wait if still process is still processing some information self . __thread = None else : # properly handle thread exit self . __thread . join ()","title":"stop()"},{"location":"bonus/reference/screengear/","text":"All ScreenGear API parameters are explained here \u27b6 ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors. ScreenGear API implements a multi-threaded wrapper around pyscreenshot & python-mss python library, and also flexibly supports its internal parameter. Furthermore, ScreenGear API relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. __init__ ( self , monitor = None , backend = '' , colorspace = None , logging = False , ** options ) special \u00b6 This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: Name Type Description Default monitor int enables mss backend and sets the index of the monitor screen. None backend str enables pyscreenshot and select suitable backend for extracting frames. '' colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False options dict provides the flexibility to manually set the dimensions of capture screen area. {} Source code in vidgear/gears/screengear.py def __init__ ( self , monitor = None , backend = \"\" , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: monitor (int): enables `mss` backend and sets the index of the monitor screen. backend (str): enables `pyscreenshot` and select suitable backend for extracting frames. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. options (dict): provides the flexibility to manually set the dimensions of capture screen area. \"\"\" # enable logging if specified: self . __logging = logging if isinstance ( logging , bool ) else False # create monitor instance for the user-defined monitor self . __monitor_instance = None self . __backend = \"\" if monitor is None : self . __capture_object = pysct self . __backend = backend . lower () . strip () else : self . __capture_object = mss () if backend . strip (): logger . warning ( \"Backends are disabled for Monitor Indexing(monitor>=0)!\" ) try : self . __monitor_instance = self . __capture_object . monitors [ monitor ] except Exception as e : logger . exception ( str ( e )) self . __monitor_instance = None # Initialize Queue self . __queue = None # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # log it if logging : logger . debug ( \"Enabling Threaded Queue Mode by default for ScreenGear!\" ) # intiate screen dimension handler screen_dims = {} # reformat proper mss dict and assign to screen dimension handler screen_dims = { k . strip (): v for k , v in options . items () if k . strip () in [ \"top\" , \"left\" , \"width\" , \"height\" ] } # check whether user-defined dimensions are provided if screen_dims and len ( screen_dims ) == 4 : key_order = ( \"top\" , \"left\" , \"width\" , \"height\" ) screen_dims = OrderedDict (( k , screen_dims [ k ]) for k in key_order ) if logging : logger . debug ( \"Setting Capture-Area dimensions: {} !\" . format ( screen_dims )) else : screen_dims . clear () # separately handle colorspace value to int conversion if colorspace : self . color_space = capPropId ( colorspace . strip ()) if logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) else : self . color_space = None # intialize mss capture instance self . __mss_capture_instance = \"\" try : if self . __monitor_instance is None : if screen_dims : self . __mss_capture_instance = tuple ( screen_dims . values ()) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( bbox = self . __mss_capture_instance , childprocess = False , backend = self . __backend , ) ) else : if screen_dims : self . __mss_capture_instance = { \"top\" : self . __monitor_instance [ \"top\" ] + screen_dims [ \"top\" ], \"left\" : self . __monitor_instance [ \"left\" ] + screen_dims [ \"left\" ], \"width\" : screen_dims [ \"width\" ], \"height\" : screen_dims [ \"height\" ], \"mon\" : monitor , } else : self . __mss_capture_instance = ( self . __monitor_instance # otherwise create instance from monitor ) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( self . __mss_capture_instance ) ) # intitialize and append to queue self . __queue . append ( self . frame ) except Exception as e : if isinstance ( e , ScreenShotError ): # otherwise catch and log errors if logging : logger . exception ( self . __capture_object . get_error_details ()) raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\" ) elif isinstance ( e , KeyError ): raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Invalid backend: ` {} `, Kindly Refer Docs!\" . format ( backend ) ) else : raise SystemError ( \"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\" ) # thread initialization self . __thread = None # initialize termination flag self . __terminate = False read ( self ) \u00b6 Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/screengear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check whether or not termination flag is enabled while not self . __terminate : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : continue # otherwise return NoneType return None start ( self ) \u00b6 Launches the internal Threaded Frames Extractor daemon Returns: A reference to the ScreenGear class object. Source code in vidgear/gears/screengear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the ScreenGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"ScreenGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self stop ( self ) \u00b6 Safely terminates the thread, and release the resources. Source code in vidgear/gears/screengear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the resources. \"\"\" if self . __logging : logger . debug ( \"Terminating ScreenGear Processes.\" ) # indicate that the thread should be terminated self . __terminate = True # terminate Threaded queue mode seperately if not ( self . __queue is None ): self . __queue . clear () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : self . __thread . join ()","title":"ScreenGear API"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.__init__","text":"This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: Name Type Description Default monitor int enables mss backend and sets the index of the monitor screen. None backend str enables pyscreenshot and select suitable backend for extracting frames. '' colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False options dict provides the flexibility to manually set the dimensions of capture screen area. {} Source code in vidgear/gears/screengear.py def __init__ ( self , monitor = None , backend = \"\" , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the ScreenGear class. Parameters: monitor (int): enables `mss` backend and sets the index of the monitor screen. backend (str): enables `pyscreenshot` and select suitable backend for extracting frames. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. options (dict): provides the flexibility to manually set the dimensions of capture screen area. \"\"\" # enable logging if specified: self . __logging = logging if isinstance ( logging , bool ) else False # create monitor instance for the user-defined monitor self . __monitor_instance = None self . __backend = \"\" if monitor is None : self . __capture_object = pysct self . __backend = backend . lower () . strip () else : self . __capture_object = mss () if backend . strip (): logger . warning ( \"Backends are disabled for Monitor Indexing(monitor>=0)!\" ) try : self . __monitor_instance = self . __capture_object . monitors [ monitor ] except Exception as e : logger . exception ( str ( e )) self . __monitor_instance = None # Initialize Queue self . __queue = None # define deque and assign it to global var self . __queue = deque ( maxlen = 96 ) # max len 96 to check overflow # log it if logging : logger . debug ( \"Enabling Threaded Queue Mode by default for ScreenGear!\" ) # intiate screen dimension handler screen_dims = {} # reformat proper mss dict and assign to screen dimension handler screen_dims = { k . strip (): v for k , v in options . items () if k . strip () in [ \"top\" , \"left\" , \"width\" , \"height\" ] } # check whether user-defined dimensions are provided if screen_dims and len ( screen_dims ) == 4 : key_order = ( \"top\" , \"left\" , \"width\" , \"height\" ) screen_dims = OrderedDict (( k , screen_dims [ k ]) for k in key_order ) if logging : logger . debug ( \"Setting Capture-Area dimensions: {} !\" . format ( screen_dims )) else : screen_dims . clear () # separately handle colorspace value to int conversion if colorspace : self . color_space = capPropId ( colorspace . strip ()) if logging and not ( self . color_space is None ): logger . debug ( \"Enabling ` {} ` colorspace for this video stream!\" . format ( colorspace . strip () ) ) else : self . color_space = None # intialize mss capture instance self . __mss_capture_instance = \"\" try : if self . __monitor_instance is None : if screen_dims : self . __mss_capture_instance = tuple ( screen_dims . values ()) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( bbox = self . __mss_capture_instance , childprocess = False , backend = self . __backend , ) ) else : if screen_dims : self . __mss_capture_instance = { \"top\" : self . __monitor_instance [ \"top\" ] + screen_dims [ \"top\" ], \"left\" : self . __monitor_instance [ \"left\" ] + screen_dims [ \"left\" ], \"width\" : screen_dims [ \"width\" ], \"height\" : screen_dims [ \"height\" ], \"mon\" : monitor , } else : self . __mss_capture_instance = ( self . __monitor_instance # otherwise create instance from monitor ) # extract global frame from instance self . frame = np . asanyarray ( self . __capture_object . grab ( self . __mss_capture_instance ) ) # intitialize and append to queue self . __queue . append ( self . frame ) except Exception as e : if isinstance ( e , ScreenShotError ): # otherwise catch and log errors if logging : logger . exception ( self . __capture_object . get_error_details ()) raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\" ) elif isinstance ( e , KeyError ): raise ValueError ( \"[ScreenGear:ERROR] :: ScreenShotError caught, Invalid backend: ` {} `, Kindly Refer Docs!\" . format ( backend ) ) else : raise SystemError ( \"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\" ) # thread initialization self . __thread = None # initialize termination flag self . __terminate = False","title":"__init__()"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.read","text":"Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/screengear.py def read ( self ): \"\"\" Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" # check whether or not termination flag is enabled while not self . __terminate : # check if queue is empty if len ( self . __queue ) > 0 : return self . __queue . popleft () else : continue # otherwise return NoneType return None","title":"read()"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.start","text":"Launches the internal Threaded Frames Extractor daemon Returns: A reference to the ScreenGear class object. Source code in vidgear/gears/screengear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon **Returns:** A reference to the ScreenGear class object. \"\"\" self . __thread = Thread ( target = self . __update , name = \"ScreenGear\" , args = ()) self . __thread . daemon = True self . __thread . start () return self","title":"start()"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.stop","text":"Safely terminates the thread, and release the resources. Source code in vidgear/gears/screengear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the resources. \"\"\" if self . __logging : logger . debug ( \"Terminating ScreenGear Processes.\" ) # indicate that the thread should be terminated self . __terminate = True # terminate Threaded queue mode seperately if not ( self . __queue is None ): self . __queue . clear () # wait until stream resources are released (producer thread might be still grabbing frame) if self . __thread is not None : self . __thread . join ()","title":"stop()"},{"location":"bonus/reference/stabilizer/","text":"All Stabilizer API parameters are explained here \u27b6 This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free & ultra-fast frame handling. __init__ ( self , smoothing_radius = 25 , border_type = 'black' , border_size = 0 , crop_n_zoom = False , logging = False ) special \u00b6 This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: Name Type Description Default smoothing_radius int alter averaging window size. 25 border_type str changes the extended border type. 'black' border_size int enables and set the value for extended border size to reduce the black borders. 0 crop_n_zoom bool enables croping and zooming of frames(to original size) to reduce the black borders. False logging bool enables/disables logging. False Source code in vidgear/gears/stabilizer.py def __init__ ( self , smoothing_radius = 25 , border_type = \"black\" , border_size = 0 , crop_n_zoom = False , logging = False , ): \"\"\" This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: smoothing_radius (int): alter averaging window size. border_type (str): changes the extended border type. border_size (int): enables and set the value for extended border size to reduce the black borders. crop_n_zoom (bool): enables croping and zooming of frames(to original size) to reduce the black borders. logging (bool): enables/disables logging. \"\"\" # initialize deques for handling input frames and its indexes self . __frame_queue = deque ( maxlen = smoothing_radius ) self . __frame_queue_indexes = deque ( maxlen = smoothing_radius ) # enable logging if specified self . __logging = False if logging : self . __logging = logging # define and create Adaptive histogram equalization (AHE) object for optimizations self . __clahe = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) # initialize global vars self . __smoothing_radius = smoothing_radius # averaging window, handles the quality of stabilization at expense of latency and sudden panning self . __smoothed_path = None # handles the smoothed path with box filter self . __path = None # handles path i.e cumulative sum of pevious_2_current transformations along a axis self . __transforms = [] # handles pevious_2_current transformations [dx,dy,da] self . __frame_transforms_smoothed = None # handles smoothed array of pevious_2_current transformations w.r.t to frames self . __previous_gray = None # handles previous gray frame self . __previous_keypoints = ( None # handles previous detect_GFTTed keypoints w.r.t previous gray frame ) self . __frame_height , self . frame_width = ( 0 , 0 , ) # handles width and height of input frames self . __crop_n_zoom = 0 # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable. # if check if crop_n_zoom defined if crop_n_zoom and border_size : self . __crop_n_zoom = border_size # crops and zoom frame to original size self . __border_size = 0 # zero out border size self . __frame_size = None # handles frame size for zooming if logging : logger . debug ( \"Setting Cropping margin {} pixels\" . format ( border_size )) else : # Add output borders to frame self . __border_size = border_size if self . __logging and border_size : logger . debug ( \"Setting Border size {} pixels\" . format ( border_size )) # define valid border modes border_modes = { \"black\" : cv2 . BORDER_CONSTANT , \"reflect\" : cv2 . BORDER_REFLECT , \"reflect_101\" : cv2 . BORDER_REFLECT_101 , \"replicate\" : cv2 . BORDER_REPLICATE , \"wrap\" : cv2 . BORDER_WRAP , } # choose valid border_mode from border_type if border_type in [ \"black\" , \"reflect\" , \"reflect_101\" , \"replicate\" , \"wrap\" ]: if not crop_n_zoom : # initialize global border mode variable self . __border_mode = border_modes [ border_type ] if self . __logging and border_type != \"black\" : logger . debug ( \"Setting Border type: {} \" . format ( border_type )) else : # log and reset to default if self . __logging and border_type != \"black\" : logger . debug ( \"Setting border type is disabled if cropping is enabled!\" ) self . __border_mode = border_modes [ \"black\" ] else : # otherwise log if not if logging : logger . debug ( \"Invalid input border type!\" ) self . __border_mode = border_modes [ \"black\" ] # reset to default mode # define OpenCV version self . __cv2_version = check_CV_version () # define normalized box filter self . __box_filter = np . ones ( smoothing_radius ) / smoothing_radius clean ( self ) \u00b6 Cleans Stabilizer resources Source code in vidgear/gears/stabilizer.py def clean ( self ): \"\"\" Cleans Stabilizer resources \"\"\" # check if deque present if self . __frame_queue : # clear frame deque self . __frame_queue . clear () # clear frame indexes deque self . __frame_queue_indexes . clear () stabilize ( self , frame ) \u00b6 This method takes an unstabilized video frame, and returns a stabilized one. Parameters: Name Type Description Default frame numpy.ndarray inputs unstabilized video frames. required Source code in vidgear/gears/stabilizer.py def stabilize ( self , frame ): \"\"\" This method takes an unstabilized video frame, and returns a stabilized one. Parameters: frame (numpy.ndarray): inputs unstabilized video frames. \"\"\" # check if frame is None if frame is None : # return if it does return # save frame size for zooming if self . __crop_n_zoom and self . __frame_size == None : self . __frame_size = frame . shape [: 2 ] # initiate transformations capturing if not self . __frame_queue : # for first frame previous_gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # convert to gray previous_gray = self . __clahe . apply ( previous_gray ) # optimize gray frame self . __previous_keypoints = cv2 . goodFeaturesToTrack ( previous_gray , maxCorners = 200 , qualityLevel = 0.05 , minDistance = 30.0 , blockSize = 3 , mask = None , useHarrisDetector = False , k = 0.04 , ) # track features using GFTT self . __frame_height , self . frame_width = frame . shape [ : 2 ] # save input frame height and width self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( 0 ) # save frame index to deque self . __previous_gray = previous_gray [ : ] # save gray frame clone for further processing elif self . __frame_queue_indexes [ - 1 ] <= self . __smoothing_radius - 1 : # for rest of frames self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations if self . __frame_queue_indexes [ - 1 ] == self . __smoothing_radius - 1 : # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation else : # start applying transformations self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation # return transformation applied stabilized frame return self . __apply_transformations ()","title":"Stabilizer Class"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.__init__","text":"This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: Name Type Description Default smoothing_radius int alter averaging window size. 25 border_type str changes the extended border type. 'black' border_size int enables and set the value for extended border size to reduce the black borders. 0 crop_n_zoom bool enables croping and zooming of frames(to original size) to reduce the black borders. False logging bool enables/disables logging. False Source code in vidgear/gears/stabilizer.py def __init__ ( self , smoothing_radius = 25 , border_type = \"black\" , border_size = 0 , crop_n_zoom = False , logging = False , ): \"\"\" This constructor method initializes the object state and attributes of the Stabilizer class. Parameters: smoothing_radius (int): alter averaging window size. border_type (str): changes the extended border type. border_size (int): enables and set the value for extended border size to reduce the black borders. crop_n_zoom (bool): enables croping and zooming of frames(to original size) to reduce the black borders. logging (bool): enables/disables logging. \"\"\" # initialize deques for handling input frames and its indexes self . __frame_queue = deque ( maxlen = smoothing_radius ) self . __frame_queue_indexes = deque ( maxlen = smoothing_radius ) # enable logging if specified self . __logging = False if logging : self . __logging = logging # define and create Adaptive histogram equalization (AHE) object for optimizations self . __clahe = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) # initialize global vars self . __smoothing_radius = smoothing_radius # averaging window, handles the quality of stabilization at expense of latency and sudden panning self . __smoothed_path = None # handles the smoothed path with box filter self . __path = None # handles path i.e cumulative sum of pevious_2_current transformations along a axis self . __transforms = [] # handles pevious_2_current transformations [dx,dy,da] self . __frame_transforms_smoothed = None # handles smoothed array of pevious_2_current transformations w.r.t to frames self . __previous_gray = None # handles previous gray frame self . __previous_keypoints = ( None # handles previous detect_GFTTed keypoints w.r.t previous gray frame ) self . __frame_height , self . frame_width = ( 0 , 0 , ) # handles width and height of input frames self . __crop_n_zoom = 0 # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable. # if check if crop_n_zoom defined if crop_n_zoom and border_size : self . __crop_n_zoom = border_size # crops and zoom frame to original size self . __border_size = 0 # zero out border size self . __frame_size = None # handles frame size for zooming if logging : logger . debug ( \"Setting Cropping margin {} pixels\" . format ( border_size )) else : # Add output borders to frame self . __border_size = border_size if self . __logging and border_size : logger . debug ( \"Setting Border size {} pixels\" . format ( border_size )) # define valid border modes border_modes = { \"black\" : cv2 . BORDER_CONSTANT , \"reflect\" : cv2 . BORDER_REFLECT , \"reflect_101\" : cv2 . BORDER_REFLECT_101 , \"replicate\" : cv2 . BORDER_REPLICATE , \"wrap\" : cv2 . BORDER_WRAP , } # choose valid border_mode from border_type if border_type in [ \"black\" , \"reflect\" , \"reflect_101\" , \"replicate\" , \"wrap\" ]: if not crop_n_zoom : # initialize global border mode variable self . __border_mode = border_modes [ border_type ] if self . __logging and border_type != \"black\" : logger . debug ( \"Setting Border type: {} \" . format ( border_type )) else : # log and reset to default if self . __logging and border_type != \"black\" : logger . debug ( \"Setting border type is disabled if cropping is enabled!\" ) self . __border_mode = border_modes [ \"black\" ] else : # otherwise log if not if logging : logger . debug ( \"Invalid input border type!\" ) self . __border_mode = border_modes [ \"black\" ] # reset to default mode # define OpenCV version self . __cv2_version = check_CV_version () # define normalized box filter self . __box_filter = np . ones ( smoothing_radius ) / smoothing_radius","title":"__init__()"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.clean","text":"Cleans Stabilizer resources Source code in vidgear/gears/stabilizer.py def clean ( self ): \"\"\" Cleans Stabilizer resources \"\"\" # check if deque present if self . __frame_queue : # clear frame deque self . __frame_queue . clear () # clear frame indexes deque self . __frame_queue_indexes . clear ()","title":"clean()"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.stabilize","text":"This method takes an unstabilized video frame, and returns a stabilized one. Parameters: Name Type Description Default frame numpy.ndarray inputs unstabilized video frames. required Source code in vidgear/gears/stabilizer.py def stabilize ( self , frame ): \"\"\" This method takes an unstabilized video frame, and returns a stabilized one. Parameters: frame (numpy.ndarray): inputs unstabilized video frames. \"\"\" # check if frame is None if frame is None : # return if it does return # save frame size for zooming if self . __crop_n_zoom and self . __frame_size == None : self . __frame_size = frame . shape [: 2 ] # initiate transformations capturing if not self . __frame_queue : # for first frame previous_gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # convert to gray previous_gray = self . __clahe . apply ( previous_gray ) # optimize gray frame self . __previous_keypoints = cv2 . goodFeaturesToTrack ( previous_gray , maxCorners = 200 , qualityLevel = 0.05 , minDistance = 30.0 , blockSize = 3 , mask = None , useHarrisDetector = False , k = 0.04 , ) # track features using GFTT self . __frame_height , self . frame_width = frame . shape [ : 2 ] # save input frame height and width self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( 0 ) # save frame index to deque self . __previous_gray = previous_gray [ : ] # save gray frame clone for further processing elif self . __frame_queue_indexes [ - 1 ] <= self . __smoothing_radius - 1 : # for rest of frames self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations if self . __frame_queue_indexes [ - 1 ] == self . __smoothing_radius - 1 : # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation else : # start applying transformations self . __frame_queue . append ( frame ) # save frame to deque self . __frame_queue_indexes . append ( self . __frame_queue_indexes [ - 1 ] + 1 ) # save frame index self . __generate_transformations () # generate transformations # calculate smooth path once transformation capturing is completed for i in range ( 3 ): # apply normalized box filter to the path self . __smoothed_path [:, i ] = self . __box_filter_convolve ( ( self . __path [:, i ]), window_size = self . __smoothing_radius ) # calculate deviation of path from smoothed path deviation = self . __smoothed_path - self . __path # save smoothed transformation self . __frame_transforms_smoothed = self . frame_transform + deviation # return transformation applied stabilized frame return self . __apply_transformations ()","title":"stabilize()"},{"location":"bonus/reference/streamgear/","text":"All StreamGear API parameters are explained here \u27b6 StreamGear is built for Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) with FFmpeg to generate the chunked-encoded media segments of the content, in just few lines of python code. StreamGear provides a standalone, highly extensible and flexible wrapper around FFmpeg - a leading multimedia framework and access to almost all of its parameter for seamlessly generating these streams. SteamGear API automatically transcodes source videos/audio files & real-time frames, and breaks them into a sequence of multiple smaller chunks/segments (typically 2-4 seconds in length) at different quality levels (i.e. different bitrates or spatial resolutions) . It also creates a media presentation description (MPD in-case of DASH) that describes these segment information (timing, URL, media characteristics like video resolution and bit rates) , and is provided to the client prior to the streaming session. Thereby, segments are served on a web-server and can be downloaded through HTTP standard compliant GET requests. This makes it possible to stream videos at different quality levels, and to switch in the middle of a video from one quality level to another one. SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. stream ( self , frame , rgb_mode = False ) \u00b6 Pipelines ndarray frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format instead of default BGR) . False Source code in vidgear/gears/streamgear.py def stream ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_. \"\"\" # check if function is called in correct context if self . __video_source : raise RuntimeError ( \"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\" ) # None-Type frames will be skipped if frame is None : return # extract height, width and number of channels of frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate_stream : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __sourceframerate = ( 25.0 if not ( self . __inputframerate ) else self . __inputframerate ) if self . __logging : logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same number of channels!\" ) # initiate FFmpeg process on first run if self . __initiate_stream : # launch pre-processing self . __PreProcess ( channels = channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame to pipeline try : self . __process . stdin . write ( frame . tostring ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only terminate ( self ) \u00b6 Safely terminates StreamGear. Source code in vidgear/gears/streamgear.py def terminate ( self ): \"\"\" Safely terminates StreamGear. \"\"\" # return if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): return # close `stdin` output if self . __process . stdin : self . __process . stdin . close () # wait if still process is still processing some information self . __process . wait () self . __process = None # log it logger . critical ( \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\" . format ( self . __format . upper () ) ) transcode_source ( self ) \u00b6 Transcodes entire Video Source (with audio) into multi-bitrate streamable assets Source code in vidgear/gears/streamgear.py def transcode_source ( self ): \"\"\" Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets \"\"\" # check if function is called in correct context if not ( self . __video_source ): raise RuntimeError ( \"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\" ) # assign height, width and framerate self . __inputheight = int ( self . __aspect_source [ 1 ]) self . __inputwidth = int ( self . __aspect_source [ 0 ]) self . __sourceframerate = float ( self . __fps_source ) # launch pre-processing self . __PreProcess ()","title":"StreamGear API"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.stream","text":"Pipelines ndarray frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format instead of default BGR) . False Source code in vidgear/gears/streamgear.py def stream ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_. \"\"\" # check if function is called in correct context if self . __video_source : raise RuntimeError ( \"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\" ) # None-Type frames will be skipped if frame is None : return # extract height, width and number of channels of frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate_stream : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels self . __sourceframerate = ( 25.0 if not ( self . __inputframerate ) else self . __inputframerate ) if self . __logging : logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[StreamGear:ERROR] :: All frames must have same number of channels!\" ) # initiate FFmpeg process on first run if self . __initiate_stream : # launch pre-processing self . __PreProcess ( channels = channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame to pipeline try : self . __process . stdin . write ( frame . tostring ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only","title":"stream()"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.terminate","text":"Safely terminates StreamGear. Source code in vidgear/gears/streamgear.py def terminate ( self ): \"\"\" Safely terminates StreamGear. \"\"\" # return if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): return # close `stdin` output if self . __process . stdin : self . __process . stdin . close () # wait if still process is still processing some information self . __process . wait () self . __process = None # log it logger . critical ( \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\" . format ( self . __format . upper () ) )","title":"terminate()"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.transcode_source","text":"Transcodes entire Video Source (with audio) into multi-bitrate streamable assets Source code in vidgear/gears/streamgear.py def transcode_source ( self ): \"\"\" Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets \"\"\" # check if function is called in correct context if not ( self . __video_source ): raise RuntimeError ( \"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\" ) # assign height, width and framerate self . __inputheight = int ( self . __aspect_source [ 1 ]) self . __inputwidth = int ( self . __aspect_source [ 0 ]) self . __sourceframerate = float ( self . __fps_source ) # launch pre-processing self . __PreProcess ()","title":"transcode_source()"},{"location":"bonus/reference/videogear/","text":"All VideoGear API parameters are explained here \u27b6 VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and using just fewer lines of code. __init__ ( self , enablePiCamera = False , stabilize = False , camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , source = 0 , stream_mode = False , backend = 0 , time_delay = 0 , colorspace = None , logging = False , ** options ) special \u00b6 This constructor method initializes the object state and attributes of the VideoGear class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 30 source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/videogear.py def __init__ ( self , # VideoGear parameters enablePiCamera = False , stabilize = False , # PiGear parameters camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , # CamGear parameters source = 0 , stream_mode = False , backend = 0 , # common parameters time_delay = 0 , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the VideoGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. \"\"\" # initialize stabilizer self . __stablization_mode = stabilize # enable logging if specified self . __logging = False if logging : self . __logging = logging # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} if self . __stablization_mode : from .stabilizer import Stabilizer s_radius = options . pop ( \"SMOOTHING_RADIUS\" , 25 ) if not isinstance ( s_radius , int ): s_radius = 25 border_size = options . pop ( \"BORDER_SIZE\" , 0 ) if not isinstance ( border_size , int ): border_size = 0 border_type = options . pop ( \"BORDER_TYPE\" , \"black\" ) if not isinstance ( border_type , str ): border_type = \"black\" crop_n_zoom = options . pop ( \"CROP_N_ZOOM\" , False ) if not isinstance ( crop_n_zoom , bool ): crop_n_zoom = False self . __stabilizer_obj = Stabilizer ( smoothing_radius = s_radius , border_type = border_type , border_size = border_size , crop_n_zoom = crop_n_zoom , logging = logging , ) if self . __logging : logger . debug ( \"Enabling Stablization Mode for the current video source!\" ) # log info if enablePiCamera : # only import the pigear module only if required from .pigear import PiGear # initialize the picamera stream by enabling PiGear API self . stream = PiGear ( camera_num = camera_num , resolution = resolution , framerate = framerate , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) else : # otherwise, we are using OpenCV so initialize the webcam # stream by activating CamGear API self . stream = CamGear ( source = source , stream_mode = stream_mode , backend = backend , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) # initialize framerate variable self . framerate = self . stream . framerate read ( self ) \u00b6 Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/videogear.py def read ( self ): \"\"\" Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __stablization_mode : frame = self . stream . read () if frame is None : break frame_stab = self . __stabilizer_obj . stabilize ( frame ) if not ( frame_stab is None ): return frame_stab return self . stream . read () start ( self ) \u00b6 Launches the internal Threaded Frames Extractor daemon of API in use. Returns: A reference to the selected class object. Source code in vidgear/gears/videogear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon of API in use. **Returns:** A reference to the selected class object. \"\"\" self . stream . start () return self stop ( self ) \u00b6 Safely terminates the thread, and release the respective VideoStream resources. Source code in vidgear/gears/videogear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the respective VideoStream resources. \"\"\" self . stream . stop () # logged if self . __logging : logger . debug ( \"Terminating VideoGear.\" ) # clean queue if self . __stablization_mode : self . __stabilizer_obj . clean ()","title":"VideoGear API"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.__init__","text":"This constructor method initializes the object state and attributes of the VideoGear class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 30 source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/videogear.py def __init__ ( self , # VideoGear parameters enablePiCamera = False , stabilize = False , # PiGear parameters camera_num = 0 , resolution = ( 640 , 480 ), framerate = 30 , # CamGear parameters source = 0 , stream_mode = False , backend = 0 , # common parameters time_delay = 0 , colorspace = None , logging = False , ** options ): \"\"\" This constructor method initializes the object state and attributes of the VideoGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear & Stabilizer. \"\"\" # initialize stabilizer self . __stablization_mode = stabilize # enable logging if specified self . __logging = False if logging : self . __logging = logging # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} if self . __stablization_mode : from .stabilizer import Stabilizer s_radius = options . pop ( \"SMOOTHING_RADIUS\" , 25 ) if not isinstance ( s_radius , int ): s_radius = 25 border_size = options . pop ( \"BORDER_SIZE\" , 0 ) if not isinstance ( border_size , int ): border_size = 0 border_type = options . pop ( \"BORDER_TYPE\" , \"black\" ) if not isinstance ( border_type , str ): border_type = \"black\" crop_n_zoom = options . pop ( \"CROP_N_ZOOM\" , False ) if not isinstance ( crop_n_zoom , bool ): crop_n_zoom = False self . __stabilizer_obj = Stabilizer ( smoothing_radius = s_radius , border_type = border_type , border_size = border_size , crop_n_zoom = crop_n_zoom , logging = logging , ) if self . __logging : logger . debug ( \"Enabling Stablization Mode for the current video source!\" ) # log info if enablePiCamera : # only import the pigear module only if required from .pigear import PiGear # initialize the picamera stream by enabling PiGear API self . stream = PiGear ( camera_num = camera_num , resolution = resolution , framerate = framerate , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) else : # otherwise, we are using OpenCV so initialize the webcam # stream by activating CamGear API self . stream = CamGear ( source = source , stream_mode = stream_mode , backend = backend , colorspace = colorspace , logging = logging , time_delay = time_delay , ** options ) # initialize framerate variable self . framerate = self . stream . framerate","title":"__init__()"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.read","text":"Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. Returns: A n-dimensional numpy array. Source code in vidgear/gears/videogear.py def read ( self ): \"\"\" Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full. **Returns:** A n-dimensional numpy array. \"\"\" while self . __stablization_mode : frame = self . stream . read () if frame is None : break frame_stab = self . __stabilizer_obj . stabilize ( frame ) if not ( frame_stab is None ): return frame_stab return self . stream . read ()","title":"read()"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.start","text":"Launches the internal Threaded Frames Extractor daemon of API in use. Returns: A reference to the selected class object. Source code in vidgear/gears/videogear.py def start ( self ): \"\"\" Launches the internal *Threaded Frames Extractor* daemon of API in use. **Returns:** A reference to the selected class object. \"\"\" self . stream . start () return self","title":"start()"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.stop","text":"Safely terminates the thread, and release the respective VideoStream resources. Source code in vidgear/gears/videogear.py def stop ( self ): \"\"\" Safely terminates the thread, and release the respective VideoStream resources. \"\"\" self . stream . stop () # logged if self . __logging : logger . debug ( \"Terminating VideoGear.\" ) # clean queue if self . __stablization_mode : self . __stabilizer_obj . clean ()","title":"stop()"},{"location":"bonus/reference/webgear/","text":"All WebGear API parameters are explained here \u27b6 WebGear is a powerful ASGI Video-streamer API, that is built upon Starlette - a lightweight ASGI python framework/toolkit, which is ideal for building high-performance asyncio services. WebGear API provides a highly extensible and flexible asyncio wrapper around Starlette ASGI application, and provides easy access to its complete framework. Thereby, WebGear API can flexibly interact with the Starlette's ecosystem of shared middleware and mountable applications, and its various Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. In layman's terms, WebGear can acts as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. It addition to this, WebGear API also provides a special internal wrapper around VideoGear API, which itself provides internal access to both CamGear and PiGear APIs thereby granting it exclusive power for streaming frames incoming from any device/source, such as streaming Stabilization enabled Video in real-time. __call__ ( self ) special \u00b6 Implements a custom Callable method for WebGear application. Source code in vidgear/gears/asyncio/webgear.py def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"Routing tables are not valid!\" ) # initiate stream if self . __logging : logger . debug ( \"Initiating Video Streaming.\" ) self . stream . start () # return Starlette application if self . __logging : logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , exception_handlers = self . __exception_handlers , on_shutdown = [ self . shutdown ], ) __init__ ( self , enablePiCamera = False , stabilize = False , source = 0 , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ) special \u00b6 This constructor method initializes the object state and attributes of the WebGear class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/webgear.py def __init__ ( self , enablePiCamera = False , stabilize = False , source = 0 , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the WebGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. \"\"\" # initialize global params self . __jpeg_quality = 90 # 90% quality self . __jpeg_optimize = 0 # optimization off self . __jpeg_progressive = 0 # jpeg will be baseline instead self . __frame_size_reduction = 20 # 20% reduction self . __logging = logging custom_data_location = \"\" # path to save data-files to custom location data_path = \"\" # path to WebGear data-files overwrite_default = False # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # assign values to global variables if specified and valid if options : if \"frame_size_reduction\" in options : value = options [ \"frame_size_reduction\" ] if isinstance ( value , ( int , float )) and value >= 0 and value <= 90 : self . __frame_size_reduction = value else : logger . warning ( \"Skipped invalid `frame_size_reduction` value!\" ) del options [ \"frame_size_reduction\" ] # clean if \"frame_jpeg_quality\" in options : value = options [ \"frame_jpeg_quality\" ] if isinstance ( value , ( int , float )) and value >= 10 and value <= 95 : self . __jpeg_quality = int ( value ) else : logger . warning ( \"Skipped invalid `frame_jpeg_quality` value!\" ) del options [ \"frame_jpeg_quality\" ] # clean if \"frame_jpeg_optimize\" in options : value = options [ \"frame_jpeg_optimize\" ] if isinstance ( value , bool ): self . __jpeg_optimize = int ( value ) else : logger . warning ( \"Skipped invalid `frame_jpeg_optimize` value!\" ) del options [ \"frame_jpeg_optimize\" ] # clean if \"frame_jpeg_progressive\" in options : value = options [ \"frame_jpeg_progressive\" ] if isinstance ( value , bool ): self . __jpeg_progressive = int ( value ) else : logger . warning ( \"Skipped invalid `frame_jpeg_progressive` value!\" ) del options [ \"frame_jpeg_progressive\" ] # clean if \"custom_data_location\" in options : value = options [ \"custom_data_location\" ] if isinstance ( value , str ): assert os . access ( value , os . W_OK ), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\" custom_data_location = os . path . abspath ( value ) else : logger . warning ( \"Skipped invalid `custom_data_location` value!\" ) del options [ \"custom_data_location\" ] # clean if \"overwrite_default_files\" in options : value = options [ \"overwrite_default_files\" ] if isinstance ( value , bool ): overwrite_default = value else : logger . warning ( \"Skipped invalid `overwrite_default_files` value!\" ) del options [ \"overwrite_default_files\" ] # clean # define stream with necessary params self . stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # check if custom certificates path is specified if custom_data_location : data_path = generate_webdata ( custom_data_location , overwrite_default = overwrite_default , logging = logging , ) else : # otherwise generate suitable path from os.path import expanduser data_path = generate_webdata ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), overwrite_default = overwrite_default , logging = logging , ) # log it if self . __logging : logger . debug ( \"` {} ` is the default location for saving WebGear data-files.\" . format ( data_path ) ) if self . __logging : logger . debug ( \"Setting params:: Size Reduction: {} %, JPEG quality: {} %, JPEG optimizations: {} , JPEG progressive: {} \" . format ( self . __frame_size_reduction , self . __jpeg_quality , bool ( self . __jpeg_optimize ), bool ( self . __jpeg_progressive ), ) ) # define Jinja2 templates handler self . __templates = Jinja2Templates ( directory = \" {} /templates\" . format ( data_path )) # define custom exception handlers self . __exception_handlers = { 404 : self . __not_found , 500 : self . __server_error } # define routing tables self . routes = [ Route ( \"/\" , endpoint = self . __homepage ), Route ( \"/video\" , endpoint = self . __video ), Mount ( \"/static\" , app = StaticFiles ( directory = \" {} /static\" . format ( data_path )), name = \"static\" , ), ] # copying original routing tables for further validation self . __rt_org_copy = self . routes [:] # keeps check if producer loop should be running self . __isrunning = True shutdown ( self ) \u00b6 Implements a Callable to be run on application shutdown Source code in vidgear/gears/asyncio/webgear.py def shutdown ( self ): \"\"\" Implements a Callable to be run on application shutdown \"\"\" if not ( self . stream is None ): if self . __logging : logger . debug ( \"Closing Video Streaming.\" ) # stops producer self . __isrunning = False # stops VideoGear stream self . stream . stop () # prevent any re-iteration self . stream = None","title":"WebGear API"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__call__","text":"Implements a custom Callable method for WebGear application. Source code in vidgear/gears/asyncio/webgear.py def __call__ ( self ): \"\"\" Implements a custom Callable method for WebGear application. \"\"\" # validate routing tables assert not ( self . routes is None ), \"Routing tables are NoneType!\" if not isinstance ( self . routes , list ) or not all ( x in self . routes for x in self . __rt_org_copy ): raise RuntimeError ( \"Routing tables are not valid!\" ) # initiate stream if self . __logging : logger . debug ( \"Initiating Video Streaming.\" ) self . stream . start () # return Starlette application if self . __logging : logger . debug ( \"Running Starlette application.\" ) return Starlette ( debug = ( True if self . __logging else False ), routes = self . routes , exception_handlers = self . __exception_handlers , on_shutdown = [ self . shutdown ], )","title":"__call__()"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__init__","text":"This constructor method initializes the object state and attributes of the WebGear class. Parameters: Name Type Description Default enablePiCamera bool provide access to PiGear(if True) or CamGear(if False) APIs respectively. False stabilize bool enable access to Stabilizer Class for stabilizing frames. False camera_num int selects the camera module index which will be used as Rpi source. 0 resolution tuple sets the resolution (i.e. (width,height) ) of the Rpi source. (640, 480) framerate int/float sets the framerate of the Rpi source. 25 source based on input defines the source for the input stream. 0 stream_mode bool controls the exclusive YouTube Mode. False backend int selects the backend for OpenCV's VideoCapture class. 0 colorspace str selects the colorspace of the input stream. None logging bool enables/disables logging. False time_delay int time delay (in sec) before start reading the frames. 0 options dict provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. {} Source code in vidgear/gears/asyncio/webgear.py def __init__ ( self , enablePiCamera = False , stabilize = False , source = 0 , camera_num = 0 , stream_mode = False , backend = 0 , colorspace = None , resolution = ( 640 , 480 ), framerate = 25 , logging = False , time_delay = 0 , ** options ): \"\"\" This constructor method initializes the object state and attributes of the WebGear class. Parameters: enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively. stabilize (bool): enable access to Stabilizer Class for stabilizing frames. camera_num (int): selects the camera module index which will be used as Rpi source. resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source. framerate (int/float): sets the framerate of the Rpi source. source (based on input): defines the source for the input stream. stream_mode (bool): controls the exclusive YouTube Mode. backend (int): selects the backend for OpenCV's VideoCapture class. colorspace (str): selects the colorspace of the input stream. logging (bool): enables/disables logging. time_delay (int): time delay (in sec) before start reading the frames. options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear & Stabilizer. \"\"\" # initialize global params self . __jpeg_quality = 90 # 90% quality self . __jpeg_optimize = 0 # optimization off self . __jpeg_progressive = 0 # jpeg will be baseline instead self . __frame_size_reduction = 20 # 20% reduction self . __logging = logging custom_data_location = \"\" # path to save data-files to custom location data_path = \"\" # path to WebGear data-files overwrite_default = False # reformat dictionary options = { str ( k ) . strip (): v for k , v in options . items ()} # assign values to global variables if specified and valid if options : if \"frame_size_reduction\" in options : value = options [ \"frame_size_reduction\" ] if isinstance ( value , ( int , float )) and value >= 0 and value <= 90 : self . __frame_size_reduction = value else : logger . warning ( \"Skipped invalid `frame_size_reduction` value!\" ) del options [ \"frame_size_reduction\" ] # clean if \"frame_jpeg_quality\" in options : value = options [ \"frame_jpeg_quality\" ] if isinstance ( value , ( int , float )) and value >= 10 and value <= 95 : self . __jpeg_quality = int ( value ) else : logger . warning ( \"Skipped invalid `frame_jpeg_quality` value!\" ) del options [ \"frame_jpeg_quality\" ] # clean if \"frame_jpeg_optimize\" in options : value = options [ \"frame_jpeg_optimize\" ] if isinstance ( value , bool ): self . __jpeg_optimize = int ( value ) else : logger . warning ( \"Skipped invalid `frame_jpeg_optimize` value!\" ) del options [ \"frame_jpeg_optimize\" ] # clean if \"frame_jpeg_progressive\" in options : value = options [ \"frame_jpeg_progressive\" ] if isinstance ( value , bool ): self . __jpeg_progressive = int ( value ) else : logger . warning ( \"Skipped invalid `frame_jpeg_progressive` value!\" ) del options [ \"frame_jpeg_progressive\" ] # clean if \"custom_data_location\" in options : value = options [ \"custom_data_location\" ] if isinstance ( value , str ): assert os . access ( value , os . W_OK ), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to ' {} ' directory!\" . format ( value ) assert os . path . isdir ( os . path . abspath ( value ) ), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\" custom_data_location = os . path . abspath ( value ) else : logger . warning ( \"Skipped invalid `custom_data_location` value!\" ) del options [ \"custom_data_location\" ] # clean if \"overwrite_default_files\" in options : value = options [ \"overwrite_default_files\" ] if isinstance ( value , bool ): overwrite_default = value else : logger . warning ( \"Skipped invalid `overwrite_default_files` value!\" ) del options [ \"overwrite_default_files\" ] # clean # define stream with necessary params self . stream = VideoGear ( enablePiCamera = enablePiCamera , stabilize = stabilize , source = source , camera_num = camera_num , stream_mode = stream_mode , backend = backend , colorspace = colorspace , resolution = resolution , framerate = framerate , logging = logging , time_delay = time_delay , ** options ) # check if custom certificates path is specified if custom_data_location : data_path = generate_webdata ( custom_data_location , overwrite_default = overwrite_default , logging = logging , ) else : # otherwise generate suitable path from os.path import expanduser data_path = generate_webdata ( os . path . join ( expanduser ( \"~\" ), \".vidgear\" ), overwrite_default = overwrite_default , logging = logging , ) # log it if self . __logging : logger . debug ( \"` {} ` is the default location for saving WebGear data-files.\" . format ( data_path ) ) if self . __logging : logger . debug ( \"Setting params:: Size Reduction: {} %, JPEG quality: {} %, JPEG optimizations: {} , JPEG progressive: {} \" . format ( self . __frame_size_reduction , self . __jpeg_quality , bool ( self . __jpeg_optimize ), bool ( self . __jpeg_progressive ), ) ) # define Jinja2 templates handler self . __templates = Jinja2Templates ( directory = \" {} /templates\" . format ( data_path )) # define custom exception handlers self . __exception_handlers = { 404 : self . __not_found , 500 : self . __server_error } # define routing tables self . routes = [ Route ( \"/\" , endpoint = self . __homepage ), Route ( \"/video\" , endpoint = self . __video ), Mount ( \"/static\" , app = StaticFiles ( directory = \" {} /static\" . format ( data_path )), name = \"static\" , ), ] # copying original routing tables for further validation self . __rt_org_copy = self . routes [:] # keeps check if producer loop should be running self . __isrunning = True","title":"__init__()"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.shutdown","text":"Implements a Callable to be run on application shutdown Source code in vidgear/gears/asyncio/webgear.py def shutdown ( self ): \"\"\" Implements a Callable to be run on application shutdown \"\"\" if not ( self . stream is None ): if self . __logging : logger . debug ( \"Closing Video Streaming.\" ) # stops producer self . __isrunning = False # stops VideoGear stream self . stream . stop () # prevent any re-iteration self . stream = None","title":"shutdown()"},{"location":"bonus/reference/writegear/","text":"All WriteGear Class parameters: Compression Mode here\u27b6 and Non-Compression Mode here\u27b6 WriteGear API provides a complete, flexible and robust wrapper around FFmpeg , a leading multimedia framework. With WriteGear, we can process real-time frames into a lossless compressed video-file with any suitable specification in just few easy lines of codes. These specifications include setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, etc. , and also performing complex tasks such as multiplexing video with audio in real-time, while handling all errors robustly. Best of all, WriteGear grants the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function , without relying on any Third-party library. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API which provides some basic tools for video frames encoding but without compression. Modes of Operation WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. __init__ ( self , output_filename = '' , compression_mode = True , custom_ffmpeg = '' , logging = False , ** output_params ) special \u00b6 This constructor method initializes the object state and attributes of the WriteGear class. Parameters: Name Type Description Default output_filename str sets the valid filename/path/URL for the video output. '' compression_mode bool selects the WriteGear's Primary Mode of Operation. True custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executables. '' logging bool enables/disables logging. False output_params dict provides the flexibility to control supported internal parameters and properities. {} Source code in vidgear/gears/writegear.py def __init__ ( self , output_filename = \"\" , compression_mode = True , custom_ffmpeg = \"\" , logging = False , ** output_params ): \"\"\" This constructor method initializes the object state and attributes of the WriteGear class. Parameters: output_filename (str): sets the valid filename/path/URL for the video output. compression_mode (bool): selects the WriteGear's Primary Mode of Operation. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables. logging (bool): enables/disables logging. output_params (dict): provides the flexibility to control supported internal parameters and properities. \"\"\" # assign parameter values to class variables self . __compression = compression_mode self . __os_windows = ( True if os . name == \"nt\" else False ) # checks if machine in-use is running windows os or not # enable logging if specified self . __logging = False if logging : self . __logging = logging # initialize various important class variables self . __output_parameters = {} self . __inputheight = None self . __inputwidth = None self . __inputchannels = None self . __process = None # handle process to be frames written self . __cmd = \"\" # handle FFmpeg Pipe command self . __ffmpeg = \"\" # handle valid FFmpeg binaries location self . __initiate = ( True # initiate one time process for valid process initialization ) self . __out_file = None # handles output filename # handles output file name (if not given) if not output_filename : raise ValueError ( \"[WriteGear:ERROR] :: Kindly provide a valid `output_filename` value. Refer Docs for more information.\" ) else : # validate this class has the access rights to specified directory or not abs_path = os . path . abspath ( output_filename ) if ( self . __os_windows or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( abs_path ), os . W_OK ): if os . path . isdir ( abs_path ): # check if given path is directory abs_path = os . path . join ( abs_path , \"VidGear- {} .mp4\" . format ( time . strftime ( \"%Y%m %d -%H%M%S\" )), ) # auto-assign valid name and adds it to path # assign output file absolute path to class variable self . __out_file = abs_path else : # log warning if logger . warning ( \"The given path:` {} ` does not have write access permission. Skipped!\" . format ( output_filename ) ) # cleans and reformat output parameters self . __output_parameters = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( list , tuple , int , float )) else v for k , v in output_params . items () } # handles FFmpeg binaries validity tests if self . __compression : if self . __logging : logger . debug ( \"Compression Mode is enabled therefore checking for valid FFmpeg executables.\" ) logger . debug ( \"Output Parameters: {} \" . format ( self . __output_parameters )) # handles where to save the downloaded FFmpeg Static Binaries on Windows(if specified) __ffmpeg_download_path = self . __output_parameters . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , ( str )): # reset improper values __ffmpeg_download_path = \"\" # handle user defined output dimensions(must be a tuple or list) self . __output_dimensions = self . __output_parameters . pop ( \"-output_dimensions\" , None ) if not isinstance ( self . __output_dimensions , ( list , tuple )): # reset improper values self . __output_dimensions = None # handle user defined framerate self . __inputframerate = self . __output_parameters . pop ( \"-input_framerate\" , 0.0 ) if not isinstance ( self . __inputframerate , ( float , int )): # reset improper values self . __inputframerate = 0.0 else : # must be float self . __inputframerate = float ( self . __inputframerate ) # handle special-case force-termination in compression mode self . __force_termination = self . __output_parameters . pop ( \"-disable_force_termination\" , False ) if not isinstance ( self . __force_termination , bool ): # handle improper values self . __force_termination = ( True if ( \"-i\" in self . __output_parameters ) else False ) else : self . __force_termination = ( self . __force_termination if ( \"-i\" in self . __output_parameters ) else False ) # validate the FFmpeg path/binaries and returns valid FFmpeg file executable location (also downloads static binaries on windows) self . __ffmpeg = get_valid_ffmpeg_path ( custom_ffmpeg , self . __os_windows , ffmpeg_download_path = __ffmpeg_download_path , logging = self . __logging , ) # check if valid path returned if self . __ffmpeg : if self . __logging : logger . debug ( \"Found valid FFmpeg executables: ` {} `.\" . format ( self . __ffmpeg ) ) else : # otherwise disable Compression Mode logger . warning ( \"Disabling Compression Mode since no valid FFmpeg executables found on this machine!\" ) if self . __logging and not self . __os_windows : logger . debug ( \"Kindly install working FFmpeg or provide a valid custom FFmpeg binary path. See docs for more info.\" ) self . __compression = False # compression mode disabled # display confirmation if logging is enabled/disabled if self . __compression and self . __ffmpeg : # check whether is valid url instead if self . __out_file is None : if is_valid_url ( self . __ffmpeg , url = output_filename , logging = self . __logging ): if self . __logging : logger . debug ( \"URL:` {} ` is sucessfully configured for streaming.\" . format ( output_filename ) ) self . __out_file = output_filename else : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not valid/supported in Compression Mode!\" . format ( output_filename ) ) if self . __logging : logger . debug ( \"Compression Mode is configured properly!\" ) else : if self . __out_file is None : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not vaild in Non-Compression Mode!\" . format ( output_filename ) ) if self . __logging : logger . debug ( \"Compression Mode is disabled, Activating OpenCV built-in Writer!\" ) close ( self ) \u00b6 Safely terminates various WriteGear process. Source code in vidgear/gears/writegear.py def close ( self ): \"\"\" Safely terminates various WriteGear process. \"\"\" if self . __logging : logger . debug ( \"Terminating WriteGear Processes.\" ) if self . __compression : # if Compression Mode is enabled if self . __process is None or not ( self . __process . poll () is None ): return # no process was initiated at first place if self . __process . stdin : self . __process . stdin . close () # close `stdin` output if self . __force_termination : self . __process . terminate () self . __process . wait () # wait if still process is still processing some information self . __process = None else : # if Compression Mode is disabled if self . __process is None : return # no process was initiated at first place self . __process . release () # close it execute_ffmpeg_cmd ( self , cmd = None ) \u00b6 Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: Name Type Description Default cmd list inputs list data-type command. None Source code in vidgear/gears/writegear.py def execute_ffmpeg_cmd ( self , cmd = None ): \"\"\" Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: cmd (list): inputs list data-type command. \"\"\" # check if valid command if cmd is None or not ( cmd ): logger . warning ( \"Input FFmpeg command is empty, Nothing to execute!\" ) return else : if not ( isinstance ( cmd , list )): raise ValueError ( \"[WriteGear:ERROR] :: Invalid input FFmpeg command datatype! Kindly read docs.\" ) # check if Compression Mode is enabled if not ( self . __compression ): raise RuntimeError ( \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function!\" ) # add configured FFmpeg path cmd = [ self . __ffmpeg ] + cmd try : # write to pipeline if self . __logging : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode sp . run ( cmd , stdin = sp . PIPE , stdout = sp . PIPE , stderr = None ) else : sp . run ( cmd , stdin = sp . PIPE , stdout = sp . DEVNULL , stderr = sp . STDOUT ) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only write ( self , frame , rgb_mode = False ) \u00b6 Pipelines ndarray frames to respective API (FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode) . Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR) . False Source code in vidgear/gears/writegear.py def write ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to respective API _(FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode)_. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" if frame is None : # None-Type frames will be skipped return # get height, width and number of channels of current frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels if self . __logging : logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[WriteGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[WriteGear:ERROR] :: All frames must have same number of channels!\" ) if self . __compression : # checks if compression mode is enabled # initiate FFmpeg process on first run if self . __initiate : # start pre-processing and initiate process self . __Preprocess ( channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame try : self . __process . stdin . write ( frame . tostring ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only else : # otherwise initiate OpenCV's VideoWriter Class if self . __initiate : # start VideoWriter Class process self . __startCV_Process () # Check status of the process assert self . __process is not None if self . __logging : # log OpenCV warning logger . info ( \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet, switch to `compression_mode` to use them!\" ) # write the frame self . __process . write ( frame )","title":"WriteGear API"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.__init__","text":"This constructor method initializes the object state and attributes of the WriteGear class. Parameters: Name Type Description Default output_filename str sets the valid filename/path/URL for the video output. '' compression_mode bool selects the WriteGear's Primary Mode of Operation. True custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executables. '' logging bool enables/disables logging. False output_params dict provides the flexibility to control supported internal parameters and properities. {} Source code in vidgear/gears/writegear.py def __init__ ( self , output_filename = \"\" , compression_mode = True , custom_ffmpeg = \"\" , logging = False , ** output_params ): \"\"\" This constructor method initializes the object state and attributes of the WriteGear class. Parameters: output_filename (str): sets the valid filename/path/URL for the video output. compression_mode (bool): selects the WriteGear's Primary Mode of Operation. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables. logging (bool): enables/disables logging. output_params (dict): provides the flexibility to control supported internal parameters and properities. \"\"\" # assign parameter values to class variables self . __compression = compression_mode self . __os_windows = ( True if os . name == \"nt\" else False ) # checks if machine in-use is running windows os or not # enable logging if specified self . __logging = False if logging : self . __logging = logging # initialize various important class variables self . __output_parameters = {} self . __inputheight = None self . __inputwidth = None self . __inputchannels = None self . __process = None # handle process to be frames written self . __cmd = \"\" # handle FFmpeg Pipe command self . __ffmpeg = \"\" # handle valid FFmpeg binaries location self . __initiate = ( True # initiate one time process for valid process initialization ) self . __out_file = None # handles output filename # handles output file name (if not given) if not output_filename : raise ValueError ( \"[WriteGear:ERROR] :: Kindly provide a valid `output_filename` value. Refer Docs for more information.\" ) else : # validate this class has the access rights to specified directory or not abs_path = os . path . abspath ( output_filename ) if ( self . __os_windows or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( abs_path ), os . W_OK ): if os . path . isdir ( abs_path ): # check if given path is directory abs_path = os . path . join ( abs_path , \"VidGear- {} .mp4\" . format ( time . strftime ( \"%Y%m %d -%H%M%S\" )), ) # auto-assign valid name and adds it to path # assign output file absolute path to class variable self . __out_file = abs_path else : # log warning if logger . warning ( \"The given path:` {} ` does not have write access permission. Skipped!\" . format ( output_filename ) ) # cleans and reformat output parameters self . __output_parameters = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( list , tuple , int , float )) else v for k , v in output_params . items () } # handles FFmpeg binaries validity tests if self . __compression : if self . __logging : logger . debug ( \"Compression Mode is enabled therefore checking for valid FFmpeg executables.\" ) logger . debug ( \"Output Parameters: {} \" . format ( self . __output_parameters )) # handles where to save the downloaded FFmpeg Static Binaries on Windows(if specified) __ffmpeg_download_path = self . __output_parameters . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , ( str )): # reset improper values __ffmpeg_download_path = \"\" # handle user defined output dimensions(must be a tuple or list) self . __output_dimensions = self . __output_parameters . pop ( \"-output_dimensions\" , None ) if not isinstance ( self . __output_dimensions , ( list , tuple )): # reset improper values self . __output_dimensions = None # handle user defined framerate self . __inputframerate = self . __output_parameters . pop ( \"-input_framerate\" , 0.0 ) if not isinstance ( self . __inputframerate , ( float , int )): # reset improper values self . __inputframerate = 0.0 else : # must be float self . __inputframerate = float ( self . __inputframerate ) # handle special-case force-termination in compression mode self . __force_termination = self . __output_parameters . pop ( \"-disable_force_termination\" , False ) if not isinstance ( self . __force_termination , bool ): # handle improper values self . __force_termination = ( True if ( \"-i\" in self . __output_parameters ) else False ) else : self . __force_termination = ( self . __force_termination if ( \"-i\" in self . __output_parameters ) else False ) # validate the FFmpeg path/binaries and returns valid FFmpeg file executable location (also downloads static binaries on windows) self . __ffmpeg = get_valid_ffmpeg_path ( custom_ffmpeg , self . __os_windows , ffmpeg_download_path = __ffmpeg_download_path , logging = self . __logging , ) # check if valid path returned if self . __ffmpeg : if self . __logging : logger . debug ( \"Found valid FFmpeg executables: ` {} `.\" . format ( self . __ffmpeg ) ) else : # otherwise disable Compression Mode logger . warning ( \"Disabling Compression Mode since no valid FFmpeg executables found on this machine!\" ) if self . __logging and not self . __os_windows : logger . debug ( \"Kindly install working FFmpeg or provide a valid custom FFmpeg binary path. See docs for more info.\" ) self . __compression = False # compression mode disabled # display confirmation if logging is enabled/disabled if self . __compression and self . __ffmpeg : # check whether is valid url instead if self . __out_file is None : if is_valid_url ( self . __ffmpeg , url = output_filename , logging = self . __logging ): if self . __logging : logger . debug ( \"URL:` {} ` is sucessfully configured for streaming.\" . format ( output_filename ) ) self . __out_file = output_filename else : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not valid/supported in Compression Mode!\" . format ( output_filename ) ) if self . __logging : logger . debug ( \"Compression Mode is configured properly!\" ) else : if self . __out_file is None : raise ValueError ( \"[WriteGear:ERROR] :: output_filename value:` {} ` is not vaild in Non-Compression Mode!\" . format ( output_filename ) ) if self . __logging : logger . debug ( \"Compression Mode is disabled, Activating OpenCV built-in Writer!\" )","title":"__init__()"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.close","text":"Safely terminates various WriteGear process. Source code in vidgear/gears/writegear.py def close ( self ): \"\"\" Safely terminates various WriteGear process. \"\"\" if self . __logging : logger . debug ( \"Terminating WriteGear Processes.\" ) if self . __compression : # if Compression Mode is enabled if self . __process is None or not ( self . __process . poll () is None ): return # no process was initiated at first place if self . __process . stdin : self . __process . stdin . close () # close `stdin` output if self . __force_termination : self . __process . terminate () self . __process . wait () # wait if still process is still processing some information self . __process = None else : # if Compression Mode is disabled if self . __process is None : return # no process was initiated at first place self . __process . release () # close it","title":"close()"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.execute_ffmpeg_cmd","text":"Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: Name Type Description Default cmd list inputs list data-type command. None Source code in vidgear/gears/writegear.py def execute_ffmpeg_cmd ( self , cmd = None ): \"\"\" Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only). Parameters: cmd (list): inputs list data-type command. \"\"\" # check if valid command if cmd is None or not ( cmd ): logger . warning ( \"Input FFmpeg command is empty, Nothing to execute!\" ) return else : if not ( isinstance ( cmd , list )): raise ValueError ( \"[WriteGear:ERROR] :: Invalid input FFmpeg command datatype! Kindly read docs.\" ) # check if Compression Mode is enabled if not ( self . __compression ): raise RuntimeError ( \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function!\" ) # add configured FFmpeg path cmd = [ self . __ffmpeg ] + cmd try : # write to pipeline if self . __logging : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode sp . run ( cmd , stdin = sp . PIPE , stdout = sp . PIPE , stderr = None ) else : sp . run ( cmd , stdin = sp . PIPE , stdout = sp . DEVNULL , stderr = sp . STDOUT ) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only","title":"execute_ffmpeg_cmd()"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.write","text":"Pipelines ndarray frames to respective API (FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode) . Parameters: Name Type Description Default frame ndarray a valid numpy frame required rgb_mode boolean enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR) . False Source code in vidgear/gears/writegear.py def write ( self , frame , rgb_mode = False ): \"\"\" Pipelines `ndarray` frames to respective API _(FFmpeg in Compression Mode & OpenCV VideoWriter API in Non-Compression Mode)_. Parameters: frame (ndarray): a valid numpy frame rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_. \"\"\" if frame is None : # None-Type frames will be skipped return # get height, width and number of channels of current frame height , width = frame . shape [: 2 ] channels = frame . shape [ - 1 ] if frame . ndim == 3 else 1 # assign values to class variables on first run if self . __initiate : self . __inputheight = height self . __inputwidth = width self . __inputchannels = channels if self . __logging : logger . debug ( \"InputFrame => Height: {} Width: {} Channels: {} \" . format ( self . __inputheight , self . __inputwidth , self . __inputchannels ) ) # validate size of frame if height != self . __inputheight or width != self . __inputwidth : raise ValueError ( \"[WriteGear:ERROR] :: All frames must have same size!\" ) # validate number of channels if channels != self . __inputchannels : raise ValueError ( \"[WriteGear:ERROR] :: All frames must have same number of channels!\" ) if self . __compression : # checks if compression mode is enabled # initiate FFmpeg process on first run if self . __initiate : # start pre-processing and initiate process self . __Preprocess ( channels , rgb = rgb_mode ) # Check status of the process assert self . __process is not None # write the frame try : self . __process . stdin . write ( frame . tostring ()) except ( OSError , IOError ): # log something is wrong! logger . error ( \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\" ) raise ValueError # for testing purpose only else : # otherwise initiate OpenCV's VideoWriter Class if self . __initiate : # start VideoWriter Class process self . __startCV_Process () # Check status of the process assert self . __process is not None if self . __logging : # log OpenCV warning logger . info ( \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet, switch to `compression_mode` to use them!\" ) # write the frame self . __process . write ( frame )","title":"write()"},{"location":"contribution/PR/","text":"Submitting Pull Request(PR) Guidelines: \u00b6 The following guidelines tells you how to submit a valid PR for vidGear: Working on your first Pull Request for VidGear? If you don't know how to contribute to an Open Source Project on GitHub, then You can learn about it from here \u27b6 If you're stuck at something, please join our Gitter community channel . We will help you get started! Kindly follow the EXEMPLARY tag for some finest PR examples. Clone Testing branch \u00b6 All changes MUST be pushed against VidGear's testing branch only for triggering CI testing. If it is not, then rebase it \u27b6 Make sure the testing branch of your Forked repository is up-to-date with VidGear, before starting working on Pull Request. You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest testing branch as follows: VidGear's Github Branches Following are the base branches for VidGear's code in its Github Repository: Master/Main Branch Features: Most-Stable Includes the latest stable-release. Lacks any latest bug-fixes and changes. Everything CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear Testing Branch Features: Stable. Includes latest stable bug-fixes and changes. Used for pushing PR commits. Everything CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing Development Branch Features: Unstable. Includes latest experimental changes. Used for pushing experimental commits. Nothing CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest development branch git checkout development Workflow: Typically any feature/improvement/bug-fix code flows as follows: # clone your forked repository(change with your username) and get inside git clone https://github.com/ { YOUR USERNAME } /vidgear.git && cd vidgear # pull any recent updates git pull # checkout the latest testing branch git checkout testing # Now create your new branch with suitable name(such as \"subbranch_of_testing\") git checkout -b subbranch_of_testing Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual. PR Submission Checklist \u00b6 There are some important checks you need to perform while submitting your Pull Request(s) for VidGear library: Submit a Related Issue: The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request. Submit a Draft Pull Request: Submit the draft pull request from the first day of your development. Add a brief but descriptive title for your PR. Explain what the PR adds, fixes, or improves. In case of bug fixes, add a new unit test case that would fail against your bug fix. Provide output or screenshots, if you can. Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against testing branch) . If it's somehow failing, then ask the maintainer for a review. Click \"ready for review\" when finished. Test, Format & lint code locally: Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6 Make sensible commit messages: If your pull request fixes a separate issue number, remember to include \"resolves #issue_number\" in the commit message. Learn more about it here \u27b6 . Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with git commit --amend command. Perform Integrity Checks: Any duplicate pull request will be Rejected! Search GitHub if there's a similar open or closed PR that relates to your submission. Check if your purpose code matches the overall direction, simplicity, and structure of the VidGear and improves it. Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6 . Link your Issues: For more information on Linking a pull request to an issue, See this wiki doc\u27b6 Finally, when you're confident enough, make your pull request public. You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue. Testing, Formatting & Linting \u00b6 All Pull Request(s) must be tested, formatted & linted against our library standards as discussed below: Requirements \u00b6 Testing VidGear requires additional test dependencies and dataset, which can be handled manually as follows: Install additional python libraries: You can easily install these dependencies via pip: Note for Windows The mpegdash library has not yet been updated and bugs on windows machines. Kindly instead try the forked DEV-version of mpegdash as follows: python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev/mpegdash-0.3.0.dev0-py3-none-any.whl pip install --upgrade six, flake8, black, pytest, pytest-asyncio, mpegdash Download Tests Dataset: To perform tests, you also need to download additional dataset (to your temp dir) by running prepare_dataset.sh bash script as follows: chmod +x scripts/bash/prepare_dataset.sh # On linux and MacOS .scripts/bash/prepare_dataset.sh # On Windows sh scripts/bash/prepare_dataset.sh Running Tests \u00b6 All tests can be run with pytest ( in VidGear's root folder ) as follows: pytest -sv #-sv for verbose output. Formatting & Linting \u00b6 For formatting and linting, following libraries are used: Flake8: You must run flake8 linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity: flake8 . --count --select = E9,F63,F7,F82 --show-source --statistics Black: Vidgear follows black formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: black { source_file_or_directory } Frequently Asked Questions \u00b6 Q1. Why do my changes taking so long to be Reviewed and/or Merged? Submission Aftermaths After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository. The changes will remain in testing branch until next VidGear version is released, then it will be merged into master branch. After a successful Merge, your newer contributions will be given priority over others. Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request. Q2. Would you accept a huge Pull Request with Lots of Changes? First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the VidGear Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!","title":"Submitting Pull Request(PR) Guidelines"},{"location":"contribution/PR/#submitting-pull-requestpr-guidelines","text":"The following guidelines tells you how to submit a valid PR for vidGear: Working on your first Pull Request for VidGear? If you don't know how to contribute to an Open Source Project on GitHub, then You can learn about it from here \u27b6 If you're stuck at something, please join our Gitter community channel . We will help you get started! Kindly follow the EXEMPLARY tag for some finest PR examples.","title":"Submitting Pull Request(PR) Guidelines:"},{"location":"contribution/PR/#clone-testing-branch","text":"All changes MUST be pushed against VidGear's testing branch only for triggering CI testing. If it is not, then rebase it \u27b6 Make sure the testing branch of your Forked repository is up-to-date with VidGear, before starting working on Pull Request. You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest testing branch as follows: VidGear's Github Branches Following are the base branches for VidGear's code in its Github Repository: Master/Main Branch Features: Most-Stable Includes the latest stable-release. Lacks any latest bug-fixes and changes. Everything CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear Testing Branch Features: Stable. Includes latest stable bug-fixes and changes. Used for pushing PR commits. Everything CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing Development Branch Features: Unstable. Includes latest experimental changes. Used for pushing experimental commits. Nothing CI tested. Cloning: # clone your forked repository and `cd` inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest development branch git checkout development Workflow: Typically any feature/improvement/bug-fix code flows as follows: # clone your forked repository(change with your username) and get inside git clone https://github.com/ { YOUR USERNAME } /vidgear.git && cd vidgear # pull any recent updates git pull # checkout the latest testing branch git checkout testing # Now create your new branch with suitable name(such as \"subbranch_of_testing\") git checkout -b subbranch_of_testing Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual.","title":"Clone Testing branch"},{"location":"contribution/PR/#pr-submission-checklist","text":"There are some important checks you need to perform while submitting your Pull Request(s) for VidGear library: Submit a Related Issue: The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request. Submit a Draft Pull Request: Submit the draft pull request from the first day of your development. Add a brief but descriptive title for your PR. Explain what the PR adds, fixes, or improves. In case of bug fixes, add a new unit test case that would fail against your bug fix. Provide output or screenshots, if you can. Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against testing branch) . If it's somehow failing, then ask the maintainer for a review. Click \"ready for review\" when finished. Test, Format & lint code locally: Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6 Make sensible commit messages: If your pull request fixes a separate issue number, remember to include \"resolves #issue_number\" in the commit message. Learn more about it here \u27b6 . Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with git commit --amend command. Perform Integrity Checks: Any duplicate pull request will be Rejected! Search GitHub if there's a similar open or closed PR that relates to your submission. Check if your purpose code matches the overall direction, simplicity, and structure of the VidGear and improves it. Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6 . Link your Issues: For more information on Linking a pull request to an issue, See this wiki doc\u27b6 Finally, when you're confident enough, make your pull request public. You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue.","title":"PR Submission Checklist"},{"location":"contribution/PR/#testing-formatting-linting","text":"All Pull Request(s) must be tested, formatted & linted against our library standards as discussed below:","title":"Testing, Formatting &amp; Linting"},{"location":"contribution/PR/#requirements","text":"Testing VidGear requires additional test dependencies and dataset, which can be handled manually as follows: Install additional python libraries: You can easily install these dependencies via pip: Note for Windows The mpegdash library has not yet been updated and bugs on windows machines. Kindly instead try the forked DEV-version of mpegdash as follows: python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev/mpegdash-0.3.0.dev0-py3-none-any.whl pip install --upgrade six, flake8, black, pytest, pytest-asyncio, mpegdash Download Tests Dataset: To perform tests, you also need to download additional dataset (to your temp dir) by running prepare_dataset.sh bash script as follows: chmod +x scripts/bash/prepare_dataset.sh # On linux and MacOS .scripts/bash/prepare_dataset.sh # On Windows sh scripts/bash/prepare_dataset.sh","title":"Requirements"},{"location":"contribution/PR/#running-tests","text":"All tests can be run with pytest ( in VidGear's root folder ) as follows: pytest -sv #-sv for verbose output.","title":"Running Tests"},{"location":"contribution/PR/#formatting-linting","text":"For formatting and linting, following libraries are used: Flake8: You must run flake8 linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity: flake8 . --count --select = E9,F63,F7,F82 --show-source --statistics Black: Vidgear follows black formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: black { source_file_or_directory }","title":"Formatting &amp; Linting"},{"location":"contribution/PR/#frequently-asked-questions","text":"Q1. Why do my changes taking so long to be Reviewed and/or Merged? Submission Aftermaths After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository. The changes will remain in testing branch until next VidGear version is released, then it will be merged into master branch. After a successful Merge, your newer contributions will be given priority over others. Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request. Q2. Would you accept a huge Pull Request with Lots of Changes? First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the VidGear Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!","title":"Frequently Asked Questions"},{"location":"contribution/issue/","text":"Submitting an Issue Guidelines \u00b6 If you've found a new bug or you've come up with some new feature which can improve the quality of the VidGear, then related issues are welcomed! But, Before you do, please read the following guidelines: First Issue on GitHub? You can easily learn about it from creating an issue wiki. Info Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon. Search the Docs and Previous Issues \u00b6 Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel. Also, go comprehensively through our dedicated FAQ & Troubleshooting section . Gather Required Information \u00b6 All VidGear APIs provides a logging boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter True in the respective API for getting debug output, and paste it with your Issue. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. Check and paste, exact VidGear version by running command python -c \"import vidgear; print(vidgear.__version__)\" . Follow the Issue Template \u00b6 Please stick to the issue template. Any improper/insufficient reports will be marked with MISSING : INFORMATION and MISSING : TEMPLATE like labels, and if we don't hear back from you we may close the issue. Raise the Issue \u00b6 Add a brief but descriptive title for your issue. Keep the issue phrasing in context of the problem. Attach source-code/screenshots if you have one. Finally, raise it by choosing the appropriate Issue Template: Bug report , Proposal , Question .","title":"Submitting an Issue Guidelines"},{"location":"contribution/issue/#submitting-an-issue-guidelines","text":"If you've found a new bug or you've come up with some new feature which can improve the quality of the VidGear, then related issues are welcomed! But, Before you do, please read the following guidelines: First Issue on GitHub? You can easily learn about it from creating an issue wiki. Info Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon.","title":"Submitting an Issue Guidelines"},{"location":"contribution/issue/#search-the-docs-and-previous-issues","text":"Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel. Also, go comprehensively through our dedicated FAQ & Troubleshooting section .","title":"Search the Docs and Previous Issues"},{"location":"contribution/issue/#gather-required-information","text":"All VidGear APIs provides a logging boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter True in the respective API for getting debug output, and paste it with your Issue. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. Check and paste, exact VidGear version by running command python -c \"import vidgear; print(vidgear.__version__)\" .","title":"Gather Required Information"},{"location":"contribution/issue/#follow-the-issue-template","text":"Please stick to the issue template. Any improper/insufficient reports will be marked with MISSING : INFORMATION and MISSING : TEMPLATE like labels, and if we don't hear back from you we may close the issue.","title":"Follow the Issue Template"},{"location":"contribution/issue/#raise-the-issue","text":"Add a brief but descriptive title for your issue. Keep the issue phrasing in context of the problem. Attach source-code/screenshots if you have one. Finally, raise it by choosing the appropriate Issue Template: Bug report , Proposal , Question .","title":"Raise the Issue"},{"location":"gears/camgear/overview/","text":"CamGear API \u00b6 CamGear API's generalized workflow Overview \u00b6 CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports Gstreamer's RAW pipelines and various live video streaming sites like YouTube, Twitch, Dailymotion etc. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters . It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. CamGear internally employs streamlink for piping live videos from various streaming services like Twitch , Livestream , Dailymotion etc., and also utilizies pafy with youtube-dl at its backend for seamless YouTube pipelining . \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. You can use framerate class variable to retrieve framerate of the input source. Its usage example can be found here \u27b6 \u2009 Importing \u00b6 You can import CamGear API in your program as follows: from vidgear.gears import CamGear \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/camgear/overview/#camgear-api","text":"CamGear API's generalized workflow","title":"CamGear API"},{"location":"gears/camgear/overview/#overview","text":"CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format ( upto 4k tested ), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports Gstreamer's RAW pipelines and various live video streaming sites like YouTube, Twitch, Dailymotion etc. CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters . It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling. CamGear internally employs streamlink for piping live videos from various streaming services like Twitch , Livestream , Dailymotion etc., and also utilizies pafy with youtube-dl at its backend for seamless YouTube pipelining . \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. You can use framerate class variable to retrieve framerate of the input source. Its usage example can be found here \u27b6","title":"Overview"},{"location":"gears/camgear/overview/#importing","text":"You can import CamGear API in your program as follows: from vidgear.gears import CamGear","title":"Importing"},{"location":"gears/camgear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/camgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/camgear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/camgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/camgear/params/","text":"CamGear API Parameters \u00b6 source \u00b6 CamGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: CamGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: CamGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Youtube URLs: CamGear utilizes pafy with youtube-dl backend. For example \"https://youtu.be/bvetuLwJIkA\" as follows: Valid YouTube URL formats All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} CamGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Streaming Websites URLs: CamGear utilizes streamlink backend. For example \"https://www.dailymotion.com/video/x7xsoud\" as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.dailymotion.com/video/x7xsoud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: CamGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: CamGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u00b6 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . CamGear automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! CamGear will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . colorspace \u00b6 This parameter selects the colorspace of the input stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 backend \u00b6 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . To workaround a FFmpeg bug , CamGear automatically enforce GStreamer backend( backend=cv2.CAP_GSTREAMER ) for YouTube-livestreams in Stream Mode . This behavior discards any backend parameter value for those streams. Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: CamGear ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u00b6 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to CamGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it CamGear ( source = 0 , ** options ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 0 , logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the CamGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: CamGear ( source = 0 , time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/camgear/params/#camgear-api-parameters","text":"","title":"CamGear API Parameters"},{"location":"gears/camgear/params/#source","text":"CamGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: CamGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: CamGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) CamGear automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Youtube URLs: CamGear utilizes pafy with youtube-dl backend. For example \"https://youtu.be/bvetuLwJIkA\" as follows: Valid YouTube URL formats All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} CamGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Streaming Websites URLs: CamGear utilizes streamlink backend. For example \"https://www.dailymotion.com/video/x7xsoud\" as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 CamGear ( source = 'https://www.dailymotion.com/video/x7xsoud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: CamGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: CamGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/camgear/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the CamGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . CamGear automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! CamGear will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/camgear/params/#colorspace","text":"This parameter selects the colorspace of the input stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/camgear/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . To workaround a FFmpeg bug , CamGear automatically enforce GStreamer backend( backend=cv2.CAP_GSTREAMER ) for YouTube-livestreams in Stream Mode . This behavior discards any backend parameter value for those streams. Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: CamGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/camgear/params/#options","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to CamGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it CamGear ( source = 0 , ** options )","title":"options"},{"location":"gears/camgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: CamGear ( source = 0 , logging = True )","title":"logging"},{"location":"gears/camgear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the CamGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: CamGear ( source = 0 , time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/camgear/usage/","text":"CamGear API Usage Examples: \u00b6 \u2009 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with CamGear API: # import required libraries from vidgear.gears import CamGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Camgear with Streaming Websites \u00b6 CamGear API provides direct support for piping video streams from various big streaming services like Twitch , Livestream , Dailymotion , and many more \u27b6 . All you have to do is to provide the desired Video's URL to its source parameter, and enable the stream_mode parameter. The complete usage example is as follows: To workaround a FFmpeg bug that causes video to freeze frequently, You must always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for Livestreams (such as Twitch URLs) . Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support. CamGear also provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(streamlink) parameters) with its option dictionary parameter. More information can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # set desired quality as 720p options = { \"STREAM_RESOLUTION\" : \"720p\" } # Add any desire Video URL as input source # for e.g https://www.dailymotion.com/video/x7xsoud # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://www.dailymotion.com/video/x7xsoud\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Camgear with Youtube Videos \u00b6 CamGear API provides direct support for Live (with GStreamer) + Normal YouTube Video frames pipelining . All you have to do is to provide the desired YouTube Video's URL to its source parameter and enable the stream_mode parameter. The complete usage example is as follows: To workaround a FFmpeg bug , CamGear automatically enforces GStreamer backend for YouTube-livestreams! Checkout this FAQ for compiling OpenCV with GStreamer support. CamGear also provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(youtube-dl) parameters) with its option dictionary parameter. More information can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # Add YouTube Video URL as input source (for e.g https://youtu.be/bvetuLwJIkA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/bvetuLwJIkA\" , stream_mode = True , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using CamGear with Variable Camera Properties \u00b6 CamGear API also flexibly support various Source Tweak Parameters available within OpenCV's VideoCapture API . These tweak parameters can be used to manipulate input source Camera-Device properties (such as its brightness, saturation, size, iso, gain etc.) seamlessly, and can be easily applied in CamGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All the supported Source Tweak Parameters can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 , } # To open live video stream on webcam at first index(i.e. 0) # device and apply source tweak parameters stream = CamGear ( source = 0 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using Camgear with Direct Colorspace Manipulation \u00b6 CamGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import CamGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) # and change its colorspace to `HSV` stream = CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Usage Examples"},{"location":"gears/camgear/usage/#camgear-api-usage-examples","text":"","title":"CamGear API Usage Examples:"},{"location":"gears/camgear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with CamGear API: # import required libraries from vidgear.gears import CamGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/camgear/usage/#using-camgear-with-streaming-websites","text":"CamGear API provides direct support for piping video streams from various big streaming services like Twitch , Livestream , Dailymotion , and many more \u27b6 . All you have to do is to provide the desired Video's URL to its source parameter, and enable the stream_mode parameter. The complete usage example is as follows: To workaround a FFmpeg bug that causes video to freeze frequently, You must always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for Livestreams (such as Twitch URLs) . Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support. CamGear also provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(streamlink) parameters) with its option dictionary parameter. More information can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # set desired quality as 720p options = { \"STREAM_RESOLUTION\" : \"720p\" } # Add any desire Video URL as input source # for e.g https://www.dailymotion.com/video/x7xsoud # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://www.dailymotion.com/video/x7xsoud\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Camgear with Streaming Websites"},{"location":"gears/camgear/usage/#using-camgear-with-youtube-videos","text":"CamGear API provides direct support for Live (with GStreamer) + Normal YouTube Video frames pipelining . All you have to do is to provide the desired YouTube Video's URL to its source parameter and enable the stream_mode parameter. The complete usage example is as follows: To workaround a FFmpeg bug , CamGear automatically enforces GStreamer backend for YouTube-livestreams! Checkout this FAQ for compiling OpenCV with GStreamer support. CamGear also provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(youtube-dl) parameters) with its option dictionary parameter. More information can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # Add YouTube Video URL as input source (for e.g https://youtu.be/bvetuLwJIkA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/bvetuLwJIkA\" , stream_mode = True , logging = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Camgear with Youtube Videos"},{"location":"gears/camgear/usage/#using-camgear-with-variable-camera-properties","text":"CamGear API also flexibly support various Source Tweak Parameters available within OpenCV's VideoCapture API . These tweak parameters can be used to manipulate input source Camera-Device properties (such as its brightness, saturation, size, iso, gain etc.) seamlessly, and can be easily applied in CamGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All the supported Source Tweak Parameters can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # define suitable tweak parameters for your stream. options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 , } # To open live video stream on webcam at first index(i.e. 0) # device and apply source tweak parameters stream = CamGear ( source = 0 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using CamGear with Variable Camera Properties"},{"location":"gears/camgear/usage/#using-camgear-with-direct-colorspace-manipulation","text":"CamGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import CamGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) # and change its colorspace to `HSV` stream = CamGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using Camgear with Direct Colorspace Manipulation"},{"location":"gears/camgear/advanced/source_params/","text":"Source Tweak Parameters for CamGear API \u00b6 Overview \u00b6 The option dictionary parameter in CamGear, gives user the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture Class . These tweak parameters can be used to manipulate input source Camera-Device properties (such as its brightness, saturation, size, iso, gain etc.) seamlessly. Thereby, All Source Tweak Parameters supported by CamGear API are disscussed in this document. \u2003 Exclusive CamGear Parameters \u00b6 In addition to Source Tweak Parameters, CamGear also provides some exclusive attributes for its option dictionary parameters. These attributes are as follows: STREAM_RESOLUTION (string) : This attribute can be used in CamGear's Stream Mode ( stream_mode=True ) for specifying supported stream resolution. Its possible values can be: 144p , 240p , 360p , 480p , 720p , 1080p , 1440p , 2160p , worst , best , and its default value is best . Its usage is as follows: In case specificed STREAM_RESOLUTION value is unavailable within Source Stream, it defaults to best ! options = { \"STREAM_RESOLUTION\" : \"720p\" } # 720p stream will be used. Its complete usage example is given here \u27b6 STREAM_PARAMS (dict) : This dictionary attribute can be used in CamGear's Stream Mode ( stream_mode=True ) for specifying underlying API(e.g. youtube-dl ) parameters. Its usage is as follows: All supported parameters for Youtube-DL can be found here \u27b6 options = { \"STREAM_PARAMS\" : { \"nocheckcertificate\" : True }} # disables verifying SSL certificates in Youtube-DL Its complete usage example is given here \u27b6 THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode to manually disable it: Disabling Threaded-Queue-Mode can be dangerous! Read more here \u27b6 options = { \"THREADED_QUEUE_MODE\" : False } # disable Threaded Queue Mode. Supported Source Tweak Parameters \u00b6 All Source Tweak Parameters supported by CamGear API are as follows: Remember, Not all parameters are supported by all cameras devices, which is one of the most troublesome thing with OpenCV library. Each camera type, from android cameras, to USB cameras , to professional ones, offers a different interface to modify its parameters. Therefore, there are many branches in OpenCV code to support as many of them, but of course, not all possible devices are covered, and thereby works. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . You can easily check parameter values supported by your webcam, by hooking it to a Linux machine, and using the command v4l2-ctl -d 0 --list-formats-ext (where 0 is an index of the given camera) to list the supported video parameters and their values. If that doesn't works, refer to its datasheet (if available) . These parameters can be passed to CamGear's option dictionary parameter by formatting them as its string attributes. Its complete usage example is here \u27b6 \u2009 Values Description CAP_PROP_POS_MSEC Current position of the video file in milliseconds. CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0=start of the film, 1=end of the film. CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CAP_PROP_FPS Frame rate. CAP_PROP_FOURCC 4-character code of codec. see VideoWriter::fourcc . CAP_PROP_FRAME_COUNT Number of frames in the video file. CAP_PROP_FORMAT Format of the Mat objects returned by VideoCapture::retrieve() . CAP_PROP_MODE Backend-specific value indicating the current capture mode. CAP_PROP_BRIGHTNESS Brightness of the image (only for those cameras that support). CAP_PROP_CONTRAST Contrast of the image (only for cameras). CAP_PROP_SATURATION Saturation of the image (only for cameras). CAP_PROP_HUE Hue of the image (only for cameras). CAP_PROP_GAIN Gain of the image (only for those cameras that support). CAP_PROP_EXPOSURE Exposure (only for those cameras that support). CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CAP_PROP_WHITE_BALANCE_BLUE_U Currently unsupported. CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently). CAP_PROP_MONOCHROME CAP_PROP_SHARPNESS CAP_PROP_AUTO_EXPOSURE DC1394: exposure control done by camera, user can adjust reference level using this feature. CAP_PROP_GAMMA CAP_PROP_TEMPERATURE CAP_PROP_TRIGGER CAP_PROP_TRIGGER_DELAY CAP_PROP_WHITE_BALANCE_RED_V CAP_PROP_ZOOM CAP_PROP_FOCUS CAP_PROP_GUID CAP_PROP_ISO_SPEED CAP_PROP_BACKLIGHT CAP_PROP_PAN CAP_PROP_TILT CAP_PROP_ROLL CAP_PROP_IRIS CAP_PROP_SETTINGS Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored) CAP_PROP_BUFFERSIZE CAP_PROP_AUTOFOCUS CAP_PROP_SAR_NUM Sample aspect ratio: num/den (num) CAP_PROP_SAR_DEN Sample aspect ratio: num/den (den) CAP_PROP_BACKEND Current backend (enum VideoCapture APIs). Read-only property. CAP_PROP_CHANNEL Video input or Channel Number (only for those cameras that support) CAP_PROP_AUTO_WB enable/ disable auto white-balance CAP_PROP_WB_TEMPERATURE white-balance color temperature","title":"Source Tweak Parameters"},{"location":"gears/camgear/advanced/source_params/#source-tweak-parameters-for-camgear-api","text":"","title":"Source Tweak Parameters for CamGear API"},{"location":"gears/camgear/advanced/source_params/#overview","text":"The option dictionary parameter in CamGear, gives user the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture Class . These tweak parameters can be used to manipulate input source Camera-Device properties (such as its brightness, saturation, size, iso, gain etc.) seamlessly. Thereby, All Source Tweak Parameters supported by CamGear API are disscussed in this document.","title":"Overview"},{"location":"gears/camgear/advanced/source_params/#exclusive-camgear-parameters","text":"In addition to Source Tweak Parameters, CamGear also provides some exclusive attributes for its option dictionary parameters. These attributes are as follows: STREAM_RESOLUTION (string) : This attribute can be used in CamGear's Stream Mode ( stream_mode=True ) for specifying supported stream resolution. Its possible values can be: 144p , 240p , 360p , 480p , 720p , 1080p , 1440p , 2160p , worst , best , and its default value is best . Its usage is as follows: In case specificed STREAM_RESOLUTION value is unavailable within Source Stream, it defaults to best ! options = { \"STREAM_RESOLUTION\" : \"720p\" } # 720p stream will be used. Its complete usage example is given here \u27b6 STREAM_PARAMS (dict) : This dictionary attribute can be used in CamGear's Stream Mode ( stream_mode=True ) for specifying underlying API(e.g. youtube-dl ) parameters. Its usage is as follows: All supported parameters for Youtube-DL can be found here \u27b6 options = { \"STREAM_PARAMS\" : { \"nocheckcertificate\" : True }} # disables verifying SSL certificates in Youtube-DL Its complete usage example is given here \u27b6 THREADED_QUEUE_MODE (boolean) : This attribute can be used to override Threaded-Queue-Mode mode to manually disable it: Disabling Threaded-Queue-Mode can be dangerous! Read more here \u27b6 options = { \"THREADED_QUEUE_MODE\" : False } # disable Threaded Queue Mode.","title":"Exclusive CamGear Parameters"},{"location":"gears/camgear/advanced/source_params/#supported-source-tweak-parameters","text":"All Source Tweak Parameters supported by CamGear API are as follows: Remember, Not all parameters are supported by all cameras devices, which is one of the most troublesome thing with OpenCV library. Each camera type, from android cameras, to USB cameras , to professional ones, offers a different interface to modify its parameters. Therefore, there are many branches in OpenCV code to support as many of them, but of course, not all possible devices are covered, and thereby works. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . You can easily check parameter values supported by your webcam, by hooking it to a Linux machine, and using the command v4l2-ctl -d 0 --list-formats-ext (where 0 is an index of the given camera) to list the supported video parameters and their values. If that doesn't works, refer to its datasheet (if available) . These parameters can be passed to CamGear's option dictionary parameter by formatting them as its string attributes. Its complete usage example is here \u27b6 \u2009 Values Description CAP_PROP_POS_MSEC Current position of the video file in milliseconds. CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0=start of the film, 1=end of the film. CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CAP_PROP_FPS Frame rate. CAP_PROP_FOURCC 4-character code of codec. see VideoWriter::fourcc . CAP_PROP_FRAME_COUNT Number of frames in the video file. CAP_PROP_FORMAT Format of the Mat objects returned by VideoCapture::retrieve() . CAP_PROP_MODE Backend-specific value indicating the current capture mode. CAP_PROP_BRIGHTNESS Brightness of the image (only for those cameras that support). CAP_PROP_CONTRAST Contrast of the image (only for cameras). CAP_PROP_SATURATION Saturation of the image (only for cameras). CAP_PROP_HUE Hue of the image (only for cameras). CAP_PROP_GAIN Gain of the image (only for those cameras that support). CAP_PROP_EXPOSURE Exposure (only for those cameras that support). CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CAP_PROP_WHITE_BALANCE_BLUE_U Currently unsupported. CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently). CAP_PROP_MONOCHROME CAP_PROP_SHARPNESS CAP_PROP_AUTO_EXPOSURE DC1394: exposure control done by camera, user can adjust reference level using this feature. CAP_PROP_GAMMA CAP_PROP_TEMPERATURE CAP_PROP_TRIGGER CAP_PROP_TRIGGER_DELAY CAP_PROP_WHITE_BALANCE_RED_V CAP_PROP_ZOOM CAP_PROP_FOCUS CAP_PROP_GUID CAP_PROP_ISO_SPEED CAP_PROP_BACKLIGHT CAP_PROP_PAN CAP_PROP_TILT CAP_PROP_ROLL CAP_PROP_IRIS CAP_PROP_SETTINGS Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored) CAP_PROP_BUFFERSIZE CAP_PROP_AUTOFOCUS CAP_PROP_SAR_NUM Sample aspect ratio: num/den (num) CAP_PROP_SAR_DEN Sample aspect ratio: num/den (den) CAP_PROP_BACKEND Current backend (enum VideoCapture APIs). Read-only property. CAP_PROP_CHANNEL Video input or Channel Number (only for those cameras that support) CAP_PROP_AUTO_WB enable/ disable auto white-balance CAP_PROP_WB_TEMPERATURE white-balance color temperature","title":"Supported Source Tweak Parameters"},{"location":"gears/netgear/overview/","text":"NetGear API \u00b6 NetGear API generalized Overview \u00b6 NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. Lazy Pirate pattern in NetGear API NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns( zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Netgear API also provides max_retries and request_timeout like attributes for controlling this polling. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc . \u2009 Modes of Operation \u00b6 Primary Modes \u00b6 NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Activate this mode by setting parameter receive_mode = True . Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. Activate this mode by setting parameter receive_mode = True . Exclusive Modes \u00b6 In addition to the primary modes, NetGear API also offers applications-specific Exclusive Modes: Also, check this compatibility chart for these modes interoperability. Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Each new Server on the network can be identified on the client's end by using its unique port address. Also, it exhibits a feature where if all the connected servers on the network get disconnected, the client itself automatically exits to save resources. You can learn about this mode here \u27b6 . Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Each Client on the network can be uniquely identified on the Server's end by using its unique port address. This mode is ideal for applications, where broadcasting/streaming video-frames & data from a single broadcaster to multiple connected users is required. You can learn about this mode here \u27b6 . Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames . Using this mode, the user can now send or receive any data(of any datatype) between Server and Client easily in real-time. You can learn more about this mode here \u27b6 . Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. You can learn more about this mode here \u27b6 . \u2009 Important Information When compiling/installing pyzmq with pip on Linux, it is generally recommended that zeromq binaries to be installed separately, via homebrew, apt, yum, etc. as follows: # Debian-based sudo apt-get install libzmq3-dev # RHEL-based sudo yum install libzmq3-devel # OSX-based brew install zeromq If zeromq binaries are not found, pyzmq will try to build libzmq as a Python Extension, though this is not guaranteed to work! It is advised to enable logging ( logging = True ) on the first run, to easily identify any runtime errors. Kindly go through each given Usage Examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using send() function in Receive Mode) , will result in ValueError . \u2009 Importing \u00b6 You can import NetGear API in your program as follows: from vidgear.gears import NetGear Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/netgear/overview/#netgear-api","text":"NetGear API generalized","title":"NetGear API"},{"location":"gears/netgear/overview/#overview","text":"NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time. NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time. Lazy Pirate pattern in NetGear API NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns( zmq.PAIR & zmq.REQ/zmq.REP ) at both Server and Client ends, where its API instead of doing a blocking receive, will: Poll the socket and receive from it only when it's sure a reply has arrived. Attempt to reconnect, if no reply has arrived within a timeout period. Abandon the connection if there is still no reply after several requests. Netgear API also provides max_retries and request_timeout like attributes for controlling this polling. NetGear as of now seamlessly supports three ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) whereas the supported protocol are: tcp and ipc .","title":"Overview"},{"location":"gears/netgear/overview/#modes-of-operation","text":"","title":"Modes of Operation"},{"location":"gears/netgear/overview/#primary-modes","text":"NetGear API primarily has two modes of operations: Send Mode: which employs send() function to send video frames over the network in real-time. Activate this mode by setting parameter receive_mode = True . Receive Mode: which employs recv() function to receive frames, sent over the network with Send Mode in real-time. Activate this mode by setting parameter receive_mode = True .","title":"Primary Modes"},{"location":"gears/netgear/overview/#exclusive-modes","text":"In addition to the primary modes, NetGear API also offers applications-specific Exclusive Modes: Also, check this compatibility chart for these modes interoperability. Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once , thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. Each new Server on the network can be identified on the client's end by using its unique port address. Also, it exhibits a feature where if all the connected servers on the network get disconnected, the client itself automatically exits to save resources. You can learn about this mode here \u27b6 . Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once , thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. Each Client on the network can be uniquely identified on the Server's end by using its unique port address. This mode is ideal for applications, where broadcasting/streaming video-frames & data from a single broadcaster to multiple connected users is required. You can learn about this mode here \u27b6 . Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames . Using this mode, the user can now send or receive any data(of any datatype) between Server and Client easily in real-time. You can learn more about this mode here \u27b6 . Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart & secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. You can learn more about this mode here \u27b6 . \u2009 Important Information When compiling/installing pyzmq with pip on Linux, it is generally recommended that zeromq binaries to be installed separately, via homebrew, apt, yum, etc. as follows: # Debian-based sudo apt-get install libzmq3-dev # RHEL-based sudo yum install libzmq3-devel # OSX-based brew install zeromq If zeromq binaries are not found, pyzmq will try to build libzmq as a Python Extension, though this is not guaranteed to work! It is advised to enable logging ( logging = True ) on the first run, to easily identify any runtime errors. Kindly go through each given Usage Examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using send() function in Receive Mode) , will result in ValueError .","title":"Exclusive Modes"},{"location":"gears/netgear/overview/#importing","text":"You can import NetGear API in your program as follows: from vidgear.gears import NetGear","title":"Importing"},{"location":"gears/netgear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/netgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/netgear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/netgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/netgear/params/","text":"NetGear API Parameters \u00b6 address \u00b6 This parameter sets the valid Network IP address for Server/Client. Network addresses are unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode , i.e 'localhost' for Send Mode and '*' for Receive Mode on a local machine. Usage: NetGear ( address = \"192.168.0.145\" ) port \u00b6 This parameter sets the valid Network Port for Server/Client. Network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Exception for Exclusive Modes In Multi-Servers Mode : A unique port number MUST be assigned to each Server on the network using this parameter. At Client end, a List/Tuple of all available Server(s) ports MUST be assigned using this same parameter. See its usage example here \u27b6 . In Multi-Client Mode : A unique port number MUST be assigned to each Client on the network using this parameter. At Server end, a List/Tuple of all available Client(s) ports MUST be assigned using this same parameter. See its usage example here \u27b6 . Data-Type: String or List/Tuple Default Value: Its default value is '5555' Usage: NetGear ( port = \"5575\" ) protocol \u00b6 This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear ( protocol = \"ipc\" ) pattern \u00b6 This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). Supported ZMQ patterns All supported ZMQ patterns for NetGear are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. Usage: NetGear ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern receive_mode \u00b6 This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear ( receive_mode = True ) # activates Recieve Mode options \u00b6 This parameter provides the flexibility to alter various NetGear API's internal properties, modes, and some PyZMQ flags. Data-Type: Dictionary Default Value: Its default value is {} Usage: Supported dictionary attributes for NetGear API multiserver_mode ( boolean ) : This internal attribute activates the exclusive Multi-Servers Mode , if enabled( True ). multiclient_mode ( boolean ) : This internal attribute activates the exclusive Multi-Clients Mode , if enabled( True ). secure_mode ( integer ) : This internal attribute selects the exclusive Secure Mode . Its possible values are: 0 (i.e. Grassland(no security)) or 1 (i.e. StoneHouse) or 2 (i.e. IronHouse) . bidirectional_mode ( boolean ) : This internal attribute activates the exclusive Bidirectional Mode , if enabled( True ). custom_cert_location ( string ) : In Secure Mode, This internal attribute assigns user-defined location/path to directory for generating/storing Public+Secret Keypair necessary for encryption. More information can be found here \u27b6 overwrite_cert ( boolean ) : In Secure Mode, This internal attribute decides whether to overwrite existing Public+Secret Keypair/Certificates or not, at the Server-end only . More information can be found here \u27b6 compression_format ( string ): This internal attribute activates frame compression with selected encoding format. The possible values are .jpg , .png , .bmp . More information can be found here \u27b6 compression_param ( integer & list/tuple ): This internal attribute allow us to pass different format-specific Encoding parameters and Decoding flags . More information can be found here \u27b6 max_retries ( integer ): This internal attribute controls the maximum retries before Server/Client exit itself, if it's unable to get any response/reply from the socket before a certain amount of time, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 3 . request_timeout ( integer ): This internal attribute controls the timeout value (in seconds) , after which the Server/Client exit itself if it's unable to get any response/reply from the socket, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 10 seconds. flag ( integer ): This PyZMQ attribute value can be either 0 or zmq.NOBLOCK ( i.e. 1) . More information can be found here \u27b6 . copy ( boolean ): This PyZMQ attribute selects if message be received in a copying or non-copying manner. If False a object is returned, if True a string copy of the message is returned. track ( boolean ): This PyZMQ attribute check if the message is tracked for notification that ZMQ has finished with it. ( ignored if copy=True ). The desired attributes can be passed to NetGear API as follows: # formatting parameters as dictionary attributes options = { \"secure_mode\" : 2 , \"custom_cert_location\" : \"/home/foo/foo1/foo2\" , \"overwrite_cert\" : True , \"flag\" : 0 , \"copy\" : False , \"track\" : False , } # assigning it NetGear ( logging = True , ** options ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"Parameters"},{"location":"gears/netgear/params/#netgear-api-parameters","text":"","title":"NetGear API Parameters"},{"location":"gears/netgear/params/#address","text":"This parameter sets the valid Network IP address for Server/Client. Network addresses are unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode , i.e 'localhost' for Send Mode and '*' for Receive Mode on a local machine. Usage: NetGear ( address = \"192.168.0.145\" )","title":"address"},{"location":"gears/netgear/params/#port","text":"This parameter sets the valid Network Port for Server/Client. Network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Exception for Exclusive Modes In Multi-Servers Mode : A unique port number MUST be assigned to each Server on the network using this parameter. At Client end, a List/Tuple of all available Server(s) ports MUST be assigned using this same parameter. See its usage example here \u27b6 . In Multi-Client Mode : A unique port number MUST be assigned to each Client on the network using this parameter. At Server end, a List/Tuple of all available Client(s) ports MUST be assigned using this same parameter. See its usage example here \u27b6 . Data-Type: String or List/Tuple Default Value: Its default value is '5555' Usage: NetGear ( port = \"5575\" )","title":"port"},{"location":"gears/netgear/params/#protocol","text":"This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear ( protocol = \"ipc\" )","title":"protocol"},{"location":"gears/netgear/params/#pattern","text":"This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). Supported ZMQ patterns All supported ZMQ patterns for NetGear are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. Usage: NetGear ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern","title":"pattern"},{"location":"gears/netgear/params/#receive_mode","text":"This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear ( receive_mode = True ) # activates Recieve Mode","title":"receive_mode"},{"location":"gears/netgear/params/#options","text":"This parameter provides the flexibility to alter various NetGear API's internal properties, modes, and some PyZMQ flags. Data-Type: Dictionary Default Value: Its default value is {} Usage: Supported dictionary attributes for NetGear API multiserver_mode ( boolean ) : This internal attribute activates the exclusive Multi-Servers Mode , if enabled( True ). multiclient_mode ( boolean ) : This internal attribute activates the exclusive Multi-Clients Mode , if enabled( True ). secure_mode ( integer ) : This internal attribute selects the exclusive Secure Mode . Its possible values are: 0 (i.e. Grassland(no security)) or 1 (i.e. StoneHouse) or 2 (i.e. IronHouse) . bidirectional_mode ( boolean ) : This internal attribute activates the exclusive Bidirectional Mode , if enabled( True ). custom_cert_location ( string ) : In Secure Mode, This internal attribute assigns user-defined location/path to directory for generating/storing Public+Secret Keypair necessary for encryption. More information can be found here \u27b6 overwrite_cert ( boolean ) : In Secure Mode, This internal attribute decides whether to overwrite existing Public+Secret Keypair/Certificates or not, at the Server-end only . More information can be found here \u27b6 compression_format ( string ): This internal attribute activates frame compression with selected encoding format. The possible values are .jpg , .png , .bmp . More information can be found here \u27b6 compression_param ( integer & list/tuple ): This internal attribute allow us to pass different format-specific Encoding parameters and Decoding flags . More information can be found here \u27b6 max_retries ( integer ): This internal attribute controls the maximum retries before Server/Client exit itself, if it's unable to get any response/reply from the socket before a certain amount of time, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 3 . request_timeout ( integer ): This internal attribute controls the timeout value (in seconds) , after which the Server/Client exit itself if it's unable to get any response/reply from the socket, when synchronous messaging patterns like ( zmq.PAIR & zmq.REQ/zmq.REP ) are being used. It's value can anything greater than 0 , and its default value is 10 seconds. flag ( integer ): This PyZMQ attribute value can be either 0 or zmq.NOBLOCK ( i.e. 1) . More information can be found here \u27b6 . copy ( boolean ): This PyZMQ attribute selects if message be received in a copying or non-copying manner. If False a object is returned, if True a string copy of the message is returned. track ( boolean ): This PyZMQ attribute check if the message is tracked for notification that ZMQ has finished with it. ( ignored if copy=True ). The desired attributes can be passed to NetGear API as follows: # formatting parameters as dictionary attributes options = { \"secure_mode\" : 2 , \"custom_cert_location\" : \"/home/foo/foo1/foo2\" , \"overwrite_cert\" : True , \"flag\" : 0 , \"copy\" : False , \"track\" : False , } # assigning it NetGear ( logging = True , ** options )","title":"options"},{"location":"gears/netgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"logging"},{"location":"gears/netgear/usage/","text":"NetGear API Usage Examples: \u00b6 Danger Kindly go through each given examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. NetGear provides auto-termination feature, where if you terminate server end manually, the connected client(s) end will also terminate themselves to save resources. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode ( for e.g using send() function in Receive Mode ), will result in ValueError . Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with NetGear API: Server's End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # Define Netgear Server with default parameters server = NetGear () # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client's End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define Netgear Client with `receive_mode = True` and default parameter client = NetGear ( receive_mode = True ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using NetGear with OpenCV \u00b6 You can easily use NetGear directly with any Video Processing library such as OpenCV itself. The complete usage example is as follows: Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 0 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the received frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # define tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 0 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Using NetGear with Other VideoCapture Gears \u00b6 You can use any VideoCapture Gear in the similar manner. Let's implement given usage example with ScreenGear: Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u00b6 Now, Open the terminal on another Server System (let's say you want to transmit Monitor Screen Frames from a Laptop) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import NetGear # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Start capturing live Monitor screen frames with default settings stream = ScreenGear () . start () # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Usage Examples"},{"location":"gears/netgear/usage/#netgear-api-usage-examples","text":"Danger Kindly go through each given examples thoroughly, any incorrect settings/parameter may result in errors or no output at all. NetGear provides auto-termination feature, where if you terminate server end manually, the connected client(s) end will also terminate themselves to save resources. Only either of two functions (i.e. send() and recv() ) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode ( for e.g using send() function in Receive Mode ), will result in ValueError .","title":"NetGear API Usage Examples:"},{"location":"gears/netgear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/usage/#servers-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # Define Netgear Server with default parameters server = NetGear () # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#clients-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define Netgear Client with `receive_mode = True` and default parameter client = NetGear ( receive_mode = True ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#using-netgear-with-variable-parameters","text":"","title":"Using NetGear with Variable Parameters"},{"location":"gears/netgear/usage/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#using-netgear-with-opencv","text":"You can easily use NetGear directly with any Video Processing library such as OpenCV itself. The complete usage example is as follows:","title":"Using NetGear with OpenCV"},{"location":"gears/netgear/usage/#clients-end_2","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 0 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the received frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_2","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # define tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 0 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/usage/#using-netgear-with-other-videocapture-gears","text":"You can use any VideoCapture Gear in the similar manner. Let's implement given usage example with ScreenGear:","title":"Using NetGear with Other VideoCapture Gears"},{"location":"gears/netgear/usage/#clients-end_3","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Define Netgear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/usage/#servers-end_3","text":"Now, Open the terminal on another Server System (let's say you want to transmit Monitor Screen Frames from a Laptop) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import NetGear # define various tweak flags options = { \"flag\" : 0 , \"copy\" : False , \"track\" : False } # Start capturing live Monitor screen frames with default settings stream = ScreenGear () . start () # Define Netgear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/bidirectional_mode/","text":"Bidirectional Mode for NetGear API \u00b6 NetGear's Bidirectional Mode Overview \u00b6 Bidirectional Mode enables seamless support for Bidirectional data transmission between Client/Consumer and Sender/Publisher along with video-frames through its synchronous messaging patterns such as zmq.PAIR (ZMQ Pair Pattern) & zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern). In Bidirectional Mode, we utilizes the NetGear API's message parameter of send() method for sending data from Server-to-Client, and return_data parameter of recv() method to return data back from Client-to-Server all while transferring frames in real-time. This mode can be easily activated in NetGear through bidirectional_mode attribute of its option dictionary parameter during initialization. Important Information In Bidirectional Mode, zmq.PAIR (ZMQ Pair) & zmq.REQ/zmq.REP (ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in ValueError . Bidirectional Mode enables you to send data of ANY 1 Data-type along with frame bidirectionally. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! Bidirectional Mode is smart enough to sense data (if available or not) , and DOES NOT interfere with transferring of video-frames (unless data is huge) , as both mechanisms works independently. Bidirectional Mode is NOT compatibile with Multi-Servers mode and Multi-Clients mode exclusive modes. Thereby, if Bidirectional mode is enabled with any of these modes, it will be DISABLED automatically. Features of Bidirectional Mode \u00b6 Enables easy-to-use seamless Bidirectional data transmission between two systems. Supports zmq.PAIR & zmq.REQ/zmq.REP messaging patterns. Support for sending data of almost any 1 datatype. Auto-enables reconnection if Server or Client disconnects prematurely. Method Parameters \u00b6 To send data bidirectionally, NetGear API provides two exclusive parameters for its methods: message : It enables user to send data to Client, directly through send() method at Server's end. return_data : It enables user to send data back to Server, directly through recv() method at Client's end. Usage Examples \u00b6 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with Bidirectional Mode in NetGear API: Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server with defined parameters server = NetGear ( logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Bidirectional Mode with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print recieved server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u00b6 Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import PiGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using Bidirectional Mode for Video-Frames Transfer \u00b6 In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. This feature is great for building applications like Real-Time Video Chat. We're also using reducer() method for reducing frame-size on-the-go for additional performance. Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency! Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) # reduce frame by 30% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # again open the same video stream stream = VideoGear ( source = \"test.mp4\" ) . start () # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) # reduce frame by 30% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close client client . close () Using Bidirectional Mode for Video-Frames Transfer with Frame Compression \u00b6 See complete usage example here \u27b6 Additional data of numpy.ndarray data-type is ONLY SUPPORTED at Client's end with its return_data parameter. \u21a9 \u21a9","title":"Bidirectional Mode"},{"location":"gears/netgear/advanced/bidirectional_mode/#bidirectional-mode-for-netgear-api","text":"","title":"Bidirectional Mode for NetGear API"},{"location":"gears/netgear/advanced/bidirectional_mode/#overview","text":"Bidirectional Mode enables seamless support for Bidirectional data transmission between Client/Consumer and Sender/Publisher along with video-frames through its synchronous messaging patterns such as zmq.PAIR (ZMQ Pair Pattern) & zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern). In Bidirectional Mode, we utilizes the NetGear API's message parameter of send() method for sending data from Server-to-Client, and return_data parameter of recv() method to return data back from Client-to-Server all while transferring frames in real-time. This mode can be easily activated in NetGear through bidirectional_mode attribute of its option dictionary parameter during initialization. Important Information In Bidirectional Mode, zmq.PAIR (ZMQ Pair) & zmq.REQ/zmq.REP (ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in ValueError . Bidirectional Mode enables you to send data of ANY 1 Data-type along with frame bidirectionally. Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised! Bidirectional Mode is smart enough to sense data (if available or not) , and DOES NOT interfere with transferring of video-frames (unless data is huge) , as both mechanisms works independently. Bidirectional Mode is NOT compatibile with Multi-Servers mode and Multi-Clients mode exclusive modes. Thereby, if Bidirectional mode is enabled with any of these modes, it will be DISABLED automatically.","title":"Overview"},{"location":"gears/netgear/advanced/bidirectional_mode/#features-of-bidirectional-mode","text":"Enables easy-to-use seamless Bidirectional data transmission between two systems. Supports zmq.PAIR & zmq.REQ/zmq.REP messaging patterns. Support for sending data of almost any 1 datatype. Auto-enables reconnection if Server or Client disconnects prematurely.","title":"Features of Bidirectional Mode"},{"location":"gears/netgear/advanced/bidirectional_mode/#method-parameters","text":"To send data bidirectionally, NetGear API provides two exclusive parameters for its methods: message : It enables user to send data to Client, directly through send() method at Server's end. return_data : It enables user to send data back to Server, directly through recv() method at Client's end.","title":"Method Parameters"},{"location":"gears/netgear/advanced/bidirectional_mode/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/bidirectional_mode/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Bidirectional Mode in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server with defined parameters server = NetGear ( logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-with-variable-parameters","text":"","title":"Using Bidirectional Mode with Variable Parameters"},{"location":"gears/netgear/advanced/bidirectional_mode/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am a Client here.\" # receive data from server and also send our data data = client . recv ( return_data = target_data ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print recieved server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_1","text":"Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import PiGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # print data just received from Client if not ( recv_data is None ): print ( recv_data ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer","text":"In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. This feature is great for building applications like Real-Time Video Chat. We're also using reducer() method for reducing frame-size on-the-go for additional performance. Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency!","title":"Using Bidirectional Mode for Video-Frames Transfer"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) # reduce frame by 30% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end_1","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode options = { \"bidirectional_mode\" : True } # again open the same video stream stream = VideoGear ( source = \"test.mp4\" ) . start () # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want more performance, otherwise comment this line frame = reducer ( frame , percentage = 30 ) # reduce frame by 30% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","text":"See complete usage example here \u27b6 Additional data of numpy.ndarray data-type is ONLY SUPPORTED at Client's end with its return_data parameter. \u21a9 \u21a9","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression"},{"location":"gears/netgear/advanced/compression/","text":"Frame Compression for NetGear API \u00b6 Overview \u00b6 NetGear API supports real-time Frame Compression for optimizing performance while sending frames over the network. When Frame Compression is enabled, NetGear encodes (using imencode ) video-frames before sending it at Server's end, and cleverly decodes(using imdecode ) it at the Client's end, thereby leveraging performance in real-time at the cost of quality. Frame Compression can be easily activated in NetGear API through compression_format & compression_param attributes of its option dictionary parameter during initialization. Important Information Frame Compression only supports three JPG or JPEG , PNG & BMP encoding formats as of now. Extreme Frame-Compression may be lead to degraded quality of video-frames. User discretion is advised! Any Incorrect/Invalid encoding format will DISABLE this Frame Compression! Incorrect Format-specific parameters through compression_param attribute are skipped automatically. Features of Frame Compression \u00b6 Enables real-time Frame Compression for further optimizing performance. Client's End autonomously decodes frame based on encoding used at Server End. Encoding and decoding supports all Format-specific flags. Support for JPG , PNG & BMP encoding formats. Compatible with any messaging pattern and exclusive Multi-Server mode. Supported Attributes \u00b6 For implementing Frame Compression, NetGear API currently provide following attribute for its option dictionary parameter: compression_format ( string ): This attribute activates compression with selected encoding format. Its possible valid values are: '.jpg' / '.jpeg' or '.png' or '.bmp' , and its usage is as follows: Any Incorrect/Invalid encoding format value on compression_format attribute will DISABLE this Frame Compression! Even if you assign different compression_format value at Client's end, NetGear will auto-select the Server's encoding format instead. Fastest compression format for NetGear API? See this FAQ answer \u27b6 # activate jpeg encoding options = { 'compression_format' : '.jpg' } compression_param : This attribute allow us to pass different compression-format specific encoding/decoding flags. Its possible value are as follows: Encoding : Assigning Encoding List Parameters at Server's end only: # activate jpeg encoding and compression quality 80 options = { \"compression_format\" : \".jpg\" , \"compression_param\" : [ cv2 . IMWRITE_JPEG_QUALITY , 80 ], } All supported Encoding( Imwrite ) Flags can be found here \u27b6 Decoding : Assigning Integer Decoding flag at Client's end only: # decode image as is with alpha channel options = { \"compression_param\" : cv2 . IMREAD_UNCHANGED } All supported Decoding( Imread ) Flags can be found here \u27b6 Usage Examples \u00b6 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with Frame Compression in NetGear API: Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate jpeg encoding and specify other related parameters options = { \"compression_format\" : \".jpg\" , \"compression_param\" : [ cv2 . IMWRITE_JPEG_QUALITY , 50 ], } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define decode image as 3 channel BGR color image options = { \"compression_format\" : \".jpg\" , \"compression_param\" : cv2 . IMREAD_COLOR } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Frame Compression with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { \"compression_format\" : \".jpg\" , \"compression_param\" : [ cv2 . IMWRITE_JPEG_QUALITY , 80 , cv2 . IMWRITE_JPEG_PROGRESSIVE , True , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ], } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # define decode image as 3 channel BGR color image options = { \"compression_format\" : \".jpg\" , \"compression_param\" : cv2 . IMREAD_COLOR } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Using Bidirectional Mode for Video-Frames Transfer with Frame Compression \u00b6 NetGear now supports Dual Frame Compression for transferring video-frames with its exclusive Bidirectional Mode for achieving unmatchable performance bidirectionally. You can easily pass the required encoding/decoding parameters by formatting them as tuple for altering Frame Compression while sending/receiving video-frames at both ends. In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time for testing the real-time performance and synchronization between the Server and Client using Bidirectional Mode . Furthermore, we're going to use optimal Dual Frame Compression Setting for Sending and Receiving frames at both Server and Client end. This feature is great for building applications like Real-time Video Chat System . This Dual Frame Compression feature also available for Multi-Clients Mode at Client(s) end only. We're also using reducer() Helper method for reducing frame-size on-the-go for additional performance. Remember, sending large HQ video-frames may required more network bandwidth and packet size, which may add to video latency! Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate Bidirectional mode and Dual Frame Compression options = { \"bidirectional_mode\" : True , \"compression_format\" : \".jpg\" , \"compression_param\" : ( cv2 . IMREAD_COLOR , [ cv2 . IMWRITE_JPEG_QUALITY , 60 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ], ), } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode and Dual Frame Compression options = { \"bidirectional_mode\" : True , \"compression_format\" : \".jpg\" , \"compression_param\" : ( cv2 . IMREAD_COLOR , [ cv2 . IMWRITE_JPEG_QUALITY , 60 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ], ), } # again open the same video stream stream = VideoGear ( source = \"test.mp4\" ) . start () # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close client client . close ()","title":"Frame Compression"},{"location":"gears/netgear/advanced/compression/#frame-compression-for-netgear-api","text":"","title":"Frame Compression for NetGear API"},{"location":"gears/netgear/advanced/compression/#overview","text":"NetGear API supports real-time Frame Compression for optimizing performance while sending frames over the network. When Frame Compression is enabled, NetGear encodes (using imencode ) video-frames before sending it at Server's end, and cleverly decodes(using imdecode ) it at the Client's end, thereby leveraging performance in real-time at the cost of quality. Frame Compression can be easily activated in NetGear API through compression_format & compression_param attributes of its option dictionary parameter during initialization. Important Information Frame Compression only supports three JPG or JPEG , PNG & BMP encoding formats as of now. Extreme Frame-Compression may be lead to degraded quality of video-frames. User discretion is advised! Any Incorrect/Invalid encoding format will DISABLE this Frame Compression! Incorrect Format-specific parameters through compression_param attribute are skipped automatically.","title":"Overview"},{"location":"gears/netgear/advanced/compression/#features-of-frame-compression","text":"Enables real-time Frame Compression for further optimizing performance. Client's End autonomously decodes frame based on encoding used at Server End. Encoding and decoding supports all Format-specific flags. Support for JPG , PNG & BMP encoding formats. Compatible with any messaging pattern and exclusive Multi-Server mode.","title":"Features of Frame Compression"},{"location":"gears/netgear/advanced/compression/#supported-attributes","text":"For implementing Frame Compression, NetGear API currently provide following attribute for its option dictionary parameter: compression_format ( string ): This attribute activates compression with selected encoding format. Its possible valid values are: '.jpg' / '.jpeg' or '.png' or '.bmp' , and its usage is as follows: Any Incorrect/Invalid encoding format value on compression_format attribute will DISABLE this Frame Compression! Even if you assign different compression_format value at Client's end, NetGear will auto-select the Server's encoding format instead. Fastest compression format for NetGear API? See this FAQ answer \u27b6 # activate jpeg encoding options = { 'compression_format' : '.jpg' } compression_param : This attribute allow us to pass different compression-format specific encoding/decoding flags. Its possible value are as follows: Encoding : Assigning Encoding List Parameters at Server's end only: # activate jpeg encoding and compression quality 80 options = { \"compression_format\" : \".jpg\" , \"compression_param\" : [ cv2 . IMWRITE_JPEG_QUALITY , 80 ], } All supported Encoding( Imwrite ) Flags can be found here \u27b6 Decoding : Assigning Integer Decoding flag at Client's end only: # decode image as is with alpha channel options = { \"compression_param\" : cv2 . IMREAD_UNCHANGED } All supported Decoding( Imread ) Flags can be found here \u27b6","title":"Supported Attributes"},{"location":"gears/netgear/advanced/compression/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/compression/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Frame Compression in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/compression/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate jpeg encoding and specify other related parameters options = { \"compression_format\" : \".jpg\" , \"compression_param\" : [ cv2 . IMWRITE_JPEG_QUALITY , 50 ], } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # define decode image as 3 channel BGR color image options = { \"compression_format\" : \".jpg\" , \"compression_param\" : cv2 . IMREAD_COLOR } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/compression/#using-frame-compression-with-variable-parameters","text":"","title":"Using Frame Compression with Variable Parameters"},{"location":"gears/netgear/advanced/compression/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate jpeg encoding and specify other related parameters options = { \"compression_format\" : \".jpg\" , \"compression_param\" : [ cv2 . IMWRITE_JPEG_QUALITY , 80 , cv2 . IMWRITE_JPEG_PROGRESSIVE , True , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ], } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/compression/#server-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear import cv2 # define decode image as 3 channel BGR color image options = { \"compression_format\" : \".jpg\" , \"compression_param\" : cv2 . IMREAD_COLOR } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","text":"NetGear now supports Dual Frame Compression for transferring video-frames with its exclusive Bidirectional Mode for achieving unmatchable performance bidirectionally. You can easily pass the required encoding/decoding parameters by formatting them as tuple for altering Frame Compression while sending/receiving video-frames at both ends. In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time for testing the real-time performance and synchronization between the Server and Client using Bidirectional Mode . Furthermore, we're going to use optimal Dual Frame Compression Setting for Sending and Receiving frames at both Server and Client end. This feature is great for building applications like Real-time Video Chat System . This Dual Frame Compression feature also available for Multi-Clients Mode at Client(s) end only. We're also using reducer() Helper method for reducing frame-size on-the-go for additional performance. Remember, sending large HQ video-frames may required more network bandwidth and packet size, which may add to video latency!","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression"},{"location":"gears/netgear/advanced/compression/#server-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear from vidgear.gears.helper import reducer import numpy as np import cv2 # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate Bidirectional mode and Dual Frame Compression options = { \"bidirectional_mode\" : True , \"compression_format\" : \".jpg\" , \"compression_param\" : ( cv2 . IMREAD_COLOR , [ cv2 . IMWRITE_JPEG_QUALITY , 60 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ], ), } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # {do something with the frame here} # prepare data to be sent(a simple text in our case) target_data = \"Hello, I am a Server.\" # send frame & data and also receive data from Client recv_data = server . send ( frame , message = target_data ) # check data just received from Client is of numpy datatype if not ( recv_data is None ) and isinstance ( recv_data , np . ndarray ): # {do something with received numpy array here} # Let's show it on output window cv2 . imshow ( \"Received Frame\" , recv_data ) key = cv2 . waitKey ( 1 ) & 0xFF except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/compression/#client-end_1","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear from vidgear.gears.helper import reducer import cv2 # activate Bidirectional mode and Dual Frame Compression options = { \"bidirectional_mode\" : True , \"compression_format\" : \".jpg\" , \"compression_param\" : ( cv2 . IMREAD_COLOR , [ cv2 . IMWRITE_JPEG_QUALITY , 60 , cv2 . IMWRITE_JPEG_PROGRESSIVE , False , cv2 . IMWRITE_JPEG_OPTIMIZE , True , ], ), } # again open the same video stream stream = VideoGear ( source = \"test.mp4\" ) . start () # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( receive_mode = True , pattern = 1 , logging = True , ** options ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # reducer frames size if you want even more performance, otherwise comment this line frame = reducer ( frame , percentage = 20 ) # reduce frame by 20% # receive data from server and also send our data data = client . recv ( return_data = frame ) # check for data if None if data is None : break # extract server_data & frame from data server_data , frame = data # again check for frame if None if frame is None : break # {do something with the extracted frame and data here} # lets print extracted server data if not ( server_data is None ): print ( server_data ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/multi_client/","text":"Multi-Clients Mode for NetGear API \u00b6 Overview \u00b6 NetGear's Multi-Clients Mode In Multi-Clients Mode, NetGear robustly handles Multiple Clients at once thereby able to broadcast frames and data across multiple Clients/Consumers in the network at same time. This mode works almost contrary to Multi-Servers Mode but here data transfer works unidirectionally with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) only. Every new Client that connects to single Server can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ) and can be easily activated in NetGear API through multiclient_mode attribute of its option dictionary parameter during initialization. Multi-Clients is best for tranferring Data with Video-frames to specific multiple Clients at the same time. But if you're looking for sheer performance for broadcasting see WebGear API . Multi-Clients Mode Requirements A unique PORT address MUST be assigned to each Client on the network using its port parameter. A list/tuple of PORT addresses of all unique Cients MUST be assigned at Server's end using its port parameter for a successful connection. Patterns 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported pattern values for this Mode. Therefore, calling any other pattern value with is mode will result in ValueError . The address parameter value of each Client MUST exactly match the Server. Features of Multi-Clients Mode \u00b6 Enables Multiple Client(s) connection with a single Server. Ability to send any additional data of any datatype along with frames in real-time. Number of Clients can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Client on the network can be identified at Server's end by their unique port addresses. NetGear API actively tracks the state of each connected Client. If the server gets disconnected, all the clients will automatically exit to save resources. Usage Examples \u00b6 Important Information Frame/Data transmission will NOT START until all given Client(s) are connected to the Server. Multi-Clients and Multi-Servers exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . For sake of simplicity, in these examples we will use only two unique Clients, but the number of these Clients can be extended to SEVERAL numbers depending upon your Network bandwidth and System Capabilities. Bare-Minimum Usage \u00b6 In this example, we will capturing live video-frames from a source (a.k.a Servers) with a webcam connected to it. Afterwards, those captured frame will be transferred over the network to a two independent system (a.k.a Client) at the same time, and will be displayed in Output Window at real-time. All this by using this Multi-Clients Mode in NetGear API. Server's End \u00b6 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of # all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = ( 5567 , 5577 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client-1's End \u00b6 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u00b6 Finally, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Bare-Minimum Usage with OpenCV \u00b6 In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API. Server's End \u00b6 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = ( 5567 , 5577 ), protocol = \"tcp\" , pattern = 2 , logging = True , ** options ) # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Client-1's End \u00b6 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u00b6 Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Multi-Clients Mode with Custom Data Transfer \u00b6 Info With Multi-Clients Mode, you can also send additional data of any data-type (such as list, tuple, string, int, ndarray etc.) along with frame, from all connected Clients(s) back to a Server unidirectionally. In Multi-Clients Mode, unidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) ! In this example, We will be transferring video-frames from a single Server (consisting of Raspberry Pi with Camera Module) over the network to two independent Client for displaying them in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) from both the Client(s) back to our Server, which will be printed onto the terminal. Server's End \u00b6 Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import PiGear from vidgear.gears import NetGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client-1's End \u00b6 Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5577 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Client-2's End \u00b6 Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5578 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5578 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Multi-Clients Mode"},{"location":"gears/netgear/advanced/multi_client/#multi-clients-mode-for-netgear-api","text":"","title":"Multi-Clients Mode for NetGear API"},{"location":"gears/netgear/advanced/multi_client/#overview","text":"NetGear's Multi-Clients Mode In Multi-Clients Mode, NetGear robustly handles Multiple Clients at once thereby able to broadcast frames and data across multiple Clients/Consumers in the network at same time. This mode works almost contrary to Multi-Servers Mode but here data transfer works unidirectionally with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) only. Every new Client that connects to single Server can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ) and can be easily activated in NetGear API through multiclient_mode attribute of its option dictionary parameter during initialization. Multi-Clients is best for tranferring Data with Video-frames to specific multiple Clients at the same time. But if you're looking for sheer performance for broadcasting see WebGear API . Multi-Clients Mode Requirements A unique PORT address MUST be assigned to each Client on the network using its port parameter. A list/tuple of PORT addresses of all unique Cients MUST be assigned at Server's end using its port parameter for a successful connection. Patterns 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported pattern values for this Mode. Therefore, calling any other pattern value with is mode will result in ValueError . The address parameter value of each Client MUST exactly match the Server.","title":"Overview"},{"location":"gears/netgear/advanced/multi_client/#features-of-multi-clients-mode","text":"Enables Multiple Client(s) connection with a single Server. Ability to send any additional data of any datatype along with frames in real-time. Number of Clients can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Client on the network can be identified at Server's end by their unique port addresses. NetGear API actively tracks the state of each connected Client. If the server gets disconnected, all the clients will automatically exit to save resources.","title":"Features of Multi-Clients Mode"},{"location":"gears/netgear/advanced/multi_client/#usage-examples","text":"Important Information Frame/Data transmission will NOT START until all given Client(s) are connected to the Server. Multi-Clients and Multi-Servers exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . For sake of simplicity, in these examples we will use only two unique Clients, but the number of these Clients can be extended to SEVERAL numbers depending upon your Network bandwidth and System Capabilities.","title":"Usage Examples"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage","text":"In this example, we will capturing live video-frames from a source (a.k.a Servers) with a webcam connected to it. Afterwards, those captured frame will be transferred over the network to a two independent system (a.k.a Client) at the same time, and will be displayed in Output Window at real-time. All this by using this Multi-Clients Mode in NetGear API.","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/multi_client/#servers-end","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of # all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = ( 5567 , 5577 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end","text":"Finally, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage-with-opencv","text":"In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/netgear/advanced/multi_client/#servers-end_1","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = ( 5567 , 5577 ), protocol = \"tcp\" , pattern = 2 , logging = True , ** options ) # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_1","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5567 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_1","text":"Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive data from server frame = client . recv () # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_client/#using-multi-clients-mode-with-custom-data-transfer","text":"Info With Multi-Clients Mode, you can also send additional data of any data-type (such as list, tuple, string, int, ndarray etc.) along with frame, from all connected Clients(s) back to a Server unidirectionally. In Multi-Clients Mode, unidirectional data transfer ONLY works with pattern 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) , and NOT with pattern 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) ! In this example, We will be transferring video-frames from a single Server (consisting of Raspberry Pi with Camera Module) over the network to two independent Client for displaying them in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) from both the Client(s) back to our Server, which will be printed onto the terminal.","title":"Using Multi-Clients Mode with Custom Data Transfer"},{"location":"gears/netgear/advanced/multi_client/#servers-end_2","text":"Now, Open the terminal on a Server System (with a webcam connected to it at index 0 ) . Now execute the following python code: Important Notes Note down the IP-address of this system(required at all Client's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Client you are going to connect to this system. Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server. You can terminate streaming anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import PiGear from vidgear.gears import NetGear # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiclient_mode mode options = { \"multiclient_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters server = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received data dictionary data_dict = {} # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame and also receive data from Client(s) recv_data = server . send ( frame ) # check if valid data recieved if not ( recv_data is None ): # extract unique port address and its respective data unique_address , data = recv_data # update the extracted data in the data dictionary data_dict [ unique_address ] = data if data_dict : # print data just received from Client(s) for key , value in data_dict . items (): print ( \"Client at port {} said: {} \" . format ( key , value )) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server's End"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_2","text":"Now, Open a terminal on another Client System (where you want to display the input frames received from Server) , let's name it Client-1. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5577 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5577 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-1's End"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_2","text":"Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server) , let's name it Client-2. Execute the following python code: Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system) . You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate Multi-Clients mode options = { \"multiclient_mode\" : True } # Define NetGear Client at Server's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # prepare data to be sent target_data = \"Hi, I am 5578 Client here.\" # receive data from server and also send our data frame = client . recv ( return_data = target_data ) # check for frame if None if frame is None : break # {do something with frame here} # Show output window cv2 . imshow ( \"Client 5578 Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client-2's End"},{"location":"gears/netgear/advanced/multi_server/","text":"Multi-Servers Mode for NetGear API \u00b6 Overview \u00b6 NetGear's Multi-Servers Mode In Multi-Servers Mode, NetGear API robustly handles Multiple Servers at once, thereby providing seamless access to frames and unidirectional data transfer across multiple Publishers/Servers in the network at the same time. Each new server connects to a single client can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ) and can be easily activated in NetGear API through multiserver_mode attribute of its option dictionary parameter during initialization. Multi-Servers Mode Requirements A unique PORT address MUST be assigned to each Server on the network using its port parameter. A list/tuple of PORT addresses of all unique Servers MUST be assigned at Client's end using its port parameter for a successful connection. Patterns 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported values for this Mode. Therefore, calling any other pattern value with is mode will result in ValueError . The address parameter value of each Server MUST exactly match the Client. Key Features \u00b6 Enables Multiple Server(s) connection with a single Client. Ability to send any additional data of any 1 datatype along with frames in real-time. Number of Servers can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Server on the network can be identified at Client's end by their unique port addresses. NetGear API actively tracks the state of each connected Server. If all the connected servers on the network get disconnected, the client itself automatically exits to save resources. Usage Examples \u00b6 Important Information For sake of simplicity, in these examples we will use only two unique Servers, but, the number of these Servers can be extended to several numbers depending upon your system hardware limits. All of Servers will be transferring frames to a single Client system at the same time, which will be displaying received frames as a montage (multiple frames concatenated together) . For building Frames Montage at Client's end, We are going to use imutils python library function to build montages, by concatenating together frames recieved from different servers. Therefore, Kindly install this library with pip install imutils terminal command. Multi-Servers and Multi-Clients exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError . Bare-Minimum Usage \u00b6 In this example, we will capturing live video-frames on two independent sources (a.k.a Servers) , each with a webcam connected to it. Then, those frames will be transferred over the network to a single system (a.k.a Client) at the same time, and will be displayed as a real-time montage. All this by using this Multi-Servers Mode in NetGear API. Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from Multiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple # of all unique Server((5566,5567) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5566 , 5567 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server-1's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5566\" , protocol = \"tcp\" , pattern = 1 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Server-2's End \u00b6 Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 1 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Bare-Minimum Usage with OpenCV \u00b6 In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API. Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all # unique Server((5566,5567) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5566 , 5567 ), protocol = \"tcp\" , pattern = 2 , receive_mode = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server-1's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameter # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5566\" , protocol = \"tcp\" , pattern = 2 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Server-2's End \u00b6 Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 2 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close () Using Multi-Servers Mode with Custom Data Transfer \u00b6 Info With Multi-Servers Mode, you can send additional data of any data-type (such as list, tuple, string, int etc.) along with frame, from all connected Server(s) to a single Client unidirectionally. But numpy.ndarray data-type is NOT supported as data. In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) , from all two Servers (consisting of a Raspberry Pi with Camera Module & a Laptop with webcam) to a single Client over the network in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal. Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters client = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame and received data unique_address , extracted_data , frame = data # {do something with the extracted frame and data here} # let's display extracted data on our extracted frame cv2 . putText ( frame , extracted_data , ( 10 , frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server-1's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = VideoGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-1 at Port: 5577\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Server-2's End \u00b6 Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.1.xxx\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-2 at Port: 5578\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream. stream . stop () # safely close server server . close () Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its message parameter. \u21a9","title":"Multi-Servers Mode"},{"location":"gears/netgear/advanced/multi_server/#multi-servers-mode-for-netgear-api","text":"","title":"Multi-Servers Mode for NetGear API"},{"location":"gears/netgear/advanced/multi_server/#overview","text":"NetGear's Multi-Servers Mode In Multi-Servers Mode, NetGear API robustly handles Multiple Servers at once, thereby providing seamless access to frames and unidirectional data transfer across multiple Publishers/Servers in the network at the same time. Each new server connects to a single client can be identified by its unique port address on the network. The supported patterns for this mode are Publish/Subscribe ( zmq.PUB/zmq.SUB ) and Request/Reply( zmq.REQ/zmq.REP ) and can be easily activated in NetGear API through multiserver_mode attribute of its option dictionary parameter during initialization. Multi-Servers Mode Requirements A unique PORT address MUST be assigned to each Server on the network using its port parameter. A list/tuple of PORT addresses of all unique Servers MUST be assigned at Client's end using its port parameter for a successful connection. Patterns 1 (i.e. Request/Reply zmq.REQ/zmq.REP ) and 2 (i.e. Publish/Subscribe zmq.PUB/zmq.SUB ) are the only supported values for this Mode. Therefore, calling any other pattern value with is mode will result in ValueError . The address parameter value of each Server MUST exactly match the Client.","title":"Overview"},{"location":"gears/netgear/advanced/multi_server/#key-features","text":"Enables Multiple Server(s) connection with a single Client. Ability to send any additional data of any 1 datatype along with frames in real-time. Number of Servers can be extended to several numbers depending upon your system's hardware limit. Employs powerful Publish/Subscribe & Request/Reply messaging patterns. Each new Server on the network can be identified at Client's end by their unique port addresses. NetGear API actively tracks the state of each connected Server. If all the connected servers on the network get disconnected, the client itself automatically exits to save resources.","title":"Key Features"},{"location":"gears/netgear/advanced/multi_server/#usage-examples","text":"Important Information For sake of simplicity, in these examples we will use only two unique Servers, but, the number of these Servers can be extended to several numbers depending upon your system hardware limits. All of Servers will be transferring frames to a single Client system at the same time, which will be displaying received frames as a montage (multiple frames concatenated together) . For building Frames Montage at Client's end, We are going to use imutils python library function to build montages, by concatenating together frames recieved from different servers. Therefore, Kindly install this library with pip install imutils terminal command. Multi-Servers and Multi-Clients exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw ValueError .","title":"Usage Examples"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage","text":"In this example, we will capturing live video-frames on two independent sources (a.k.a Servers) , each with a webcam connected to it. Then, those frames will be transferred over the network to a single system (a.k.a Client) at the same time, and will be displayed as a real-time montage. All this by using this Multi-Servers Mode in NetGear API.","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/multi_server/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from Multiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple # of all unique Server((5566,5567) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5566 , 5567 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5566\" , protocol = \"tcp\" , pattern = 1 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end","text":"Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import CamGear # Open suitable video stream (webcam on first index in our case) stream = CamGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 1 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server-2's End"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage-with-opencv","text":"In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/netgear/advanced/multi_server/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all # unique Server((5566,5567) in our case) and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.x\" , port = ( 5566 , 5567 ), protocol = \"tcp\" , pattern = 2 , receive_mode = True , ** options ) # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame unique_address , frame = data # {do something with the extracted frame here} # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the received frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameter # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5566\" , protocol = \"tcp\" , pattern = 2 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_1","text":"Finally, Open the terminal on another Server System (also with a webcam connected to it at index 0 ) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = cv2 . VideoCapture ( 0 ) # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5567\" , protocol = \"tcp\" , pattern = 2 , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . release () # safely close server server . close ()","title":"Server-2's End"},{"location":"gears/netgear/advanced/multi_server/#using-multi-servers-mode-with-custom-data-transfer","text":"Info With Multi-Servers Mode, you can send additional data of any data-type (such as list, tuple, string, int etc.) along with frame, from all connected Server(s) to a single Client unidirectionally. But numpy.ndarray data-type is NOT supported as data. In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) , from all two Servers (consisting of a Raspberry Pi with Camera Module & a Laptop with webcam) to a single Client over the network in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal.","title":"Using Multi-Servers Mode with Custom Data Transfer"},{"location":"gears/netgear/advanced/multi_server/#clients-end_2","text":"Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: Important Notes Note down the IP-address of this system(required at all Server's end) by executing the command: hostname -I and also replace it in the following code. Also, assign the tuple/list of port address of all Servers you are going to connect to this system. You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear from imutils import build_montages import cv2 # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters client = NetGear ( address = \"192.168.x.x\" , port = ( 5577 , 5578 ), protocol = \"tcp\" , pattern = 1 , receive_mode = True , logging = True , ** options ) # !!! change following IP address '192.168.x.xxx' with yours !!! # Define received frame dictionary frame_dict = {} # loop over until Keyboard Interrupted while True : try : # receive data from network data = client . recv () # check if data received isn't None if data is None : break # extract unique port address and its respective frame and received data unique_address , extracted_data , frame = data # {do something with the extracted frame and data here} # let's display extracted data on our extracted frame cv2 . putText ( frame , extracted_data , ( 10 , frame . shape [ 0 ] - 10 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 255 , 0 ), 2 , ) # get extracted frame's shape ( h , w ) = frame . shape [: 2 ] # update the extracted frame in the frame dictionary frame_dict [ unique_address ] = frame # build a montage using data dictionary montages = build_montages ( frame_dict . values (), ( w , h ), ( 2 , 1 )) # display the montage(s) on the screen for ( i , montage ) in enumerate ( montages ): cv2 . imshow ( \"Montage Footage {} \" . format ( i ), montage ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break except KeyboardInterrupt : break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_2","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and let's called it Server-1. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import VideoGear import cv2 # Open suitable video stream (webcam on first index in our case) stream = VideoGear ( source = 0 ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.x.x\" , port = \"5577\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-1 at Port: 5577\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server-1's End"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_2","text":"Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it) , and let's called it Server-2. Now execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system) . You can terminate stream anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears import NetGear from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # activate multiserver_mode options = { \"multiserver_mode\" : True } # Define NetGear Server at Client's IP address and assign a unique port address and other parameters # !!! change following IP address '192.168.x.xxx' with yours !!! server = NetGear ( address = \"192.168.1.xxx\" , port = \"5578\" , protocol = \"tcp\" , pattern = 1 , logging = True , ** options ) # loop over until Keyboard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with frame and data(to be sent) here} # let's prepare a text string as data text = \"I'm Server-2 at Port: 5578\" # send frame and data through server server . send ( frame , message = text ) except KeyboardInterrupt : break # safely close video stream. stream . stop () # safely close server server . close () Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its message parameter. \u21a9","title":"Server-2's End"},{"location":"gears/netgear/advanced/secure_mode/","text":"Secure Mode for NetGear API \u00b6 Overview \u00b6 Secure Mode provides easy access to powerful, smart & secure ZeroMQ's Security Layers in NetGear API that enables strong encryption on data, and unbreakable authentication between the Server and the Client with the help of custom Certificates/keys and brings cheap, standardized privacy and authentication for distributed systems over the network. Secure Mode uses a new wire protocol, ZMTP 3.0 that adds a security handshake to all ZeroMQ connections and a new security protocol, CurveZMQ , that implements \"perfect forward security\" between two ZeroMQ peers over a TCP connection. Secure Mode can be easily activated in NetGear API through secure_mode attribute of its option dictionary parameter, during initialization. Furthermore, for managing this mode, NetGear API provides additional custom_cert_location & overwrite_cert like attribute too. Supported ZMQ Security Layers \u00b6 Secure mode supports the two most powerful ZMQ security layers: Stonehouse: which switches to the CURVE security protocol that provides strong encryption on data, and almost unbreakable authentication. Stonehouse is the minimum you would use over public networks and assures clients that they are speaking to an authentic server while allowing any client to connect. This security layer is less secure but at the same time faster than IronHouse security mechanism. Ironhouse: which further extends Stonehouse layer with client public key authentication. This is the strongest security model present in ZeroMQ, protecting against every attack we know about except end-point attacks . This security layer enhanced security comes at a price of additional latency. Secure Mode Requirements The secure_mode attribute value at the Client's end MUST match exactly the Server's end (i.e. IronHouse security layer is only compatible with IronHouse , and NOT with StoneHouse ) . The Public+Secret Keypairs generated at the Server end MUST be made available at the Client's end too for successful authentication. If mismatched, connection failure will occur. By Default, the Public+Secret Keypairs will be generated/stored at the $HOME/.vidgear/keys directory of your machine (e.g. /home/foo/.vidgear/keys on Linux) . But you can also use custom_cert_location attribute to set your own Custom-Path for a directory to generate/store these Keypairs. DO NOT share generated public+secret Keypairs with anyone else on the network to avoid any potential security breach. At the Server End, You can easily use the 'overwrite_cert' attribute for regenerating New-Keypairs on initialization. But make sure those newly generated Keypairs at the Server-End MUST be made available at Client's End for successful authentication. IronHouse is the strongest Security Layer available, but it involves certain security checks that lead to ADDITIONAL LATENCY . Secure Mode only supports libzmq library version >= 4.0 . Features \u00b6 Supports the two most powerful ZMQ security layers: StoneHouse & IronHouse. Auto-generates, auto-validates & auto-stores the required Public+Secret Keypairs safely. Compatible with all messaging pattern, primary and exclusive modes. Strong data encryption & Unbreakable authentication. Able to protect against many man-in-the-middle (MITM) attacks. Minimum hassle and very easy to enable and integrate. Supported Attributes \u00b6 For implementing Secure Mode, NetGear API currently provide following attribute for its option dictionary parameter: secure_mode ( integer ) : This attribute activates and sets the ZMQ security Mechanism. Its possible values are: 1 ( StoneHouse ) & 2 ( IronHouse ), and its default value is 0 ( Grassland(no security) ). Its usage is as follows: #activates IronHouse Security Mechanism options = { 'secure_mode' : 2 } custom_cert_location ( string ): This attribute sets a custom location/path to directory to generate/store Public+Secret Keypair/Certificates for enabling encryption. This attribute will force NetGear to create .vidgear folder (only if not available) at the assigned custom path (instead of home directory) , and then use that directory for storing new Keypairs/Certificates. It can be used as follows: # set custom Keypair location to '/home/foo/foo1/foo2' options = { \"secure_mode\" : 2 , \"custom_cert_location\" : \"/home/foo/foo1/foo2\" , } overwrite_cert ( bool ): [For Server-end only] This attribute sets whether to overwrite existing Public+Secret Keypair/Certificates and re-generate new ones, to protect against any potential security breach. If set to True a new Keypair/Certificates will be generated during NetGear initialization in place of old ones. Its usage is as follows: overwrite_cert parameter is disabled for Client's end! # a new Keypair will be generated options = { \"secure_mode\" : 2 , \"overwrite_cert\" : True } Usage Examples \u00b6 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with Secure Mode in NetGear API: Server End \u00b6 Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate StoneHouse security mechanism options = { \"secure_mode\" : 1 } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close () Client End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate StoneHouse security mechanism options = { \"secure_mode\" : 1 } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Using Secure Mode with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You need to paste the Public+Secret Keypairs (generated at the Server End) at the $HOME/.vidgear/keys directory of your Client machine for a successful authentication! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate IronHouse security mechanism options = { \"secure_mode\" : 2 } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close () Server End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You also need to copy the Public+Secret Keypairs (generated on running this example code) present in the $HOME/.vidgear/keys directory, and make available at Client's end for a successful authentication. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # activate IronHouse security mechanism, and # [BEWARE!!!] generating new Keypairs for this example !!! options = { \"secure_mode\" : 2 , \"overwrite_cert\" : True } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Secure Mode"},{"location":"gears/netgear/advanced/secure_mode/#secure-mode-for-netgear-api","text":"","title":"Secure Mode for NetGear API"},{"location":"gears/netgear/advanced/secure_mode/#overview","text":"Secure Mode provides easy access to powerful, smart & secure ZeroMQ's Security Layers in NetGear API that enables strong encryption on data, and unbreakable authentication between the Server and the Client with the help of custom Certificates/keys and brings cheap, standardized privacy and authentication for distributed systems over the network. Secure Mode uses a new wire protocol, ZMTP 3.0 that adds a security handshake to all ZeroMQ connections and a new security protocol, CurveZMQ , that implements \"perfect forward security\" between two ZeroMQ peers over a TCP connection. Secure Mode can be easily activated in NetGear API through secure_mode attribute of its option dictionary parameter, during initialization. Furthermore, for managing this mode, NetGear API provides additional custom_cert_location & overwrite_cert like attribute too.","title":"Overview"},{"location":"gears/netgear/advanced/secure_mode/#supported-zmq-security-layers","text":"Secure mode supports the two most powerful ZMQ security layers: Stonehouse: which switches to the CURVE security protocol that provides strong encryption on data, and almost unbreakable authentication. Stonehouse is the minimum you would use over public networks and assures clients that they are speaking to an authentic server while allowing any client to connect. This security layer is less secure but at the same time faster than IronHouse security mechanism. Ironhouse: which further extends Stonehouse layer with client public key authentication. This is the strongest security model present in ZeroMQ, protecting against every attack we know about except end-point attacks . This security layer enhanced security comes at a price of additional latency. Secure Mode Requirements The secure_mode attribute value at the Client's end MUST match exactly the Server's end (i.e. IronHouse security layer is only compatible with IronHouse , and NOT with StoneHouse ) . The Public+Secret Keypairs generated at the Server end MUST be made available at the Client's end too for successful authentication. If mismatched, connection failure will occur. By Default, the Public+Secret Keypairs will be generated/stored at the $HOME/.vidgear/keys directory of your machine (e.g. /home/foo/.vidgear/keys on Linux) . But you can also use custom_cert_location attribute to set your own Custom-Path for a directory to generate/store these Keypairs. DO NOT share generated public+secret Keypairs with anyone else on the network to avoid any potential security breach. At the Server End, You can easily use the 'overwrite_cert' attribute for regenerating New-Keypairs on initialization. But make sure those newly generated Keypairs at the Server-End MUST be made available at Client's End for successful authentication. IronHouse is the strongest Security Layer available, but it involves certain security checks that lead to ADDITIONAL LATENCY . Secure Mode only supports libzmq library version >= 4.0 .","title":"Supported ZMQ Security Layers"},{"location":"gears/netgear/advanced/secure_mode/#features","text":"Supports the two most powerful ZMQ security layers: StoneHouse & IronHouse. Auto-generates, auto-validates & auto-stores the required Public+Secret Keypairs safely. Compatible with all messaging pattern, primary and exclusive modes. Strong data encryption & Unbreakable authentication. Able to protect against many man-in-the-middle (MITM) attacks. Minimum hassle and very easy to enable and integrate.","title":"Features"},{"location":"gears/netgear/advanced/secure_mode/#supported-attributes","text":"For implementing Secure Mode, NetGear API currently provide following attribute for its option dictionary parameter: secure_mode ( integer ) : This attribute activates and sets the ZMQ security Mechanism. Its possible values are: 1 ( StoneHouse ) & 2 ( IronHouse ), and its default value is 0 ( Grassland(no security) ). Its usage is as follows: #activates IronHouse Security Mechanism options = { 'secure_mode' : 2 } custom_cert_location ( string ): This attribute sets a custom location/path to directory to generate/store Public+Secret Keypair/Certificates for enabling encryption. This attribute will force NetGear to create .vidgear folder (only if not available) at the assigned custom path (instead of home directory) , and then use that directory for storing new Keypairs/Certificates. It can be used as follows: # set custom Keypair location to '/home/foo/foo1/foo2' options = { \"secure_mode\" : 2 , \"custom_cert_location\" : \"/home/foo/foo1/foo2\" , } overwrite_cert ( bool ): [For Server-end only] This attribute sets whether to overwrite existing Public+Secret Keypair/Certificates and re-generate new ones, to protect against any potential security breach. If set to True a new Keypair/Certificates will be generated during NetGear initialization in place of old ones. Its usage is as follows: overwrite_cert parameter is disabled for Client's end! # a new Keypair will be generated options = { \"secure_mode\" : 2 , \"overwrite_cert\" : True }","title":"Supported Attributes"},{"location":"gears/netgear/advanced/secure_mode/#usage-examples","text":"","title":"Usage Examples"},{"location":"gears/netgear/advanced/secure_mode/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with Secure Mode in NetGear API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear/advanced/secure_mode/#server-end","text":"Open your favorite terminal and execute the following python code: You can terminate both sides anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # open any valid video stream(for e.g `test.mp4` file) stream = VideoGear ( source = \"test.mp4\" ) . start () # activate StoneHouse security mechanism options = { \"secure_mode\" : 1 } # Define NetGear Server with defined parameters server = NetGear ( pattern = 1 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear/advanced/secure_mode/#client-end","text":"Then open another terminal on the same system and execute the following python code and see the output: You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate StoneHouse security mechanism options = { \"secure_mode\" : 1 } # define NetGear Client with `receive_mode = True` and defined parameter client = NetGear ( pattern = 1 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client End"},{"location":"gears/netgear/advanced/secure_mode/#using-secure-mode-with-variable-parameters","text":"","title":"Using Secure Mode with Variable Parameters"},{"location":"gears/netgear/advanced/secure_mode/#clients-end","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. You need to paste the Public+Secret Keypairs (generated at the Server End) at the $HOME/.vidgear/keys directory of your Client machine for a successful authentication! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import NetGear import cv2 # activate IronHouse security mechanism options = { \"secure_mode\" : 2 } # Define NetGear Client at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with yours !!! client = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ** options ) # loop over while True : # receive frames from network frame = client . recv () # check for received frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear/advanced/secure_mode/#server-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You also need to copy the Public+Secret Keypairs (generated on running this example code) present in the $HOME/.vidgear/keys directory, and make available at Client's end for a successful authentication. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import required libraries from vidgear.gears import VideoGear from vidgear.gears import NetGear # activate IronHouse security mechanism, and # [BEWARE!!!] generating new Keypairs for this example !!! options = { \"secure_mode\" : 2 , \"overwrite_cert\" : True } # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define NetGear server at given IP address and define parameters # !!! change following IP address '192.168.x.xxx' with client's IP address !!! server = NetGear ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , logging = True , ** options ) # loop over until KeyBoard Interrupted while True : try : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to server server . send ( frame ) except KeyboardInterrupt : break # safely close video stream stream . stop () # safely close server server . close ()","title":"Server End"},{"location":"gears/netgear_async/overview/","text":"NetGear_Async API \u00b6 Overview \u00b6 NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but it doesn't support any of yet. NetGear_Async is built on zmq.asyncio , and powered by a high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API but doesn't support any NetGear's Exclusive Modes yet. Furthermore, NetGear_Async allows us to define our custom Server as source to manipulate frames easily before sending them across the network(see this doc example). In addition to all this, NetGear_Async also provides internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . \u2009 Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API. \u2009 Importing \u00b6 You can import NetGear_Async API in your program as follows: from vidgear.gears.asyncio import NetGear_Async \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/netgear_async/overview/#netgear_async-api","text":"","title":"NetGear_Async API"},{"location":"gears/netgear_async/overview/#overview","text":"NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but it doesn't support any of yet. NetGear_Async is built on zmq.asyncio , and powered by a high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system. NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API but doesn't support any NetGear's Exclusive Modes yet. Furthermore, NetGear_Async allows us to define our custom Server as source to manipulate frames easily before sending them across the network(see this doc example). In addition to all this, NetGear_Async also provides internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network. NetGear_Async as of now supports four ZeroMQ messaging patterns: zmq.PAIR (ZMQ Pair Pattern) zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern) zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern) zmq.PUSH/zmq.PULL (ZMQ Push/Pull Pattern) Whereas supported protocol are: tcp and ipc . \u2009 Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API.","title":"Overview"},{"location":"gears/netgear_async/overview/#importing","text":"You can import NetGear_Async API in your program as follows: from vidgear.gears.asyncio import NetGear_Async","title":"Importing"},{"location":"gears/netgear_async/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/netgear_async/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/netgear_async/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/netgear_async/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/netgear_async/params/","text":"NetGear_Async API Parameters \u00b6 address \u00b6 This parameter sets the valid network address of the Server/Client. Network addresses unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode, i.e 'localhost' for Send Mode and '*' for Receive Mode. Usage: NetGear_Async ( address = \"192.168.0.145\" ) port \u00b6 This parameter sets the valid Network Port of the Server/Client. A network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Data-Type: String Default Value: Its default value is '5555' Usage: NetGear_Async ( port = \"5575\" ) protocol \u00b6 This parameter sets the valid messaging protocol between Server/Client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear_Async ( protocol = \"ipc\" ) pattern \u00b6 This parameter sets the supported messaging pattern(flow of communication) between Server/Client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). All supported ZMQ patterns for NetGear_Async are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. 3 ( .i.e. zmq.PUSH/zmq.PULL ): Its sockets let you distribute messages to multiple workers, arranged in a pipeline. A Push socket will distribute sent messages to its Pull clients evenly. This is equivalent to the producer/consumer model but the results computed by the consumer are not sent upstream but downstream to another pull/consumer socket. Usage: NetGear_Async ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern receive_mode \u00b6 This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear_Async ( receive_mode = True ) # activates Recieve Mode timeout \u00b6 In NetGear_Async, the Receiver-end keeps tracks if frames are received from Server-end within this specified timeout value (in seconds) , Otherwise TimeoutError will be raised, which helps to close the Receiver-end safely if the Server has lost connection prematurely. This parameter controls that timeout value (i.e. the maximum waiting time (in seconds)) after which Client exit itself with a TimeoutError to save resources. Its minimum value is 0.0 but no maximum value. Data-Type: Float/Integer Default Value: Its default value is 10.0 . Usage: NetGear_Async ( timeout = 5.0 ) # sets 5secs timeout Parameters for VideoGear backend \u00b6 enablePiCamera \u00b6 This parameter provide access to PiGear or CamGear APIs respectively. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . Parameters for Stabilizer Backend \u00b6 stabilize \u00b6 This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 . options \u00b6 This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters for CamGear backend \u00b6 Enable this backend with enablePiCamera=False on NetGear_Async. source \u00b6 NetGear_Async API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: NetGear_Async ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: NetGear_Async ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) NetGear_Async automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Youtube URLs: CamGear utilizes pafy with youtube-dl backend. For example \"https://youtu.be/bvetuLwJIkA\" as follows: Valid YouTube URL formats All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} NetGear_Async ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Streaming Websites URLs: CamGear utilizes streamlink backend. For example \"https://www.dailymotion.com/video/x7xsoud\" as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 NetGear_Async ( source = 'https://www.dailymotion.com/video/x7xsoud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: NetGear_Async ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: NetGear_Async ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u00b6 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the NetGear_Async API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . NetGear_Async automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! NetGear_Async will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . backend \u00b6 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . To workaround a FFmpeg bug , NetGear_Async automatically enforce GStreamer backend( backend=cv2.CAP_GSTREAMER ) for YouTube-livestreams in Stream Mode . This behavior discards any backend parameter value for those streams. Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: NetGear_Async ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u00b6 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it NetGear_Async ( source = 0 , ** options ) Parameters for PiGear backend \u00b6 Enable this backend with enablePiCamera=True on NetGear_Async. camera_num \u00b6 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( camera_num = 0 ) resolution \u00b6 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: NetGear_Async ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u00b6 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: NetGear_Async ( framerate = 60 ) # sets 60fps framerate options \u00b6 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it NetGear_Async ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u00b6 colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 NetGear_Async ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the NetGear_Async API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/netgear_async/params/#netgear_async-api-parameters","text":"","title":"NetGear_Async API Parameters"},{"location":"gears/netgear_async/params/#address","text":"This parameter sets the valid network address of the Server/Client. Network addresses unique identifiers across the network. Data-Type: String Default Value: Its default value is based on selected primary mode, i.e 'localhost' for Send Mode and '*' for Receive Mode. Usage: NetGear_Async ( address = \"192.168.0.145\" )","title":"address"},{"location":"gears/netgear_async/params/#port","text":"This parameter sets the valid Network Port of the Server/Client. A network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. Data-Type: String Default Value: Its default value is '5555' Usage: NetGear_Async ( port = \"5575\" )","title":"port"},{"location":"gears/netgear_async/params/#protocol","text":"This parameter sets the valid messaging protocol between Server/Client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: 'tcp' and 'ipc' . Data-Type: String Default Value: Its default value is 'tcp' Usage: NetGear_Async ( protocol = \"ipc\" )","title":"protocol"},{"location":"gears/netgear_async/params/#pattern","text":"This parameter sets the supported messaging pattern(flow of communication) between Server/Client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns. Data-Type: Integer Default Value: Its default value is 0 ( i.e zmq.PAIR ). All supported ZMQ patterns for NetGear_Async are: 0 ( .i.e. zmq.PAIR ): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it. 1 ( .i.e. zmq.REQ/zmq.REP ): In this pattern, it employs ZMQ REQ sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket zmq.REQ will block send unless it has successfully received a reply back and socket zmq.REP will block on recv() unless it has received a request. 2 ( .i.e. zmq.PUB/zmq.SUB ): It is an another classic pattern where senders of messages, called publishers , do not program the messages to be sent directly to specific receivers, called subscribers . Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A ZMQ.SUB can connect to multiple ZMQ.PUB (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved. 3 ( .i.e. zmq.PUSH/zmq.PULL ): Its sockets let you distribute messages to multiple workers, arranged in a pipeline. A Push socket will distribute sent messages to its Pull clients evenly. This is equivalent to the producer/consumer model but the results computed by the consumer are not sent upstream but downstream to another pull/consumer socket. Usage: NetGear_Async ( pattern = 1 ) # sets zmq.REQ/zmq.REP pattern","title":"pattern"},{"location":"gears/netgear_async/params/#receive_mode","text":"This parameter select the Netgear's Mode of operation. It basically activates Receive Mode ( if True ) and Send Mode ( if False ). Furthermore, recv() method will only work when this flag is enabled( i.e. Receive Mode ), whereas send() method will only work when this flag is disabled( i.e. Send Mode ). Data-Type: Boolean Default Value: Its default value is False ( i.e. Send Mode is activated by default ). Usage: NetGear_Async ( receive_mode = True ) # activates Recieve Mode","title":"receive_mode"},{"location":"gears/netgear_async/params/#timeout","text":"In NetGear_Async, the Receiver-end keeps tracks if frames are received from Server-end within this specified timeout value (in seconds) , Otherwise TimeoutError will be raised, which helps to close the Receiver-end safely if the Server has lost connection prematurely. This parameter controls that timeout value (i.e. the maximum waiting time (in seconds)) after which Client exit itself with a TimeoutError to save resources. Its minimum value is 0.0 but no maximum value. Data-Type: Float/Integer Default Value: Its default value is 10.0 . Usage: NetGear_Async ( timeout = 5.0 ) # sets 5secs timeout","title":"timeout"},{"location":"gears/netgear_async/params/#parameters-for-videogear-backend","text":"","title":"Parameters for VideoGear backend"},{"location":"gears/netgear_async/params/#enablepicamera","text":"This parameter provide access to PiGear or CamGear APIs respectively. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/netgear_async/params/#parameters-for-stabilizer-backend","text":"","title":"Parameters for Stabilizer Backend"},{"location":"gears/netgear_async/params/#stabilize","text":"This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/netgear_async/params/#options","text":"This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/netgear_async/params/#parameters-for-camgear-backend","text":"Enable this backend with enablePiCamera=False on NetGear_Async.","title":"Parameters for CamGear backend"},{"location":"gears/netgear_async/params/#source","text":"NetGear_Async API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: NetGear_Async ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: NetGear_Async ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) NetGear_Async automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Youtube URLs: CamGear utilizes pafy with youtube-dl backend. For example \"https://youtu.be/bvetuLwJIkA\" as follows: Valid YouTube URL formats All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} NetGear_Async ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Streaming Websites URLs: CamGear utilizes streamlink backend. For example \"https://www.dailymotion.com/video/x7xsoud\" as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 NetGear_Async ( source = 'https://www.dailymotion.com/video/x7xsoud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: NetGear_Async ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: NetGear_Async ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/netgear_async/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the NetGear_Async API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . NetGear_Async automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! NetGear_Async will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/netgear_async/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . To workaround a FFmpeg bug , NetGear_Async automatically enforce GStreamer backend( backend=cv2.CAP_GSTREAMER ) for YouTube-livestreams in Stream Mode . This behavior discards any backend parameter value for those streams. Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: NetGear_Async ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/netgear_async/params/#options_1","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it NetGear_Async ( source = 0 , ** options )","title":"options"},{"location":"gears/netgear_async/params/#parameters-for-pigear-backend","text":"Enable this backend with enablePiCamera=True on NetGear_Async.","title":"Parameters for PiGear backend"},{"location":"gears/netgear_async/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( camera_num = 0 )","title":"camera_num"},{"location":"gears/netgear_async/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: NetGear_Async ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/netgear_async/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: NetGear_Async ( framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/netgear_async/params/#options_2","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it NetGear_Async ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/netgear_async/params/#common-parameters","text":"","title":"Common Parameters"},{"location":"gears/netgear_async/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 NetGear_Async ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/netgear_async/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: NetGear_Async ( logging = True )","title":"logging"},{"location":"gears/netgear_async/params/#time_delay","text":"This parameter set the time delay (in seconds) before the NetGear_Async API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: NetGear_Async ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/netgear_async/usage/","text":"NetGear_Async API Usage Examples: \u00b6 Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API. Requirement \u00b6 NetGear_Async API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ] Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with NetGear_Async API: Server's End \u00b6 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source server = NetGear_Async ( source = \"/home/foo/foo1.mp4\" ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Client's End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear_Async with Variable Parameters \u00b6 Client's End \u00b6 Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True`. #change following IP address '192.168.x.xxx' with yours client = NetGear_Async ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Server's End \u00b6 Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source server = NetGear_Async ( source = 0 , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , logging = True , ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Using NetGear_Async with a Custom Source(OpenCV) \u00b6 NetGear_Async allows you to easily define your own custom Source at Server-end that you want to use to manipulate your frames before sending them onto the network. Let's implement a bare-minimum example with a Custom Source using NetGear_Async API and OpenCV: Server's End \u00b6 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # initialize Server server = NetGear_Async ( logging = True ) # Create a async frame generator as custom source async def my_frame_generator (): # Open any video stream such as live webcam video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check if frame empty if not grabbed : # if True break the infinite loop break # do something with the frame to be sent here # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0.00001 ) if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Client's End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True , logging = True ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0.01 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () Using NetGear_Async with Other Gears \u00b6 NetGear_Async can be used with any other Gears without any compatibility issues. Let's implement a bare-minimum example where we are sending Stabilized frames from Server-end and saving them at Client's end with WriteGear as follows: Server's End \u00b6 Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source and enable stabilization server = NetGear_Async ( source = \"/home/foo/foo1.mp4\" , stabilize = True , logging = True ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close () Client's End \u00b6 Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears import WriteGear import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () # Define writer with output filename 'Output.mp4' writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # write a modified frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/netgear_async/usage/#netgear_async-api-usage-examples","text":"Helpful Tips It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. It is advised to comprehend NetGear API before using this API.","title":"NetGear_Async API Usage Examples:"},{"location":"gears/netgear_async/usage/#requirement","text":"NetGear_Async API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ]","title":"Requirement"},{"location":"gears/netgear_async/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with NetGear_Async API:","title":"Bare-Minimum Usage"},{"location":"gears/netgear_async/usage/#servers-end","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source server = NetGear_Async ( source = \"/home/foo/foo1.mp4\" ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-variable-parameters","text":"","title":"Using NetGear_Async with Variable Parameters"},{"location":"gears/netgear_async/usage/#clients-end_1","text":"Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: Note down the IP-address of this system(required at Server's end) by executing the command: hostname -I and also replace it in the following code. Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True`. #change following IP address '192.168.x.xxx' with yours client = NetGear_Async ( address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , receive_mode = True , logging = True , ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # do something with received frames here # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#servers-end_1","text":"Now, Open the terminal on another Server System (with a webcam connected to it at index 0 ) , and execute the following python code: Replace the IP address in the following code with Client's IP address you noted earlier. You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source server = NetGear_Async ( source = 0 , address = \"192.168.x.xxx\" , port = \"5454\" , protocol = \"tcp\" , pattern = 2 , logging = True , ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-a-custom-sourceopencv","text":"NetGear_Async allows you to easily define your own custom Source at Server-end that you want to use to manipulate your frames before sending them onto the network. Let's implement a bare-minimum example with a Custom Source using NetGear_Async API and OpenCV:","title":"Using NetGear_Async with a Custom Source(OpenCV)"},{"location":"gears/netgear_async/usage/#servers-end_2","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import library from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # initialize Server server = NetGear_Async ( logging = True ) # Create a async frame generator as custom source async def my_frame_generator (): # Open any video stream such as live webcam video stream on first index(i.e. 0) device stream = cv2 . VideoCapture ( 0 ) # loop over stream until its terminated while True : # read frames ( grabbed , frame ) = stream . read () # check if frame empty if not grabbed : # if True break the infinite loop break # do something with the frame to be sent here # yield frame yield frame # sleep for sometime await asyncio . sleep ( 0.00001 ) if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) # Add your custom source generator to Server configuration server . config [ \"generator\" ] = my_frame_generator () # Launch the Server server . launch () try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end_2","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True , logging = True ) . launch () # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0.01 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close ()","title":"Client's End"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-other-gears","text":"NetGear_Async can be used with any other Gears without any compatibility issues. Let's implement a bare-minimum example where we are sending Stabilized frames from Server-end and saving them at Client's end with WriteGear as follows:","title":"Using NetGear_Async with Other Gears"},{"location":"gears/netgear_async/usage/#servers-end_3","text":"Open your favorite terminal and execute the following python code: You can terminate stream on both side anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async import asyncio # initialize Server with suitable source and enable stabilization server = NetGear_Async ( source = \"/home/foo/foo1.mp4\" , stabilize = True , logging = True ) . launch () if __name__ == \"__main__\" : # set event loop asyncio . set_event_loop ( server . loop ) try : # run your main function task until it is complete server . loop . run_until_complete ( server . task ) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass finally : # finally close the server server . close ()","title":"Server's End"},{"location":"gears/netgear_async/usage/#clients-end_3","text":"Then open another terminal on the same system and execute the following python code and see the output: Client will throw TimeoutError if it fails to connect to the Server in given timeout value! You can terminate client anytime by pressing Ctrl + C on your keyboard! # import libraries from vidgear.gears.asyncio import NetGear_Async from vidgear.gears import WriteGear import cv2 , asyncio # define and launch Client with `receive_mode=True` client = NetGear_Async ( receive_mode = True ) . launch () # Define writer with output filename 'Output.mp4' writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # Create a async function where you want to show/manipulate your received frames async def main (): # loop over Client's Asynchronous Frame Generator async for frame in client . recv_generator (): # {do something with received frames here} # write a modified frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) key = cv2 . waitKey ( 1 ) & 0xFF # await before continuing await asyncio . sleep ( 0.00001 ) if __name__ == \"__main__\" : # Set event loop to client's asyncio . set_event_loop ( client . loop ) try : # run your main function task until it is complete client . loop . run_until_complete ( main ()) except ( KeyboardInterrupt , SystemExit ): # wait for interrupts pass # close all output window cv2 . destroyAllWindows () # safely close client client . close () # safely close writer writer . close ()","title":"Client's End"},{"location":"gears/pigear/overview/","text":"PiGear API \u00b6 Raspberry Pi Camera Module Overview \u00b6 PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards. Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources. Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work. Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u00b6 You can import PiGear API in your program as follows: from vidgear.gears import PiGear \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/pigear/overview/#pigear-api","text":"Raspberry Pi Camera Module","title":"PiGear API"},{"location":"gears/pigear/overview/#overview","text":"PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module) . PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards. Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources. Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work. Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/pigear/overview/#importing","text":"You can import PiGear API in your program as follows: from vidgear.gears import PiGear","title":"Importing"},{"location":"gears/pigear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/pigear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/pigear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/pigear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/pigear/params/","text":"PiGear API Parameters \u00b6 \u2009 camera_num \u00b6 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( camera_num = 0 ) resolution \u00b6 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: PiGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u00b6 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: PiGear ( framerate = 60 ) # sets 60fps framerate colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 PiGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 options \u00b6 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it PiGear ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: PiGear ( logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/pigear/params/#pigear-api-parameters","text":"","title":"PiGear API Parameters"},{"location":"gears/pigear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( camera_num = 0 )","title":"camera_num"},{"location":"gears/pigear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: PiGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/pigear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: PiGear ( framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/pigear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 PiGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/pigear/params/#options","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it PiGear ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/pigear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: PiGear ( logging = True )","title":"logging"},{"location":"gears/pigear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: PiGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/pigear/usage/","text":"PiGear API Usage Examples: \u00b6 Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work. \u2009 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with PiGear API: # import required libraries from vidgear.gears import PiGear import cv2 # open pi video stream with default parameters stream = PiGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using PiGear with Variable Camera Module Properties \u00b6 PiGear supports almost every parameter available within Picamera library . These parameters can be easily applied to the source stream in PiGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All supported parameters are listed in PiCamera Docs \u27b6 # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using PiGear with Direct Colorspace Manipulation \u00b6 PiGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-Type value will immediately revert the colorspace to default (i.e. BGR ) . # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters and change colorspace to `HSV` stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , colorspace = \"COLOR_BGR2HSV\" , logging = True , ** options ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Usage Examples"},{"location":"gears/pigear/usage/#pigear-api-usage-examples","text":"Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work.","title":"PiGear API Usage Examples:"},{"location":"gears/pigear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with PiGear API: # import required libraries from vidgear.gears import PiGear import cv2 # open pi video stream with default parameters stream = PiGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/pigear/usage/#using-pigear-with-variable-camera-module-properties","text":"PiGear supports almost every parameter available within Picamera library . These parameters can be easily applied to the source stream in PiGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: All supported parameters are listed in PiCamera Docs \u27b6 # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using PiGear with Variable Camera Module Properties"},{"location":"gears/pigear/usage/#using-pigear-with-direct-colorspace-manipulation","text":"PiGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-Type value will immediately revert the colorspace to default (i.e. BGR ) . # import required libraries from vidgear.gears import PiGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # open pi video stream with defined parameters and change colorspace to `HSV` stream = PiGear ( resolution = ( 640 , 480 ), framerate = 60 , colorspace = \"COLOR_BGR2HSV\" , logging = True , ** options ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using PiGear with Direct Colorspace Manipulation"},{"location":"gears/screengear/overview/","text":"ScreenGear API \u00b6 ScreenGear API in action Overview \u00b6 ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. ScreenGear API implements a multi-threaded wrapper around pyscreenshot & python-mss python library, and also flexibly supports its internal parameter. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV Library \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u00b6 You can import ScreenGear API in your program as follows: from vidgear.gears import ScreenGear \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/screengear/overview/#screengear-api","text":"ScreenGear API in action","title":"ScreenGear API"},{"location":"gears/screengear/overview/#overview","text":"ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. ScreenGear API implements a multi-threaded wrapper around pyscreenshot & python-mss python library, and also flexibly supports its internal parameter. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV Library \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/screengear/overview/#importing","text":"You can import ScreenGear API in your program as follows: from vidgear.gears import ScreenGear","title":"Importing"},{"location":"gears/screengear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/screengear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/screengear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/screengear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/screengear/params/","text":"ScreenGear API Parameters \u00b6 monitor \u00b6 This parameter enables mss usage and sets the index of the monitor screen. This parameter is the most suitable for selecting index of multiple monitor screen from where you want get frames from. For example, its value can be assign to -1 , to fetch frames from all connected multiple monitor screens. More information can be found here \u27b6 Any value on monitor parameter will disable the backend parameter. Data-Type: Integer Default Value: Its default value is None (i.e. disabled by default) . Usage: ScreenGear ( monitor =- 1 ) # to fetch frames from all connected multiple screens backend \u00b6 This parameter enables pyscreenshot usage and select suitable backend for extracting frames in ScreenGear. The user have the authority of selecting suitable backend which generates best performance as well as the most compatible with their machines. The possible values are: pil , mss , scrot , maim , imagemagick , pyqt5 , pyqt , pyside2 , pyside , wx , pygdk3 , mac_screencapture , mac_quartz , gnome_dbus , gnome-screenshot , kwin_dbus . More information on these backends can be found here \u27b6 Performance Benchmarking of each backend can be found here \u27b6 Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API. Any value on monitor parameter will disable the backend parameter. You cannot use both parameters at same time. Data-Type: String Default Value: Its default value is \"\" (i.e. default backend) . Usage: ScreenGear ( backend = \"mss\" ) # to enforce `mss` as backend for extracting frames. colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 . ScreenGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 options \u00b6 This parameter provides the flexibility to manually set the dimensions of capture screen area. Supported Dimensional Parameters Supported Dimensional Parameters are as follows: left : the x-coordinate of the upper-left corner of the region top : the y-coordinate of the upper-left corner of the region width : the width of the region height : the height of the region Data-Type: Dictionary Default Value: Its default value is {} Usage: The desired dimensional parameters can be passed to ScreenGear API by formatting them as attributes, as follows: More information about screen dimensioning can be found here \u27b6 # formatting dimensional parameters as dictionary attributes options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # assigning it w.r.t monitor=1 ScreenGear ( monitor = 1 , ** options ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: ScreenGear ( logging = True )","title":"Parameters"},{"location":"gears/screengear/params/#screengear-api-parameters","text":"","title":"ScreenGear API Parameters"},{"location":"gears/screengear/params/#monitor","text":"This parameter enables mss usage and sets the index of the monitor screen. This parameter is the most suitable for selecting index of multiple monitor screen from where you want get frames from. For example, its value can be assign to -1 , to fetch frames from all connected multiple monitor screens. More information can be found here \u27b6 Any value on monitor parameter will disable the backend parameter. Data-Type: Integer Default Value: Its default value is None (i.e. disabled by default) . Usage: ScreenGear ( monitor =- 1 ) # to fetch frames from all connected multiple screens","title":"monitor"},{"location":"gears/screengear/params/#backend","text":"This parameter enables pyscreenshot usage and select suitable backend for extracting frames in ScreenGear. The user have the authority of selecting suitable backend which generates best performance as well as the most compatible with their machines. The possible values are: pil , mss , scrot , maim , imagemagick , pyqt5 , pyqt , pyside2 , pyside , wx , pygdk3 , mac_screencapture , mac_quartz , gnome_dbus , gnome-screenshot , kwin_dbus . More information on these backends can be found here \u27b6 Performance Benchmarking of each backend can be found here \u27b6 Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API. Any value on monitor parameter will disable the backend parameter. You cannot use both parameters at same time. Data-Type: String Default Value: Its default value is \"\" (i.e. default backend) . Usage: ScreenGear ( backend = \"mss\" ) # to enforce `mss` as backend for extracting frames.","title":"backend"},{"location":"gears/screengear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 . ScreenGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/screengear/params/#options","text":"This parameter provides the flexibility to manually set the dimensions of capture screen area. Supported Dimensional Parameters Supported Dimensional Parameters are as follows: left : the x-coordinate of the upper-left corner of the region top : the y-coordinate of the upper-left corner of the region width : the width of the region height : the height of the region Data-Type: Dictionary Default Value: Its default value is {} Usage: The desired dimensional parameters can be passed to ScreenGear API by formatting them as attributes, as follows: More information about screen dimensioning can be found here \u27b6 # formatting dimensional parameters as dictionary attributes options = { 'top' : 40 , 'left' : 0 , 'width' : 100 , 'height' : 100 } # assigning it w.r.t monitor=1 ScreenGear ( monitor = 1 , ** options )","title":"options"},{"location":"gears/screengear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: ScreenGear ( logging = True )","title":"logging"},{"location":"gears/screengear/usage/","text":"ScreenGear API Usage Examples: \u00b6 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with ScreenGear API: # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with default parameters stream = ScreenGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Variable Screen Dimensions \u00b6 ScreenGear API provides us the flexibility to directly set the dimensions of capturing-area of the screen. These dimensions can be easily applied to ScreenGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: # import required libraries from vidgear.gears import ScreenGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # open video stream with defined parameters stream = ScreenGear ( logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Multiple Screens \u00b6 ScreenGear API provides us the flexibility to select any connected display for fetching frames, with its monitor parameter: You can assign monitor value to -1 to fetch frames from all connected multiple monitor screens. Any value on monitor parameter will disable the backend parameter. # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with defined parameters with monitor at index `1` selected stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Variable Backend \u00b6 With ScreenGear API, you can select from many different backends that generates best performance as well as the most compatible with our machine by employing its backend parameter that supports pil , mss , scrot , maim , imagemagick , pyqt5 , pyqt , pyside2 , pyside , wx , pygdk3 , mac_screencapture , mac_quartz , gnome_dbus , gnome-screenshot , kwin_dbus like many different parameters easily: Remember to install backend library and all of its dependencies, you're planning to use with ScreenGear API. More information on these backends can be found here \u27b6 Any value on monitor parameter will disable the backend parameter. You cannot use them simultaneously. # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with defined parameters and `mss` backend for extracting frames. stream = ScreenGear ( backend = \"mss\" , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with Direct Colorspace Manipulation \u00b6 ScreenGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import ScreenGear import cv2 # Change colorspace to `HSV` stream = ScreenGear ( colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using ScreenGear with WriteGear API \u00b6 ScreenGear can be used in conjunction with WriteGear API directly without any compatibility issues. The suitable example is as follows: # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import WriteGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open video stream with defined parameters stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/screengear/usage/#screengear-api-usage-examples","text":"","title":"ScreenGear API Usage Examples:"},{"location":"gears/screengear/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with ScreenGear API: # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with default parameters stream = ScreenGear () . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage"},{"location":"gears/screengear/usage/#using-screengear-with-variable-screen-dimensions","text":"ScreenGear API provides us the flexibility to directly set the dimensions of capturing-area of the screen. These dimensions can be easily applied to ScreenGear API through its options dictionary parameter by formatting them as its attributes. The complete usage example is as follows: # import required libraries from vidgear.gears import ScreenGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # open video stream with defined parameters stream = ScreenGear ( logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Variable Screen Dimensions"},{"location":"gears/screengear/usage/#using-screengear-with-multiple-screens","text":"ScreenGear API provides us the flexibility to select any connected display for fetching frames, with its monitor parameter: You can assign monitor value to -1 to fetch frames from all connected multiple monitor screens. Any value on monitor parameter will disable the backend parameter. # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with defined parameters with monitor at index `1` selected stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Multiple Screens"},{"location":"gears/screengear/usage/#using-screengear-with-variable-backend","text":"With ScreenGear API, you can select from many different backends that generates best performance as well as the most compatible with our machine by employing its backend parameter that supports pil , mss , scrot , maim , imagemagick , pyqt5 , pyqt , pyside2 , pyside , wx , pygdk3 , mac_screencapture , mac_quartz , gnome_dbus , gnome-screenshot , kwin_dbus like many different parameters easily: Remember to install backend library and all of its dependencies, you're planning to use with ScreenGear API. More information on these backends can be found here \u27b6 Any value on monitor parameter will disable the backend parameter. You cannot use them simultaneously. # import required libraries from vidgear.gears import ScreenGear import cv2 # open video stream with defined parameters and `mss` backend for extracting frames. stream = ScreenGear ( backend = \"mss\" , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Variable Backend"},{"location":"gears/screengear/usage/#using-screengear-with-direct-colorspace-manipulation","text":"ScreenGear API also supports Direct Colorspace Manipulation , which is ideal for changing source colorspace on the run. A more detailed information on colorspace manipulation can be found here \u27b6 In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY colorspace when w key is pressed, and then LAB colorspace when e key is pressed, finally default colorspace (i.e. BGR ) when s key is pressed. Also, quit when q key is pressed: Any incorrect or None-type value, will immediately revert the colorspace to default i.e. BGR . # import required libraries from vidgear.gears import ScreenGear import cv2 # Change colorspace to `HSV` stream = ScreenGear ( colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check if 'w' key is pressed if key == ord ( \"w\" ): # directly change colorspace at any instant stream . color_space = cv2 . COLOR_BGR2GRAY # Now colorspace is GRAY # check for 'e' key is pressed if key == ord ( \"e\" ): stream . color_space = cv2 . COLOR_BGR2LAB # Now colorspace is CieLAB # check for 's' key is pressed if key == ord ( \"s\" ): stream . color_space = None # Now colorspace is default(ie BGR) # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using ScreenGear with Direct Colorspace Manipulation"},{"location":"gears/screengear/usage/#using-screengear-with-writegear-api","text":"ScreenGear can be used in conjunction with WriteGear API directly without any compatibility issues. The suitable example is as follows: # import required libraries from vidgear.gears import ScreenGear from vidgear.gears import WriteGear import cv2 # define dimensions of screen w.r.t to given monitor to be captured options = { \"top\" : 40 , \"left\" : 0 , \"width\" : 100 , \"height\" : 100 } # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # open video stream with defined parameters stream = ScreenGear ( monitor = 1 , logging = True , ** options ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using ScreenGear with WriteGear API"},{"location":"gears/stabilizer/overview/","text":"Stabilizer Class \u00b6 VidGear's Stabilizer in Action (Original Video Courtesy @SIGGRAPH2013 ) This video is transcoded with StreamGear API and hosted on GitHub Repository and served with raw.githack.com Overview \u00b6 Stabilizer is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free & ultra-fast frame handling. \u2009 Features \u00b6 Real-time stabilization with low latency and no extra resources. Works exceptionally well with low-frequency jitter. Integrated with VideoGear , therefore, can be applied to any incoming stream. Also seamlessly works standalone. \u2009 Important The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors. \u2009 Importing \u00b6 You can import Stabilizer Class in your program as follows: from vidgear.gears.stabilizer import Stabilizer \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/stabilizer/overview/#stabilizer-class","text":"VidGear's Stabilizer in Action (Original Video Courtesy @SIGGRAPH2013 ) This video is transcoded with StreamGear API and hosted on GitHub Repository and served with raw.githack.com","title":"Stabilizer Class"},{"location":"gears/stabilizer/overview/#overview","text":"Stabilizer is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free & ultra-fast frame handling.","title":"Overview"},{"location":"gears/stabilizer/overview/#features","text":"Real-time stabilization with low latency and no extra resources. Works exceptionally well with low-frequency jitter. Integrated with VideoGear , therefore, can be applied to any incoming stream. Also seamlessly works standalone. \u2009 Important The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors.","title":"Features"},{"location":"gears/stabilizer/overview/#importing","text":"You can import Stabilizer Class in your program as follows: from vidgear.gears.stabilizer import Stabilizer","title":"Importing"},{"location":"gears/stabilizer/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/stabilizer/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/stabilizer/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/stabilizer/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/stabilizer/params/","text":"Stabilizer Class Parameters \u00b6 smoothing_radius \u00b6 This parameter can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Data-Type: Integer Default Value: Its default value is 25 . Usage: You can easily pass this parameter as follows: Stabilizer ( smoothing_radius = 30 ) border_size \u00b6 This parameter enables and set the value for extended border size that compensates for reduction of black borders during stabilization. Data-Type: Integer Default Value: Its default value is 0 (no borders). Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 ) crop_n_zoom \u00b6 This parameter enables cropping and zooming of frames (to original size) to reduce the black borders from being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) during stabilization. It simply works in conjunction with the border_size parameter, i.e. when this parameter is enabled, border_size will be used for cropping border instead of extending them. Data-Type: Boolean Default Value: Its default value is False . Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 , crop_n_zoom = True ) border_type \u00b6 This parameter can be used to change the extended border type. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Altering border_type parameter is DISABLED when crop_n_zoom is enabled! Data-Type: String Default Value: Its default value is 'black' . Usage: You can easily pass this parameter as follows: Stabilizer ( border_type = 'reflect' ) logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: Stabilizer ( logging = True )","title":"Parameters"},{"location":"gears/stabilizer/params/#stabilizer-class-parameters","text":"","title":"Stabilizer Class Parameters"},{"location":"gears/stabilizer/params/#smoothing_radius","text":"This parameter can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Data-Type: Integer Default Value: Its default value is 25 . Usage: You can easily pass this parameter as follows: Stabilizer ( smoothing_radius = 30 )","title":"smoothing_radius"},{"location":"gears/stabilizer/params/#border_size","text":"This parameter enables and set the value for extended border size that compensates for reduction of black borders during stabilization. Data-Type: Integer Default Value: Its default value is 0 (no borders). Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 )","title":"border_size"},{"location":"gears/stabilizer/params/#crop_n_zoom","text":"This parameter enables cropping and zooming of frames (to original size) to reduce the black borders from being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) during stabilization. It simply works in conjunction with the border_size parameter, i.e. when this parameter is enabled, border_size will be used for cropping border instead of extending them. Data-Type: Boolean Default Value: Its default value is False . Usage: You can easily pass this parameter as follows: Stabilizer ( border_size = 10 , crop_n_zoom = True )","title":"crop_n_zoom"},{"location":"gears/stabilizer/params/#border_type","text":"This parameter can be used to change the extended border type. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Altering border_type parameter is DISABLED when crop_n_zoom is enabled! Data-Type: String Default Value: Its default value is 'black' . Usage: You can easily pass this parameter as follows: Stabilizer ( border_type = 'reflect' )","title":"border_type"},{"location":"gears/stabilizer/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: Stabilizer ( logging = True )","title":"logging"},{"location":"gears/stabilizer/usage/","text":"Stabilizer Class Usage Examples: \u00b6 \u2009 The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors. \u2009 \u2009 Bare-Minimum Usage with VideoCapture Gears \u00b6 Following is the bare-minimum code you need to get started with Stabilizer Class and various VideoCapture Gears: You can use any VideoCapture Gear instead of CamGear in the similar manner, as shown in this usage example. # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized_frame frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop () Bare-Minimum Usage with OpenCV \u00b6 The VidGear's stabilizer class can also work standalone easily with any Computer Vision library such as OpenCV itself. Following is the bare-minimum code you need to get started with Stabilizer Class and OpenCV: # import required libraries from vidgear.gears.stabilizer import Stabilizer import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the frame here} # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . release () Using Stabilizer with Variable Parameters \u00b6 Stabilizer class provide certain parameters which you can use to manipulate its internal properties. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized_frame frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop () Using Stabilizer with WriteGear \u00b6 VideoGear's stabilizer can be used in conjunction with WriteGear API directly without any compatibility issues. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream stream = CamGear ( source = \"unstabilized_stream.mp4\" ) . start () # initiate stabilizer object with default parameters stab = Stabilizer () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop () # safely close writer writer . close () Using VideoGear with Stabilizer backend \u00b6 VideoGear API provides a special internal wrapper around Stabilizer class that enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. The complete usage example can be found here \u27b6","title":"Usage Examples"},{"location":"gears/stabilizer/usage/#stabilizer-class-usage-examples","text":"The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk! The stabilizer might be slower for High-Quality videos-frames. It is advised to enable logging on the first run for easily identifying any runtime errors.","title":"Stabilizer Class Usage Examples:"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-videocapture-gears","text":"Following is the bare-minimum code you need to get started with Stabilizer Class and various VideoCapture Gears: You can use any VideoCapture Gear instead of CamGear in the similar manner, as shown in this usage example. # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized_frame frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with VideoCapture Gears"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-opencv","text":"The VidGear's stabilizer class can also work standalone easily with any Computer Vision library such as OpenCV itself. Following is the bare-minimum code you need to get started with Stabilizer Class and OpenCV: # import required libraries from vidgear.gears.stabilizer import Stabilizer import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # initiate stabilizer object with default parameters stab = Stabilizer () # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the frame here} # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . release ()","title":"Bare-Minimum Usage with OpenCV"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-variable-parameters","text":"Stabilizer class provide certain parameters which you can use to manipulate its internal properties. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear import cv2 # To open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # initiate stabilizer object with defined parameters stab = Stabilizer ( smoothing_radius = 30 , crop_n_zoom = True , border_size = 5 , logging = True ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the stabilized_frame frame here} # Show output window cv2 . imshow ( \"Output Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop ()","title":"Using Stabilizer with Variable Parameters"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-writegear","text":"VideoGear's stabilizer can be used in conjunction with WriteGear API directly without any compatibility issues. The complete usage example is as follows: # import required libraries from vidgear.gears.stabilizer import Stabilizer from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open suitable video stream stream = CamGear ( source = \"unstabilized_stream.mp4\" ) . start () # initiate stabilizer object with default parameters stab = Stabilizer () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if not None-type if frame is None : break # send current frame to stabilizer for processing stabilized_frame = stab . stabilize ( frame ) # wait for stabilizer which still be initializing if stabilized_frame is None : continue # {do something with the frame here} # write stabilized frame to writer writer . write ( stabilized_frame ) # Show output window cv2 . imshow ( \"Stabilized Frame\" , stabilized_frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # clear stabilizer resources stab . clean () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Stabilizer with WriteGear"},{"location":"gears/stabilizer/usage/#using-videogear-with-stabilizer-backend","text":"VideoGear API provides a special internal wrapper around Stabilizer class that enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. The complete usage example can be found here \u27b6","title":"Using VideoGear with Stabilizer backend"},{"location":"gears/streamgear/ffmpeg_install/","text":"FFmpeg Installation Instructions \u00b6 StreamGear must requires FFmpeg executables for transcoding Media Chunks. You can following machine-specific instructions for its installation: StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. Enable logging ( logging=True ) for debugging FFmpeg validation process. Linux FFmpeg Installation \u00b6 The StreamGear API supports Auto-Detection and Manual Configuration methods on a Linux machine: A. Auto-Detection \u00b6 This is a recommended approach on Linux Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError ! Windows FFmpeg Installation \u00b6 The StreamGear API supports Auto-Installation and Manual Configuration methods on Windows systems. A. Auto-Installation \u00b6 This is a recommended approach on Windows Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system StreamGear API auto-generates the required FFmpeg Static Binaries, according to your system specifications, into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, StreamGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then StreamGear API will exit with RuntimeError ! B. Manual Configuration \u00b6 Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: http://ffmpeg.zeranoe.com/builds/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError ! MacOS FFmpeg Installation \u00b6 The StreamGear API supports Auto-Detection and Manual Configuration methods on a macOS machine. A. Auto-Detection \u00b6 This is a recommended approach on MacOS Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#ffmpeg-installation-instructions","text":"StreamGear must requires FFmpeg executables for transcoding Media Chunks. You can following machine-specific instructions for its installation: StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. Enable logging ( logging=True ) for debugging FFmpeg validation process.","title":"FFmpeg Installation Instructions"},{"location":"gears/streamgear/ffmpeg_install/#linux-ffmpeg-installation","text":"The StreamGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:","title":"Linux FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection","text":"This is a recommended approach on Linux Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6","title":"A. Auto-Detection"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration","text":"Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/ffmpeg_install/#windows-ffmpeg-installation","text":"The StreamGear API supports Auto-Installation and Manual Configuration methods on Windows systems.","title":"Windows FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-installation","text":"This is a recommended approach on Windows Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system StreamGear API auto-generates the required FFmpeg Static Binaries, according to your system specifications, into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, StreamGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then StreamGear API will exit with RuntimeError !","title":"A. Auto-Installation"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_1","text":"Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: http://ffmpeg.zeranoe.com/builds/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/ffmpeg_install/#macos-ffmpeg-installation","text":"The StreamGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.","title":"MacOS FFmpeg Installation"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection_1","text":"This is a recommended approach on MacOS Machines If StreamGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6","title":"A. Auto-Detection"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_2","text":"Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the StreamGear API. If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"gears/streamgear/overview/","text":"StreamGear API \u00b6 StreamGear API's generalized workflow Overview \u00b6 StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content. SteamGear easily transcodes source videos/audio files & real-time video-frames and breaks them into a sequence of multiple smaller chunks/segments of fixed length. These segments make it possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests. SteamGear also creates a Manifest file (such as MPD in-case of DASH) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session. SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. Also, Multiple DRM support is yet to be implemented. \u2009 Important StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. It is advised to enable logging ( logging=True ) on the first run for easily identifying any runtime errors. \u2009 Mode of Operations \u00b6 StreamGear primarily works in two independent modes for transcoding which serves different purposes. These modes are as follows: A. Single-Source Mode \u00b6 In this mode, StreamGear transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well, when you're transcoding lossless long-duration videos(with audio) for streaming and required no extra efforts or interruptions. But on the downside, the provided source cannot be changed or manipulated before sending onto FFmpeg Pipeline for processing. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. Learn more about this mode here \u27b6 B. Real-time Frames Mode \u00b6 When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller chunks/segments for streaming. In this mode, StreamGear supports real-time numpy.ndarray frames, and process them over FFmpeg pipeline. But on the downside, audio has to added manually (as separate source) for streams. Learn more about this mode here \u27b6 \u2009 Importing \u00b6 You can import StreamGear API in your program as follows: from vidgear.gears import StreamGear \u2009 Watch Demo \u00b6 Watch StreamGear transcoded MPEG-DASH Stream: Powered by clappr & shaka-player This video assets (Manifest and segments) are hosted on GitHub Repository and served with raw.githack.com \u2009 Recommended Stream Players \u00b6 GUI Players \u00b6 MPV Player : (recommended) MPV is a free, open source, and cross-platform media player. It supports a wide variety of media file formats, audio and video codecs, and subtitle types. VLC Player : VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols. Parole : (UNIX only) Parole is a modern simple media player based on the GStreamer framework for Unix and Unix-like operating systems. Command-Line Players \u00b6 MP4Client : GPAC provides a highly configurable multimedia player called MP4Client. GPAC itself is an open source multimedia framework developed for research and academic purposes, and used in many media production chains. ffplay : FFplay is a very simple and portable media player using the FFmpeg libraries and the SDL library. It is mostly used as a testbed for the various FFmpeg APIs. Online Players \u00b6 To run Online players locally, you'll need a HTTP server. For creating one yourself, See this well-curated list \u27b6 Clapper : Clappr is an extensible media player for the web. Shaka Player : Shaka Player is an open-source JavaScript library for playing adaptive media in a browser. MediaElementPlayer : MediaElementPlayer is a complete HTML/CSS audio/video player. \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/streamgear/overview/#streamgear-api","text":"StreamGear API's generalized workflow","title":"StreamGear API"},{"location":"gears/streamgear/overview/#overview","text":"StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content. SteamGear easily transcodes source videos/audio files & real-time video-frames and breaks them into a sequence of multiple smaller chunks/segments of fixed length. These segments make it possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests. SteamGear also creates a Manifest file (such as MPD in-case of DASH) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session. SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. Also, Multiple DRM support is yet to be implemented. \u2009 Important StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. It is advised to enable logging ( logging=True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/streamgear/overview/#mode-of-operations","text":"StreamGear primarily works in two independent modes for transcoding which serves different purposes. These modes are as follows:","title":"Mode of Operations"},{"location":"gears/streamgear/overview/#a-single-source-mode","text":"In this mode, StreamGear transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well, when you're transcoding lossless long-duration videos(with audio) for streaming and required no extra efforts or interruptions. But on the downside, the provided source cannot be changed or manipulated before sending onto FFmpeg Pipeline for processing. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. Learn more about this mode here \u27b6","title":"A. Single-Source Mode"},{"location":"gears/streamgear/overview/#b-real-time-frames-mode","text":"When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes video-frames (as opposed to a entire file) , into a sequence of multiple smaller chunks/segments for streaming. In this mode, StreamGear supports real-time numpy.ndarray frames, and process them over FFmpeg pipeline. But on the downside, audio has to added manually (as separate source) for streams. Learn more about this mode here \u27b6","title":"B. Real-time Frames Mode"},{"location":"gears/streamgear/overview/#importing","text":"You can import StreamGear API in your program as follows: from vidgear.gears import StreamGear","title":"Importing"},{"location":"gears/streamgear/overview/#watch-demo","text":"Watch StreamGear transcoded MPEG-DASH Stream: Powered by clappr & shaka-player This video assets (Manifest and segments) are hosted on GitHub Repository and served with raw.githack.com","title":"Watch Demo"},{"location":"gears/streamgear/overview/#recommended-stream-players","text":"","title":"Recommended Stream Players"},{"location":"gears/streamgear/overview/#gui-players","text":"MPV Player : (recommended) MPV is a free, open source, and cross-platform media player. It supports a wide variety of media file formats, audio and video codecs, and subtitle types. VLC Player : VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols. Parole : (UNIX only) Parole is a modern simple media player based on the GStreamer framework for Unix and Unix-like operating systems.","title":"GUI Players"},{"location":"gears/streamgear/overview/#command-line-players","text":"MP4Client : GPAC provides a highly configurable multimedia player called MP4Client. GPAC itself is an open source multimedia framework developed for research and academic purposes, and used in many media production chains. ffplay : FFplay is a very simple and portable media player using the FFmpeg libraries and the SDL library. It is mostly used as a testbed for the various FFmpeg APIs.","title":"Command-Line Players"},{"location":"gears/streamgear/overview/#online-players","text":"To run Online players locally, you'll need a HTTP server. For creating one yourself, See this well-curated list \u27b6 Clapper : Clappr is an extensible media player for the web. Shaka Player : Shaka Player is an open-source JavaScript library for playing adaptive media in a browser. MediaElementPlayer : MediaElementPlayer is a complete HTML/CSS audio/video player.","title":"Online Players"},{"location":"gears/streamgear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/streamgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/streamgear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/streamgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/streamgear/params/","text":"StreamGear API Parameters \u00b6 output \u00b6 This parameter sets the valid filename/path for storing the StreamGear assets (Manifest file(such as Media Presentation Description(MPD) in-case of DASH) & Transcoded sequence of segments) . StreamGear API will throw ValueError if output provided is empty or invalid. StreamGear generated sequence of multiple chunks/segments are also stored in the same directory. You can easily delete all previous assets at output location, by using -clear_prev_assets attribute of stream_params dictionary parameter. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory. In this case, StreamGear API will automatically assign a unique filename for Manifest file. This can be defined as follows: streamer = StreamGear ( output = '/home/foo/foo1' ) # Define streamer with manifest saving directory path Filename (with/without path) : Valid filename( with valid extension ) of the output Manifest file. In case filename is provided without path, then current working directory will be used. streamer = StreamGear ( output = 'output_foo.mpd' ) # Define streamer with manifest file name Make sure to provide valid filename with valid file-extension for selected format value (such as output.mpd in case of MPEG-DASH) , otherwise StreamGear will throw AssertionError . URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for directly storing assets to a network server. For example, you can use a http protocol URL as follows: streamer = StreamGear ( output = 'http://195.167.1.101/live/test.mpd' ) #Define streamer formats \u00b6 This parameter select the adaptive HTTP streaming format. HTTP streaming works by breaking the overall stream into a sequence of small HTTP-based file downloads, each downloading one short chunk of an overall potentially unbounded transport stream. For now, the only supported format is: 'dash' (i.e MPEG-DASH ) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. Data-Type: String Default Value: Its default value is 'dash' Usage: StreamGear ( output = 'output_foo.mpd' , format = \"dash\" ) custom_ffmpeg \u00b6 This parameter assigns the custom path/directory where the custom/downloaded FFmpeg executables are located. Behavior on Windows If a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then StreamGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" StreamGear ( output = 'output_foo.mpd' , custom_ffmpeg = \"/foo/foo1/ffmpeg\" ) stream_params \u00b6 This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly change its internal settings for transcoding and seamlessly generating high-quality streams. All supported parameters can formatting as attributes for this dictionary parameter: Kindly read FFmpeg Docs carefully, before passing any additional values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u00b6 A. Exclusive Parameters \u00b6 StreamGear API provides some exclusive internal parameters to easily generate Streaming Assets and effortlessly tweak its internal properties. These parameters are discussed below: -streams (list of dicts) : This important attribute makes it simple and pretty straight-forward to define additional multiple streams as list of dictionaries of different quality levels (i.e. different bitrates or spatial resolutions) for streaming. Important -streams attribute facts On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input Video, at the index 0 . You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. To construct the additional stream dictionaries, you'll will need following sub-attributes: -resolution (string) : It is compulsory to define the required resolution/dimension/size for the stream, otherwise given stream will be rejected. Its value can be a \"{width}x{height}\" as follows: \"-streams\" = [{ \"-resolution\" : \"1280x720\" }] # to produce a 1280x720 resolution/scale \u2002 -video_bitrate (string) : It is an optional (can be ignored if -framerate parameter is defined) sub-attribute that generally determines the bandwidth and quality of stream, i.e. the higher the bitrate, the better the quality and the larger will be bandwidth and more will be strain on network. It value is generally in kbps (kilobits per second) for OBS (Open Broadcasting Softwares). You can easily define this attribute as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"2000k\" }] # to produce a 1280x720 resolution and 2000kbps bitrate stream \u2002 -framerate (float/int) : It is another optional (can be ignored if -video_bitrate parameter is defined) sub-attribute that defines the assumed framerate for the stream. Thereby, StreamGear automatically appropriate calculates the suitable video-bitrate using its value along with -bpps and -resolution values , so you don't have to. It's value can be float/integer as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-framerate\" : \"60.0\" }] # to produce a 1280x720 resolution and 60fps framerate stream \u2002 Usage: You can easily define any number of streams using -streams attribute as follows: Usage example can be found here \u27b6 stream_params = { \"-streams\" : [{ \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : \"30.0\" }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : \"60.0\" }, # Stream3: 640x360 at 60fps ]} \u2002 -video_source (string) : This attribute takes valid Video path as input and activates Single-Source Mode , for transcoding it into multiple smaller chunks/segments for streaming after successful validation. Its value be one of the following: Usage example can be found here \u27b6 Video Filename : Valid path to Video file as follows: stream_params = { \"-video_source\" : \"/home/foo/foo1.mp4\" } # set input video source: /home/foo/foo1.mp4 Video URL : Valid URL of a network video stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-video_source\" : \"http://livefeed.com:5050\" } # set input video source: http://livefeed.com:5050 \u2002 -audio (dict) : This attribute takes external custom audio path as audio-input for all StreamGear streams. Its value be one of the following: Make sure this audio-source is compatible with provided video -source, otherwise you encounter multiple errors, or even no output at all! Usage example can be found here \u27b6 Audio Filename : Valid path to Audio file as follows: stream_params = { \"-audio\" : \"/home/foo/foo1.aac\" } # set input audio source: /home/foo/foo1.aac Audio URL : Valid URL of a network audio stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-audio\" : \"https://exampleaudio.org/example-160.mp3\" } # set input audio source: https://exampleaudio.org/example-160.mp3 \u2002 -livestream (bool) : (optional) specifies whether to enable Livestream Support (chunks will contain information for new frames only) for the selected mode, or not. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: Use window_size & extra_window_size FFmpeg parameters for controlling number of frames to be kept in New Chunks. stream_params = { \"-livestream\" : True } # enable livestreaming \u2002 -input_framerate (float/int) : (optional) specifies the assumed input video source framerate, and only works in Real-time Frames Mode . It can be used as follows: Usage example can be found here \u27b6 stream_params = { \"-input_framerate\" : 60.0 } # set input video source framerate to 60fps \u2002 -bpp (float/int) : (optional) This attribute controls constant Bits-Per-Pixel (BPP) value, which is kind of a constant value to ensure good quality of high motion scenes ,and thereby used in calculating desired video-bitrate for streams. Higher the BPP, better will be motion quality. Its default value is 0.1 . Going over 0.1 helps to fill gaps between current bitrate and upload limit/ingest cap. Its value can be anything above 0.001 , can be used as follows: Important BPP tips for streaming -bpp a sensitive value, try 0.001, and then make increments in 0.0001 to fine tune If your desired resolution/fps/audio combination is below maximum service bitrate, raise BPP to match it for extra quality. It is generally better to lower resolution (and/or fps) and raise BPP than raise resolution and loose on BPP. stream_params = { \"-bpp\" : 0.05 } # sets BPP to 0.05 \u2002 -gop (float/int) : (optional) specifies the Keyframe interval, also known as GOP length. This attributes manually sets both minimum and maximum distance between I-frames for accurate fixed GOP length. It can be used as follows: By default, StreamGear automatically sets recommended fixed GOP value (i.e. every two seconds) w.r.t input framerate and selected encoder. stream_params = { \"-gop\" : 70 } # set GOP length to 70 \u2002 -clones (list) : (optional) sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Usage is as follows: stream_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} \u2002 -ffmpeg_download_path (string) : (optional) sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: stream_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" \u2002 -clear_prev_assets (bool) : (optional) specify whether to force-delete any previous copies of StreamGear Assets (i.e. Manifest files(.mpd) & streaming chunks(.m4s)) present at path specified by output parameter. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: stream_params = { \"-clear_prev_assets\" : True } # will delete all previous assets \u2002 B. FFmpeg Parameters \u00b6 Almost all FFmpeg parameter can be passed as dictionary attributes in stream_params . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters In addition to these parameters, almost any FFmpeg parameter (supported by installed FFmpeg) is also supported. But make sure to read FFmpeg Docs carefully first. stream_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } \u2002 Supported Encoders and Decoders \u00b6 All the encoders and decoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: # for checking encoder ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows # for checking decoders ffmpeg -decoders # use `ffmpeg.exe -decoders` on windows logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: StreamGear ( logging = True ) In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9","title":"Parameters"},{"location":"gears/streamgear/params/#streamgear-api-parameters","text":"","title":"StreamGear API Parameters"},{"location":"gears/streamgear/params/#output","text":"This parameter sets the valid filename/path for storing the StreamGear assets (Manifest file(such as Media Presentation Description(MPD) in-case of DASH) & Transcoded sequence of segments) . StreamGear API will throw ValueError if output provided is empty or invalid. StreamGear generated sequence of multiple chunks/segments are also stored in the same directory. You can easily delete all previous assets at output location, by using -clear_prev_assets attribute of stream_params dictionary parameter. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory. In this case, StreamGear API will automatically assign a unique filename for Manifest file. This can be defined as follows: streamer = StreamGear ( output = '/home/foo/foo1' ) # Define streamer with manifest saving directory path Filename (with/without path) : Valid filename( with valid extension ) of the output Manifest file. In case filename is provided without path, then current working directory will be used. streamer = StreamGear ( output = 'output_foo.mpd' ) # Define streamer with manifest file name Make sure to provide valid filename with valid file-extension for selected format value (such as output.mpd in case of MPEG-DASH) , otherwise StreamGear will throw AssertionError . URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for directly storing assets to a network server. For example, you can use a http protocol URL as follows: streamer = StreamGear ( output = 'http://195.167.1.101/live/test.mpd' ) #Define streamer","title":"output"},{"location":"gears/streamgear/params/#formats","text":"This parameter select the adaptive HTTP streaming format. HTTP streaming works by breaking the overall stream into a sequence of small HTTP-based file downloads, each downloading one short chunk of an overall potentially unbounded transport stream. For now, the only supported format is: 'dash' (i.e MPEG-DASH ) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. Data-Type: String Default Value: Its default value is 'dash' Usage: StreamGear ( output = 'output_foo.mpd' , format = \"dash\" )","title":"formats"},{"location":"gears/streamgear/params/#custom_ffmpeg","text":"This parameter assigns the custom path/directory where the custom/downloaded FFmpeg executables are located. Behavior on Windows If a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then StreamGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" StreamGear ( output = 'output_foo.mpd' , custom_ffmpeg = \"/foo/foo1/ffmpeg\" )","title":"custom_ffmpeg"},{"location":"gears/streamgear/params/#stream_params","text":"This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly change its internal settings for transcoding and seamlessly generating high-quality streams. All supported parameters can formatting as attributes for this dictionary parameter: Kindly read FFmpeg Docs carefully, before passing any additional values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} .","title":"stream_params"},{"location":"gears/streamgear/params/#supported-parameters","text":"","title":"Supported Parameters"},{"location":"gears/streamgear/params/#a-exclusive-parameters","text":"StreamGear API provides some exclusive internal parameters to easily generate Streaming Assets and effortlessly tweak its internal properties. These parameters are discussed below: -streams (list of dicts) : This important attribute makes it simple and pretty straight-forward to define additional multiple streams as list of dictionaries of different quality levels (i.e. different bitrates or spatial resolutions) for streaming. Important -streams attribute facts On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input Video, at the index 0 . You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. To construct the additional stream dictionaries, you'll will need following sub-attributes: -resolution (string) : It is compulsory to define the required resolution/dimension/size for the stream, otherwise given stream will be rejected. Its value can be a \"{width}x{height}\" as follows: \"-streams\" = [{ \"-resolution\" : \"1280x720\" }] # to produce a 1280x720 resolution/scale \u2002 -video_bitrate (string) : It is an optional (can be ignored if -framerate parameter is defined) sub-attribute that generally determines the bandwidth and quality of stream, i.e. the higher the bitrate, the better the quality and the larger will be bandwidth and more will be strain on network. It value is generally in kbps (kilobits per second) for OBS (Open Broadcasting Softwares). You can easily define this attribute as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"2000k\" }] # to produce a 1280x720 resolution and 2000kbps bitrate stream \u2002 -framerate (float/int) : It is another optional (can be ignored if -video_bitrate parameter is defined) sub-attribute that defines the assumed framerate for the stream. Thereby, StreamGear automatically appropriate calculates the suitable video-bitrate using its value along with -bpps and -resolution values , so you don't have to. It's value can be float/integer as follows: \"-streams\" : [{ \"-resolution\" : \"1280x720\" , \"-framerate\" : \"60.0\" }] # to produce a 1280x720 resolution and 60fps framerate stream \u2002 Usage: You can easily define any number of streams using -streams attribute as follows: Usage example can be found here \u27b6 stream_params = { \"-streams\" : [{ \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : \"30.0\" }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : \"60.0\" }, # Stream3: 640x360 at 60fps ]} \u2002 -video_source (string) : This attribute takes valid Video path as input and activates Single-Source Mode , for transcoding it into multiple smaller chunks/segments for streaming after successful validation. Its value be one of the following: Usage example can be found here \u27b6 Video Filename : Valid path to Video file as follows: stream_params = { \"-video_source\" : \"/home/foo/foo1.mp4\" } # set input video source: /home/foo/foo1.mp4 Video URL : Valid URL of a network video stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-video_source\" : \"http://livefeed.com:5050\" } # set input video source: http://livefeed.com:5050 \u2002 -audio (dict) : This attribute takes external custom audio path as audio-input for all StreamGear streams. Its value be one of the following: Make sure this audio-source is compatible with provided video -source, otherwise you encounter multiple errors, or even no output at all! Usage example can be found here \u27b6 Audio Filename : Valid path to Audio file as follows: stream_params = { \"-audio\" : \"/home/foo/foo1.aac\" } # set input audio source: /home/foo/foo1.aac Audio URL : Valid URL of a network audio stream as follows: Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with ffmpeg -protocols terminal command) stream_params = { \"-audio\" : \"https://exampleaudio.org/example-160.mp3\" } # set input audio source: https://exampleaudio.org/example-160.mp3 \u2002 -livestream (bool) : (optional) specifies whether to enable Livestream Support (chunks will contain information for new frames only) for the selected mode, or not. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: Use window_size & extra_window_size FFmpeg parameters for controlling number of frames to be kept in New Chunks. stream_params = { \"-livestream\" : True } # enable livestreaming \u2002 -input_framerate (float/int) : (optional) specifies the assumed input video source framerate, and only works in Real-time Frames Mode . It can be used as follows: Usage example can be found here \u27b6 stream_params = { \"-input_framerate\" : 60.0 } # set input video source framerate to 60fps \u2002 -bpp (float/int) : (optional) This attribute controls constant Bits-Per-Pixel (BPP) value, which is kind of a constant value to ensure good quality of high motion scenes ,and thereby used in calculating desired video-bitrate for streams. Higher the BPP, better will be motion quality. Its default value is 0.1 . Going over 0.1 helps to fill gaps between current bitrate and upload limit/ingest cap. Its value can be anything above 0.001 , can be used as follows: Important BPP tips for streaming -bpp a sensitive value, try 0.001, and then make increments in 0.0001 to fine tune If your desired resolution/fps/audio combination is below maximum service bitrate, raise BPP to match it for extra quality. It is generally better to lower resolution (and/or fps) and raise BPP than raise resolution and loose on BPP. stream_params = { \"-bpp\" : 0.05 } # sets BPP to 0.05 \u2002 -gop (float/int) : (optional) specifies the Keyframe interval, also known as GOP length. This attributes manually sets both minimum and maximum distance between I-frames for accurate fixed GOP length. It can be used as follows: By default, StreamGear automatically sets recommended fixed GOP value (i.e. every two seconds) w.r.t input framerate and selected encoder. stream_params = { \"-gop\" : 70 } # set GOP length to 70 \u2002 -clones (list) : (optional) sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Usage is as follows: stream_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} \u2002 -ffmpeg_download_path (string) : (optional) sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: stream_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" \u2002 -clear_prev_assets (bool) : (optional) specify whether to force-delete any previous copies of StreamGear Assets (i.e. Manifest files(.mpd) & streaming chunks(.m4s)) present at path specified by output parameter. You can easily set it to True to enable this feature, and default value is False . It can be used as follows: stream_params = { \"-clear_prev_assets\" : True } # will delete all previous assets","title":"A. Exclusive Parameters"},{"location":"gears/streamgear/params/#b-ffmpeg-parameters","text":"Almost all FFmpeg parameter can be passed as dictionary attributes in stream_params . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters In addition to these parameters, almost any FFmpeg parameter (supported by installed FFmpeg) is also supported. But make sure to read FFmpeg Docs carefully first. stream_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" }","title":"B. FFmpeg Parameters"},{"location":"gears/streamgear/params/#supported-encoders-and-decoders","text":"All the encoders and decoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: # for checking encoder ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows # for checking decoders ffmpeg -decoders # use `ffmpeg.exe -decoders` on windows","title":"Supported Encoders and Decoders"},{"location":"gears/streamgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: StreamGear ( logging = True ) In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9","title":"logging"},{"location":"gears/streamgear/usage/","text":"StreamGear API Usage Examples: \u00b6 Important Information StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. By default, when no additional streams are defined, StreamGear generates a primary stream of same resolution and framerate 1 as the input video (at the index 0 ) . Always use terminate() function at the very end of the main code. \u2009 A. Single-Source Mode \u00b6 Single-Source Mode generalized workflow In this mode, StreamGear transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well, when you're transcoding lossless long-duration videos(with audio) for streaming and required no extra efforts or interruptions. But on the downside, the provided source cannot be changed or manipulated before sending onto FFmpeg Pipeline for processing. This mode provide transcode_source() function to process audio-video files into streamable chunks. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. Warning Using stream() function instead of transcode_source() in Single-Source Mode will instantly result in RuntimeError ! Any invalid value to the -video_source attribute will result in AssertionError ! \u2009 A.1 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with StreamGear API in Single-Source Mode: If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input stream_params = { \"-video_source\" : \"foo.mp4\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () After running these bare-minimum commands, StreamGear will produce a Manifest file ( dash.mpd ) with steamable chunks that contains information about a Primary Stream of same resolution and framerate as the input. \u2009 A.2 Bare-Minimum Usage with Live-Streaming \u00b6 If you want to Livestream in Single-Source Mode (chunks will contain information for few new frames only, and forgets all previous ones) , you can use exclusive -livestream attribute of stream_params dictionary parameter as follows: Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. All Chunks will be overwritten in this mode after every few Chunks (equal to the sum of -window_size & -extra_window_size values) , Hence Newer Chunks and Manifest contains NO information of any older video-frames. If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input and enable livestreaming stream_params = { \"-video_source\" : 0 , \"-livestream\" : True } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () \u2009 A.3 Usage with Additional Streams \u00b6 In addition to Primary Stream, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically (More detailed information can be found here \u27b6 ) . The complete example is as follows: If input video-source contains any audio stream/channel, then it automatically gets assigned to all generated streams without any extra efforts. Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and also define various streams stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () \u2009 A.4 Usage with Custom Audio \u00b6 By default, if input video-source (i.e. -video_source ) contains any audio, then it gets automatically mapped to all generated streams. But, if you want to add any custom audio, you can easily do it by using exclusive -audio attribute of stream_params dictionary parameter. You just need to input the path of your audio file to this attribute as string, and StreamGear API will automatically validate and map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () \u2009 A.5 Usage with Variable FFmpeg Parameters \u00b6 For seamlessly generating these streaming assets, StreamGear provides a highly extensible and flexible wrapper around FFmpeg , and access to almost all of its parameter. Hence, you can access almost any parameter available with FFmpeg itself as dictionary attributes in stream_params dictionary parameter , and use it to manipulate transcoding as you like. For this example, let us use our own H.265/HEVC video and AAC audio encoder, and set custom audio bitrate, and various other optimizations: This example is just conveying the idea on how to use FFmpeg's encoders/parameters with StreamGear API. You can use any FFmpeg parameter in the similar manner. Kindly read FFmpeg Docs carefully, before passing any FFmpeg values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Always use -streams attribute to define additional streams safely, any duplicate or incorrect stream definition can break things! # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various other parameters stream_params = { \"-video_source\" : \"foo.mp4\" , # define Video-Source \"-vcodec\" : \"libx265\" , # assigns H.265/HEVC video encoder \"-x265-params\" : \"lossless=1\" , # enables Lossless encoding \"-crf\" : 25 , # Constant Rate Factor: 25 \"-bpp\" : \"0.15\" , # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream2: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" , # define input audio-source: \"/home/foo/foo1.aac\", \"-acodec\" : \"libfdk_aac\" , # assign lossless AAC audio encoder \"-vbr\" : 4 , # Variable Bit Rate: `4` } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , logging = True , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () B. Real-time Frames Mode \u00b6 Real-time Frames Mode generalized workflow When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes real-time numpy.ndarray video-frames (as opposed to a entire file) into a sequence of multiple smaller chunks/segments for streaming. In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. This mode provide stream() function for directly trancoding video-frames into streamable chunks over the FFmpeg pipeline. Warning Using transcode_source() function instead of stream() in Real-time Frames Mode will instantly result in RuntimeError ! NEVER assign anything to -video_source attribute of stream_params dictionary parameter, otherwise Single-Source Mode may get activated, and as a result, using stream() function will throw RuntimeError ! In this mode, Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25.0 fps. \u2009 B.1 Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with StreamGear API in Real-time Frames Mode: We are using CamGear in this Bare-Minimum example, but any VideoCapture Gear will work in the similar manner. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () After running these bare-minimum commands, StreamGear will produce a Manifest file ( dash.mpd ) with steamable chunks that contains information about a Primary Stream of same resolution and framerate 1 as input (without any audio) . \u2009 B.2 Bare-Minimum Usage with Live-Streaming \u00b6 If you want to Livestream in Real-time Frames Mode (chunks will contain information for few new frames only) , which is excellent for building Low Latency solutions such as Live Camera Streaming, then you can use exclusive -livestream attribute of stream_params dictionary parameter as follows: Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. All Chunks will be overwritten in this mode after every few Chunks (equal to the sum of -window_size & -extra_window_size values) , Hence Newer Chunks and Manifest contains NO information of any older video-frames. If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(from web-camera attached at index `0`) stream = CamGear ( source = 0 ) . start () # enable livestreaming stream_params = { \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.3 Bare-Minimum Usage with RGB Mode \u00b6 In Real-time Frames Mode, StreamGear API provide rgb_mode boolean parameter with its stream() function, which if enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) , thereby also known as RGB Mode . The complete usage example is as follows: # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {simulating RGB frame for this example} frame_rgb = frame [:,:,:: - 1 ] # send frame to streamer streamer . stream ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.4 Bare-Minimum Usage with controlled Input-framerate \u00b6 In Real-time Frames Mode, StreamGear API provides exclusive -input_framerate attribute for its stream_params dictionary parameter, that allow us to set the assumed constant framerate for incoming frames. In this example, we will retrieve framerate from webcam video-stream, and set it as value for -input_framerate attribute in StreamGear: Remember, the Primary Stream framerate default to -input_framerate attribute value (if defined) in Real-time Frames Mode. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` value stream_params = { \"-input_framerate\" : stream . framerate } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.5 Bare-Minimum Usage with OpenCV \u00b6 You can easily use StreamGear API directly with any other Video Processing library( For e.g. OpenCV itself ) in Real-time Frames Mode. The complete usage example is as follows: This just a bare-minimum example with OpenCV, but any other Real-time Frames Mode feature/example will work in the similar manner. # import required libraries from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # send frame to streamer streamer . stream ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close streamer streamer . terminate () \u2009 B.6 Usage with Additional Streams \u00b6 Similar to Single-Source Mode, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter (More detailed information can be found here \u27b6 ) in Real-time Frames Mode. The complete example is as follows: Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # define various streams stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.7 Usage with Audio-Input \u00b6 In Real-time Frames Mode, if you want to add audio to your streams, you've to use exclusive -audio attribute of stream_params dictionary parameter. You need to input the path of your audio to this attribute as string value, and StreamGear API will automatically validate and map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () \u2009 B.8 Usage with Hardware Video-Encoder \u00b6 In Real-time Frames Mode, you can also easily change encoder as per your requirement just by passing -vcodec FFmpeg parameter as an attribute in stream_params dictionary parameter. In addition to this, you can also specify the additional properties/features/optimizations for your system's GPU similarly. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY-NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import VideoGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = VideoGear ( source = 0 ) . start () # activate Single-Source Mode and various streams with custom Video Encoder and optimizations stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-vcodec\" : \"h264_vaapi\" , # define custom Video encoder \"-vaapi_device\" : \"/dev/dri/renderD128\" , # define device location \"-vf\" : \"format=nv12,hwupload\" , # define video pixformat } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9 \u21a9 \u21a9","title":"Usage Examples"},{"location":"gears/streamgear/usage/#streamgear-api-usage-examples","text":"Important Information StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. StreamGear API will throw RuntimeError , if it fails to detect valid FFmpeg executables on your system. By default, when no additional streams are defined, StreamGear generates a primary stream of same resolution and framerate 1 as the input video (at the index 0 ) . Always use terminate() function at the very end of the main code.","title":"StreamGear API Usage Examples:"},{"location":"gears/streamgear/usage/#a-single-source-mode","text":"Single-Source Mode generalized workflow In this mode, StreamGear transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well, when you're transcoding lossless long-duration videos(with audio) for streaming and required no extra efforts or interruptions. But on the downside, the provided source cannot be changed or manipulated before sending onto FFmpeg Pipeline for processing. This mode provide transcode_source() function to process audio-video files into streamable chunks. This mode can be easily activated by assigning suitable video path as input to -video_source attribute of stream_params dictionary parameter, during StreamGear initialization. Warning Using stream() function instead of transcode_source() in Single-Source Mode will instantly result in RuntimeError ! Any invalid value to the -video_source attribute will result in AssertionError !","title":"A. Single-Source Mode"},{"location":"gears/streamgear/usage/#a1-bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with StreamGear API in Single-Source Mode: If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input stream_params = { \"-video_source\" : \"foo.mp4\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate () After running these bare-minimum commands, StreamGear will produce a Manifest file ( dash.mpd ) with steamable chunks that contains information about a Primary Stream of same resolution and framerate as the input.","title":"A.1 Bare-Minimum Usage"},{"location":"gears/streamgear/usage/#a2-bare-minimum-usage-with-live-streaming","text":"If you want to Livestream in Single-Source Mode (chunks will contain information for few new frames only, and forgets all previous ones) , you can use exclusive -livestream attribute of stream_params dictionary parameter as follows: Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. All Chunks will be overwritten in this mode after every few Chunks (equal to the sum of -window_size & -extra_window_size values) , Hence Newer Chunks and Manifest contains NO information of any older video-frames. If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode with valid video input and enable livestreaming stream_params = { \"-video_source\" : 0 , \"-livestream\" : True } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"A.2 Bare-Minimum Usage with Live-Streaming"},{"location":"gears/streamgear/usage/#a3-usage-with-additional-streams","text":"In addition to Primary Stream, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically (More detailed information can be found here \u27b6 ) . The complete example is as follows: If input video-source contains any audio stream/channel, then it automatically gets assigned to all generated streams without any extra efforts. Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and also define various streams stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"A.3 Usage with Additional Streams"},{"location":"gears/streamgear/usage/#a4-usage-with-custom-audio","text":"By default, if input video-source (i.e. -video_source ) contains any audio, then it gets automatically mapped to all generated streams. But, if you want to add any custom audio, you can easily do it by using exclusive -audio attribute of stream_params dictionary parameter. You just need to input the path of your audio file to this attribute as string, and StreamGear API will automatically validate and map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-video_source\" : \"foo.mp4\" , \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"A.4 Usage with Custom Audio"},{"location":"gears/streamgear/usage/#a5-usage-with-variable-ffmpeg-parameters","text":"For seamlessly generating these streaming assets, StreamGear provides a highly extensible and flexible wrapper around FFmpeg , and access to almost all of its parameter. Hence, you can access almost any parameter available with FFmpeg itself as dictionary attributes in stream_params dictionary parameter , and use it to manipulate transcoding as you like. For this example, let us use our own H.265/HEVC video and AAC audio encoder, and set custom audio bitrate, and various other optimizations: This example is just conveying the idea on how to use FFmpeg's encoders/parameters with StreamGear API. You can use any FFmpeg parameter in the similar manner. Kindly read FFmpeg Docs carefully, before passing any FFmpeg values to stream_params parameter. Wrong values may result in undesired errors or no output at all. Always use -streams attribute to define additional streams safely, any duplicate or incorrect stream definition can break things! # import required libraries from vidgear.gears import StreamGear # activate Single-Source Mode and various other parameters stream_params = { \"-video_source\" : \"foo.mp4\" , # define Video-Source \"-vcodec\" : \"libx265\" , # assigns H.265/HEVC video encoder \"-x265-params\" : \"lossless=1\" , # enables Lossless encoding \"-crf\" : 25 , # Constant Rate Factor: 25 \"-bpp\" : \"0.15\" , # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1280x720 at 4000kbs bitrate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream2: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" , # define input audio-source: \"/home/foo/foo1.aac\", \"-acodec\" : \"libfdk_aac\" , # assign lossless AAC audio encoder \"-vbr\" : 4 , # Variable Bit Rate: `4` } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , logging = True , ** stream_params ) # trancode source streamer . transcode_source () # terminate streamer . terminate ()","title":"A.5 Usage with Variable FFmpeg Parameters"},{"location":"gears/streamgear/usage/#b-real-time-frames-mode","text":"Real-time Frames Mode generalized workflow When no valid input is received on -video_source attribute of stream_params dictionary parameter, StreamGear API activates this mode where it directly transcodes real-time numpy.ndarray video-frames (as opposed to a entire file) into a sequence of multiple smaller chunks/segments for streaming. In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through -audio attribute of stream_params dictionary parameter. This mode provide stream() function for directly trancoding video-frames into streamable chunks over the FFmpeg pipeline. Warning Using transcode_source() function instead of stream() in Real-time Frames Mode will instantly result in RuntimeError ! NEVER assign anything to -video_source attribute of stream_params dictionary parameter, otherwise Single-Source Mode may get activated, and as a result, using stream() function will throw RuntimeError ! In this mode, Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25.0 fps.","title":"B. Real-time Frames Mode"},{"location":"gears/streamgear/usage/#b1-bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with StreamGear API in Real-time Frames Mode: We are using CamGear in this Bare-Minimum example, but any VideoCapture Gear will work in the similar manner. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () After running these bare-minimum commands, StreamGear will produce a Manifest file ( dash.mpd ) with steamable chunks that contains information about a Primary Stream of same resolution and framerate 1 as input (without any audio) .","title":"B.1 Bare-Minimum Usage"},{"location":"gears/streamgear/usage/#b2-bare-minimum-usage-with-live-streaming","text":"If you want to Livestream in Real-time Frames Mode (chunks will contain information for few new frames only) , which is excellent for building Low Latency solutions such as Live Camera Streaming, then you can use exclusive -livestream attribute of stream_params dictionary parameter as follows: Use -window_size & -extra_window_size FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency. All Chunks will be overwritten in this mode after every few Chunks (equal to the sum of -window_size & -extra_window_size values) , Hence Newer Chunks and Manifest contains NO information of any older video-frames. If input video-source (i.e. -video_source ) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(from web-camera attached at index `0`) stream = CamGear ( source = 0 ) . start () # enable livestreaming stream_params = { \"-livestream\" : True } # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.2 Bare-Minimum Usage with Live-Streaming"},{"location":"gears/streamgear/usage/#b3-bare-minimum-usage-with-rgb-mode","text":"In Real-time Frames Mode, StreamGear API provide rgb_mode boolean parameter with its stream() function, which if enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) , thereby also known as RGB Mode . The complete usage example is as follows: # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {simulating RGB frame for this example} frame_rgb = frame [:,:,:: - 1 ] # send frame to streamer streamer . stream ( frame_rgb , rgb_mode = True ) #activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.3 Bare-Minimum Usage with RGB Mode"},{"location":"gears/streamgear/usage/#b4-bare-minimum-usage-with-controlled-input-framerate","text":"In Real-time Frames Mode, StreamGear API provides exclusive -input_framerate attribute for its stream_params dictionary parameter, that allow us to set the assumed constant framerate for incoming frames. In this example, we will retrieve framerate from webcam video-stream, and set it as value for -input_framerate attribute in StreamGear: Remember, the Primary Stream framerate default to -input_framerate attribute value (if defined) in Real-time Frames Mode. # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` value stream_params = { \"-input_framerate\" : stream . framerate } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.4 Bare-Minimum Usage with controlled Input-framerate"},{"location":"gears/streamgear/usage/#b5-bare-minimum-usage-with-opencv","text":"You can easily use StreamGear API directly with any other Video Processing library( For e.g. OpenCV itself ) in Real-time Frames Mode. The complete usage example is as follows: This just a bare-minimum example with OpenCV, but any other Real-time Frames Mode feature/example will work in the similar manner. # import required libraries from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # describe a suitable manifest-file location/name streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # send frame to streamer streamer . stream ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close streamer streamer . terminate ()","title":"B.5 Bare-Minimum Usage with OpenCV"},{"location":"gears/streamgear/usage/#b6-usage-with-additional-streams","text":"Similar to Single-Source Mode, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive -streams attribute of stream_params dictionary parameter (More detailed information can be found here \u27b6 ) in Real-time Frames Mode. The complete example is as follows: Important -streams attribute Information On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate 1 as the input, at the index 0 . Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! You MUST need to define -resolution value for your stream, otherwise stream will be discarded! You only need either of -video_bitrate or -framerate for defining a valid stream. Since with -framerate value defined, video-bitrate is calculated automatically. If you define both -video_bitrate and -framerate values at the same time, StreamGear will discard the -framerate value automatically. Always use -stream attribute to define additional streams safely, any duplicate or incorrect definition can break things! # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = CamGear ( source = 0 ) . start () # define various streams stream_params = { \"-streams\" : [ { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps framerate { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps framerate { \"-resolution\" : \"320x240\" , \"-video_bitrate\" : \"500k\" }, # Stream3: 320x240 at 500kbs bitrate ], } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.6 Usage with Additional Streams"},{"location":"gears/streamgear/usage/#b7-usage-with-audio-input","text":"In Real-time Frames Mode, if you want to add audio to your streams, you've to use exclusive -audio attribute of stream_params dictionary parameter. You need to input the path of your audio to this attribute as string value, and StreamGear API will automatically validate and map it to all generated streams. The complete example is as follows: Make sure this -audio audio-source it compatible with provided video-source, otherwise you encounter multiple errors or no output at all. You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6 # import required libraries from vidgear.gears import CamGear from vidgear.gears import StreamGear import cv2 # open any valid video stream(for e.g `foo1.mp4` file) stream = CamGear ( source = 'foo1.mp4' ) . start () # activate Single-Source Mode and various streams, along with custom audio stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-audio\" : \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\" } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate ()","title":"B.7 Usage with Audio-Input"},{"location":"gears/streamgear/usage/#b8-usage-with-hardware-video-encoder","text":"In Real-time Frames Mode, you can also easily change encoder as per your requirement just by passing -vcodec FFmpeg parameter as an attribute in stream_params dictionary parameter. In addition to this, you can also specify the additional properties/features/optimizations for your system's GPU similarly. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY-NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import VideoGear from vidgear.gears import StreamGear import cv2 # Open suitable video stream, such as webcam on first index(i.e. 0) stream = VideoGear ( source = 0 ) . start () # activate Single-Source Mode and various streams with custom Video Encoder and optimizations stream_params = { \"-streams\" : [ { \"-resolution\" : \"1920x1080\" , \"-video_bitrate\" : \"4000k\" }, # Stream1: 1920x1080 at 4000kbs bitrate { \"-resolution\" : \"1280x720\" , \"-framerate\" : 30.0 }, # Stream2: 1280x720 at 30fps { \"-resolution\" : \"640x360\" , \"-framerate\" : 60.0 }, # Stream3: 640x360 at 60fps ], \"-vcodec\" : \"h264_vaapi\" , # define custom Video encoder \"-vaapi_device\" : \"/dev/dri/renderD128\" , # define device location \"-vf\" : \"format=nv12,hwupload\" , # define video pixformat } # describe a suitable manifest-file location/name and assign params streamer = StreamGear ( output = \"dash_out.mpd\" , ** stream_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # send frame to streamer streamer . stream ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close streamer streamer . terminate () In Real-time Frames Mode, the Primary Stream's framerate defaults to -input_framerate attribute value, if defined, else it will be 25fps. \u21a9 \u21a9 \u21a9","title":"B.8 Usage with Hardware Video-Encoder"},{"location":"gears/videogear/overview/","text":"VideoGear API \u00b6 VideoGear API's generalized workflow Overview \u00b6 VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag. VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Make sure to enable Raspberry Pi hardware-specific settings prior using PiGear API, otherwise nothing will work. \u2009 Importing \u00b6 You can import VideoGear API in your program as follows: from vidgear.gears import VideoGear \u2009 Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/videogear/overview/#videogear-api","text":"VideoGear API's generalized workflow","title":"VideoGear API"},{"location":"gears/videogear/overview/#overview","text":"VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag. VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Make sure to enable Raspberry Pi hardware-specific settings prior using PiGear API, otherwise nothing will work.","title":"Overview"},{"location":"gears/videogear/overview/#importing","text":"You can import VideoGear API in your program as follows: from vidgear.gears import VideoGear","title":"Importing"},{"location":"gears/videogear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/videogear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/videogear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/videogear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/videogear/params/","text":"VideoGear API Parameters \u00b6 \u2009 enablePiCamera \u00b6 This parameter provide access to PiGear or CamGear APIs respectively. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . Parameters for Stabilizer Backend \u00b6 stabilize \u00b6 This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 . options \u00b6 This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters for CamGear backend \u00b6 Enable this backend with enablePiCamera=False on VideoGear. source \u00b6 VideoGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: VideoGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: VideoGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) VideoGear automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Youtube URLs: CamGear utilizes pafy with youtube-dl backend. For example \"https://youtu.be/bvetuLwJIkA\" as follows: Valid YouTube URL formats All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} VideoGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Streaming Websites URLs: CamGear utilizes streamlink backend. For example \"https://www.dailymotion.com/video/x7xsoud\" as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 VideoGear ( source = 'https://www.dailymotion.com/video/x7xsoud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: VideoGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: VideoGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u00b6 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the VideoGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . VideoGear automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! VideoGear will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . backend \u00b6 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . To workaround a FFmpeg bug , VideoGear automatically enforce GStreamer backend( backend=cv2.CAP_GSTREAMER ) for YouTube-livestreams in Stream Mode . This behavior discards any backend parameter value for those streams. Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: VideoGear ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u00b6 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it VideoGear ( source = 0 , ** options ) Parameters for PiGear backend \u00b6 Enable this backend with enablePiCamera=False on VideoGear. camera_num \u00b6 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( camera_num = 0 ) resolution \u00b6 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: VideoGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u00b6 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: VideoGear ( framerate = 60 ) # sets 60fps framerate options \u00b6 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it VideoGear ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u00b6 colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 VideoGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the VideoGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/videogear/params/#videogear-api-parameters","text":"","title":"VideoGear API Parameters"},{"location":"gears/videogear/params/#enablepicamera","text":"This parameter provide access to PiGear or CamGear APIs respectively. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/videogear/params/#parameters-for-stabilizer-backend","text":"","title":"Parameters for Stabilizer Backend"},{"location":"gears/videogear/params/#stabilize","text":"This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/videogear/params/#options","text":"This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/videogear/params/#parameters-for-camgear-backend","text":"Enable this backend with enablePiCamera=False on VideoGear.","title":"Parameters for CamGear backend"},{"location":"gears/videogear/params/#source","text":"VideoGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: VideoGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: VideoGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) VideoGear automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Youtube URLs: CamGear utilizes pafy with youtube-dl backend. For example \"https://youtu.be/bvetuLwJIkA\" as follows: Valid YouTube URL formats All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} VideoGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Streaming Websites URLs: CamGear utilizes streamlink backend. For example \"https://www.dailymotion.com/video/x7xsoud\" as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 VideoGear ( source = 'https://www.dailymotion.com/video/x7xsoud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: VideoGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: VideoGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/videogear/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the VideoGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . VideoGear automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! VideoGear will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/videogear/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . To workaround a FFmpeg bug , VideoGear automatically enforce GStreamer backend( backend=cv2.CAP_GSTREAMER ) for YouTube-livestreams in Stream Mode . This behavior discards any backend parameter value for those streams. Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: VideoGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/videogear/params/#options_1","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it VideoGear ( source = 0 , ** options )","title":"options"},{"location":"gears/videogear/params/#parameters-for-pigear-backend","text":"Enable this backend with enablePiCamera=False on VideoGear.","title":"Parameters for PiGear backend"},{"location":"gears/videogear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( camera_num = 0 )","title":"camera_num"},{"location":"gears/videogear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: VideoGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/videogear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: VideoGear ( framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/videogear/params/#options_2","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it VideoGear ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/videogear/params/#common-parameters","text":"","title":"Common Parameters"},{"location":"gears/videogear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 VideoGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/videogear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: VideoGear ( logging = True )","title":"logging"},{"location":"gears/videogear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the VideoGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: VideoGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/videogear/usage/","text":"VideoGear API Usage Examples: \u00b6 \u2009 Bare-Minimum Usage with CamGear backend \u00b6 Following is the bare-minimum code you need to access CamGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file stream = VideoGear ( source = \"myvideo.avi\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Bare-Minimum Usage with PiGear backend \u00b6 Following is the bare-minimum code you need to access PiGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # enable enablePiCamera boolean flag to access PiGear API backend stream = VideoGear ( enablePiCamera = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using VideoGear with Video Stabilizer backend \u00b6 VideoGear API provides a special internal wrapper around VidGear's Exclusive Video Stabilizer class and provides easy way of activating stabilization for various video-streams (real-time or not) with its stabilize boolean parameter during initialization. The complete usage example is as follows: For a more detailed information on Video-Stabilizer Class, Read here \u27b6 # import required libraries from vidgear.gears import VideoGear import numpy as np import cv2 # open any valid video stream with stabilization enabled(`stabilize = True`) stream_stab = VideoGear ( source = \"test.mp4\" , stabilize = True ) . start () # loop over while True : # read stabilized frames frame_stab = stream_stab . read () # check for stabilized frame if None-type if frame_stab is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Stabilized Output\" , frame_stab ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close streams stream_stab . stop () VideoGear contains a special enablePiCamera flag that provides internal access to both CamGear and PiGear APIs, and thereby only one of them can be accessed at a given instance. Therefore, the additional parameters of VideoGear API are also based on API ( PiGear API or CamGear API ) being accessed. The complete usage example of VideoGear API with Variable PiCamera Properties is as follows: This example is basically a VideoGear API implementation of this PiGear usage example . Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner. # import required libraries from vidgear.gears import VideoGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # activate enablePiCamera and open pi video stream with defined parameters stream = VideoGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () Using VideoGear with Colorspace Manipulation \u00b6 VideoGear API also supports Colorspace Manipulation but not direct like other VideoCapture Gears. Important color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . More details can be found here \u27b6 Any incorrect or None-type value on colorspace parameter will be skipped automatically. In following example code, we will convert source colorspace to HSV on initialization: # import required libraries from vidgear.gears import VideoGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV` stream = VideoGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Usage Examples"},{"location":"gears/videogear/usage/#videogear-api-usage-examples","text":"","title":"VideoGear API Usage Examples:"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-camgear-backend","text":"Following is the bare-minimum code you need to access CamGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file stream = VideoGear ( source = \"myvideo.avi\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with CamGear backend"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-pigear-backend","text":"Following is the bare-minimum code you need to access PiGear API with VideoGear: # import required libraries from vidgear.gears import VideoGear import cv2 # enable enablePiCamera boolean flag to access PiGear API backend stream = VideoGear ( enablePiCamera = True ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Bare-Minimum Usage with PiGear backend"},{"location":"gears/videogear/usage/#using-videogear-with-video-stabilizer-backend","text":"VideoGear API provides a special internal wrapper around VidGear's Exclusive Video Stabilizer class and provides easy way of activating stabilization for various video-streams (real-time or not) with its stabilize boolean parameter during initialization. The complete usage example is as follows: For a more detailed information on Video-Stabilizer Class, Read here \u27b6 # import required libraries from vidgear.gears import VideoGear import numpy as np import cv2 # open any valid video stream with stabilization enabled(`stabilize = True`) stream_stab = VideoGear ( source = \"test.mp4\" , stabilize = True ) . start () # loop over while True : # read stabilized frames frame_stab = stream_stab . read () # check for stabilized frame if None-type if frame_stab is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Stabilized Output\" , frame_stab ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close streams stream_stab . stop () VideoGear contains a special enablePiCamera flag that provides internal access to both CamGear and PiGear APIs, and thereby only one of them can be accessed at a given instance. Therefore, the additional parameters of VideoGear API are also based on API ( PiGear API or CamGear API ) being accessed. The complete usage example of VideoGear API with Variable PiCamera Properties is as follows: This example is basically a VideoGear API implementation of this PiGear usage example . Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner. # import required libraries from vidgear.gears import VideoGear import cv2 # add various Picamera tweak parameters to dictionary options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # activate enablePiCamera and open pi video stream with defined parameters stream = VideoGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using VideoGear with Video Stabilizer backend"},{"location":"gears/videogear/usage/#using-videogear-with-colorspace-manipulation","text":"VideoGear API also supports Colorspace Manipulation but not direct like other VideoCapture Gears. Important color_space global variable is NOT Supported in VideoGear API, calling it will result in AttribueError . More details can be found here \u27b6 Any incorrect or None-type value on colorspace parameter will be skipped automatically. In following example code, we will convert source colorspace to HSV on initialization: # import required libraries from vidgear.gears import VideoGear import cv2 # Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV` stream = VideoGear ( source = 0 , colorspace = \"COLOR_BGR2HSV\" , logging = True ) . start () # loop over while True : # read HSV frames frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the HSV frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for key if pressed key = cv2 . waitKey ( 1 ) & 0xFF # check for 'q' key is pressed if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"Using VideoGear with Colorspace Manipulation"},{"location":"gears/webgear/advanced/","text":"WebGear API Advanced Usage: \u00b6 This is a continuation of the WebGear doc \u27b6 . Thereby, It's advised to first get familiarize with this API, and its requirements . Using WebGear with Custom Mounting Points \u00b6 With our highly extensible WebGear API, you can add your own mounting points, where additional files located, as follows: # import libs import uvicorn from starlette.routing import Mount from starlette.staticfiles import StaticFiles from vidgear.gears.asyncio import WebGear # various performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , } # initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory web . routes . append ( Mount ( \"/test\" , app = StaticFiles ( directory = \"/home/foo/.vidgear/test\" ), name = \"test\" ) ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script jquery-3.3.1.slim.min.js in this folder and want to integrate it, then, we can do something like this: < script src = \"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\" ></ script > Using WebGear with Custom Webpage Routes \u00b6 With Webgear's flexible API, you can even add your additional HTML Static webpages without any extra efforts. Suppose we want to add a simple hello world webpage to our WebGear server. So let's create a bare-minimum hello.html file with HTML code as follows: < html > < header > < title > This is Hello world page </ title > </ header > < body > < h1 > Hello World </ h1 > < p > how ya doing? </ p > </ body > </ html > Then in our application code, we can integrate this webpage route, as follows: # import libs import uvicorn , asyncio from starlette.templating import Jinja2Templates from starlette.routing import Route from vidgear.gears.asyncio import WebGear # Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located template = Jinja2Templates ( directory = \"/home/foo/.vidgear/custom_template\" ) # render and return our webpage template async def hello_world ( request ): page = \"hello.html\" context = { \"request\" : request } return template . TemplateResponse ( page , context ) # add various performance tweaks as usual options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , } # initialize WebGear app with a valid source web = WebGear ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route to point our rendered webpage web . routes . append ( Route ( \"/hello\" , endpoint = hello_world )) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/hello address. Rules for Altering WebGear Files and Folders \u00b6 WebGear gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to keep the following rules in mind: Rules for Altering Data Files \u00b6 You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions. You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files i.e index.html , 404.html & 500.html present in templates folder at the default location , otherwise, it will trigger Auto-generation process , and it will overwrite the existing files with Server ones. You're allowed to add your own additional .html , .css , .js , etc. files in the respective folders at the default location and custom mounted Data folders . Rules for Altering Data Folders \u00b6 You're allowed to add/mount any number of additional folder as shown in this example above . You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename templates folder where critical data-files i.e index.html , 404.html & 500.html are located, otherwise, it will trigger Auto-generation process . Bonus Usage Examples \u00b6 Because of WebGear API's flexible internal wapper around VideoGear , it can easily access any parameter of CamGear and PiGear videocapture APIs. Following usage examples are just an idea of what can be done with WebGear API, you can try various VideoGear , CamGear and PiGear parameters directly in WebGear API in the similar manner. Using WebGear with Pi Camera Module \u00b6 Here's a bare-minimum example of using WebGear API with the Raspberry Pi camera module while tweaking its various properties in just one-liner: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # various webgear performance and Rasbperry camera tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # initialize WebGear app web = WebGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Using WebGear with real-time Video Stabilization enabled \u00b6 Here's an example of using WebGear API with real-time Video Stabilization enabled: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # various webgear performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , } # initialize WebGear app with a raw source and enable video stabilization(`stabilize=True`) web = WebGear ( source = \"foo.mp4\" , stabilize = True , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"Advanced Usages"},{"location":"gears/webgear/advanced/#webgear-api-advanced-usage","text":"This is a continuation of the WebGear doc \u27b6 . Thereby, It's advised to first get familiarize with this API, and its requirements .","title":"WebGear API Advanced Usage:"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-mounting-points","text":"With our highly extensible WebGear API, you can add your own mounting points, where additional files located, as follows: # import libs import uvicorn from starlette.routing import Mount from starlette.staticfiles import StaticFiles from vidgear.gears.asyncio import WebGear # various performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , } # initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory web . routes . append ( Mount ( \"/test\" , app = StaticFiles ( directory = \"/home/foo/.vidgear/test\" ), name = \"test\" ) ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script jquery-3.3.1.slim.min.js in this folder and want to integrate it, then, we can do something like this: < script src = \"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\" ></ script >","title":"Using WebGear with Custom Mounting Points"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-webpage-routes","text":"With Webgear's flexible API, you can even add your additional HTML Static webpages without any extra efforts. Suppose we want to add a simple hello world webpage to our WebGear server. So let's create a bare-minimum hello.html file with HTML code as follows: < html > < header > < title > This is Hello world page </ title > </ header > < body > < h1 > Hello World </ h1 > < p > how ya doing? </ p > </ body > </ html > Then in our application code, we can integrate this webpage route, as follows: # import libs import uvicorn , asyncio from starlette.templating import Jinja2Templates from starlette.routing import Route from vidgear.gears.asyncio import WebGear # Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located template = Jinja2Templates ( directory = \"/home/foo/.vidgear/custom_template\" ) # render and return our webpage template async def hello_world ( request ): page = \"hello.html\" context = { \"request\" : request } return template . TemplateResponse ( page , context ) # add various performance tweaks as usual options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , } # initialize WebGear app with a valid source web = WebGear ( source = \"/home/foo/foo1.mp4\" , logging = True , ** options ) # enable source i.e. `test.mp4` and enable `logging` for debugging # append new route to point our rendered webpage web . routes . append ( Route ( \"/hello\" , endpoint = hello_world )) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () And that's all, Now you can see output at http://localhost:8000/hello address.","title":"Using WebGear with Custom Webpage Routes"},{"location":"gears/webgear/advanced/#rules-for-altering-webgear-files-and-folders","text":"WebGear gives us complete freedom of altering data files generated in Auto-Generation Process , But you've to keep the following rules in mind:","title":"Rules for Altering WebGear Files and Folders"},{"location":"gears/webgear/advanced/#rules-for-altering-data-files","text":"You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions. You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files i.e index.html , 404.html & 500.html present in templates folder at the default location , otherwise, it will trigger Auto-generation process , and it will overwrite the existing files with Server ones. You're allowed to add your own additional .html , .css , .js , etc. files in the respective folders at the default location and custom mounted Data folders .","title":"Rules for Altering Data Files"},{"location":"gears/webgear/advanced/#rules-for-altering-data-folders","text":"You're allowed to add/mount any number of additional folder as shown in this example above . You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename templates folder where critical data-files i.e index.html , 404.html & 500.html are located, otherwise, it will trigger Auto-generation process .","title":"Rules for Altering Data Folders"},{"location":"gears/webgear/advanced/#bonus-usage-examples","text":"Because of WebGear API's flexible internal wapper around VideoGear , it can easily access any parameter of CamGear and PiGear videocapture APIs. Following usage examples are just an idea of what can be done with WebGear API, you can try various VideoGear , CamGear and PiGear parameters directly in WebGear API in the similar manner.","title":"Bonus Usage Examples"},{"location":"gears/webgear/advanced/#using-webgear-with-pi-camera-module","text":"Here's a bare-minimum example of using WebGear API with the Raspberry Pi camera module while tweaking its various properties in just one-liner: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # various webgear performance and Rasbperry camera tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # initialize WebGear app web = WebGear ( enablePiCamera = True , resolution = ( 640 , 480 ), framerate = 60 , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"Using WebGear with Pi Camera Module"},{"location":"gears/webgear/advanced/#using-webgear-with-real-time-video-stabilization-enabled","text":"Here's an example of using WebGear API with real-time Video Stabilization enabled: # import libs import uvicorn from vidgear.gears.asyncio import WebGear # various webgear performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , } # initialize WebGear app with a raw source and enable video stabilization(`stabilize=True`) web = WebGear ( source = \"foo.mp4\" , stabilize = True , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown ()","title":"Using WebGear with real-time Video Stabilization enabled"},{"location":"gears/webgear/overview/","text":"WebGear API \u00b6 WebGear API's Video Server running at http://localhost:8000/ address. Overview \u00b6 WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting video-frames from a single source to multiple recipients via the browser. WebGear API provides a highly extensible and flexible async wrapper around Starlette 's ASGI application and provides easy access to its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes , Routing tables , Static Files , Templating engine(with Jinja2) , etc. In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides a special internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power of broadcasting frames from any incoming stream. \u2009 Data-Files Auto-Generation WorkFlow for WebGear \u00b6 On initializing WebGear API, it automatically checks for three critical data-files i.e index.html , 404.html & 500.html inside templates folder at the default location , which give rise to possible scenario: If data-files found: it will proceed normally for instantiating the Starlette application. If data-files not found: it will trigger the Auto-Generation process Default Location \u00b6 A default location is the path of the directory where data files/folders are downloaded/generated/saved. By default, the .vidgear the folder at the home directory of your machine (for e.g /home/foo/.vidgear on Linux) serves as the default location . But you can also use WebGear's custom_data_location dictionary attribute to change/alter default location path to somewhere else. Tip You can set logging=True during initialization, for easily identifying the selected default location , which will be something like this (on a Linux machine) : WebGear :: DEBUG :: ` /home/foo/.vidgear ` is the default location for saving WebGear data-files. Auto-Generation process \u00b6 Info You can also force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected. It is advised to enable logging( logging=True ) on the first run for easily identifying any runtime errors On triggering this process, WebGear API creates templates and static folders along with js , css , img sub-folders at the assigned default location . Thereby at this default location , the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order: .vidgear \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u251c\u2500\u2500 bootstrap.min.css \u2502 \u2502 \u2514\u2500\u2500 cover.css \u2502 \u251c\u2500\u2500 img \u2502 \u2502 \u2514\u2500\u2500 favicon-32x32.png \u2502 \u2514\u2500\u2500 js \u2502 \u251c\u2500\u2500 bootstrap.min.js \u2502 \u251c\u2500\u2500 jquery-3.4.1.slim.min.js \u2502 \u2514\u2500\u2500 popper.min.js \u2514\u2500\u2500 templates \u251c\u2500\u2500 404 .html \u251c\u2500\u2500 500 .html \u251c\u2500\u2500 base.html \u2514\u2500\u2500 index.html 5 directories, 10 files Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally. Importing \u00b6 You can import WebGear API in your program as follows: from vidgear.gears.asyncio import WebGear \u2009 WebGear's Default Template \u00b6 The WebGear API by default uses simple & elegant Bootstrap's Cover template , by @mdo , which looks like something as follows: Index.html \u00b6 Can be accessed by visiting WebGear app server, running at http://localhost:8000/ : 404.html \u00b6 Appears when respective URL is not found, for example http://localhost:8000/ok : 500.html \u00b6 Appears when an API Error is encountered: If logging is enabled and an error occurs, then instead of displaying this 500 handler, WebGear will respond with a traceback response. Usage Examples \u00b6 See here \ud83d\ude80 Parameters \u00b6 See here \ud83d\ude80 References \u00b6 See here \ud83d\ude80 FAQs \u00b6 See here \ud83d\ude80","title":"Overview"},{"location":"gears/webgear/overview/#webgear-api","text":"WebGear API's Video Server running at http://localhost:8000/ address.","title":"WebGear API"},{"location":"gears/webgear/overview/#overview","text":"WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting video-frames from a single source to multiple recipients via the browser. WebGear API provides a highly extensible and flexible async wrapper around Starlette 's ASGI application and provides easy access to its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes , Routing tables , Static Files , Templating engine(with Jinja2) , etc. In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides a special internal wrapper around VideoGear , which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power of broadcasting frames from any incoming stream.","title":"Overview"},{"location":"gears/webgear/overview/#data-files-auto-generation-workflow-for-webgear","text":"On initializing WebGear API, it automatically checks for three critical data-files i.e index.html , 404.html & 500.html inside templates folder at the default location , which give rise to possible scenario: If data-files found: it will proceed normally for instantiating the Starlette application. If data-files not found: it will trigger the Auto-Generation process","title":"Data-Files Auto-Generation WorkFlow for WebGear"},{"location":"gears/webgear/overview/#default-location","text":"A default location is the path of the directory where data files/folders are downloaded/generated/saved. By default, the .vidgear the folder at the home directory of your machine (for e.g /home/foo/.vidgear on Linux) serves as the default location . But you can also use WebGear's custom_data_location dictionary attribute to change/alter default location path to somewhere else. Tip You can set logging=True during initialization, for easily identifying the selected default location , which will be something like this (on a Linux machine) : WebGear :: DEBUG :: ` /home/foo/.vidgear ` is the default location for saving WebGear data-files.","title":"Default Location"},{"location":"gears/webgear/overview/#auto-generation-process","text":"Info You can also force trigger the Auto-generation process to overwrite existing data-files using overwrite_default_files dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected. It is advised to enable logging( logging=True ) on the first run for easily identifying any runtime errors On triggering this process, WebGear API creates templates and static folders along with js , css , img sub-folders at the assigned default location . Thereby at this default location , the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order: .vidgear \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u251c\u2500\u2500 bootstrap.min.css \u2502 \u2502 \u2514\u2500\u2500 cover.css \u2502 \u251c\u2500\u2500 img \u2502 \u2502 \u2514\u2500\u2500 favicon-32x32.png \u2502 \u2514\u2500\u2500 js \u2502 \u251c\u2500\u2500 bootstrap.min.js \u2502 \u251c\u2500\u2500 jquery-3.4.1.slim.min.js \u2502 \u2514\u2500\u2500 popper.min.js \u2514\u2500\u2500 templates \u251c\u2500\u2500 404 .html \u251c\u2500\u2500 500 .html \u251c\u2500\u2500 base.html \u2514\u2500\u2500 index.html 5 directories, 10 files Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally.","title":"Auto-Generation process"},{"location":"gears/webgear/overview/#importing","text":"You can import WebGear API in your program as follows: from vidgear.gears.asyncio import WebGear","title":"Importing"},{"location":"gears/webgear/overview/#webgears-default-template","text":"The WebGear API by default uses simple & elegant Bootstrap's Cover template , by @mdo , which looks like something as follows:","title":"WebGear's Default Template"},{"location":"gears/webgear/overview/#indexhtml","text":"Can be accessed by visiting WebGear app server, running at http://localhost:8000/ :","title":"Index.html"},{"location":"gears/webgear/overview/#404html","text":"Appears when respective URL is not found, for example http://localhost:8000/ok :","title":"404.html"},{"location":"gears/webgear/overview/#500html","text":"Appears when an API Error is encountered: If logging is enabled and an error occurs, then instead of displaying this 500 handler, WebGear will respond with a traceback response.","title":"500.html"},{"location":"gears/webgear/overview/#usage-examples","text":"See here \ud83d\ude80","title":"Usage Examples"},{"location":"gears/webgear/overview/#parameters","text":"See here \ud83d\ude80","title":"Parameters"},{"location":"gears/webgear/overview/#references","text":"See here \ud83d\ude80","title":"References"},{"location":"gears/webgear/overview/#faqs","text":"See here \ud83d\ude80","title":"FAQs"},{"location":"gears/webgear/params/","text":"WebGear API Parameters \u00b6 options \u00b6 This parameter can be used to pass user-defined parameter to WebGear API by formatting them as this parameter's attribute. Data-Type: Dictionary Default Value: Its default value is {} WebGear Specific attributes \u00b6 custom_data_location (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows: # set default location to '/home/foo/foo1' options = { \"custom_data_location\" : \"/home/foo/foo1\" } # assign it WebGear ( logging = True , ** options ) overwrite_default_files (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows: Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten. # force trigger the Auto-generation process options = { \"overwrite_default_files\" : True } # assign it WebGear ( logging = True , ** options ) frame_size_reduction (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server._ The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40-60 . Its usage is as follows: # frame-size will be reduced by 50% options = { \"frame_size_reduction\" : 50 } # assign it WebGear ( logging = True , ** options ) Various Encoding Parameters: In WebGear, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) video compression format in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: frame_jpeg_quality (integer) : It controls the JPEG encoder quality and value varies from 0 to 100 (the higher is the better quality but performance will be lower). Its default value is 95 . Its usage is as follows: # JPEG will be encoded at 80% quality options = { \"frame_jpeg_quality\" : 80 } # assign it WebGear ( logging = True , ** options ) frame_jpeg_optimize (boolean) : It enables various JPEG compression optimizations such as Chroma subsampling, Quantization table, etc. Its default value is False . Its usage is as follows: # JPEG optimizations are enabled options = { \"frame_jpeg_optimize\" : True } # assign it WebGear ( logging = True , ** options ) frame_jpeg_progressive (boolean) : It enables Progressive JPEG encoding instead of the Baseline . Progressive Mode. Its default value is False means baseline mode is in-use. Its usage is as follows: # Progressive JPEG encoding enabled options = { \"frame_jpeg_progressive\" : True } # assign it WebGear ( logging = True , ** options ) Parameters for VideoGear backend \u00b6 enablePiCamera \u00b6 This parameter provide access to PiGear or CamGear APIs respectively. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 . Parameters for Stabilizer Backend \u00b6 stabilize \u00b6 This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 . options \u00b6 This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' } Parameters for CamGear backend \u00b6 Enable this backend with enablePiCamera=False on WebGear. source \u00b6 WebGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: WebGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: WebGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) WebGear automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Youtube URLs: CamGear utilizes pafy with youtube-dl backend. For example \"https://youtu.be/bvetuLwJIkA\" as follows: Valid YouTube URL formats All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} WebGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Streaming Websites URLs: CamGear utilizes streamlink backend. For example \"https://www.dailymotion.com/video/x7xsoud\" as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 WebGear ( source = 'https://www.dailymotion.com/video/x7xsoud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: WebGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: WebGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' ) stream_mode \u00b6 This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the WebGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . WebGear automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! WebGear will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 . backend \u00b6 This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . To workaround a FFmpeg bug , WebGear automatically enforce GStreamer backend( backend=cv2.CAP_GSTREAMER ) for YouTube-livestreams in Stream Mode . This behavior discards any backend parameter value for those streams. Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: WebGear ( source = 0 , backend = cv2 . CAP_DSHOW ) options \u00b6 This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it WebGear ( source = 0 , ** options ) Parameters for PiGear backend \u00b6 Enable this backend with enablePiCamera=True on WebGear. camera_num \u00b6 This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( camera_num = 0 ) resolution \u00b6 This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: WebGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution framerate \u00b6 This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: WebGear ( framerate = 60 ) # sets 60fps framerate options \u00b6 This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it WebGear ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds Common Parameters \u00b6 colorspace \u00b6 This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 WebGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6 logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( logging = True ) time_delay \u00b6 This parameter set the time delay (in seconds) before the WebGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( time_delay = 1 ) # set 1 seconds time delay","title":"Parameters"},{"location":"gears/webgear/params/#webgear-api-parameters","text":"","title":"WebGear API Parameters"},{"location":"gears/webgear/params/#options","text":"This parameter can be used to pass user-defined parameter to WebGear API by formatting them as this parameter's attribute. Data-Type: Dictionary Default Value: Its default value is {}","title":"options"},{"location":"gears/webgear/params/#webgear-specific-attributes","text":"custom_data_location (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows: # set default location to '/home/foo/foo1' options = { \"custom_data_location\" : \"/home/foo/foo1\" } # assign it WebGear ( logging = True , ** options ) overwrite_default_files (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows: Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten. # force trigger the Auto-generation process options = { \"overwrite_default_files\" : True } # assign it WebGear ( logging = True , ** options ) frame_size_reduction (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server._ The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40-60 . Its usage is as follows: # frame-size will be reduced by 50% options = { \"frame_size_reduction\" : 50 } # assign it WebGear ( logging = True , ** options ) Various Encoding Parameters: In WebGear, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) video compression format in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: frame_jpeg_quality (integer) : It controls the JPEG encoder quality and value varies from 0 to 100 (the higher is the better quality but performance will be lower). Its default value is 95 . Its usage is as follows: # JPEG will be encoded at 80% quality options = { \"frame_jpeg_quality\" : 80 } # assign it WebGear ( logging = True , ** options ) frame_jpeg_optimize (boolean) : It enables various JPEG compression optimizations such as Chroma subsampling, Quantization table, etc. Its default value is False . Its usage is as follows: # JPEG optimizations are enabled options = { \"frame_jpeg_optimize\" : True } # assign it WebGear ( logging = True , ** options ) frame_jpeg_progressive (boolean) : It enables Progressive JPEG encoding instead of the Baseline . Progressive Mode. Its default value is False means baseline mode is in-use. Its usage is as follows: # Progressive JPEG encoding enabled options = { \"frame_jpeg_progressive\" : True } # assign it WebGear ( logging = True , ** options )","title":"WebGear Specific attributes"},{"location":"gears/webgear/params/#parameters-for-videogear-backend","text":"","title":"Parameters for VideoGear backend"},{"location":"gears/webgear/params/#enablepicamera","text":"This parameter provide access to PiGear or CamGear APIs respectively. This means the if enablePiCamera flag is True , the PiGear API will be accessed, and if False , the CamGear API will be accessed. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( enablePiCamera = True ) # enable access to PiGear API Its complete usage example is given here \u27b6 .","title":"enablePiCamera"},{"location":"gears/webgear/params/#parameters-for-stabilizer-backend","text":"","title":"Parameters for Stabilizer Backend"},{"location":"gears/webgear/params/#stabilize","text":"This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to True ( to enable ) or unset to False ( to disable ). Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( stabilize = True ) # enable stablization Its complete usage example is given here \u27b6 .","title":"stabilize"},{"location":"gears/webgear/params/#options_1","text":"This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class . These parameters can be formatted as this parameter's attribute. Supported dictionary attributes for Stabilizer Class are: SMOOTHING_RADIUS ( integer ) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is 25 . You can easily pass this attribute as follows: options = { 'SMOOTHING_RADIUS' : 30 } BORDER_SIZE ( integer ) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is 0 (no borders). You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 } CROP_N_ZOOM ( boolean ): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) . It simply works in conjunction with the BORDER_SIZE attribute, i.e. when this attribute is enabled, BORDER_SIZE will be used for cropping border instead of extending them. Its default value is False . You can easily pass this attribute as follows: options = { 'BORDER_SIZE' : 10 , 'CROP_N_ZOOM' : True } BORDER_TYPE ( string ) : This attribute can be used to change the extended border style. Valid border types are 'black' , 'reflect' , 'reflect_101' , 'replicate' and 'wrap' , learn more about it here . Its default value is 'black' . You can easily pass this attribute as follows: Altering BORDER_TYPE attribute is Disabled while CROP_N_ZOOM is enabled. options = { 'BORDER_TYPE' : 'black' }","title":"options"},{"location":"gears/webgear/params/#parameters-for-camgear-backend","text":"Enable this backend with enablePiCamera=False on WebGear.","title":"Parameters for CamGear backend"},{"location":"gears/webgear/params/#source","text":"WebGear API will throw RuntimeError if source provided is invalid. This parameter defines the source for the input stream. Data-Type: Based on input. Default Value: Its default value is 0 . Its valid input can be one of the following: Index ( integer ): Valid index of the connected video device, for e.g 0 , or 1 , or 2 etc. as follows: WebGear ( source = 0 ) Filepath ( string ): Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: WebGear ( source = '/home/foo.mp4' ) Streaming Services URL Address ( string ): Valid Video URL as input when Stream Mode is enabled( i.e. stream_mode=True ) WebGear automatically detects whether source belong to YouTube or elsewhere, and handles it with appropriate API. Youtube URLs: CamGear utilizes pafy with youtube-dl backend. For example \"https://youtu.be/bvetuLwJIkA\" as follows: Valid YouTube URL formats All YouTube URLS with following format are supported: https://youtu.be/{video-id} http://www.youtube.com/watch?v={video-id} http://www.youtube.com/v/{video-id} {video-id} WebGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Streaming Websites URLs: CamGear utilizes streamlink backend. For example \"https://www.dailymotion.com/video/x7xsoud\" as follows: Supported Streaming Websites The list of all supported Streaming Websites URLs can be found here \u27b6 WebGear ( source = 'https://www.dailymotion.com/video/x7xsoud' , stream_mode = True ) Network Address ( string ): Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://192.168.31.163:554/' as input: WebGear ( source = 'rtsp://192.168.31.163:554/' ) GStreamer Pipeline: CamGear API also supports GStreamer Pipeline. Requirements for GStreamer Pipelining Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support. Thereby, You can easily check GStreamer support by running print(cv2.getBuildInformation()) python command and see if output contains something similar as follows: Video I/O: ... GStreamer: YES ( ver 1 .8.3 ) ... Be sure convert video output into BGR colorspace before pipelining as follows: WebGear ( source = 'udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink' )","title":"source"},{"location":"gears/webgear/params/#stream_mode","text":"This parameter controls the Stream Mode, .i.e if enabled( stream_mode=True ), the WebGear API will interpret the given source input as YouTube URL address. Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend ( backend=cv2.CAP_GSTREAMER ) for any livestreams (such as Twitch) . WebGear automatically enforce GStreamer backend (backend= cv2.CAP_GSTREAMER ) for YouTube-livestreams! WebGear will exit with RuntimeError for YouTube livestreams, if OpenCV is not compiled with GStreamer( >=v1.0.0 ) support. Checkout this FAQ for compiling OpenCV with GStreamer support. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( source = 'https://youtu.be/bvetuLwJIkA' , stream_mode = True ) Its complete usage example is given here \u27b6 .","title":"stream_mode"},{"location":"gears/webgear/params/#backend","text":"This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified) . To workaround a FFmpeg bug , WebGear automatically enforce GStreamer backend( backend=cv2.CAP_GSTREAMER ) for YouTube-livestreams in Stream Mode . This behavior discards any backend parameter value for those streams. Data-Type: Integer Default Value: Its default value is 0 Usage: All supported backends are listed here \u27b6 Its value can be for e.g. backend = cv2.CAP_DSHOW for selecting Direct Show as backend: WebGear ( source = 0 , backend = cv2 . CAP_DSHOW )","title":"backend"},{"location":"gears/webgear/params/#options_2","text":"This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed here \u27b6 The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"CAP_PROP_FRAME_WIDTH\" : 320 , \"CAP_PROP_FRAME_HEIGHT\" : 240 , \"CAP_PROP_FPS\" : 60 } # assigning it WebGear ( source = 0 , ** options )","title":"options"},{"location":"gears/webgear/params/#parameters-for-pigear-backend","text":"Enable this backend with enablePiCamera=True on WebGear.","title":"Parameters for PiGear backend"},{"location":"gears/webgear/params/#camera_num","text":"This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw ValueError for any negative value. This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board .\" Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( camera_num = 0 )","title":"camera_num"},{"location":"gears/webgear/params/#resolution","text":"This parameter sets the resolution (i.e. (width,height) ) of the source. For more information read here \u27b6 Data-Type: Tuple Default Value: Its default value is (640,480) . Usage: WebGear ( resolution = ( 1280 , 720 )) # sets 1280x720 resolution","title":"resolution"},{"location":"gears/webgear/params/#framerate","text":"This parameter sets the framerate of the source. For more information read here \u27b6 Data-Type: integer/float Default Value: Its default value is 30 . Usage: WebGear ( framerate = 60 ) # sets 60fps framerate","title":"framerate"},{"location":"gears/webgear/params/#options_3","text":"This parameter provides the ability to alter various Tweak Parameters like brightness, saturation, senor_mode, resolution, etc. available within Picamera library . Data-Type: Dictionary Default Value: Its default value is {} Usage: All supported parameters are listed in PiCamera Docs The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows: # formatting parameters as dictionary attributes options = { \"hflip\" : True , \"exposure_mode\" : \"auto\" , \"iso\" : 800 , \"exposure_compensation\" : 15 , \"awb_mode\" : \"horizon\" , \"sensor_mode\" : 0 , } # assigning it WebGear ( logging = True , ** options ) User-specific attributes: Additionally, options parameter also support some User-specific attributes, which are as follows: HWFAILURE_TIMEOUT (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a SystemError to save resources. Its value can only be between 1.0 (min) and 10.0 (max) and its default value is 2.0 . Its usage is as follows: options = { \"HWFAILURE_TIMEOUT\" : 2.5 } # sets timeout to 2.5 seconds","title":"options"},{"location":"gears/webgear/params/#common-parameters","text":"","title":"Common Parameters"},{"location":"gears/webgear/params/#colorspace","text":"This parameter selects the colorspace of the source stream. Data-Type: String Default Value: Its default value is None . Usage: All supported colorspace values are given here \u27b6 WebGear ( colorspace = \"COLOR_BGR2HSV\" ) Its complete usage example is given here \u27b6","title":"colorspace"},{"location":"gears/webgear/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WebGear ( logging = True )","title":"logging"},{"location":"gears/webgear/params/#time_delay","text":"This parameter set the time delay (in seconds) before the WebGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. Data-Type: Integer Default Value: Its default value is 0 . Usage: WebGear ( time_delay = 1 ) # set 1 seconds time delay","title":"time_delay"},{"location":"gears/webgear/usage/","text":"WebGear API Usage Examples: \u00b6 Requirements \u00b6 Installation with Asyncio Support \u00b6 WebGear API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ] ASGI Server \u00b6 You'll also need to install an ASGI Server to run following WebGear usage examples, and by default WebGear ships the state-of-the-art uvicorn Server. But you can also use other ASGI server such as daphne , or hypercorn with it. Performance Enhancements \u00b6 WebGear provides certain performance enhancing attributes for its option dictionary parameter to cope with performance-throttling. Performance Enhancing Attributes frame_size_reduction : (int/float) This attribute controls the size reduction(in percentage) of the frame to be streamed on Server. Its value has the most significant effect on WebGear performance: More its value, smaller will be frame size and faster will be live streaming. The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40~60 . Its usage is as follows: options = { \"frame_size_reduction\" : 50 } #frame-size will be reduced by 50% Various Encoding Parameters: In WebGear API, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) compression format, in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: frame_jpeg_quality : (int) It controls the JPEG encoder quality. Its value varies from 0 to 100 (the higher is the better quality but performance will be lower). Its default value is 95 . Its usage is as follows: options = { \"frame_jpeg_quality\" : 80 } #JPEG will be encoded at 80% quality. frame_jpeg_optimize : (bool) It enables various JPEG compression optimizations such as Chroma sub-sampling, Quantization table, etc. These optimizations based on JPEG libs which are used while compiling OpenCV binaries, and recent versions of OpenCV uses TurboJPEG library , which is highly recommended for performance. Its default value is False . Its usage is as follows: options = { \"frame_jpeg_optimize\" : True } #JPEG optimizations are enabled. frame_jpeg_progressive : (bool) It enables Progressive JPEG encoding instead of the Baseline . Progressive Mode, displays an image in such a way that it shows a blurry/low-quality photo in its entirety, and then becomes clearer as the image downloads, whereas in Baseline Mode, an image created using the JPEG compression algorithm that will start to display the image as the data is made available, line by line. Progressive Mode, can drastically improve the performance in WebGear but at the expense of additional CPU load, thereby suitable for powerful systems only. Its default value is False meaning baseline mode is in-use. Its usage is as follows: options = { \"frame_jpeg_progressive\" : True } #Progressive JPEG encoding enabled. Bare-Minimum Usage with Performance Enhancements \u00b6 Let's re-implement our previous Bare-Minimum usage example with these Performance Enhancing Attributes \u27b6 for speeding up the output. Running Programmatically \u00b6 You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: If you want see output on different machine on the same network, then you need to note down the IP-address of host system. Finally you need to replace this address (along with selected port) on the target machine's browser. # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear # various performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , } # initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () which can be accessed on any browser on the network at http://localhost:8000/ . Running from Terminal \u00b6 You can also access and run WebGear Server directly from the terminal commandline. The following command will run a WebGear VideoStreamer server at http://localhost:8000/ : Make sure your PYTHON_PATH is set to python 3.6+ versions only. If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes. python3 -m vidgear.gears.asyncio --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"frame_jpeg_quality\": 80, \"frame_jpeg_optimize\": True, \"frame_jpeg_progressive\": False}' which can also be accessed on any browser on the network at http://localhost:8000/ . Advanced Usage from Terminal You can run python3 - m vidgear . gears - h help command to see all the advanced settings, as follows: If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes as shown in this example . usage: python -m vidgear.gears.asyncio [ -h ] [ -s SOURCE ] [ -ep ENABLEPICAMERA ] [ -S STABILIZE ] [ -cn CAMERA_NUM ] [ -yt stream_mode ] [ -b BACKEND ] [ -cs COLORSPACE ] [ -r RESOLUTION ] [ -f FRAMERATE ] [ -td TIME_DELAY ] [ -ip IPADDRESS ] [ -pt PORT ] [ -l LOGGING ] [ -op OPTIONS ] Runs WebGear VideoStreaming Server through terminal. optional arguments: -h, --help show this help message and exit -s SOURCE, --source SOURCE Path to input source for CamGear API. -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA Sets the flag to access PiGear ( if True ) or otherwise CamGear API respectively. -S STABILIZE, --stabilize STABILIZE Enables/disables real-time video stabilization. -cn CAMERA_NUM, --camera_num CAMERA_NUM Sets the camera module index that will be used by PiGear API. -yt stream_mode, --stream_mode stream_mode Enables YouTube Mode in CamGear API. -b BACKEND, --backend BACKEND Sets the backend of the video source in CamGear API. -cs COLORSPACE, --colorspace COLORSPACE Sets the colorspace of the output video stream. -r RESOLUTION, --resolution RESOLUTION Sets the resolution ( width,height ) for camera module in PiGear API. -f FRAMERATE, --framerate FRAMERATE Sets the framerate for camera module in PiGear API. -td TIME_DELAY, --time_delay TIME_DELAY Sets the time delay ( in seconds ) before start reading the frames. -ip IPADDRESS, --ipaddress IPADDRESS Uvicorn binds the socket to this ipaddress. -pt PORT, --port PORT Uvicorn binds the socket to this port. -l LOGGING, --logging LOGGING Enables/disables error logging, essential for debugging. -op OPTIONS, --options OPTIONS Sets the parameters supported by APIs ( whichever being accessed ) to the input videostream, But make sure to wrap your dict value in single or double quotes.","title":"Usage Examples"},{"location":"gears/webgear/usage/#webgear-api-usage-examples","text":"","title":"WebGear API Usage Examples:"},{"location":"gears/webgear/usage/#requirements","text":"","title":"Requirements"},{"location":"gears/webgear/usage/#installation-with-asyncio-support","text":"WebGear API is the part of asyncio package of VidGear, thereby you need to install VidGear with asyncio support as follows: pip install vidgear [ asyncio ]","title":"Installation with Asyncio Support"},{"location":"gears/webgear/usage/#asgi-server","text":"You'll also need to install an ASGI Server to run following WebGear usage examples, and by default WebGear ships the state-of-the-art uvicorn Server. But you can also use other ASGI server such as daphne , or hypercorn with it.","title":"ASGI Server"},{"location":"gears/webgear/usage/#performance-enhancements","text":"WebGear provides certain performance enhancing attributes for its option dictionary parameter to cope with performance-throttling. Performance Enhancing Attributes frame_size_reduction : (int/float) This attribute controls the size reduction(in percentage) of the frame to be streamed on Server. Its value has the most significant effect on WebGear performance: More its value, smaller will be frame size and faster will be live streaming. The value defaults to 20 , and must be no higher than 90 (fastest, max compression, Barely Visible frame-size) and no lower than 0 (slowest, no compression, Original frame-size) . Its recommended value is between 40~60 . Its usage is as follows: options = { \"frame_size_reduction\" : 50 } #frame-size will be reduced by 50% Various Encoding Parameters: In WebGear API, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG ) compression format, in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows: frame_jpeg_quality : (int) It controls the JPEG encoder quality. Its value varies from 0 to 100 (the higher is the better quality but performance will be lower). Its default value is 95 . Its usage is as follows: options = { \"frame_jpeg_quality\" : 80 } #JPEG will be encoded at 80% quality. frame_jpeg_optimize : (bool) It enables various JPEG compression optimizations such as Chroma sub-sampling, Quantization table, etc. These optimizations based on JPEG libs which are used while compiling OpenCV binaries, and recent versions of OpenCV uses TurboJPEG library , which is highly recommended for performance. Its default value is False . Its usage is as follows: options = { \"frame_jpeg_optimize\" : True } #JPEG optimizations are enabled. frame_jpeg_progressive : (bool) It enables Progressive JPEG encoding instead of the Baseline . Progressive Mode, displays an image in such a way that it shows a blurry/low-quality photo in its entirety, and then becomes clearer as the image downloads, whereas in Baseline Mode, an image created using the JPEG compression algorithm that will start to display the image as the data is made available, line by line. Progressive Mode, can drastically improve the performance in WebGear but at the expense of additional CPU load, thereby suitable for powerful systems only. Its default value is False meaning baseline mode is in-use. Its usage is as follows: options = { \"frame_jpeg_progressive\" : True } #Progressive JPEG encoding enabled.","title":"Performance Enhancements"},{"location":"gears/webgear/usage/#bare-minimum-usage-with-performance-enhancements","text":"Let's re-implement our previous Bare-Minimum usage example with these Performance Enhancing Attributes \u27b6 for speeding up the output.","title":"Bare-Minimum Usage with Performance Enhancements"},{"location":"gears/webgear/usage/#running-programmatically","text":"You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows: If you want see output on different machine on the same network, then you need to note down the IP-address of host system. Finally you need to replace this address (along with selected port) on the target machine's browser. # import required libraries import uvicorn from vidgear.gears.asyncio import WebGear # various performance tweaks options = { \"frame_size_reduction\" : 40 , \"frame_jpeg_quality\" : 80 , \"frame_jpeg_optimize\" : True , \"frame_jpeg_progressive\" : False , } # initialize WebGear app web = WebGear ( source = \"foo.mp4\" , logging = True , ** options ) # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = \"localhost\" , port = 8000 ) # close app safely web . shutdown () which can be accessed on any browser on the network at http://localhost:8000/ .","title":"Running Programmatically"},{"location":"gears/webgear/usage/#running-from-terminal","text":"You can also access and run WebGear Server directly from the terminal commandline. The following command will run a WebGear VideoStreamer server at http://localhost:8000/ : Make sure your PYTHON_PATH is set to python 3.6+ versions only. If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes. python3 -m vidgear.gears.asyncio --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"frame_jpeg_quality\": 80, \"frame_jpeg_optimize\": True, \"frame_jpeg_progressive\": False}' which can also be accessed on any browser on the network at http://localhost:8000/ . Advanced Usage from Terminal You can run python3 - m vidgear . gears - h help command to see all the advanced settings, as follows: If you're using --options/-op flag, then kindly wrap your dictionary value in single '' quotes as shown in this example . usage: python -m vidgear.gears.asyncio [ -h ] [ -s SOURCE ] [ -ep ENABLEPICAMERA ] [ -S STABILIZE ] [ -cn CAMERA_NUM ] [ -yt stream_mode ] [ -b BACKEND ] [ -cs COLORSPACE ] [ -r RESOLUTION ] [ -f FRAMERATE ] [ -td TIME_DELAY ] [ -ip IPADDRESS ] [ -pt PORT ] [ -l LOGGING ] [ -op OPTIONS ] Runs WebGear VideoStreaming Server through terminal. optional arguments: -h, --help show this help message and exit -s SOURCE, --source SOURCE Path to input source for CamGear API. -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA Sets the flag to access PiGear ( if True ) or otherwise CamGear API respectively. -S STABILIZE, --stabilize STABILIZE Enables/disables real-time video stabilization. -cn CAMERA_NUM, --camera_num CAMERA_NUM Sets the camera module index that will be used by PiGear API. -yt stream_mode, --stream_mode stream_mode Enables YouTube Mode in CamGear API. -b BACKEND, --backend BACKEND Sets the backend of the video source in CamGear API. -cs COLORSPACE, --colorspace COLORSPACE Sets the colorspace of the output video stream. -r RESOLUTION, --resolution RESOLUTION Sets the resolution ( width,height ) for camera module in PiGear API. -f FRAMERATE, --framerate FRAMERATE Sets the framerate for camera module in PiGear API. -td TIME_DELAY, --time_delay TIME_DELAY Sets the time delay ( in seconds ) before start reading the frames. -ip IPADDRESS, --ipaddress IPADDRESS Uvicorn binds the socket to this ipaddress. -pt PORT, --port PORT Uvicorn binds the socket to this port. -l LOGGING, --logging LOGGING Enables/disables error logging, essential for debugging. -op OPTIONS, --options OPTIONS Sets the parameters supported by APIs ( whichever being accessed ) to the input videostream, But make sure to wrap your dict value in single or double quotes.","title":"Running from Terminal"},{"location":"gears/writegear/introduction/","text":"WriteGear API \u00b6 WriteGear API generalized workflow Overview \u00b6 WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data. WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg , a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specification (such as bitrate, codec, framerate, resolution, subtitles, etc. ) . It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch) and Multiplexing Video-Audio with real-time frames in way fewer lines of code. Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc ) without relying on any third-party API. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression. \u2009 Modes of Operation \u00b6 WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. \u2009 Importing \u00b6 You can import WriteGear API in your program as follows: from vidgear.gears import WriteGear","title":"Introduction"},{"location":"gears/writegear/introduction/#writegear-api","text":"WriteGear API generalized workflow","title":"WriteGear API"},{"location":"gears/writegear/introduction/#overview","text":"WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data. WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg , a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specification (such as bitrate, codec, framerate, resolution, subtitles, etc. ) . It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch) and Multiplexing Video-Audio with real-time frames in way fewer lines of code. Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc ) without relying on any third-party API. In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression.","title":"Overview"},{"location":"gears/writegear/introduction/#modes-of-operation","text":"WriteGear primarily operates in following modes: Compression Mode : In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. Non-Compression Mode : In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. \u2009 Helpful Tips If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6 It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Modes of Operation"},{"location":"gears/writegear/introduction/#importing","text":"You can import WriteGear API in your program as follows: from vidgear.gears import WriteGear","title":"Importing"},{"location":"gears/writegear/compression/overview/","text":"WriteGear API: Compression Mode \u00b6 WriteGear API's Compression Mode generalized workflow Overview \u00b6 When compression_mode parameter is enabled (.i.e compression_mode = True), WriteGear API provides a complete, flexible & robust wrapper around FFmpeg to encode lossless & compressed multimedia files. This mode can process real-time video frames into a lossless compressed format with any suitable setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, and much more in just a few easy lines of code. It can also perform complex tasks such as Live-Streaming (such as for Twitch) , multiplexing video with audio in real-time (see this usage example ) while handling all errors robustly. Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . In Compression Mode, you can speed up the execution time by disabling logging (.i.e logging = False ), and by tweaking output_params parameter values (for e.g. using '-preset: ultrafast' in case of 'libx264' encoder). Look into FFmpeg docs \u27b6 for such hacks. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors. Custom FFmpeg Commands in WriteGear API \u00b6 WriteGear API now provides the execute_ffmpeg_cmd Function in Compression Mode, that enables the user to pass any custom CLI commands as an input to its internal FFmpeg Pipeline by formating it as a list. This function opens endless possibilities of exploiting any FFmpeg supported parameter within WriteGear, without relying on a third-party library/API to do the same, and while doing that it robustly handles all errors/warnings quietly. A complete guide on execute_ffmpeg_cmd Function can be found here \u27b6","title":"Overview"},{"location":"gears/writegear/compression/overview/#writegear-api-compression-mode","text":"WriteGear API's Compression Mode generalized workflow","title":"WriteGear API: Compression Mode"},{"location":"gears/writegear/compression/overview/#overview","text":"When compression_mode parameter is enabled (.i.e compression_mode = True), WriteGear API provides a complete, flexible & robust wrapper around FFmpeg to encode lossless & compressed multimedia files. This mode can process real-time video frames into a lossless compressed format with any suitable setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, and much more in just a few easy lines of code. It can also perform complex tasks such as Live-Streaming (such as for Twitch) , multiplexing video with audio in real-time (see this usage example ) while handling all errors robustly. Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . In Compression Mode, you can speed up the execution time by disabling logging (.i.e logging = False ), and by tweaking output_params parameter values (for e.g. using '-preset: ultrafast' in case of 'libx264' encoder). Look into FFmpeg docs \u27b6 for such hacks. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/writegear/compression/overview/#custom-ffmpeg-commands-in-writegear-api","text":"WriteGear API now provides the execute_ffmpeg_cmd Function in Compression Mode, that enables the user to pass any custom CLI commands as an input to its internal FFmpeg Pipeline by formating it as a list. This function opens endless possibilities of exploiting any FFmpeg supported parameter within WriteGear, without relying on a third-party library/API to do the same, and while doing that it robustly handles all errors/warnings quietly. A complete guide on execute_ffmpeg_cmd Function can be found here \u27b6","title":"Custom FFmpeg Commands in WriteGear API"},{"location":"gears/writegear/compression/params/","text":"WriteGear API Parameters: Compression Mode \u00b6 output_filename \u00b6 This parameter sets the valid filename/path/URL for the video output. Warning WriteGear API will throw ValueError if output_filename provided is empty or invalid. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer Make sure to provide valid filename with valid file-extension based on the encoder in use. URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for building a Video-Streaming Server with FFmpeg in WriteGear API. For example, you can stream on a rtmp protocol URL as follows: writer = WriteGear ( output_filename = 'rtmp://localhost/live/test' ) #Define writer compression_mode \u00b6 This parameter selects the WriteGear's Primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding files/streams. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = True ) custom_ffmpeg \u00b6 This parameter assigns the custom path/directory where the custom FFmpeg executables are located in Compression Mode only. Compression Mode Behavior on Windows In Compression Mode, if a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then WriteGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # if ffmpeg executables are located at \"/foo/foo1/FFmpeg\" WriteGear ( output_filename = 'output.mp4' , custom_ffmpeg = \"/foo/foo1/FFmpeg\" ) output_params \u00b6 This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly for encoding in Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and encoders for compression mode discussed below: Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u00b6 FFmpeg Parameters: All parameters based on selected encoder in use, are supported, and can be passed as dictionary attributes in output_param . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: DO NOT provide additional video-source with -i FFmpeg parameter in output_params , otherwise it will interfere with frame you input later and it will break things! Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } Special Internal Parameters: In addition to FFmpeg parameters, WriteGear API also supports some Special Parameters to tweak its internal properties. These parameters are discussed below: -ffmpeg_download_path (string) : sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: output_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" -input_framerate (float/int) : sets the constant framerate of the output. It can be used as follows: output_params = { \"-input_framerate\" : 60.0 } # set the constant framerate to 60fps Its usage example can be found here \u27b6 -output_dimensions (tuple/list) : sets the custom dimensions( size/resolution ) of the output video (otherwise input video-frame size will be used) . Its value can either be a tuple => (width,height) or a list => [width, height] , Its usage is as follows: output_params = { \"-output_dimensions\" : ( 1280 , 720 )} #to produce a 1280x720 resolution/scale output video * -clones (list) : sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Its usage is as follows: output_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} -disable_force_termination (bool) : sets a special flag to disable the default forced-termination behaviour in WriteGear API when -i FFmpeg parameter is used (For more details, see issue: #149 ) . Its usage is as follows: output_params = { \"-disable_force_termination\" : True } # disable the default forced-termination behaviour Supported Encoders \u00b6 All the encoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"Parameters"},{"location":"gears/writegear/compression/params/#writegear-api-parameters-compression-mode","text":"","title":"WriteGear API Parameters: Compression Mode"},{"location":"gears/writegear/compression/params/#output_filename","text":"This parameter sets the valid filename/path/URL for the video output. Warning WriteGear API will throw ValueError if output_filename provided is empty or invalid. Data-Type: String Usage: Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer Make sure to provide valid filename with valid file-extension based on the encoder in use. URL : Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command ffmpeg -protocols ) only. This is useful for building a Video-Streaming Server with FFmpeg in WriteGear API. For example, you can stream on a rtmp protocol URL as follows: writer = WriteGear ( output_filename = 'rtmp://localhost/live/test' ) #Define writer","title":"output_filename"},{"location":"gears/writegear/compression/params/#compression_mode","text":"This parameter selects the WriteGear's Primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding files/streams. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = True )","title":"compression_mode"},{"location":"gears/writegear/compression/params/#custom_ffmpeg","text":"This parameter assigns the custom path/directory where the custom FFmpeg executables are located in Compression Mode only. Compression Mode Behavior on Windows In Compression Mode, if a custom FFmpeg executable's path | directory is not provided through custom_ffmpeg parameter on Windows machine, then WriteGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . Data-Type: String Default Value: Its default value is None . Usage: # if ffmpeg executables are located at \"/foo/foo1/FFmpeg\" WriteGear ( output_filename = 'output.mp4' , custom_ffmpeg = \"/foo/foo1/FFmpeg\" )","title":"custom_ffmpeg"},{"location":"gears/writegear/compression/params/#output_params","text":"This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly for encoding in Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and encoders for compression mode discussed below: Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Data-Type: Dictionary Default Value: Its default value is {} .","title":"output_params"},{"location":"gears/writegear/compression/params/#supported-parameters","text":"FFmpeg Parameters: All parameters based on selected encoder in use, are supported, and can be passed as dictionary attributes in output_param . For example, for using libx264 encoder to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows: DO NOT provide additional video-source with -i FFmpeg parameter in output_params , otherwise it will interfere with frame you input later and it will break things! Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" , \"-tune\" : \"zerolatency\" } Special Internal Parameters: In addition to FFmpeg parameters, WriteGear API also supports some Special Parameters to tweak its internal properties. These parameters are discussed below: -ffmpeg_download_path (string) : sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: output_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" -input_framerate (float/int) : sets the constant framerate of the output. It can be used as follows: output_params = { \"-input_framerate\" : 60.0 } # set the constant framerate to 60fps Its usage example can be found here \u27b6 -output_dimensions (tuple/list) : sets the custom dimensions( size/resolution ) of the output video (otherwise input video-frame size will be used) . Its value can either be a tuple => (width,height) or a list => [width, height] , Its usage is as follows: output_params = { \"-output_dimensions\" : ( 1280 , 720 )} #to produce a 1280x720 resolution/scale output video * -clones (list) : sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue ) as list only. Its usage is as follows: output_params = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} -disable_force_termination (bool) : sets a special flag to disable the default forced-termination behaviour in WriteGear API when -i FFmpeg parameter is used (For more details, see issue: #149 ) . Its usage is as follows: output_params = { \"-disable_force_termination\" : True } # disable the default forced-termination behaviour","title":"Supported Parameters"},{"location":"gears/writegear/compression/params/#supported-encoders","text":"All the encoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal: ffmpeg -encoders # use `ffmpeg.exe -encoders` on windows","title":"Supported Encoders"},{"location":"gears/writegear/compression/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"logging"},{"location":"gears/writegear/compression/usage/","text":"WriteGear API Usage Examples: Compression Mode \u00b6 Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities in Compression Mode. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . DO NOT feed frames with different dimensions or channels to WriteGear, otherwise WriteGear will exit with ValueError . DO NOT provide additional video-source with -i FFmpeg parameter in output_params , otherwise it will interfere with frame you input later, and it will break things! Heavy resolution multimedia files take time to render which can last up to 0.1-1 seconds . Kindly wait till the WriteGear API terminates itself, and DO NOT try to kill the process instead. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior. Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with WriteGear API in Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode in RGB Mode \u00b6 In Compression Mode, WriteGear API contains rgb_mode boolean parameter for RGB Mode, which when enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) . This mode makes WriteGear directly compatible with libraries that only supports RGB format. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # simulating RGB frame for example frame_rgb = frame [:, :, :: - 1 ] # writing RGB frame to writer writer . write ( frame_rgb , rgb_mode = True ) # activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with controlled FrameRate \u00b6 WriteGear API provides -input_framerate attribute for its options dictionary parameter in Compression Mode, which allow us to control/set the constant framerate of the output video. Advanced Tip for setting constant framerate If -input_framerate attribute doesn't works for you, then define it in conjunction with another -r FFmpeg parameter as attribute: # set output constant framerate to (say 60 fps) output_params = { \"-input_framerate\" : 60 , \"-r\" : 60 } # assign that to WriteGear writer = WriteGear ( output_filename = \"out.mp4\" , logging = True , ** output_params ) But make sure you MUST set value of -r and -input_framerate parameter less than or equal to your input source framerate. In this code we will retrieve framerate from video stream, and set it as -input_framerate attribute for option parameter in WriteGear API: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter output_params = { \"-input_framerate\" : stream . framerate } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode for Streaming URLs \u00b6 In Compression Mode, WriteGear can make complex job look easy with FFmpeg. It also allows any URLs (as output) for network streaming with its output_filename parameter. In this example, let's stream Live Camera Feed directly to Twitch! This example assume you already have a Twitch Account for publishing video. Make sure to change Twitch Stream Key with yours in following code before running! # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg optimizing parameters for your writer output_params = { \"-preset:v\" : \"veryfast\" , \"-g\" : 60 , \"-keyint_min\" : 60 , \"-sc_threshold\" : 0 , \"-bufsize\" : \"2500k\" , \"-f\" : \"flv\" , } # [WARNING] Change your Twitch Stream Key here: TWITCH_KEY = \"live_XXXXXXXXXX~XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" # Define writer with defined parameters and writer = WriteGear ( output_filename = \"rtmp://live.twitch.tv/app/ {} \" . format ( TWITCH_KEY ), logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with Hardware encoders \u00b6 By default, WriteGear API uses libx264 encoder for encoding its output files in Compression Mode. But you can easily change encoder to your suitable supported encoder by passing -vcodec FFmpeg parameter as an attribute in its output_param dictionary parameter. In addition to this, you can also specify the additional properties/features of your system's GPU easily. User Discretion Advised This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg parameters for your writer output_params = { \"-vcodec\" : \"h264_vaapi\" , \"-vaapi_device\" : \"/dev/dri/renderD128\" , \"-vf\" : \"format=nv12,hwupload\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Compression Mode with OpenCV \u00b6 You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close () Using Compression Mode with Live Audio Input \u00b6 In Compression Mode, WriteGear API allows us to exploit almost all FFmpeg supported parameters that you can think of, in its Compression Mode. Hence, processing, encoding, and combining audio with video is pretty much straightforward. Example Assumptions You're running are Linux machine. You already have appropriate audio & video drivers and softwares installed on your machine. Locate your Sound Card Remember to locate your Sound Card before running this example: Note down the Sound Card value using arecord -L command on the your Linux terminal. It may be similar to this plughw:CARD=CAMERA,DEV=0 Tips The useful audio input options for ALSA input are -ar ( audio sample rate ) and -ac ( audio channels ). Specifying audio sampling rate/frequency will force the audio card to record the audio at that specified rate. Usually the default value is \"44100\" (Hz) but \"48000\" (Hz) works, so chose wisely. Specifying audio channels will force the audio card to record the audio as mono, stereo or even 2.1, and 5.1( if supported by your audio card ). Usually the default value is \"1\" (mono) for Mic input and \"2\" (stereo) for Line-In input. Kindly go through FFmpeg docs for more of such options. In this example code, we will merge the audio from a Audio Source (for e.g. Webcam inbuilt mic) to the frames of a Video Source (for e.g external webcam) , and save this data as a compressed video file, all in real time: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer output_params = { \"-thread_queue_size\" : \"512\" , \"-f\" : \"alsa\" , \"-ac\" : \"1\" , \"-ar\" : \"48000\" , \"-i\" : \"plughw:CARD=CAMERA,DEV=0\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/writegear/compression/usage/#writegear-api-usage-examples-compression-mode","text":"Important Information WriteGear MUST requires FFmpeg executables for its Compression capabilities in Compression Mode. Follow these dedicated Installation Instructions \u27b6 for its installation. In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . DO NOT feed frames with different dimensions or channels to WriteGear, otherwise WriteGear will exit with ValueError . DO NOT provide additional video-source with -i FFmpeg parameter in output_params , otherwise it will interfere with frame you input later, and it will break things! Heavy resolution multimedia files take time to render which can last up to 0.1-1 seconds . Kindly wait till the WriteGear API terminates itself, and DO NOT try to kill the process instead. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior.","title":"WriteGear API Usage Examples: Compression Mode"},{"location":"gears/writegear/compression/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with WriteGear API in Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Bare-Minimum Usage"},{"location":"gears/writegear/compression/usage/#using-compression-mode-in-rgb-mode","text":"In Compression Mode, WriteGear API contains rgb_mode boolean parameter for RGB Mode, which when enabled (i.e. rgb_mode=True ) , specifies that incoming frames are of RGB format (instead of default BGR format) . This mode makes WriteGear directly compatible with libraries that only supports RGB format. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # Define writer with default parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # simulating RGB frame for example frame_rgb = frame [:, :, :: - 1 ] # writing RGB frame to writer writer . write ( frame_rgb , rgb_mode = True ) # activate RGB Mode # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode in RGB Mode"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-controlled-framerate","text":"WriteGear API provides -input_framerate attribute for its options dictionary parameter in Compression Mode, which allow us to control/set the constant framerate of the output video. Advanced Tip for setting constant framerate If -input_framerate attribute doesn't works for you, then define it in conjunction with another -r FFmpeg parameter as attribute: # set output constant framerate to (say 60 fps) output_params = { \"-input_framerate\" : 60 , \"-r\" : 60 } # assign that to WriteGear writer = WriteGear ( output_filename = \"out.mp4\" , logging = True , ** output_params ) But make sure you MUST set value of -r and -input_framerate parameter less than or equal to your input source framerate. In this code we will retrieve framerate from video stream, and set it as -input_framerate attribute for option parameter in WriteGear API: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = CamGear ( source = 0 ) . start () # retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter output_params = { \"-input_framerate\" : stream . framerate } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if None-type if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with controlled FrameRate"},{"location":"gears/writegear/compression/usage/#using-compression-mode-for-streaming-urls","text":"In Compression Mode, WriteGear can make complex job look easy with FFmpeg. It also allows any URLs (as output) for network streaming with its output_filename parameter. In this example, let's stream Live Camera Feed directly to Twitch! This example assume you already have a Twitch Account for publishing video. Make sure to change Twitch Stream Key with yours in following code before running! # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg optimizing parameters for your writer output_params = { \"-preset:v\" : \"veryfast\" , \"-g\" : 60 , \"-keyint_min\" : 60 , \"-sc_threshold\" : 0 , \"-bufsize\" : \"2500k\" , \"-f\" : \"flv\" , } # [WARNING] Change your Twitch Stream Key here: TWITCH_KEY = \"live_XXXXXXXXXX~XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" # Define writer with defined parameters and writer = WriteGear ( output_filename = \"rtmp://live.twitch.tv/app/ {} \" . format ( TWITCH_KEY ), logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode for Streaming URLs"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-hardware-encoders","text":"By default, WriteGear API uses libx264 encoder for encoding its output files in Compression Mode. But you can easily change encoder to your suitable supported encoder by passing -vcodec FFmpeg parameter as an attribute in its output_param dictionary parameter. In addition to this, you can also specify the additional properties/features of your system's GPU easily. User Discretion Advised This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only. In this example, we will be using h264_vaapi as our hardware encoder and also optionally be specifying our device hardware's location (i.e. '-vaapi_device':'/dev/dri/renderD128' ) and other features such as '-vf':'format=nv12,hwupload' like properties by formatting them as option dictionary parameter's attributes, as follows: Check VAAPI support To use h264_vaapi encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: ffmpeg -hide_banner -encoders | grep vaapi V..... h264_vaapi H.264/AVC ( VAAPI ) ( codec h264 ) V..... hevc_vaapi H.265/HEVC ( VAAPI ) ( codec hevc ) V..... mjpeg_vaapi MJPEG ( VAAPI ) ( codec mjpeg ) V..... mpeg2_vaapi MPEG-2 ( VAAPI ) ( codec mpeg2video ) V..... vp8_vaapi VP8 ( VAAPI ) ( codec vp8 ) # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # Open live webcam video stream on first index(i.e. 0) device stream = CamGear ( source = 0 , logging = True ) . start () # define required FFmpeg parameters for your writer output_params = { \"-vcodec\" : \"h264_vaapi\" , \"-vaapi_device\" : \"/dev/dri/renderD128\" , \"-vf\" : \"format=nv12,hwupload\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with Hardware encoders"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-opencv","text":"You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable (Codec,CRF,preset) FFmpeg parameters for writer output_params = { \"-vcodec\" : \"libx264\" , \"-crf\" : 0 , \"-preset\" : \"fast\" } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Using Compression Mode with OpenCV"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-live-audio-input","text":"In Compression Mode, WriteGear API allows us to exploit almost all FFmpeg supported parameters that you can think of, in its Compression Mode. Hence, processing, encoding, and combining audio with video is pretty much straightforward. Example Assumptions You're running are Linux machine. You already have appropriate audio & video drivers and softwares installed on your machine. Locate your Sound Card Remember to locate your Sound Card before running this example: Note down the Sound Card value using arecord -L command on the your Linux terminal. It may be similar to this plughw:CARD=CAMERA,DEV=0 Tips The useful audio input options for ALSA input are -ar ( audio sample rate ) and -ac ( audio channels ). Specifying audio sampling rate/frequency will force the audio card to record the audio at that specified rate. Usually the default value is \"44100\" (Hz) but \"48000\" (Hz) works, so chose wisely. Specifying audio channels will force the audio card to record the audio as mono, stereo or even 2.1, and 5.1( if supported by your audio card ). Usually the default value is \"1\" (mono) for Mic input and \"2\" (stereo) for Line-In input. Kindly go through FFmpeg docs for more of such options. In this example code, we will merge the audio from a Audio Source (for e.g. Webcam inbuilt mic) to the frames of a Video Source (for e.g external webcam) , and save this data as a compressed video file, all in real time: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # Open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 ) . start () # change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer output_params = { \"-thread_queue_size\" : \"512\" , \"-f\" : \"alsa\" , \"-ac\" : \"1\" , \"-ar\" : \"48000\" , \"-i\" : \"plughw:CARD=CAMERA,DEV=0\" , } # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4 writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Compression Mode with Live Audio Input"},{"location":"gears/writegear/compression/advanced/cciw/","text":"Custom FFmpeg Commands in WriteGear API \u00b6 WriteGear API now provides the execute_ffmpeg_cmd Method in Compression Mode that enables the user to pass any custom FFmpeg CLI (Command Line Interface) commands as input to its internal FFmpeg Pipeline by formating it as a list. This opens endless possibilities of exploiting every FFmpeg params within WriteGear without relying on a third-party API to do the same and while doing that it robustly handles all errors/warnings quietly. Important Information This Feature Requires WriteGear's Compression Mode enabled( compression_mode = True ) . Follow these dedicated Installation Instructions \u27b6 for its installation. Only python list is a valid datatype as input value by this function, otherwise it will throw ValueError . Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all. Features \u00b6 Provides the ability to pass any custom command to WriteGear FFmpeg Pipeline. Compatible with any FFmpeg terminal command. Standalone On-the-fly functioning. Can work without interfering with WriteGear API's Writer pipeline. Minimum hassle and extremely easy to enable and use. Methods \u00b6 execute_ffmpeg_cmd \u00b6 This method allows the users to pass the custom FFmpeg terminal commands as a formatted list directly to WriteGear API's FFmpeg pipeline for processing/execution. Its usage is as follows: # format FFmpeg terminal command `ffmpeg -y -i source_video -acodec copy input_audio.aac` as a list ffmpeg_command = [ \"-y\" , \"-i\" , source_video , \"-acodec\" , \"copy\" , \"input_audio.aac\" ] # execute this list using this function execute_ffmpeg_cmd ( ffmpeg_command ) Usage Examples \u00b6 Following usage examples is just an idea of what can be done with this powerful function. So just Tinker with various FFmpeg parameters/commands yourself and see it working. Also, if you're unable to run any terminal FFmpeg command, then report an issue . Using WriteGear to separate Audio from Video \u00b6 In this example, we will extract and save audio from a URL stream: # import required libraries from vidgear.gears import WriteGear # define a valid url url_to_stream = ( \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\" ) # Define writer with default parameters writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format command to convert stream audio as 'output_audio.aac' as list ffmpeg_command_to_save_audio = [ \"-y\" , \"-i\" , url_to_stream , \"output_audio.aac\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command_to_save_audio ) # safely close writer writer . close () After running this script, You will get the final 'output_audio.aac' audio file. Using WriteGear to merge Audio with Video \u00b6 In this example, we will merge audio with video: Example Assumptions You already have a separate video(i.e 'input-video.mp4' ) and audio(i.e 'input-audio.aac' ) files. Both these Audio and Video files are of equal duration. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 import time # Open input video stream stream = VideoGear ( source = \"input-video.mp4\" ) . start () # set input audio stream path input_audio = \"input-audio.aac\" # define your parameters output_params = { \"-input_framerate\" : stream . framerate } # output framerate must match source framerate # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () # sleep 1 sec as the above video might still be rendering time . sleep ( 1 ) # format FFmpeg command to generate `Output_with_audio.mp4` by merging input_audio in above rendered `Output.mp4` ffmpeg_command = [ \"-y\" , \"-i\" , \"Output.mp4\" , \"-i\" , input_audio , \"-c:v\" , \"copy\" , \"-c:a\" , \"copy\" , \"-map\" , \"0:v:0\" , \"-map\" , \"1:a:0\" , \"-shortest\" , \"Output_with_audio.mp4\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) After running this script, You will get the final 'Output_with_audio.mp4' file with both video and audio merged.","title":"Custom FFmpeg Commands"},{"location":"gears/writegear/compression/advanced/cciw/#custom-ffmpeg-commands-in-writegear-api","text":"WriteGear API now provides the execute_ffmpeg_cmd Method in Compression Mode that enables the user to pass any custom FFmpeg CLI (Command Line Interface) commands as input to its internal FFmpeg Pipeline by formating it as a list. This opens endless possibilities of exploiting every FFmpeg params within WriteGear without relying on a third-party API to do the same and while doing that it robustly handles all errors/warnings quietly. Important Information This Feature Requires WriteGear's Compression Mode enabled( compression_mode = True ) . Follow these dedicated Installation Instructions \u27b6 for its installation. Only python list is a valid datatype as input value by this function, otherwise it will throw ValueError . Kindly read FFmpeg Docs carefully, before passing any values to output_param dictionary parameter. Wrong values may result in undesired Errors or no output at all.","title":"Custom FFmpeg Commands in WriteGear API"},{"location":"gears/writegear/compression/advanced/cciw/#features","text":"Provides the ability to pass any custom command to WriteGear FFmpeg Pipeline. Compatible with any FFmpeg terminal command. Standalone On-the-fly functioning. Can work without interfering with WriteGear API's Writer pipeline. Minimum hassle and extremely easy to enable and use.","title":"Features"},{"location":"gears/writegear/compression/advanced/cciw/#methods","text":"","title":"Methods"},{"location":"gears/writegear/compression/advanced/cciw/#execute_ffmpeg_cmd","text":"This method allows the users to pass the custom FFmpeg terminal commands as a formatted list directly to WriteGear API's FFmpeg pipeline for processing/execution. Its usage is as follows: # format FFmpeg terminal command `ffmpeg -y -i source_video -acodec copy input_audio.aac` as a list ffmpeg_command = [ \"-y\" , \"-i\" , source_video , \"-acodec\" , \"copy\" , \"input_audio.aac\" ] # execute this list using this function execute_ffmpeg_cmd ( ffmpeg_command )","title":"execute_ffmpeg_cmd"},{"location":"gears/writegear/compression/advanced/cciw/#usage-examples","text":"Following usage examples is just an idea of what can be done with this powerful function. So just Tinker with various FFmpeg parameters/commands yourself and see it working. Also, if you're unable to run any terminal FFmpeg command, then report an issue .","title":"Usage Examples"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-separate-audio-from-video","text":"In this example, we will extract and save audio from a URL stream: # import required libraries from vidgear.gears import WriteGear # define a valid url url_to_stream = ( \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\" ) # Define writer with default parameters writer = WriteGear ( output_filename = \"Output.mp4\" , logging = True ) # format command to convert stream audio as 'output_audio.aac' as list ffmpeg_command_to_save_audio = [ \"-y\" , \"-i\" , url_to_stream , \"output_audio.aac\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command_to_save_audio ) # safely close writer writer . close () After running this script, You will get the final 'output_audio.aac' audio file.","title":"Using WriteGear to separate Audio from Video"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-merge-audio-with-video","text":"In this example, we will merge audio with video: Example Assumptions You already have a separate video(i.e 'input-video.mp4' ) and audio(i.e 'input-audio.aac' ) files. Both these Audio and Video files are of equal duration. # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 import time # Open input video stream stream = VideoGear ( source = \"input-video.mp4\" ) . start () # set input audio stream path input_audio = \"input-audio.aac\" # define your parameters output_params = { \"-input_framerate\" : stream . framerate } # output framerate must match source framerate # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () # sleep 1 sec as the above video might still be rendering time . sleep ( 1 ) # format FFmpeg command to generate `Output_with_audio.mp4` by merging input_audio in above rendered `Output.mp4` ffmpeg_command = [ \"-y\" , \"-i\" , \"Output.mp4\" , \"-i\" , input_audio , \"-c:v\" , \"copy\" , \"-c:a\" , \"copy\" , \"-map\" , \"0:v:0\" , \"-map\" , \"1:a:0\" , \"-shortest\" , \"Output_with_audio.mp4\" , ] # `-y` parameter is to overwrite outputfile if exists # execute FFmpeg command writer . execute_ffmpeg_cmd ( ffmpeg_command ) After running this script, You will get the final 'Output_with_audio.mp4' file with both video and audio merged.","title":"Using WriteGear to merge Audio with Video"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/","text":"FFmpeg Installation Instructions \u00b6 WriteGear must requires FFmpeg executables for its Compression capabilities in Compression Mode. You can following machine-specific instructions for its installation: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode . Linux FFmpeg Installation \u00b6 The WriteGear API supports Auto-Detection and Manual Configuration methods on a Linux machine: A. Auto-Detection \u00b6 This is a recommended approach on Linux Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode! Windows FFmpeg Installation \u00b6 The WriteGear API supports Auto-Installation and Manual Configuration methods on Windows systems. A. Auto-Installation \u00b6 This is a recommended approach on Windows Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system WriteGear API auto-generates the required FFmpeg Static Binaries, according to your system specifications, into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, WriteGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then, WriteGear API will auto-disable the Compression Mode and switches to Non-Compression Mode ! B. Manual Configuration \u00b6 Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: http://ffmpeg.zeranoe.com/builds/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode! MacOS FFmpeg Installation \u00b6 The WriteGear API supports Auto-Detection and Manual Configuration methods on a macOS machine. A. Auto-Detection \u00b6 This is a recommended approach on MacOS Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#ffmpeg-installation-instructions","text":"WriteGear must requires FFmpeg executables for its Compression capabilities in Compression Mode. You can following machine-specific instructions for its installation: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it automatically fallbacks to Non-Compression Mode .","title":"FFmpeg Installation Instructions"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#linux-ffmpeg-installation","text":"The WriteGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:","title":"Linux FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection","text":"This is a recommended approach on Linux Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6","title":"A. Auto-Detection"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration","text":"Download: You can also manually download the latest Linux Static Binaries( based on your machine arch(x86/x64) ) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#windows-ffmpeg-installation","text":"The WriteGear API supports Auto-Installation and Manual Configuration methods on Windows systems.","title":"Windows FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-installation","text":"This is a recommended approach on Windows Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on Windows system WriteGear API auto-generates the required FFmpeg Static Binaries, according to your system specifications, into the temporary directory (for e.g. C:\\Temp ) of your machine. Warning The files downloaded to temporary directory (for e.g. C:\\TEMP ) , may get erased if your machine shutdowns/restarts. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through -ffmpeg_download_path parameter. If binaries were found at the specified path, WriteGear automatically skips the auto-installation step. If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then, WriteGear API will auto-disable the Compression Mode and switches to Non-Compression Mode !","title":"A. Auto-Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_1","text":"Download: You can also manually download the latest Windows Static Binaries( based on your machine arch(x86/x64) ) from the link below: Windows Static Binaries: http://ffmpeg.zeranoe.com/builds/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#macos-ffmpeg-installation","text":"The WriteGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.","title":"MacOS FFmpeg Installation"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection_1","text":"This is a recommended approach on MacOS Machines If WriteGear API not receives any input from the user on custom_ffmpeg parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs subprocess python module. Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6","title":"A. Auto-Detection"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_2","text":"Download: You can also manually download the latest macOS Static Binaries( only x64 Binaries ) from the link below: MacOS Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the WriteGear API. If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!","title":"B. Manual Configuration"},{"location":"gears/writegear/non_compression/overview/","text":"WriteGear API: Non-Compression Mode \u00b6 WriteGear API's Non-Compression Mode generalized workflow Overview \u00b6 When compression_mode parameter is disabled (.i.e compression_mode = False), WriteGear API uses basic OpenCV's inbuilt VideoWriter API tools for encoding multimedia files but without compression. This mode provides flexible access to OpenCV's VideoWriter API ,and also supports various parameters available within this API, but lacks the ability to control output quality, compression, and other important features like lossless video compression, audio encoding, etc. which are only available in Compression Mode . Thereby, the resultant output video-file size will be many times larger as compared to Compression Mode. Important Information In case WriteGear API fails to detect valid FFmpeg executables on your system, it will automatically switches to this(Non-Compression) Mode. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/writegear/non_compression/overview/#writegear-api-non-compression-mode","text":"WriteGear API's Non-Compression Mode generalized workflow","title":"WriteGear API: Non-Compression Mode"},{"location":"gears/writegear/non_compression/overview/#overview","text":"When compression_mode parameter is disabled (.i.e compression_mode = False), WriteGear API uses basic OpenCV's inbuilt VideoWriter API tools for encoding multimedia files but without compression. This mode provides flexible access to OpenCV's VideoWriter API ,and also supports various parameters available within this API, but lacks the ability to control output quality, compression, and other important features like lossless video compression, audio encoding, etc. which are only available in Compression Mode . Thereby, the resultant output video-file size will be many times larger as compared to Compression Mode. Important Information In case WriteGear API fails to detect valid FFmpeg executables on your system, it will automatically switches to this(Non-Compression) Mode. It is advised to enable logging( logging = True ) on the first run for easily identifying any runtime errors.","title":"Overview"},{"location":"gears/writegear/non_compression/params/","text":"WriteGear API Parameters: Non-Compression Mode \u00b6 output_filename \u00b6 This parameter sets the valid output Video filename/path for the output video. WriteGear API will throw RuntimeError if output_filename provided is empty or invalid. Data-Type: String Default Value: Its default value is 0 . Usage: Make sure to provide valid filename with valid file-extension based on the encoder in use (default is .mp4 ) . Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer compression_mode \u00b6 This parameter selects the WriteGear's Primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding files/streams. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = False ) custom_ffmpeg \u00b6 Not supported in Non-Compression Mode! output_params \u00b6 This parameter allows us to exploit almost all OpenCV's VideoWriter API supported parameters effortlessly and flexibly for video-encoding in Non-Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and FOURCC codecs for compression mode discussed below: Remember, Non-Compression mode lacks the ability to control output quality and other important features like lossless video compression, audio encoding, etc. , which are available with WriteGear's Compression Mode only. Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u00b6 Non-Compression Mode only gives access to a limited number of parameters, which are as follows: Parameters Description -fourcc 4-character code of codec used to encode frames -fps controls the framerate of output video(Default value: 25) -backend (optional) In case of multiple backends, this parameter allows us to specify VideoWriter API's backends to use. Its valid values are CAP_FFMPEG or CAP_GSTREAMER (if enabled) -color (optional) If it is not zero(0), the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only) -height and -width parameter are no longer supported and are automatically derived from the input frames. Usage: To assign desired parameters in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter as follows: # format parameter as dictionary attribute output_params = { \"-fps\" : 30 } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 . Supported FOURCC Codecs \u00b6 FOURCC is a 4-character code of the codec used to encode video in Non-Compression Mode(OpenCV's VideoWriter API) without compression. List of all supported FOURCC codecs can found here \u27b6 Usage: To select desired FOURCC codec in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter. For example, using MJPG as codec, we can: # format codec as dictionary attribute output_params = { \"-fourcc\" : \"MJPG\" } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 . logging \u00b6 This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"Parameters"},{"location":"gears/writegear/non_compression/params/#writegear-api-parameters-non-compression-mode","text":"","title":"WriteGear API Parameters: Non-Compression Mode"},{"location":"gears/writegear/non_compression/params/#output_filename","text":"This parameter sets the valid output Video filename/path for the output video. WriteGear API will throw RuntimeError if output_filename provided is empty or invalid. Data-Type: String Default Value: Its default value is 0 . Usage: Make sure to provide valid filename with valid file-extension based on the encoder in use (default is .mp4 ) . Its valid input can be one of the following: Path to directory : Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename ( with a default extension i.e. .mp4 ) as follows: writer = WriteGear ( output_filename = '/home/foo/foo1' ) #Define writer Filename (with/without path) : Valid filename( with valid extension ) of the output video file. In case filename is provided without path, then current working directory will be used. writer = WriteGear ( output_filename = 'output.mp4' ) #Define writer","title":"output_filename"},{"location":"gears/writegear/non_compression/params/#compression_mode","text":"This parameter selects the WriteGear's Primary Mode of Operation , i.e. if this parameter is enabled (.i.e compression_mode = True ) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e compression_mode = False ) , the OpenCV's VideoWriter API will be used for encoding files/streams. Data-Type: Boolean Default Value: Its default value is True . Usage: WriteGear ( output_filename = 'output.mp4' , compression_mode = False )","title":"compression_mode"},{"location":"gears/writegear/non_compression/params/#custom_ffmpeg","text":"Not supported in Non-Compression Mode!","title":"custom_ffmpeg"},{"location":"gears/writegear/non_compression/params/#output_params","text":"This parameter allows us to exploit almost all OpenCV's VideoWriter API supported parameters effortlessly and flexibly for video-encoding in Non-Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and FOURCC codecs for compression mode discussed below: Remember, Non-Compression mode lacks the ability to control output quality and other important features like lossless video compression, audio encoding, etc. , which are available with WriteGear's Compression Mode only. Data-Type: Dictionary Default Value: Its default value is {} .","title":"output_params"},{"location":"gears/writegear/non_compression/params/#supported-parameters","text":"Non-Compression Mode only gives access to a limited number of parameters, which are as follows: Parameters Description -fourcc 4-character code of codec used to encode frames -fps controls the framerate of output video(Default value: 25) -backend (optional) In case of multiple backends, this parameter allows us to specify VideoWriter API's backends to use. Its valid values are CAP_FFMPEG or CAP_GSTREAMER (if enabled) -color (optional) If it is not zero(0), the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only) -height and -width parameter are no longer supported and are automatically derived from the input frames. Usage: To assign desired parameters in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter as follows: # format parameter as dictionary attribute output_params = { \"-fps\" : 30 } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 .","title":"Supported Parameters"},{"location":"gears/writegear/non_compression/params/#supported-fourcc-codecs","text":"FOURCC is a 4-character code of the codec used to encode video in Non-Compression Mode(OpenCV's VideoWriter API) without compression. List of all supported FOURCC codecs can found here \u27b6 Usage: To select desired FOURCC codec in Non-Compression Mode, you can format it as dictionary attribute and pass through this( output_params ) parameter. For example, using MJPG as codec, we can: # format codec as dictionary attribute output_params = { \"-fourcc\" : \"MJPG\" } # and then, assign it WriteGear ( output_filename = 'output.mp4' , ** output_params ) Its usage example can be found here \u27b6 .","title":"Supported FOURCC Codecs"},{"location":"gears/writegear/non_compression/params/#logging","text":"This parameter enables logging (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: WriteGear ( output_filename = 'output.mp4' , logging = True )","title":"logging"},{"location":"gears/writegear/non_compression/usage/","text":"WriteGear API Usage Examples: Non-Compression Mode \u00b6 Important Information DO NOT feed frames to WriteGear with different dimensions or channels, or-else WriteGear API will exit with ValueError . In case WriteGear API fails to detect valid FFmpeg executables on your system, it will auto-switches to this(Non-Compression) Mode. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior. Bare-Minimum Usage \u00b6 Following is the bare-minimum code you need to get started with WriteGear API in Non-Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # Define writer with Non-compression mode and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Non-Compression Mode with VideoCapture Gears \u00b6 In Non-Compression mode, WriteGear API provides flexible control over OpenCV's VideoWriter API parameters through its output_param dictionary parameter by formating them as dictionary attributes. Also, WriteGear API can be used in conjunction with any other Gear effortlessly. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 , logging = True ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close () Using Non-Compression Mode with OpenCV \u00b6 You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Non-Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Usage Examples"},{"location":"gears/writegear/non_compression/usage/#writegear-api-usage-examples-non-compression-mode","text":"Important Information DO NOT feed frames to WriteGear with different dimensions or channels, or-else WriteGear API will exit with ValueError . In case WriteGear API fails to detect valid FFmpeg executables on your system, it will auto-switches to this(Non-Compression) Mode. Always use writer.close() at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior.","title":"WriteGear API Usage Examples: Non-Compression Mode"},{"location":"gears/writegear/non_compression/usage/#bare-minimum-usage","text":"Following is the bare-minimum code you need to get started with WriteGear API in Non-Compression Mode: # import required libraries from vidgear.gears import CamGear from vidgear.gears import WriteGear import cv2 # open any valid video stream(for e.g `myvideo.avi` file) stream = CamGear ( source = \"myvideo.avi\" ) . start () # Define writer with Non-compression mode and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # write frame to writer writer . write ( frame ) # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Bare-Minimum Usage"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-videocapture-gears","text":"In Non-Compression mode, WriteGear API provides flexible control over OpenCV's VideoWriter API parameters through its output_param dictionary parameter by formating them as dictionary attributes. Also, WriteGear API can be used in conjunction with any other Gear effortlessly. The complete usage example is as follows: # import required libraries from vidgear.gears import VideoGear from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # open live video stream on webcam at first index(i.e. 0) device stream = VideoGear ( source = 0 , logging = True ) . start () # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () # safely close writer writer . close ()","title":"Using Non-Compression Mode with VideoCapture Gears"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-opencv","text":"You can easily use WriterGear API directly with any Video Processing library( For e.g OpenCV itself ) in Non-Compression Mode. The complete usage example is as follows: # import required libraries from vidgear.gears import WriteGear import cv2 # define suitable tweak parameters for writer output_params = { \"-fourcc\" : \"MJPG\" , \"-fps\" : 30 } # Open suitable video stream, such as webcam on first index(i.e. 0) stream = cv2 . VideoCapture ( 0 ) # Define writer with defined parameters and suitable output filename for e.g. `Output.mp4` writer = WriteGear ( output_filename = \"Output.mp4\" , compression_mode = False , logging = True , ** output_params ) # loop over while True : # read frames from stream ( grabbed , frame ) = stream . read () # check for frame if not grabbed if not grabbed : break # {do something with the frame here} # lets convert frame to gray for this example gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) # write gray frame to writer writer . write ( gray ) # Show output window cv2 . imshow ( \"Output Gray Frame\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . release () # safely close writer writer . close ()","title":"Using Non-Compression Mode with OpenCV"},{"location":"help/camgear_faqs/","text":"CamGear FAQs \u00b6 What is CamGear API and what does it do? \u00b6 Answer: CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. For more info. see CamGear doc \u27b6 . I'm only familiar with OpenCV, how to get started with CamGear API? \u00b6 Answer: First, see Switching from OpenCV , then go through CamGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. How to change OpenCV source backend in CamGear API? \u00b6 Answer: See its Parameters \u27b6 . Its, backend (int) parameter sets the backend of the source. Its value can be for e.g. backend = cv2.CAP_DSHOW in case of Direct Show. How to get framerate of the source in CamGear API? \u00b6 Answer: CamGear's framerate global variable can be used to retrieve framerate of the input video stream. See this example \u27b6 . How to compile OpenCV with GStreamer support? \u00b6 Answer: For compiling OpenCV with GSstreamer( >=v1.0.0 ) support, checkout this tutorial for Linux and Windows OSes, and for MacOS do as follows: Step-1: First Brew install GStreamer: brew update brew install gstreamer gst-plugins-base gst-plugins-good gst-plugins-bad gst-plugins-ugly gst-libav Step-2: Then, Follow this tutorial \u27b6 How to change quality and parameters of YouTube Streams with CamGear? \u00b6 CamGear provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(e.g. youtube-dl ) parameters) with its option dictionary parameter. The complete usage example is as follows: More information on STREAM_RESOLUTION & STREAM_PARAMS attributes can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # specify attributes options = { \"STREAM_RESOLUTION\" : \"720p\" , \"STREAM_PARAMS\" : { \"nocheckcertificate\" : True }} # Add YouTube Video URL as input source (for e.g https://youtu.be/bvetuLwJIkA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/bvetuLwJIkA\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () How to open RSTP network streams with CamGear? \u00b6 You can open any local network stream (such as RTSP) just by providing its URL directly to CamGear's source parameter. The complete usage example is as follows: # import required libraries from vidgear.gears import CamGear import cv2 # open valid network video-stream stream = CamGear ( source = \"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop () How to set Camera Settings with CamGear? \u00b6 Answer: See this usage example \u27b6 . Can I play 4K video with CamGear API? \u00b6 Answer: Yes, you can if your System Hardware supports it. It proven by our playback benchmarking test . How to synchronize between two cameras? \u00b6 Answer: See this issue comment \u27b6 . Can I use GPU to decode the video source? \u00b6 Answer: See this issue comment \u27b6 . Can I perform Deep Learning task with VidGear? \u00b6 Answer: VidGear is a powerful Video Processing library (similar to OpenCV, FFmpeg, etc.) that can read, write, process, send & receive a sequence of video-frames from/to various devices in way easy, flexible, and faster manner. So for Deep Learning or Machine Learning tasks, you have to use a third-party library with VidGear. Being said that, VidGear's high-performance APIs definitely will leverage the overall performance if you're processing video/audio streams in your application along with Deep Learning tasks. Why CamGear is throwing warning that Threaded Queue Mode is disabled? \u00b6 Answer: That's a normal behavior. Please read about Threaded Queue Mode \u27b6","title":"CamGear FAQs"},{"location":"help/camgear_faqs/#camgear-faqs","text":"","title":"CamGear FAQs"},{"location":"help/camgear_faqs/#what-is-camgear-api-and-what-does-it-do","text":"Answer: CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rstp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. For more info. see CamGear doc \u27b6 .","title":"What is CamGear API and what does it do?"},{"location":"help/camgear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-camgear-api","text":"Answer: First, see Switching from OpenCV , then go through CamGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with CamGear API?"},{"location":"help/camgear_faqs/#how-to-change-opencv-source-backend-in-camgear-api","text":"Answer: See its Parameters \u27b6 . Its, backend (int) parameter sets the backend of the source. Its value can be for e.g. backend = cv2.CAP_DSHOW in case of Direct Show.","title":"How to change OpenCV source backend in CamGear API?"},{"location":"help/camgear_faqs/#how-to-get-framerate-of-the-source-in-camgear-api","text":"Answer: CamGear's framerate global variable can be used to retrieve framerate of the input video stream. See this example \u27b6 .","title":"How to get framerate of the source in CamGear API?"},{"location":"help/camgear_faqs/#how-to-compile-opencv-with-gstreamer-support","text":"Answer: For compiling OpenCV with GSstreamer( >=v1.0.0 ) support, checkout this tutorial for Linux and Windows OSes, and for MacOS do as follows: Step-1: First Brew install GStreamer: brew update brew install gstreamer gst-plugins-base gst-plugins-good gst-plugins-bad gst-plugins-ugly gst-libav Step-2: Then, Follow this tutorial \u27b6","title":"How to compile OpenCV with GStreamer support?"},{"location":"help/camgear_faqs/#how-to-change-quality-and-parameters-of-youtube-streams-with-camgear","text":"CamGear provides exclusive attributes STREAM_RESOLUTION (for specifying stream resolution) & STREAM_PARAMS (for specifying underlying API(e.g. youtube-dl ) parameters) with its option dictionary parameter. The complete usage example is as follows: More information on STREAM_RESOLUTION & STREAM_PARAMS attributes can be found here \u27b6 # import required libraries from vidgear.gears import CamGear import cv2 # specify attributes options = { \"STREAM_RESOLUTION\" : \"720p\" , \"STREAM_PARAMS\" : { \"nocheckcertificate\" : True }} # Add YouTube Video URL as input source (for e.g https://youtu.be/bvetuLwJIkA) # and enable Stream Mode (`stream_mode = True`) stream = CamGear ( source = \"https://youtu.be/bvetuLwJIkA\" , stream_mode = True , logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"How to change quality and parameters of YouTube Streams with CamGear?"},{"location":"help/camgear_faqs/#how-to-open-rstp-network-streams-with-camgear","text":"You can open any local network stream (such as RTSP) just by providing its URL directly to CamGear's source parameter. The complete usage example is as follows: # import required libraries from vidgear.gears import CamGear import cv2 # open valid network video-stream stream = CamGear ( source = \"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\" ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"How to open RSTP network streams with CamGear?"},{"location":"help/camgear_faqs/#how-to-set-camera-settings-with-camgear","text":"Answer: See this usage example \u27b6 .","title":"How to set Camera Settings with CamGear?"},{"location":"help/camgear_faqs/#can-i-play-4k-video-with-camgear-api","text":"Answer: Yes, you can if your System Hardware supports it. It proven by our playback benchmarking test .","title":"Can I play 4K video with CamGear API?"},{"location":"help/camgear_faqs/#how-to-synchronize-between-two-cameras","text":"Answer: See this issue comment \u27b6 .","title":"How to synchronize between two cameras?"},{"location":"help/camgear_faqs/#can-i-use-gpu-to-decode-the-video-source","text":"Answer: See this issue comment \u27b6 .","title":"Can I use GPU to decode the video source?"},{"location":"help/camgear_faqs/#can-i-perform-deep-learning-task-with-vidgear","text":"Answer: VidGear is a powerful Video Processing library (similar to OpenCV, FFmpeg, etc.) that can read, write, process, send & receive a sequence of video-frames from/to various devices in way easy, flexible, and faster manner. So for Deep Learning or Machine Learning tasks, you have to use a third-party library with VidGear. Being said that, VidGear's high-performance APIs definitely will leverage the overall performance if you're processing video/audio streams in your application along with Deep Learning tasks.","title":"Can I perform Deep Learning task with VidGear?"},{"location":"help/camgear_faqs/#why-camgear-is-throwing-warning-that-threaded-queue-mode-is-disabled","text":"Answer: That's a normal behavior. Please read about Threaded Queue Mode \u27b6","title":"Why CamGear is throwing warning that Threaded Queue Mode is disabled?"},{"location":"help/general_faqs/","text":"General FAQs \u00b6 \"I'm new to Python Programming or its usage in Computer Vision\", How to use vidgear in my projects? \u00b6 Answer: It's recommended to first go through the following dedicated tutorials/websites thoroughly, and learn how OpenCV-Python works (with examples) : PyImageSearch.com \u27b6 is the best resource for learning OpenCV and its Python implementation. Adrian Rosebrock provides many practical OpenCV techniques with tutorials, code examples, blogs, and books at PyImageSearch.com. I also learned a lot about computer vision methods and various useful techniques. Highly recommended! learnopencv.com \u27b6 Maintained by OpenCV CEO Satya Mallick. This blog is for programmers, hackers, engineers, scientists, students, and self-starters interested in Computer Vision and Machine Learning. There's also the official OpenCV Tutorials \u27b6 , provided by the OpenCV folks themselves. Finally, once done, see Switching from OpenCV \u27b6 and go through our Gears \u27b6 to learn how VidGear works. If you run into any trouble or have any questions, then see getting help \u27b6 \"VidGear is using Multi-threading, but Python is notorious for its poor performance in multithreading?\" \u00b6 Answer: See Threaded-Queue-Mode \u27b6 ModuleNotFoundError: No module named 'vidgear.gears'. 'vidgear' is not a package? \u00b6 Answer: This error means you either have a file named vidgear.py in your python path or you've named your python script vidgear.py . Replace vidgear name with anything else to fix this error. How to log to a file in VidGear? \u00b6 Answer: VidGear provides exclusive VIDGEAR_LOGFILE environment variable to enable logging to a file while logging is enabled (i.e. logging=True ) on respective Gear. You just have to set directory pathname (automatically creates vidgear.log file) or a log file pathname itself as value for this environment variable. This can be done on various platfroms/OSes as follows: Remember enabling this logging to a file will completely disable any output on the terminal. Linux OS # path to file export VIDGEAR_LOGFILE = \" $HOME /foo.log\" # or just directory path # !!! Make sure `foo` already exists !!! export VIDGEAR_LOGFILE = \" $HOME /foo\" Windows OS (Powershell) # path to file $Env:VIDGEAR_LOGFILE = \"D:\\foo.log\" # or just directory path # !!! Make sure `foo` already exists !!! $Env:VIDGEAR_LOGFILE = \"D:\\foo\" OSX/Mac OS # path to file export VIDGEAR_LOGFILE = \" $HOME /foo.log\" # or just directory path # !!! Make sure `foo` already exists !!! export VIDGEAR_LOGFILE = \" $HOME /foo\" Can I ask my question directly without raising an issue? \u00b6 Answer: Yes, please join our Gitter \u27b6 Community channel. How to contribute to VidGear development? \u00b6 Answer: See our Contribution Guidelines \u27b6 What OSes are supported by VidGear? \u00b6 Answer: See Supported Systems \u27b6 What Python versions are supported by VidGear? \u00b6 Answer: See Supported Python legacies \u27b6 Can I include VidGear in my project commercially or not? \u00b6 Answer: Yes, you can, but strictly under the Terms and Conditions given in VidGear License \u27b6 \"I Love using VidGear for my projects\", How can I support it? \u00b6 Answer: See Helping VidGear \u27b6","title":"General FAQs"},{"location":"help/general_faqs/#general-faqs","text":"","title":"General FAQs"},{"location":"help/general_faqs/#im-new-to-python-programming-or-its-usage-in-computer-vision-how-to-use-vidgear-in-my-projects","text":"Answer: It's recommended to first go through the following dedicated tutorials/websites thoroughly, and learn how OpenCV-Python works (with examples) : PyImageSearch.com \u27b6 is the best resource for learning OpenCV and its Python implementation. Adrian Rosebrock provides many practical OpenCV techniques with tutorials, code examples, blogs, and books at PyImageSearch.com. I also learned a lot about computer vision methods and various useful techniques. Highly recommended! learnopencv.com \u27b6 Maintained by OpenCV CEO Satya Mallick. This blog is for programmers, hackers, engineers, scientists, students, and self-starters interested in Computer Vision and Machine Learning. There's also the official OpenCV Tutorials \u27b6 , provided by the OpenCV folks themselves. Finally, once done, see Switching from OpenCV \u27b6 and go through our Gears \u27b6 to learn how VidGear works. If you run into any trouble or have any questions, then see getting help \u27b6","title":"\"I'm new to Python Programming or its usage in Computer Vision\", How to use vidgear in my projects?"},{"location":"help/general_faqs/#vidgear-is-using-multi-threading-but-python-is-notorious-for-its-poor-performance-in-multithreading","text":"Answer: See Threaded-Queue-Mode \u27b6","title":"\"VidGear is using Multi-threading, but Python is notorious for its poor performance in multithreading?\""},{"location":"help/general_faqs/#modulenotfounderror-no-module-named-vidgeargears-vidgear-is-not-a-package","text":"Answer: This error means you either have a file named vidgear.py in your python path or you've named your python script vidgear.py . Replace vidgear name with anything else to fix this error.","title":"ModuleNotFoundError: No module named 'vidgear.gears'. 'vidgear' is not a package?"},{"location":"help/general_faqs/#how-to-log-to-a-file-in-vidgear","text":"Answer: VidGear provides exclusive VIDGEAR_LOGFILE environment variable to enable logging to a file while logging is enabled (i.e. logging=True ) on respective Gear. You just have to set directory pathname (automatically creates vidgear.log file) or a log file pathname itself as value for this environment variable. This can be done on various platfroms/OSes as follows: Remember enabling this logging to a file will completely disable any output on the terminal. Linux OS # path to file export VIDGEAR_LOGFILE = \" $HOME /foo.log\" # or just directory path # !!! Make sure `foo` already exists !!! export VIDGEAR_LOGFILE = \" $HOME /foo\" Windows OS (Powershell) # path to file $Env:VIDGEAR_LOGFILE = \"D:\\foo.log\" # or just directory path # !!! Make sure `foo` already exists !!! $Env:VIDGEAR_LOGFILE = \"D:\\foo\" OSX/Mac OS # path to file export VIDGEAR_LOGFILE = \" $HOME /foo.log\" # or just directory path # !!! Make sure `foo` already exists !!! export VIDGEAR_LOGFILE = \" $HOME /foo\"","title":"How to log to a file in VidGear?"},{"location":"help/general_faqs/#can-i-ask-my-question-directly-without-raising-an-issue","text":"Answer: Yes, please join our Gitter \u27b6 Community channel.","title":"Can I ask my question directly without raising an issue?"},{"location":"help/general_faqs/#how-to-contribute-to-vidgear-development","text":"Answer: See our Contribution Guidelines \u27b6","title":"How to contribute to VidGear development?"},{"location":"help/general_faqs/#what-oses-are-supported-by-vidgear","text":"Answer: See Supported Systems \u27b6","title":"What OSes are supported by VidGear?"},{"location":"help/general_faqs/#what-python-versions-are-supported-by-vidgear","text":"Answer: See Supported Python legacies \u27b6","title":"What Python versions are supported by VidGear?"},{"location":"help/general_faqs/#can-i-include-vidgear-in-my-project-commercially-or-not","text":"Answer: Yes, you can, but strictly under the Terms and Conditions given in VidGear License \u27b6","title":"Can I include VidGear in my project commercially or not?"},{"location":"help/general_faqs/#i-love-using-vidgear-for-my-projects-how-can-i-support-it","text":"Answer: See Helping VidGear \u27b6","title":"\"I Love using VidGear for my projects\", How can I support it?"},{"location":"help/get_help/","text":"Getting Help \u00b6 Courtesy - Pinterest Would you like to get help with VidGear? There are several ways to get help with VidGear: \u2009 Frequently Asked Questions \u00b6 Got a question related to VidGear Working? Checkout our Frequently Asked Questions, a curated list of all the questions with answer that we commonly recieve, for quickly troubleshoot your problems: General FAQs \u27b6 CamGear FAQs \u27b6 PiGear FAQs \u27b6 ScreenGear FAQs \u27b6 StreamGear FAQs \u27b6 WriteGear FAQs \u27b6 NetGear FAQs \u27b6 WebGear FAQs \u27b6 VideoGear FAQs \u27b6 Stabilizer Class FAQs \u27b6 NetGear_Async FAQs \u27b6 \u2009 Join our Gitter Community channel \u00b6 Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems Join and chat on our Gitter Community channel: There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas & information, etc. \u2009 This is what you do when... \u00b6 Got a question or problem? Found a typo? Found a bug? Missing a feature/improvement? \u2009 Reporting an issues \u00b6 Want to report a bug? Suggest a new feature? Before you do, please read our guidelines \u27b6 \u2009 Preparing a Pull Request \u00b6 Interested in contributing to VidGear? Before you do, please read our guidelines \u27b6","title":"Getting Help"},{"location":"help/get_help/#getting-help","text":"Courtesy - Pinterest Would you like to get help with VidGear? There are several ways to get help with VidGear:","title":"Getting Help"},{"location":"help/get_help/#frequently-asked-questions","text":"Got a question related to VidGear Working? Checkout our Frequently Asked Questions, a curated list of all the questions with answer that we commonly recieve, for quickly troubleshoot your problems: General FAQs \u27b6 CamGear FAQs \u27b6 PiGear FAQs \u27b6 ScreenGear FAQs \u27b6 StreamGear FAQs \u27b6 WriteGear FAQs \u27b6 NetGear FAQs \u27b6 WebGear FAQs \u27b6 VideoGear FAQs \u27b6 Stabilizer Class FAQs \u27b6 NetGear_Async FAQs \u27b6","title":"Frequently Asked Questions"},{"location":"help/get_help/#join-our-gitter-community-channel","text":"Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems Join and chat on our Gitter Community channel: There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas & information, etc.","title":"Join our Gitter Community channel"},{"location":"help/get_help/#this-is-what-you-do-when","text":"Got a question or problem? Found a typo? Found a bug? Missing a feature/improvement?","title":"This is what you do when..."},{"location":"help/get_help/#reporting-an-issues","text":"Want to report a bug? Suggest a new feature? Before you do, please read our guidelines \u27b6","title":"Reporting an issues"},{"location":"help/get_help/#preparing-a-pull-request","text":"Interested in contributing to VidGear? Before you do, please read our guidelines \u27b6","title":"Preparing a Pull Request"},{"location":"help/netgear_async_faqs/","text":"NetGear_Async FAQs \u00b6 What is NetGear_Async API and what does it do? \u00b6 Answer: NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. For more info. see NetGear_Async doc \u27b6 How to get started with NetGear_Async API? \u00b6 Answer: See NetGear_Async doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \"NetGear_Async is throwing ModuleNotFoundError on importing\", Why? \u00b6 Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 . What is the key difference between NetGear_Async and NetGear APIs? \u00b6 Answer: NetGear: implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear_Async: is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to high-speed and lag-free video streaming over the network with minimal resource constraints. Key Difference: NetGear_Async is way memory efficient and little faster, but has less features as compared to NetGear API. On the other hand, NetGear API provides many powerful Exclusive Modes , but is way less memory efficient and bit slower than NetGear_Async API. Can I use Multi-Server, Bi-Directional like modes in NetGear_Async? \u00b6 Answer: No, NetGear_Async does NOT provide support for any NetGear's Exclusive modes yet. How to use NetGear_Async with custom Server Source from OpenCV? \u00b6 Answer: See this usage example \u27b6 . Why NetGear_Async is running slow? \u00b6 Answer: Checkout tips suggested in this answer \u27b6","title":"NetGear_Async FAQs"},{"location":"help/netgear_async_faqs/#netgear_async-faqs","text":"","title":"NetGear_Async FAQs"},{"location":"help/netgear_async_faqs/#what-is-netgear_async-api-and-what-does-it-do","text":"Answer: NetGear_Async is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. For more info. see NetGear_Async doc \u27b6","title":"What is NetGear_Async API and what does it do?"},{"location":"help/netgear_async_faqs/#how-to-get-started-with-netgear_async-api","text":"Answer: See NetGear_Async doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with NetGear_Async API?"},{"location":"help/netgear_async_faqs/#netgear_async-is-throwing-modulenotfounderror-on-importing-why","text":"Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 .","title":"\"NetGear_Async is throwing ModuleNotFoundError on importing\", Why?"},{"location":"help/netgear_async_faqs/#what-is-the-key-difference-between-netgear_async-and-netgear-apis","text":"Answer: NetGear: implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. NetGear_Async: is an asyncio videoframe messaging framework, built on zmq.asyncio , and powered by high-performance asyncio event loop called uvloop to high-speed and lag-free video streaming over the network with minimal resource constraints. Key Difference: NetGear_Async is way memory efficient and little faster, but has less features as compared to NetGear API. On the other hand, NetGear API provides many powerful Exclusive Modes , but is way less memory efficient and bit slower than NetGear_Async API.","title":"What is the key difference between NetGear_Async and NetGear APIs?"},{"location":"help/netgear_async_faqs/#can-i-use-multi-server-bi-directional-like-modes-in-netgear_async","text":"Answer: No, NetGear_Async does NOT provide support for any NetGear's Exclusive modes yet.","title":"Can I use Multi-Server, Bi-Directional like modes in NetGear_Async?"},{"location":"help/netgear_async_faqs/#how-to-use-netgear_async-with-custom-server-source-from-opencv","text":"Answer: See this usage example \u27b6 .","title":"How to use NetGear_Async with custom Server Source from OpenCV?"},{"location":"help/netgear_async_faqs/#why-netgear_async-is-running-slow","text":"Answer: Checkout tips suggested in this answer \u27b6","title":"Why NetGear_Async is running slow?"},{"location":"help/netgear_faqs/","text":"NetGear FAQs \u00b6 What is NetGear API and what does it do? \u00b6 Answer: NetGear is exclusively designed to transfer video frames & data synchronously (Pair & Request/Reply) as well as asynchronously (Publish/Subscribe) between various interconnecting systems over the network in real-time. For more info. see NetGear doc \u27b6 How to get started with NetGear API? \u00b6 Answer: See NetGear doc \u27b6 . Still in doubt, then discuss on Gitter \u27b6 Community channel. What Exclusive Modes are compatible with each other in NetGear API? \u00b6 Here's the compatibility chart for NetGear's Exclusive Modes : Exclusive Modes Multi-Servers Multi-Clients Secure Bidirectional Multi-Servers - No (throws error) Yes No (disables it) Multi-Clients No (throws error) - Yes No (disables it) Secure Yes Yes - Yes Bidirectional No (disabled) No (disabled) Yes - Which compression format is the fastest for NetGear API? \u00b6 Answer: According to an answer , the time varies differently for different encoding/decoding format as follows: Encoding format Time taken (in milliseconds) bmp 20-40 jpg 50-70 png 200-250 Despite bmp being the fasted, using jpg is more suitable for encoding, since highly-optimized libjpeg-turbo library is now a part of OpenCV binaries. But you can choose whatever suits you. Why NetGear is running slow? \u00b6 Answer: Here are few tips to troubleshoot performance on your machine: Update ZMQ to latest: Update your pyzmq lib as follows: sudo pip3 install -U pyzmq Install testing branch: The testing branch may contain many latest performance updates, which are not yet merged into master branch. Therefore, you can try them earlier, by installing testing branch directly \u27b6 . Use PUB/SUB pattern if you're live streaming : Try different pattern values, as each of them suits different settings. For example, you can use its Publisher/Subscriber pattern (i.e. pattern=2 ) for asynchronous high-speed transmission over real-time streams, and it works faster than other synchronous patterns for this scenario. Use Wired connection instead of Wireless connection : Remember typical 802.11g Wireless has a theoretical maximum of 54Mbps. Typical wired 10/100/1000 Ethernet has a theoretical maximum of 100 Gbps. So in theory wired is faster. However, these speeds are only on your local network. So chose your network configuration wisely. Compress your image/frame before transmission: Try Frame Encoding/Decoding Compression capabilities for NetGear API \u27b6 . Reduce Frame Size: Use VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance (see this usage example \u27b6 ) . Remember, sending large HQ video-frames may required more network bandwidth and packet size, which can lead to additional latency! Systematically, check for Hardware/Network Issues \u27b6 Finally, if nothing works then, checkout NetGear_Async API \u27b6 How to send data along with frames in Multi-Servers and Multi-Clients Modes? \u00b6 Answer: See Multi-Servers usage example \u27b6 and Multi-Clients usage example \u27b6 How to use enable Encryption and Authentication in NetGear API? \u00b6 Answer: See its Secure Mode doc \u27b6 . How to send custom data along with frames bidirectionally in NetGear API? \u00b6 Answer: See its Bidirectional Mode doc \u27b6 . Are there any side-effect of sending data with frames? \u00b6 Answer: Yes, it may lead to additional LATENCY depending upon the size/amount of the data being transferred. User discretion is advised. How can I compress frames before sending them to Client(s) in NetGear API? \u00b6 Answer: See Frame Compression doc \u27b6 Why NetGear API not working correctly? \u00b6 Answer: First, carefully go through NetGear doc \u27b6 that contains detailed information. Also, checkout PyZmq Docs \u27b6 for its various settings/parameters. If still it doesn't work for you, then let us know on Gitter \u27b6","title":"NetGear FAQs"},{"location":"help/netgear_faqs/#netgear-faqs","text":"","title":"NetGear FAQs"},{"location":"help/netgear_faqs/#what-is-netgear-api-and-what-does-it-do","text":"Answer: NetGear is exclusively designed to transfer video frames & data synchronously (Pair & Request/Reply) as well as asynchronously (Publish/Subscribe) between various interconnecting systems over the network in real-time. For more info. see NetGear doc \u27b6","title":"What is NetGear API and what does it do?"},{"location":"help/netgear_faqs/#how-to-get-started-with-netgear-api","text":"Answer: See NetGear doc \u27b6 . Still in doubt, then discuss on Gitter \u27b6 Community channel.","title":"How to get started with NetGear API?"},{"location":"help/netgear_faqs/#what-exclusive-modes-are-compatible-with-each-other-in-netgear-api","text":"Here's the compatibility chart for NetGear's Exclusive Modes : Exclusive Modes Multi-Servers Multi-Clients Secure Bidirectional Multi-Servers - No (throws error) Yes No (disables it) Multi-Clients No (throws error) - Yes No (disables it) Secure Yes Yes - Yes Bidirectional No (disabled) No (disabled) Yes -","title":"What Exclusive Modes are compatible with each other in NetGear API?"},{"location":"help/netgear_faqs/#which-compression-format-is-the-fastest-for-netgear-api","text":"Answer: According to an answer , the time varies differently for different encoding/decoding format as follows: Encoding format Time taken (in milliseconds) bmp 20-40 jpg 50-70 png 200-250 Despite bmp being the fasted, using jpg is more suitable for encoding, since highly-optimized libjpeg-turbo library is now a part of OpenCV binaries. But you can choose whatever suits you.","title":"Which compression format is the fastest for NetGear API?"},{"location":"help/netgear_faqs/#why-netgear-is-running-slow","text":"Answer: Here are few tips to troubleshoot performance on your machine: Update ZMQ to latest: Update your pyzmq lib as follows: sudo pip3 install -U pyzmq Install testing branch: The testing branch may contain many latest performance updates, which are not yet merged into master branch. Therefore, you can try them earlier, by installing testing branch directly \u27b6 . Use PUB/SUB pattern if you're live streaming : Try different pattern values, as each of them suits different settings. For example, you can use its Publisher/Subscriber pattern (i.e. pattern=2 ) for asynchronous high-speed transmission over real-time streams, and it works faster than other synchronous patterns for this scenario. Use Wired connection instead of Wireless connection : Remember typical 802.11g Wireless has a theoretical maximum of 54Mbps. Typical wired 10/100/1000 Ethernet has a theoretical maximum of 100 Gbps. So in theory wired is faster. However, these speeds are only on your local network. So chose your network configuration wisely. Compress your image/frame before transmission: Try Frame Encoding/Decoding Compression capabilities for NetGear API \u27b6 . Reduce Frame Size: Use VidGear's real-time Frame-Size Reducer ( reducer ) method for reducing frame-size on-the-go for additional performance (see this usage example \u27b6 ) . Remember, sending large HQ video-frames may required more network bandwidth and packet size, which can lead to additional latency! Systematically, check for Hardware/Network Issues \u27b6 Finally, if nothing works then, checkout NetGear_Async API \u27b6","title":"Why NetGear is running slow?"},{"location":"help/netgear_faqs/#how-to-send-data-along-with-frames-in-multi-servers-and-multi-clients-modes","text":"Answer: See Multi-Servers usage example \u27b6 and Multi-Clients usage example \u27b6","title":"How to send data along with frames in Multi-Servers and Multi-Clients Modes?"},{"location":"help/netgear_faqs/#how-to-use-enable-encryption-and-authentication-in-netgear-api","text":"Answer: See its Secure Mode doc \u27b6 .","title":"How to use enable Encryption and Authentication in NetGear API?"},{"location":"help/netgear_faqs/#how-to-send-custom-data-along-with-frames-bidirectionally-in-netgear-api","text":"Answer: See its Bidirectional Mode doc \u27b6 .","title":"How to send custom data along with frames bidirectionally in NetGear API?"},{"location":"help/netgear_faqs/#are-there-any-side-effect-of-sending-data-with-frames","text":"Answer: Yes, it may lead to additional LATENCY depending upon the size/amount of the data being transferred. User discretion is advised.","title":"Are there any side-effect of sending data with frames?"},{"location":"help/netgear_faqs/#how-can-i-compress-frames-before-sending-them-to-clients-in-netgear-api","text":"Answer: See Frame Compression doc \u27b6","title":"How can I compress frames before sending them to Client(s) in NetGear API?"},{"location":"help/netgear_faqs/#why-netgear-api-not-working-correctly","text":"Answer: First, carefully go through NetGear doc \u27b6 that contains detailed information. Also, checkout PyZmq Docs \u27b6 for its various settings/parameters. If still it doesn't work for you, then let us know on Gitter \u27b6","title":"Why NetGear API not working correctly?"},{"location":"help/pigear_faqs/","text":"PiGear FAQs \u00b6 What is PiGear API and what does it do? \u00b6 Answer: PiGear is similar to CamGear but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module ). For more info. see PiGear doc \u27b6 I'm only familiar with OpenCV, how to get started with PiGear API? \u00b6 Answer: First, see Switching from OpenCV , then go through PiGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. Why my camera module is not detected by PiGear? \u00b6 Answer: Make sure to enable Raspberry Pi hardware-specific settings \u27b6 before using PiGear. Also, recheck/change your Camera Module's ribbon-cable and Camera Module itself, if it damaged or got broken somehow. How to select camera index on Pi Compute IO board with two Cameras attached? \u00b6 Answer: See PiGear's camera_num parameter \u27b6 Why PiGear is throwing SystemError ? \u00b6 Answer: This means your Raspberry Pi CSI ribbon-cable is not connected properly to your Camera Module, or damaged, or even both. How to assign picamera settings for Camera Module with PiGear? \u00b6 Answer: See this usage example \u27b6 \"Video output is too dark with PiGear\", Why? \u00b6 Answer: Seems like the settings are wrong. Kindly see picamera docs for available parameters, and look for parameters are sensor_mode , shutter_speed and exposure_mode , try changing those values. Also, maybe your framerate value is too high. Try lowering it. How to change picamera settings for Camera Module at runtime? \u00b6 Answer: You can use stream global parameter in PiGear to feed any picamera setting at runtime. See following sample usage example: In this example we will set initial Camera Module's brightness value 80 , and will change it 50 when z key is pressed at runtime. # import required libraries from vidgear.gears import PiGear import cv2 # initial parameters options = { \"brightness\" : 80 } # set brightness to 80 # open pi video stream with default parameters stream = PiGear ( logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # check for 'z' key if pressed if key == ord ( \"z\" ): # change brightness to 50 stream . stream . brightness = 50 # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"PiGear FAQs"},{"location":"help/pigear_faqs/#pigear-faqs","text":"","title":"PiGear FAQs"},{"location":"help/pigear_faqs/#what-is-pigear-api-and-what-does-it-do","text":"Answer: PiGear is similar to CamGear but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module ). For more info. see PiGear doc \u27b6","title":"What is PiGear API and what does it do?"},{"location":"help/pigear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-pigear-api","text":"Answer: First, see Switching from OpenCV , then go through PiGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with PiGear API?"},{"location":"help/pigear_faqs/#why-my-camera-module-is-not-detected-by-pigear","text":"Answer: Make sure to enable Raspberry Pi hardware-specific settings \u27b6 before using PiGear. Also, recheck/change your Camera Module's ribbon-cable and Camera Module itself, if it damaged or got broken somehow.","title":"Why my camera module is not detected by PiGear?"},{"location":"help/pigear_faqs/#how-to-select-camera-index-on-pi-compute-io-board-with-two-cameras-attached","text":"Answer: See PiGear's camera_num parameter \u27b6","title":"How to select camera index on Pi Compute IO board with two Cameras attached?"},{"location":"help/pigear_faqs/#why-pigear-is-throwing-systemerror","text":"Answer: This means your Raspberry Pi CSI ribbon-cable is not connected properly to your Camera Module, or damaged, or even both.","title":"Why PiGear is throwing SystemError?"},{"location":"help/pigear_faqs/#how-to-assign-picamera-settings-for-camera-module-with-pigear","text":"Answer: See this usage example \u27b6","title":"How to assign picamera settings for Camera Module with PiGear?"},{"location":"help/pigear_faqs/#video-output-is-too-dark-with-pigear-why","text":"Answer: Seems like the settings are wrong. Kindly see picamera docs for available parameters, and look for parameters are sensor_mode , shutter_speed and exposure_mode , try changing those values. Also, maybe your framerate value is too high. Try lowering it.","title":"\"Video output is too dark with PiGear\", Why?"},{"location":"help/pigear_faqs/#how-to-change-picamera-settings-for-camera-module-at-runtime","text":"Answer: You can use stream global parameter in PiGear to feed any picamera setting at runtime. See following sample usage example: In this example we will set initial Camera Module's brightness value 80 , and will change it 50 when z key is pressed at runtime. # import required libraries from vidgear.gears import PiGear import cv2 # initial parameters options = { \"brightness\" : 80 } # set brightness to 80 # open pi video stream with default parameters stream = PiGear ( logging = True , ** options ) . start () # loop over while True : # read frames from stream frame = stream . read () # check for frame if Nonetype if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output Frame\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # check for 'z' key if pressed if key == ord ( \"z\" ): # change brightness to 50 stream . stream . brightness = 50 # close output window cv2 . destroyAllWindows () # safely close video stream stream . stop ()","title":"How to change picamera settings for Camera Module at runtime?"},{"location":"help/screengear_faqs/","text":"ScreenGear FAQs \u00b6 What is ScreenGear API and what does it do? \u00b6 Answer: ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. For more info. see ScreenGear doc \u27b6 I'm only familiar with OpenCV, how to get started with PiGear API? \u00b6 Answer: First, see Switching from OpenCV , then go through ScreenGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. ScreenGear is Slow? \u00b6 Answer: This maybe due to selected backend for ScreenGear API is not compatibile with your machine. See this usage example to change backend \u27b6 . Try different backends, and select which works the best for your machine. How to define area on screen to record with ScreenGear? \u00b6 Answer: See this usage example \u27b6 How to record video from all connected screens? \u00b6 Answer: See ScreenGear's monitor parameter that sets the index of the monitor to grab a frame from. If its value is -1 , it will record from all monitors. More information can be found here \u27b6","title":"ScreenGear FAQs"},{"location":"help/screengear_faqs/#screengear-faqs","text":"","title":"ScreenGear FAQs"},{"location":"help/screengear_faqs/#what-is-screengear-api-and-what-does-it-do","text":"Answer: ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. For more info. see ScreenGear doc \u27b6","title":"What is ScreenGear API and what does it do?"},{"location":"help/screengear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-pigear-api","text":"Answer: First, see Switching from OpenCV , then go through ScreenGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with PiGear API?"},{"location":"help/screengear_faqs/#screengear-is-slow","text":"Answer: This maybe due to selected backend for ScreenGear API is not compatibile with your machine. See this usage example to change backend \u27b6 . Try different backends, and select which works the best for your machine.","title":"ScreenGear is Slow?"},{"location":"help/screengear_faqs/#how-to-define-area-on-screen-to-record-with-screengear","text":"Answer: See this usage example \u27b6","title":"How to define area on screen to record with ScreenGear?"},{"location":"help/screengear_faqs/#how-to-record-video-from-all-connected-screens","text":"Answer: See ScreenGear's monitor parameter that sets the index of the monitor to grab a frame from. If its value is -1 , it will record from all monitors. More information can be found here \u27b6","title":"How to record video from all connected screens?"},{"location":"help/stabilizer_faqs/","text":"Stabilizer Class FAQs \u00b6 What is Stabilizer Class and what does it do? \u00b6 Answer: Stabilizer Class is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. For more info. see Stabilizer Class doc \u27b6 How much latency you would typically expect with Stabilizer Class? \u00b6 Answer: The stabilizer will be Slower for High-Quality videos-frames. Try reducing frames size (Use reducer() method) before feeding them for reducing latency. Also, see smoothing_radius parameter of Stabilizer class that handles the quality of stabilization at the expense of latency and sudden panning. The larger its value, the less will be panning, more will be latency, and vice-versa. How to remove black borders in output video after stabilizing it? \u00b6 Answer: See crop_n_zoom parameter of Stabilizer class, that enables the feature, where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the feature available in Adobe AfterEffects) . It works in conjunction with the border_size parameter, i.e. when this parameter is enabled border_size will be used for cropping border instead of making them. Its default value is False . Can I use Stabilizer directly with OpenCV? \u00b6 Answer: Yes, see this usage example \u27b6 . Why stabilization is not working properly for my video? \u00b6 Answer: The Stabilizer may not perform well against High-frequency jitter in video. But,you can check if increasing smoothing_radius parameter value helps but it will add latency too.","title":"Stabilizer Class FAQs"},{"location":"help/stabilizer_faqs/#stabilizer-class-faqs","text":"","title":"Stabilizer Class FAQs"},{"location":"help/stabilizer_faqs/#what-is-stabilizer-class-and-what-does-it-do","text":"Answer: Stabilizer Class is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. For more info. see Stabilizer Class doc \u27b6","title":"What is Stabilizer Class and what does it do?"},{"location":"help/stabilizer_faqs/#how-much-latency-you-would-typically-expect-with-stabilizer-class","text":"Answer: The stabilizer will be Slower for High-Quality videos-frames. Try reducing frames size (Use reducer() method) before feeding them for reducing latency. Also, see smoothing_radius parameter of Stabilizer class that handles the quality of stabilization at the expense of latency and sudden panning. The larger its value, the less will be panning, more will be latency, and vice-versa.","title":"How much latency you would typically expect with Stabilizer Class?"},{"location":"help/stabilizer_faqs/#how-to-remove-black-borders-in-output-video-after-stabilizing-it","text":"Answer: See crop_n_zoom parameter of Stabilizer class, that enables the feature, where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the feature available in Adobe AfterEffects) . It works in conjunction with the border_size parameter, i.e. when this parameter is enabled border_size will be used for cropping border instead of making them. Its default value is False .","title":"How to remove black borders in output video after stabilizing it?"},{"location":"help/stabilizer_faqs/#can-i-use-stabilizer-directly-with-opencv","text":"Answer: Yes, see this usage example \u27b6 .","title":"Can I use Stabilizer directly with OpenCV?"},{"location":"help/stabilizer_faqs/#why-stabilization-is-not-working-properly-for-my-video","text":"Answer: The Stabilizer may not perform well against High-frequency jitter in video. But,you can check if increasing smoothing_radius parameter value helps but it will add latency too.","title":"Why stabilization is not working properly for my video?"},{"location":"help/streamgear_faqs/","text":"StreamGear FAQs \u00b6 \u2009 What is StreamGear API and what does it do? \u00b6 Answer: StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. For more info. see StreamGear doc \u27b6 \u2009 How to get started with StreamGear API? \u00b6 Answer: See StreamGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \u2009 What is .mpd file created with StreamGear? \u00b6 Answer: SteamGear also creates a Manifest file (such as MPD in-case of DASH) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session. \u2009 How to play Streaming Assets created with StreamGear API? \u00b6 Answer: You can easily feed Manifest file( .mpd ) to DASH Supported Players Input but sure encoded chunks are present along with it. See this list of recommended players \u27b6 \u2009 What Adaptive Streaming Formats are supported yet? \u00b6 Answer: SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon. \u2009 Is DRM Encryption supported in StreamGear API? \u00b6 Answer: No, DRM Encryption is NOT supported yet. \u2009 How to create additional streams in StreamGear API? \u00b6 Answer: See this example \u27b6 \u2009 How to use StreamGear API with real-time frames? \u00b6 Answer: See Real-time Frames Mode \u27b6 \u2009 How to use StreamGear API with OpenCV? \u00b6 Answer: See this example \u27b6 \u2009 How to use Hardware/GPU encoder for StreamGear trancoding? \u00b6 Answer: See this example \u27b6","title":"StreamGear FAQs"},{"location":"help/streamgear_faqs/#streamgear-faqs","text":"","title":"StreamGear FAQs"},{"location":"help/streamgear_faqs/#what-is-streamgear-api-and-what-does-it-do","text":"Answer: StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. For more info. see StreamGear doc \u27b6","title":"What is StreamGear API and what does it do?"},{"location":"help/streamgear_faqs/#how-to-get-started-with-streamgear-api","text":"Answer: See StreamGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with StreamGear API?"},{"location":"help/streamgear_faqs/#what-is-mpd-file-created-with-streamgear","text":"Answer: SteamGear also creates a Manifest file (such as MPD in-case of DASH) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session.","title":"What is .mpd file created with StreamGear?"},{"location":"help/streamgear_faqs/#how-to-play-streaming-assets-created-with-streamgear-api","text":"Answer: You can easily feed Manifest file( .mpd ) to DASH Supported Players Input but sure encoded chunks are present along with it. See this list of recommended players \u27b6","title":"How to play Streaming Assets created with StreamGear API?"},{"location":"help/streamgear_faqs/#what-adaptive-streaming-formats-are-supported-yet","text":"Answer: SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon.","title":"What Adaptive Streaming Formats are supported yet?"},{"location":"help/streamgear_faqs/#is-drm-encryption-supported-in-streamgear-api","text":"Answer: No, DRM Encryption is NOT supported yet.","title":"Is DRM Encryption supported in StreamGear API?"},{"location":"help/streamgear_faqs/#how-to-create-additional-streams-in-streamgear-api","text":"Answer: See this example \u27b6","title":"How to create additional streams in StreamGear API?"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-real-time-frames","text":"Answer: See Real-time Frames Mode \u27b6","title":"How to use StreamGear API with real-time frames?"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-opencv","text":"Answer: See this example \u27b6","title":"How to use StreamGear API with OpenCV?"},{"location":"help/streamgear_faqs/#how-to-use-hardwaregpu-encoder-for-streamgear-trancoding","text":"Answer: See this example \u27b6","title":"How to use Hardware/GPU encoder for StreamGear trancoding?"},{"location":"help/videogear_faqs/","text":"VideoGear FAQs \u00b6 What is VideoGear API and what does it do? \u00b6 Answer: VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. It also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. For more info. see VideoGear doc \u27b6 What's the need of VideoGear API? \u00b6 Answer: VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum efforts and using way fewer lines of code. It also serve as backend for other powerful APIs, such WebGear and NetGear_Async . Which APIs are accessible with VideoGear API? \u00b6 Answer: VideoGear provided an internal access to both CamGear and PiGear APIs and their parameters, also it contains wrapper around Video Stabilizer class. Can we access WriteGear API or NetGear API too with VideoGear? \u00b6 Answer: No, only selected VideoCapture APIs (anwsered above) are accessible. Does using VideoGear instead of CamGear API directly, affects performance? \u00b6 Answer: No, there's no difference, as VideoGear just a high-level wrapper around CamGear API and without any modifications in-between.","title":"VideoGear FAQs"},{"location":"help/videogear_faqs/#videogear-faqs","text":"","title":"VideoGear FAQs"},{"location":"help/videogear_faqs/#what-is-videogear-api-and-what-does-it-do","text":"Answer: VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. It also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special enablePiCamera boolean flag. For more info. see VideoGear doc \u27b6","title":"What is VideoGear API and what does it do?"},{"location":"help/videogear_faqs/#whats-the-need-of-videogear-api","text":"Answer: VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum efforts and using way fewer lines of code. It also serve as backend for other powerful APIs, such WebGear and NetGear_Async .","title":"What's the need of VideoGear API?"},{"location":"help/videogear_faqs/#which-apis-are-accessible-with-videogear-api","text":"Answer: VideoGear provided an internal access to both CamGear and PiGear APIs and their parameters, also it contains wrapper around Video Stabilizer class.","title":"Which APIs are accessible with VideoGear API?"},{"location":"help/videogear_faqs/#can-we-access-writegear-api-or-netgear-api-too-with-videogear","text":"Answer: No, only selected VideoCapture APIs (anwsered above) are accessible.","title":"Can we access WriteGear API or NetGear API too with VideoGear?"},{"location":"help/videogear_faqs/#does-using-videogear-instead-of-camgear-api-directly-affects-performance","text":"Answer: No, there's no difference, as VideoGear just a high-level wrapper around CamGear API and without any modifications in-between.","title":"Does using VideoGear instead of CamGear API directly, affects performance?"},{"location":"help/webgear_faqs/","text":"WebGear FAQs \u00b6 What is WebGear API and what does it do? \u00b6 Answer: WebGear is as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. For more info. see WebGear doc \u27b6 How to get started with WebGear API? \u00b6 Answer: See WebGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel. \"WebGear is throwing ModuleNotFoundError on importing\", Why? \u00b6 Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 . Can WebGear always need Active Internet Connection? \u00b6 Answer: No, it just need internet only once during Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server or even add your own custom files . For more information see Data-Files Auto-Generation WorkFlow \u27b6 Can I manually place default files for WebGear? \u00b6 Answer: Yes, you can either download default files from Github Server , and manually place at default location , OR, you can yourself create the require three critical files (i.e index.html , 404.html & 500.html ) inside templates folder at the default location , thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6 How can I add my custom WebPage to WebGear? \u00b6 Answer: See this usage example \u27b6 . Can I change the default location? \u00b6 Answer: Yes, you can use WebGear's custom_data_location attribute of option parameter in WebGear API, to change default location to somewhere else. Can I delete/rename the WebGear default data? \u00b6 Answer: Yes, but you've to follow these rules \u27b6 What Web browser are supported by WebGear API? \u00b6 Answer: All modern browser with Javascript support are supported by WebGear. If not, then discuss with us on Gitter \u27b6 Community channel. How to send OpenCV frames directly to Webgear Server? \u00b6 Answer: Here's the trick to do it: Step-1: Trigger Auto-Generation Process: Firstly, run any WebGear usage example to trigger the Auto-generation process . Thereby, the default generated files will be saved at default location of your machine. Step-2: Change Webpage address in your own HTML file: then, Go inside templates directory at default location of your machine, and change the line -> 25 on index.html file : From: < p class = \"lead\" >< img src = \"/video\" class = \"img-fluid\" alt = \"Feed\" ></ p > To: < p class = \"lead\" >< img src = \"/my_frames\" class = \"img-fluid\" alt = \"Feed\" ></ p > Step-3: Build your own Frame Producer and add it to route: Now, create a python script code with OpenCV source, as follows: # import necessary libs import uvicorn , asyncio , cv2 from starlette.routing import Route from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer from starlette.responses import StreamingResponse # !!! define your own video source here !!! stream = cv2 . VideoCapture ( \"/home/foo/foo.avi\" ) # initialize WebGear app with same source web = WebGear ( source = \"/home/foo/foo.avi\" , logging = True ) # also enable `logging` for debugging # create your own frame producer async def my_frame_producer (): # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with frame here #reducer frames size if you want more performance otherwise comment this line frame = reducer ( frame , percentage = 50 ) #reduce frame by 50% #handle JPEG encoding encodedImage = cv2 . imencode ( '.jpg' , frame )[ 1 ] . tobytes () #yield frame in byte format yield ( b '--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n ' + encodedImage + b ' \\r\\n ' ) await asyncio . sleep ( 0.01 ) # now create your own streaming response server async def video_server ( scope ): assert scope [ 'type' ] == 'http' return StreamingResponse ( my_frame_producer (), media_type = 'multipart/x-mixed-replace; boundary=frame' ) # add your frame producer # append new route to point your own streaming response server created above web . routes . append ( Route ( '/my_frames' , endpoint = video_server )) #new route for your frames producer will be `{address}/my_frames` # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) # close app safely web . shutdown () Final Step: Finally, you can run the above python script, and see the desire output at address http://localhost:8000/ on your browser.","title":"WebGear FAQs"},{"location":"help/webgear_faqs/#webgear-faqs","text":"","title":"WebGear FAQs"},{"location":"help/webgear_faqs/#what-is-webgear-api-and-what-does-it-do","text":"Answer: WebGear is as powerful Video Streaming Server that transfers live video-frames to any web browser on a network. For more info. see WebGear doc \u27b6","title":"What is WebGear API and what does it do?"},{"location":"help/webgear_faqs/#how-to-get-started-with-webgear-api","text":"Answer: See WebGear doc \u27b6 . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"How to get started with WebGear API?"},{"location":"help/webgear_faqs/#webgear-is-throwing-modulenotfounderror-on-importing-why","text":"Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6 .","title":"\"WebGear is throwing ModuleNotFoundError on importing\", Why?"},{"location":"help/webgear_faqs/#can-webgear-always-need-active-internet-connection","text":"Answer: No, it just need internet only once during Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server or even add your own custom files . For more information see Data-Files Auto-Generation WorkFlow \u27b6","title":"Can WebGear always need Active Internet Connection?"},{"location":"help/webgear_faqs/#can-i-manually-place-default-files-for-webgear","text":"Answer: Yes, you can either download default files from Github Server , and manually place at default location , OR, you can yourself create the require three critical files (i.e index.html , 404.html & 500.html ) inside templates folder at the default location , thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6","title":"Can I manually place default files for WebGear?"},{"location":"help/webgear_faqs/#how-can-i-add-my-custom-webpage-to-webgear","text":"Answer: See this usage example \u27b6 .","title":"How can I add my custom WebPage to WebGear?"},{"location":"help/webgear_faqs/#can-i-change-the-default-location","text":"Answer: Yes, you can use WebGear's custom_data_location attribute of option parameter in WebGear API, to change default location to somewhere else.","title":"Can I change the default location?"},{"location":"help/webgear_faqs/#can-i-deleterename-the-webgear-default-data","text":"Answer: Yes, but you've to follow these rules \u27b6","title":"Can I delete/rename the WebGear default data?"},{"location":"help/webgear_faqs/#what-web-browser-are-supported-by-webgear-api","text":"Answer: All modern browser with Javascript support are supported by WebGear. If not, then discuss with us on Gitter \u27b6 Community channel.","title":"What Web browser are supported by WebGear API?"},{"location":"help/webgear_faqs/#how-to-send-opencv-frames-directly-to-webgear-server","text":"Answer: Here's the trick to do it: Step-1: Trigger Auto-Generation Process: Firstly, run any WebGear usage example to trigger the Auto-generation process . Thereby, the default generated files will be saved at default location of your machine. Step-2: Change Webpage address in your own HTML file: then, Go inside templates directory at default location of your machine, and change the line -> 25 on index.html file : From: < p class = \"lead\" >< img src = \"/video\" class = \"img-fluid\" alt = \"Feed\" ></ p > To: < p class = \"lead\" >< img src = \"/my_frames\" class = \"img-fluid\" alt = \"Feed\" ></ p > Step-3: Build your own Frame Producer and add it to route: Now, create a python script code with OpenCV source, as follows: # import necessary libs import uvicorn , asyncio , cv2 from starlette.routing import Route from vidgear.gears.asyncio import WebGear from vidgear.gears.asyncio.helper import reducer from starlette.responses import StreamingResponse # !!! define your own video source here !!! stream = cv2 . VideoCapture ( \"/home/foo/foo.avi\" ) # initialize WebGear app with same source web = WebGear ( source = \"/home/foo/foo.avi\" , logging = True ) # also enable `logging` for debugging # create your own frame producer async def my_frame_producer (): # loop over frames while True : # read frame from provided source ( grabbed , frame ) = stream . read () # break if NoneType if not grabbed : break # do something with frame here #reducer frames size if you want more performance otherwise comment this line frame = reducer ( frame , percentage = 50 ) #reduce frame by 50% #handle JPEG encoding encodedImage = cv2 . imencode ( '.jpg' , frame )[ 1 ] . tobytes () #yield frame in byte format yield ( b '--frame \\r\\n Content-Type:image/jpeg \\r\\n\\r\\n ' + encodedImage + b ' \\r\\n ' ) await asyncio . sleep ( 0.01 ) # now create your own streaming response server async def video_server ( scope ): assert scope [ 'type' ] == 'http' return StreamingResponse ( my_frame_producer (), media_type = 'multipart/x-mixed-replace; boundary=frame' ) # add your frame producer # append new route to point your own streaming response server created above web . routes . append ( Route ( '/my_frames' , endpoint = video_server )) #new route for your frames producer will be `{address}/my_frames` # run this app on Uvicorn server at address http://localhost:8000/ uvicorn . run ( web (), host = 'localhost' , port = 8000 ) # close app safely web . shutdown () Final Step: Finally, you can run the above python script, and see the desire output at address http://localhost:8000/ on your browser.","title":"How to send OpenCV frames directly to Webgear Server?"},{"location":"help/writegear_faqs/","text":"WriteGear FAQs \u00b6 What is WriteGear API and what does it do? \u00b6 Answer: WriteGear handles various powerful Writer Tools that provide us the freedom to do almost anything imagine with multimedia files. For more info. see WriteGear doc \u27b6 I'm only familiar with OpenCV, how to get started with WriteGear API? \u00b6 Answer: First, see Switching from OpenCV , then go through WriteGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel. Why WriteGear is throwing ValueError ? \u00b6 Answer: WriteGear will exit with ValueError if you feed frames of different dimensions or channels. How to install and configure FFmpeg correctly for WriteGear on my machine? \u00b6 Answer: Follow these Installation Instructions \u27b6 for its installation. Can I use WriteGear directly with OpenCV? \u00b6 Answer: Yes, For Compression Mode: See this usage example \u27b6 . For Non-Compression Mode: See this usage example \u27b6 What FFmpeg's encoders and parameters are supported by WriteGear in compression mode? \u00b6 Answer: See Supported Parameters \u27b6 and Supported encoders \u27b6 What OpenCV's FOURCC and parameters are supported by WriteGear in non-compression mode? \u00b6 Answer: See Supported Parameters \u27b6 and Supported FOURCC \u27b6 . Why this FOURCC is not working for me? \u00b6 Answer: Remember not all the FOURCC and Video extensions are compatible and supported by OpenCV VideoWriter Class. You\u2019ll need to try different combinations of FourCC and file extensions. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error . Can I pass my custom FFmpeg commands directly in WriteGear API? \u00b6 Answer: Yes, See Custom FFmpeg Commands in WriteGear API \u27b6 . How to use specific Hardware Encoder in WriteGear? \u00b6 Answer: See this usage example \u27b6 How to add live audio to WriteGear? \u00b6 Answer: See this doc \u27b6 How to separate and merge audio from/to video? \u00b6 Answer: See these usage examples \u27b6 Can I live stream with WriteGear API? \u00b6 Answer: Yes, See this usage example \u27b6 Why this FFmpeg parameter is not working for me in compression mode? \u00b6 Answer: If some FFmpeg parameter doesn't work for you, then tell us on Gitter \u27b6 , and if that doesn't help, then finally report an issue \u27b6 Why WriteGear is switching to Non-compression Mode, even if it is not enable? \u00b6 Answer: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it will automatically fallback to Non-Compression Mode. Follow Installation Instructions \u27b6 for FFmpeg installation.","title":"WriteGear FAQs"},{"location":"help/writegear_faqs/#writegear-faqs","text":"","title":"WriteGear FAQs"},{"location":"help/writegear_faqs/#what-is-writegear-api-and-what-does-it-do","text":"Answer: WriteGear handles various powerful Writer Tools that provide us the freedom to do almost anything imagine with multimedia files. For more info. see WriteGear doc \u27b6","title":"What is WriteGear API and what does it do?"},{"location":"help/writegear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-writegear-api","text":"Answer: First, see Switching from OpenCV , then go through WriteGear doc . Still in doubt, then ask us on Gitter \u27b6 Community channel.","title":"I'm only familiar with OpenCV, how to get started with WriteGear API?"},{"location":"help/writegear_faqs/#why-writegear-is-throwing-valueerror","text":"Answer: WriteGear will exit with ValueError if you feed frames of different dimensions or channels.","title":"Why WriteGear is throwing ValueError?"},{"location":"help/writegear_faqs/#how-to-install-and-configure-ffmpeg-correctly-for-writegear-on-my-machine","text":"Answer: Follow these Installation Instructions \u27b6 for its installation.","title":"How to install and configure FFmpeg correctly for WriteGear on my machine?"},{"location":"help/writegear_faqs/#can-i-use-writegear-directly-with-opencv","text":"Answer: Yes, For Compression Mode: See this usage example \u27b6 . For Non-Compression Mode: See this usage example \u27b6","title":"Can I use WriteGear directly with OpenCV?"},{"location":"help/writegear_faqs/#what-ffmpegs-encoders-and-parameters-are-supported-by-writegear-in-compression-mode","text":"Answer: See Supported Parameters \u27b6 and Supported encoders \u27b6","title":"What FFmpeg's encoders and parameters are supported by WriteGear in compression mode?"},{"location":"help/writegear_faqs/#what-opencvs-fourcc-and-parameters-are-supported-by-writegear-in-non-compression-mode","text":"Answer: See Supported Parameters \u27b6 and Supported FOURCC \u27b6 .","title":"What OpenCV's FOURCC and parameters are supported by WriteGear in non-compression mode?"},{"location":"help/writegear_faqs/#why-this-fourcc-is-not-working-for-me","text":"Answer: Remember not all the FOURCC and Video extensions are compatible and supported by OpenCV VideoWriter Class. You\u2019ll need to try different combinations of FourCC and file extensions. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error .","title":"Why this FOURCC is not working for me?"},{"location":"help/writegear_faqs/#can-i-pass-my-custom-ffmpeg-commands-directly-in-writegear-api","text":"Answer: Yes, See Custom FFmpeg Commands in WriteGear API \u27b6 .","title":"Can I pass my custom FFmpeg commands directly in WriteGear API?"},{"location":"help/writegear_faqs/#how-to-use-specific-hardware-encoder-in-writegear","text":"Answer: See this usage example \u27b6","title":"How to use specific Hardware Encoder in WriteGear?"},{"location":"help/writegear_faqs/#how-to-add-live-audio-to-writegear","text":"Answer: See this doc \u27b6","title":"How to add live audio to WriteGear?"},{"location":"help/writegear_faqs/#how-to-separate-and-merge-audio-fromto-video","text":"Answer: See these usage examples \u27b6","title":"How to separate and merge audio from/to video?"},{"location":"help/writegear_faqs/#can-i-live-stream-with-writegear-api","text":"Answer: Yes, See this usage example \u27b6","title":"Can I live stream with WriteGear API?"},{"location":"help/writegear_faqs/#why-this-ffmpeg-parameter-is-not-working-for-me-in-compression-mode","text":"Answer: If some FFmpeg parameter doesn't work for you, then tell us on Gitter \u27b6 , and if that doesn't help, then finally report an issue \u27b6","title":"Why this FFmpeg parameter is not working for me in compression mode?"},{"location":"help/writegear_faqs/#why-writegear-is-switching-to-non-compression-mode-even-if-it-is-not-enable","text":"Answer: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled) , it will automatically fallback to Non-Compression Mode. Follow Installation Instructions \u27b6 for FFmpeg installation.","title":"Why WriteGear is switching to Non-compression Mode, even if it is not enable?"},{"location":"installation/pip_install/","text":"Install using pip \u00b6 Best option for quickly getting stable VidGear installed. Prerequisites \u00b6 When installing VidGear with pip, you need to check manually if following dependencies are installed: OpenCV \u00b6 Must require OpenCV(3.0+) python binaries installed for its core functions. You install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux and Raspberry Pi machines manually from its source. pip install -U opencv-python FFmpeg \u00b6 Must require for the video compression and encoding compatibilities within Compression Mode in WriteGear API. FFmpeg Installation Follow this dedicated FFmpeg Installation doc for its installation. Picamera \u00b6 Must Required if you're using Raspberry Pi Camera Modules with its PiGear API. You can easily install it via pip: Make sure to enable Raspberry Pi hardware-specific settings prior to using this library, otherwise it won't work. pip install picamera Uvloop \u00b6 Must required if you're using the NetGear_Async API on a UNIX machine for maximum performance. You can easily install it via pip: uvloop is NOT yet supported on Windows Machines . pip install uvloop Installation \u00b6 Installation is as simple as: Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: python -m pip install vidgear # or with asyncio support python -m pip install vidgear [ asyncio ] If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: python -m pip install --user vidgear # or with asyncio support python -m pip install --user vidgear [ asyncio ] # Install stable release pip install vidgear # Or Install stable release with Asyncio support pip install vidgear [ asyncio ] And if you prefer to install VidGear directly from the repository: pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear # or with asyncio support pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear [ asyncio ] Or you can also download its wheel ( .whl ) package from our releases , and thereby can be installed as follows: pip install vidgear-0.1.7-py3-none-any.whl # or with asyncio support pip install vidgear-0.1.7-py3-none-any.whl [ asyncio ]","title":"Install using pip"},{"location":"installation/pip_install/#install-using-pip","text":"Best option for quickly getting stable VidGear installed.","title":"Install using pip"},{"location":"installation/pip_install/#prerequisites","text":"When installing VidGear with pip, you need to check manually if following dependencies are installed:","title":"Prerequisites"},{"location":"installation/pip_install/#opencv","text":"Must require OpenCV(3.0+) python binaries installed for its core functions. You install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux and Raspberry Pi machines manually from its source. pip install -U opencv-python","title":"OpenCV"},{"location":"installation/pip_install/#ffmpeg","text":"Must require for the video compression and encoding compatibilities within Compression Mode in WriteGear API. FFmpeg Installation Follow this dedicated FFmpeg Installation doc for its installation.","title":"FFmpeg"},{"location":"installation/pip_install/#picamera","text":"Must Required if you're using Raspberry Pi Camera Modules with its PiGear API. You can easily install it via pip: Make sure to enable Raspberry Pi hardware-specific settings prior to using this library, otherwise it won't work. pip install picamera","title":"Picamera"},{"location":"installation/pip_install/#uvloop","text":"Must required if you're using the NetGear_Async API on a UNIX machine for maximum performance. You can easily install it via pip: uvloop is NOT yet supported on Windows Machines . pip install uvloop","title":"Uvloop"},{"location":"installation/pip_install/#installation","text":"Installation is as simple as: Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: python -m pip install vidgear # or with asyncio support python -m pip install vidgear [ asyncio ] If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: python -m pip install --user vidgear # or with asyncio support python -m pip install --user vidgear [ asyncio ] # Install stable release pip install vidgear # Or Install stable release with Asyncio support pip install vidgear [ asyncio ] And if you prefer to install VidGear directly from the repository: pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear # or with asyncio support pip install git+git://github.com/abhiTronix/vidgear@master#egg = vidgear [ asyncio ] Or you can also download its wheel ( .whl ) package from our releases , and thereby can be installed as follows: pip install vidgear-0.1.7-py3-none-any.whl # or with asyncio support pip install vidgear-0.1.7-py3-none-any.whl [ asyncio ]","title":"Installation"},{"location":"installation/source_install/","text":"Install from source \u00b6 Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all dependencies(except FFmpeg). Prerequisites \u00b6 When installing VidGear from source, FFmpeg is the only dependency you need to install manually: What about rest of the dependencies? Any other python dependencies will be automatically installed based on your OS specifications. FFmpeg \u00b6 Must require for the video compression and encoding compatibilities within Compression Mode in WriteGear API. FFmpeg Installation Follow this dedicated FFmpeg Installation doc for its installation. Installation \u00b6 If you want to just install and try out the checkout the latest beta testing branch , you can do so with the following command. This can be useful if you want to provide feedback for a new feature or want to confirm if a bug you have encountered is fixed in the testing branch. DO NOT clone or install development branch, as it is not tested with CI environments and is possibly very unstable or unusable. Windows Installation Install git for windows . Use following commands to clone and install VidGear: # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # install normally python -m pip install . # OR install with asyncio support python - m pip install . [ asyncio ] # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # install normally pip install . # OR install with asyncio support pip install . [ asyncio ] Or just install directly without cloning: pip install git+git://github.com/abhiTronix/vidgear@testing#egg = vidgear # or with asyncio support pip install git+git://github.com/abhiTronix/vidgear@testing#egg = vidgear [ asyncio ]","title":"Install from source"},{"location":"installation/source_install/#install-from-source","text":"Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all dependencies(except FFmpeg).","title":"Install from source"},{"location":"installation/source_install/#prerequisites","text":"When installing VidGear from source, FFmpeg is the only dependency you need to install manually: What about rest of the dependencies? Any other python dependencies will be automatically installed based on your OS specifications.","title":"Prerequisites"},{"location":"installation/source_install/#ffmpeg","text":"Must require for the video compression and encoding compatibilities within Compression Mode in WriteGear API. FFmpeg Installation Follow this dedicated FFmpeg Installation doc for its installation.","title":"FFmpeg"},{"location":"installation/source_install/#installation","text":"If you want to just install and try out the checkout the latest beta testing branch , you can do so with the following command. This can be useful if you want to provide feedback for a new feature or want to confirm if a bug you have encountered is fixed in the testing branch. DO NOT clone or install development branch, as it is not tested with CI environments and is possibly very unstable or unusable. Windows Installation Install git for windows . Use following commands to clone and install VidGear: # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # install normally python -m pip install . # OR install with asyncio support python - m pip install . [ asyncio ] # clone the repository and get inside git clone https://github.com/abhiTronix/vidgear.git && cd vidgear # checkout the latest testing branch git checkout testing # install normally pip install . # OR install with asyncio support pip install . [ asyncio ] Or just install directly without cloning: pip install git+git://github.com/abhiTronix/vidgear@testing#egg = vidgear # or with asyncio support pip install git+git://github.com/abhiTronix/vidgear@testing#egg = vidgear [ asyncio ]","title":"Installation"}]}